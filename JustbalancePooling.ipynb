{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boot/anaconda3/envs/zeyu1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import sys\n",
    "import torch\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from typing import Optional\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data.datapipes import functional_transform\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.datasets import WebKB\n",
    "from torch_geometric.datasets import Actor\n",
    "from torch_geometric.datasets import GNNBenchmarkDataset\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from sklearn.metrics import r2_score\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch.nn import Linear\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "from torch_sparse import spspmm\n",
    "from torch_sparse import coalesce\n",
    "from torch_sparse import eye\n",
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter_add\n",
    "from torch_scatter import scatter_max\n",
    "\n",
    "from torch_scatter import scatter_add, scatter\n",
    "from torch_geometric.nn.inits import uniform\n",
    "from torch_geometric.nn.resolver import activation_resolver\n",
    "from torch_geometric.nn import GCNConv, GATConv, LEConv, SAGEConv, GraphConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.utils import add_remaining_self_loops, to_dense_adj, add_self_loops\n",
    "from typing import Callable, Optional, Union\n",
    "from torch_sparse import coalesce, transpose\n",
    "from torch_scatter import scatter\n",
    "from torch import Tensor\n",
    "\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import math\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn.models.mlp import Linear\n",
    "from torch_geometric.nn.resolver import activation_resolver\n",
    "from torch_geometric.nn import BatchNorm\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_mincut_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "EPS = 1e-15\n",
    "\n",
    "\n",
    "def just_balance_pool(x, adj, s, mask=None, normalize=True):\n",
    "    r\"\"\"The Just Balance pooling operator from the `\"Simplifying Clustering with\n",
    "    Graph Neural Networks\" <https://arxiv.org/abs/2207.08779>`_ paper\n",
    "\n",
    "    .. math::\n",
    "        \\mathbf{X}^{\\prime} &= {\\mathrm{softmax}(\\mathbf{S})}^{\\top} \\cdot\n",
    "        \\mathbf{X}\n",
    "\n",
    "        \\mathbf{A}^{\\prime} &= {\\mathrm{softmax}(\\mathbf{S})}^{\\top} \\cdot\n",
    "        \\mathbf{A} \\cdot \\mathrm{softmax}(\\mathbf{S})\n",
    "\n",
    "    based on dense learned assignments :math:`\\mathbf{S} \\in \\mathbb{R}^{B\n",
    "    \\times N \\times C}`.\n",
    "    Returns the pooled node feature matrix, the coarsened and symmetrically\n",
    "    normalized adjacency matrix and the following auxiliary objective:\n",
    "\n",
    "    .. math::\n",
    "        \\mathcal{L} = - {\\mathrm{Tr}(\\sqrt{\\mathbf{S}^{\\top} \\mathbf{S}})}\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): Node feature tensor :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times N \\times F}`\n",
    "            with batch-size :math:`B`, (maximum) number of nodes :math:`N`\n",
    "            for each graph, and feature dimension :math:`F`.\n",
    "        adj (Tensor): Symmetrically normalized adjacency tensor\n",
    "            :math:`\\mathbf{A} \\in \\mathbb{R}^{B \\times N \\times N}`.\n",
    "        s (Tensor): Assignment tensor :math:`\\mathbf{S} \\in \\mathbb{R}^{B \\times N \\times C}`\n",
    "            with number of clusters :math:`C`. The softmax does not have to be\n",
    "            applied beforehand, since it is executed within this method.\n",
    "        mask (BoolTensor, optional): Mask matrix\n",
    "            :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}` indicating\n",
    "            the valid nodes for each graph. (default: :obj:`None`)\n",
    "\n",
    "    :rtype: (:class:`Tensor`, :class:`Tensor`, :class:`Tensor`,\n",
    "        :class:`Tensor`)\n",
    "    \"\"\"\n",
    "\n",
    "    x = x.unsqueeze(0) if x.dim() == 2 else x\n",
    "    adj = adj.unsqueeze(0) if adj.dim() == 2 else adj\n",
    "    s = s.unsqueeze(0) if s.dim() == 2 else s\n",
    "\n",
    "    (batch_size, num_nodes, _), k = x.size(), s.size(-1)\n",
    "\n",
    "    s = torch.softmax(s, dim=-1)\n",
    "\n",
    "    if mask is not None:\n",
    "        mask = mask.view(batch_size, num_nodes, 1).to(x.dtype)\n",
    "        x, s = x * mask, s * mask\n",
    "\n",
    "    out = torch.matmul(s.transpose(1, 2), x)\n",
    "    out_adj = torch.matmul(torch.matmul(s.transpose(1, 2), adj), s)\n",
    "\n",
    "    # Loss\n",
    "    ss = torch.matmul(s.transpose(1, 2), s)\n",
    "    ss_sqrt = torch.sqrt(ss + EPS)\n",
    "    loss = torch.mean(-_rank3_trace(ss_sqrt))\n",
    "    if normalize:\n",
    "        loss = loss / torch.sqrt(torch.tensor(num_nodes * k))\n",
    "\n",
    "    # Fix and normalize coarsened adjacency matrix.\n",
    "    ind = torch.arange(k, device=out_adj.device)\n",
    "    out_adj[:, ind, ind] = 0\n",
    "    d = torch.einsum('ijk->ij', out_adj)\n",
    "    d = torch.sqrt(d)[:, None] + EPS\n",
    "    out_adj = (out_adj / d) / d.transpose(1, 2)\n",
    "\n",
    "    return out, out_adj, loss\n",
    "\n",
    "\n",
    "def _rank3_trace(x):\n",
    "    return torch.einsum('ijj->i', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROTEINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 152 for seed 42\n",
      "Early stopping at epoch 151 for seed 43\n",
      "Early stopping at epoch 162 for seed 44\n",
      "Average Time: 359.24 seconds\n",
      "Var Time: 1291.91 seconds\n",
      "Average Memory: 2201.33 MB\n",
      "Average Best Val Acc: 0.6787\n",
      "Std Best Test Acc: 0.0297\n",
      "Average Test Acc: 0.6885\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "max_nodes = 700\n",
    "data_path = \"/data/Zeyu/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"PROTEINS\",\n",
    "    transform=T.Compose([T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_justbalance(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        #x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        #x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        #x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_justbalance().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = Net_justbalance().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        #print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCI1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6810, Val Acc: 0.5081, Test Acc: 0.4814\n",
      "Seed: 42, Epoch: 002, Loss: 0.6483, Val Acc: 0.6364, Test Acc: 0.6418\n",
      "Seed: 42, Epoch: 003, Loss: 0.6285, Val Acc: 0.5877, Test Acc: 0.5900\n",
      "Seed: 42, Epoch: 004, Loss: 0.6158, Val Acc: 0.6429, Test Acc: 0.6126\n",
      "Seed: 42, Epoch: 005, Loss: 0.6052, Val Acc: 0.6558, Test Acc: 0.6418\n",
      "Seed: 42, Epoch: 006, Loss: 0.6047, Val Acc: 0.6347, Test Acc: 0.6483\n",
      "Seed: 42, Epoch: 007, Loss: 0.5959, Val Acc: 0.6461, Test Acc: 0.6110\n",
      "Seed: 42, Epoch: 008, Loss: 0.5857, Val Acc: 0.6964, Test Acc: 0.6872\n",
      "Seed: 42, Epoch: 009, Loss: 0.5879, Val Acc: 0.6672, Test Acc: 0.6596\n",
      "Seed: 42, Epoch: 010, Loss: 0.5844, Val Acc: 0.6899, Test Acc: 0.6953\n",
      "Seed: 42, Epoch: 011, Loss: 0.5738, Val Acc: 0.6623, Test Acc: 0.6467\n",
      "Seed: 42, Epoch: 012, Loss: 0.5736, Val Acc: 0.6623, Test Acc: 0.6742\n",
      "Seed: 42, Epoch: 013, Loss: 0.5692, Val Acc: 0.6185, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 014, Loss: 0.5653, Val Acc: 0.6932, Test Acc: 0.6969\n",
      "Seed: 42, Epoch: 015, Loss: 0.5623, Val Acc: 0.6526, Test Acc: 0.6661\n",
      "Seed: 42, Epoch: 016, Loss: 0.5510, Val Acc: 0.7175, Test Acc: 0.7229\n",
      "Seed: 42, Epoch: 017, Loss: 0.5564, Val Acc: 0.7208, Test Acc: 0.6953\n",
      "Seed: 42, Epoch: 018, Loss: 0.5471, Val Acc: 0.7192, Test Acc: 0.7066\n",
      "Seed: 42, Epoch: 019, Loss: 0.5430, Val Acc: 0.6916, Test Acc: 0.6823\n",
      "Seed: 42, Epoch: 020, Loss: 0.5510, Val Acc: 0.7208, Test Acc: 0.7180\n",
      "Seed: 42, Epoch: 021, Loss: 0.5384, Val Acc: 0.6705, Test Acc: 0.6483\n",
      "Seed: 42, Epoch: 022, Loss: 0.5451, Val Acc: 0.7240, Test Acc: 0.7018\n",
      "Seed: 42, Epoch: 023, Loss: 0.5295, Val Acc: 0.7013, Test Acc: 0.7180\n",
      "Seed: 42, Epoch: 024, Loss: 0.5255, Val Acc: 0.7370, Test Acc: 0.7310\n",
      "Seed: 42, Epoch: 025, Loss: 0.5151, Val Acc: 0.6834, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 026, Loss: 0.5154, Val Acc: 0.7451, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 027, Loss: 0.5092, Val Acc: 0.7403, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 028, Loss: 0.5180, Val Acc: 0.6834, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 029, Loss: 0.5091, Val Acc: 0.7354, Test Acc: 0.7261\n",
      "Seed: 42, Epoch: 030, Loss: 0.4989, Val Acc: 0.7029, Test Acc: 0.6823\n",
      "Seed: 42, Epoch: 031, Loss: 0.5116, Val Acc: 0.7175, Test Acc: 0.6710\n",
      "Seed: 42, Epoch: 032, Loss: 0.4995, Val Acc: 0.7013, Test Acc: 0.7002\n",
      "Seed: 42, Epoch: 033, Loss: 0.4957, Val Acc: 0.7208, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 034, Loss: 0.5035, Val Acc: 0.7273, Test Acc: 0.7326\n",
      "Seed: 42, Epoch: 035, Loss: 0.4881, Val Acc: 0.7386, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 036, Loss: 0.5220, Val Acc: 0.7338, Test Acc: 0.7180\n",
      "Seed: 42, Epoch: 037, Loss: 0.4887, Val Acc: 0.7224, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 038, Loss: 0.4923, Val Acc: 0.7516, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 039, Loss: 0.4836, Val Acc: 0.7727, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 040, Loss: 0.4752, Val Acc: 0.7451, Test Acc: 0.7342\n",
      "Seed: 42, Epoch: 041, Loss: 0.4756, Val Acc: 0.7565, Test Acc: 0.7342\n",
      "Seed: 42, Epoch: 042, Loss: 0.4775, Val Acc: 0.6769, Test Acc: 0.6726\n",
      "Seed: 42, Epoch: 043, Loss: 0.4874, Val Acc: 0.7565, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 044, Loss: 0.4679, Val Acc: 0.7029, Test Acc: 0.6921\n",
      "Seed: 42, Epoch: 045, Loss: 0.4718, Val Acc: 0.7468, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 046, Loss: 0.4671, Val Acc: 0.7224, Test Acc: 0.6969\n",
      "Seed: 42, Epoch: 047, Loss: 0.4585, Val Acc: 0.7338, Test Acc: 0.7115\n",
      "Seed: 42, Epoch: 048, Loss: 0.4594, Val Acc: 0.7565, Test Acc: 0.7326\n",
      "Seed: 42, Epoch: 049, Loss: 0.4480, Val Acc: 0.7646, Test Acc: 0.7407\n",
      "Seed: 42, Epoch: 050, Loss: 0.4524, Val Acc: 0.7565, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 051, Loss: 0.4437, Val Acc: 0.7727, Test Acc: 0.7472\n",
      "Seed: 42, Epoch: 052, Loss: 0.4507, Val Acc: 0.7565, Test Acc: 0.7245\n",
      "Seed: 42, Epoch: 053, Loss: 0.4461, Val Acc: 0.7581, Test Acc: 0.7277\n",
      "Seed: 42, Epoch: 054, Loss: 0.4462, Val Acc: 0.7565, Test Acc: 0.7245\n",
      "Seed: 42, Epoch: 055, Loss: 0.4532, Val Acc: 0.7338, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 056, Loss: 0.4371, Val Acc: 0.7776, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 057, Loss: 0.4331, Val Acc: 0.7386, Test Acc: 0.7245\n",
      "Seed: 42, Epoch: 058, Loss: 0.4506, Val Acc: 0.7175, Test Acc: 0.7115\n",
      "Seed: 42, Epoch: 059, Loss: 0.4402, Val Acc: 0.7305, Test Acc: 0.7018\n",
      "Seed: 42, Epoch: 060, Loss: 0.4323, Val Acc: 0.7662, Test Acc: 0.7310\n",
      "Seed: 42, Epoch: 061, Loss: 0.4306, Val Acc: 0.7808, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 062, Loss: 0.4320, Val Acc: 0.7825, Test Acc: 0.7553\n",
      "Seed: 42, Epoch: 063, Loss: 0.4325, Val Acc: 0.7354, Test Acc: 0.6969\n",
      "Seed: 42, Epoch: 064, Loss: 0.4569, Val Acc: 0.7500, Test Acc: 0.7099\n",
      "Seed: 42, Epoch: 065, Loss: 0.4268, Val Acc: 0.7776, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 066, Loss: 0.4494, Val Acc: 0.7305, Test Acc: 0.7277\n",
      "Seed: 42, Epoch: 067, Loss: 0.4326, Val Acc: 0.7776, Test Acc: 0.7553\n",
      "Seed: 42, Epoch: 068, Loss: 0.4125, Val Acc: 0.7354, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 069, Loss: 0.4150, Val Acc: 0.7841, Test Acc: 0.7553\n",
      "Seed: 42, Epoch: 070, Loss: 0.4117, Val Acc: 0.7825, Test Acc: 0.7634\n",
      "Seed: 42, Epoch: 071, Loss: 0.4155, Val Acc: 0.7532, Test Acc: 0.7261\n",
      "Seed: 42, Epoch: 072, Loss: 0.4101, Val Acc: 0.7516, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 073, Loss: 0.4249, Val Acc: 0.7224, Test Acc: 0.7310\n",
      "Seed: 42, Epoch: 074, Loss: 0.4166, Val Acc: 0.7565, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 075, Loss: 0.4215, Val Acc: 0.7825, Test Acc: 0.7407\n",
      "Seed: 42, Epoch: 076, Loss: 0.4026, Val Acc: 0.7549, Test Acc: 0.7131\n",
      "Seed: 42, Epoch: 077, Loss: 0.4058, Val Acc: 0.8003, Test Acc: 0.7553\n",
      "Seed: 42, Epoch: 078, Loss: 0.3974, Val Acc: 0.7305, Test Acc: 0.7229\n",
      "Seed: 42, Epoch: 079, Loss: 0.4043, Val Acc: 0.7273, Test Acc: 0.7569\n",
      "Seed: 42, Epoch: 080, Loss: 0.3889, Val Acc: 0.7971, Test Acc: 0.7553\n",
      "Seed: 42, Epoch: 081, Loss: 0.3847, Val Acc: 0.7727, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 082, Loss: 0.3888, Val Acc: 0.7419, Test Acc: 0.7326\n",
      "Seed: 42, Epoch: 083, Loss: 0.4092, Val Acc: 0.7549, Test Acc: 0.7569\n",
      "Seed: 42, Epoch: 084, Loss: 0.3918, Val Acc: 0.7451, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 085, Loss: 0.3893, Val Acc: 0.7825, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 086, Loss: 0.3918, Val Acc: 0.7727, Test Acc: 0.7342\n",
      "Seed: 42, Epoch: 087, Loss: 0.3895, Val Acc: 0.7857, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 088, Loss: 0.3815, Val Acc: 0.7841, Test Acc: 0.7634\n",
      "Seed: 42, Epoch: 089, Loss: 0.3853, Val Acc: 0.7873, Test Acc: 0.7585\n",
      "Seed: 42, Epoch: 090, Loss: 0.3831, Val Acc: 0.7419, Test Acc: 0.7050\n",
      "Seed: 42, Epoch: 091, Loss: 0.3831, Val Acc: 0.7679, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 092, Loss: 0.3833, Val Acc: 0.7630, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 093, Loss: 0.3869, Val Acc: 0.7500, Test Acc: 0.7407\n",
      "Seed: 42, Epoch: 094, Loss: 0.3857, Val Acc: 0.7630, Test Acc: 0.7536\n",
      "Seed: 42, Epoch: 095, Loss: 0.3832, Val Acc: 0.7484, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 096, Loss: 0.3836, Val Acc: 0.8036, Test Acc: 0.7553\n",
      "Seed: 42, Epoch: 097, Loss: 0.3764, Val Acc: 0.7646, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 098, Loss: 0.3805, Val Acc: 0.7630, Test Acc: 0.7618\n",
      "Seed: 42, Epoch: 099, Loss: 0.3772, Val Acc: 0.7516, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 100, Loss: 0.3712, Val Acc: 0.7808, Test Acc: 0.7326\n",
      "Seed: 42, Epoch: 101, Loss: 0.3623, Val Acc: 0.7938, Test Acc: 0.7634\n",
      "Seed: 42, Epoch: 102, Loss: 0.3743, Val Acc: 0.7792, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 103, Loss: 0.3653, Val Acc: 0.7370, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 104, Loss: 0.3639, Val Acc: 0.7484, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 105, Loss: 0.3705, Val Acc: 0.7679, Test Acc: 0.7553\n",
      "Seed: 42, Epoch: 106, Loss: 0.3829, Val Acc: 0.7386, Test Acc: 0.7342\n",
      "Seed: 42, Epoch: 107, Loss: 0.3803, Val Acc: 0.7581, Test Acc: 0.7277\n",
      "Seed: 42, Epoch: 108, Loss: 0.3820, Val Acc: 0.7760, Test Acc: 0.7699\n",
      "Seed: 42, Epoch: 109, Loss: 0.3699, Val Acc: 0.7419, Test Acc: 0.7147\n",
      "Seed: 42, Epoch: 110, Loss: 0.3578, Val Acc: 0.7890, Test Acc: 0.7666\n",
      "Seed: 42, Epoch: 111, Loss: 0.3558, Val Acc: 0.7451, Test Acc: 0.7310\n",
      "Seed: 42, Epoch: 112, Loss: 0.3627, Val Acc: 0.7565, Test Acc: 0.7131\n",
      "Seed: 42, Epoch: 113, Loss: 0.3743, Val Acc: 0.7808, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 114, Loss: 0.3599, Val Acc: 0.7403, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 115, Loss: 0.3526, Val Acc: 0.7727, Test Acc: 0.7618\n",
      "Seed: 42, Epoch: 116, Loss: 0.3672, Val Acc: 0.7354, Test Acc: 0.7536\n",
      "Seed: 42, Epoch: 117, Loss: 0.3441, Val Acc: 0.7825, Test Acc: 0.8006\n",
      "Seed: 42, Epoch: 118, Loss: 0.3500, Val Acc: 0.7711, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 119, Loss: 0.3497, Val Acc: 0.7679, Test Acc: 0.7536\n",
      "Seed: 42, Epoch: 120, Loss: 0.3462, Val Acc: 0.7435, Test Acc: 0.7634\n",
      "Seed: 42, Epoch: 121, Loss: 0.3634, Val Acc: 0.7646, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 122, Loss: 0.3565, Val Acc: 0.7532, Test Acc: 0.7569\n",
      "Seed: 42, Epoch: 123, Loss: 0.3490, Val Acc: 0.7614, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 124, Loss: 0.3690, Val Acc: 0.7516, Test Acc: 0.7569\n",
      "Seed: 42, Epoch: 125, Loss: 0.3576, Val Acc: 0.7857, Test Acc: 0.7585\n",
      "Seed: 42, Epoch: 126, Loss: 0.3402, Val Acc: 0.7500, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 127, Loss: 0.3478, Val Acc: 0.7386, Test Acc: 0.7229\n",
      "Seed: 42, Epoch: 128, Loss: 0.3490, Val Acc: 0.7484, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 129, Loss: 0.3498, Val Acc: 0.7565, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 130, Loss: 0.3414, Val Acc: 0.7435, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 131, Loss: 0.3399, Val Acc: 0.7760, Test Acc: 0.7618\n",
      "Seed: 42, Epoch: 132, Loss: 0.3367, Val Acc: 0.7744, Test Acc: 0.7618\n",
      "Seed: 42, Epoch: 133, Loss: 0.3338, Val Acc: 0.7792, Test Acc: 0.7585\n",
      "Seed: 42, Epoch: 134, Loss: 0.3253, Val Acc: 0.7532, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 135, Loss: 0.3364, Val Acc: 0.7532, Test Acc: 0.7261\n",
      "Seed: 42, Epoch: 136, Loss: 0.3246, Val Acc: 0.7484, Test Acc: 0.7472\n",
      "Seed: 42, Epoch: 137, Loss: 0.3319, Val Acc: 0.7403, Test Acc: 0.7634\n",
      "Seed: 42, Epoch: 138, Loss: 0.3381, Val Acc: 0.7516, Test Acc: 0.7682\n",
      "Seed: 42, Epoch: 139, Loss: 0.3331, Val Acc: 0.7695, Test Acc: 0.7828\n",
      "Seed: 42, Epoch: 140, Loss: 0.3324, Val Acc: 0.7873, Test Acc: 0.7666\n",
      "Seed: 42, Epoch: 141, Loss: 0.3293, Val Acc: 0.7841, Test Acc: 0.7553\n",
      "Seed: 42, Epoch: 142, Loss: 0.3228, Val Acc: 0.7857, Test Acc: 0.7796\n",
      "Seed: 42, Epoch: 143, Loss: 0.3345, Val Acc: 0.7792, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 144, Loss: 0.3191, Val Acc: 0.7565, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 145, Loss: 0.3324, Val Acc: 0.7403, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 146, Loss: 0.3213, Val Acc: 0.7711, Test Acc: 0.7536\n",
      "Seed: 42, Epoch: 147, Loss: 0.3181, Val Acc: 0.7468, Test Acc: 0.7715\n",
      "Seed: 42, Epoch: 148, Loss: 0.3079, Val Acc: 0.7808, Test Acc: 0.7585\n",
      "Seed: 42, Epoch: 149, Loss: 0.3203, Val Acc: 0.7175, Test Acc: 0.6969\n",
      "Seed: 42, Epoch: 150, Loss: 0.3049, Val Acc: 0.7386, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 151, Loss: 0.3370, Val Acc: 0.7744, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 152, Loss: 0.3333, Val Acc: 0.7808, Test Acc: 0.7666\n",
      "Seed: 42, Epoch: 153, Loss: 0.3098, Val Acc: 0.7727, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 154, Loss: 0.3192, Val Acc: 0.7484, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 155, Loss: 0.3122, Val Acc: 0.7679, Test Acc: 0.7699\n",
      "Seed: 42, Epoch: 156, Loss: 0.3032, Val Acc: 0.7532, Test Acc: 0.7261\n",
      "Seed: 42, Epoch: 157, Loss: 0.3080, Val Acc: 0.8084, Test Acc: 0.7601\n",
      "Seed: 42, Epoch: 158, Loss: 0.3136, Val Acc: 0.7792, Test Acc: 0.7326\n",
      "Seed: 42, Epoch: 159, Loss: 0.3173, Val Acc: 0.7484, Test Acc: 0.7618\n",
      "Seed: 42, Epoch: 160, Loss: 0.3071, Val Acc: 0.7630, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 161, Loss: 0.2978, Val Acc: 0.8003, Test Acc: 0.7715\n",
      "Seed: 42, Epoch: 162, Loss: 0.3064, Val Acc: 0.7370, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 163, Loss: 0.3117, Val Acc: 0.7825, Test Acc: 0.7715\n",
      "Seed: 42, Epoch: 164, Loss: 0.3122, Val Acc: 0.7695, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 165, Loss: 0.2976, Val Acc: 0.7581, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 166, Loss: 0.3031, Val Acc: 0.7841, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 167, Loss: 0.3091, Val Acc: 0.7695, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 168, Loss: 0.2993, Val Acc: 0.7776, Test Acc: 0.7569\n",
      "Seed: 42, Epoch: 169, Loss: 0.2945, Val Acc: 0.7451, Test Acc: 0.7585\n",
      "Seed: 42, Epoch: 170, Loss: 0.2925, Val Acc: 0.7630, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 171, Loss: 0.3040, Val Acc: 0.7565, Test Acc: 0.7407\n",
      "Seed: 42, Epoch: 172, Loss: 0.2871, Val Acc: 0.7727, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 173, Loss: 0.3058, Val Acc: 0.7468, Test Acc: 0.7569\n",
      "Seed: 42, Epoch: 174, Loss: 0.2984, Val Acc: 0.7597, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 175, Loss: 0.3142, Val Acc: 0.7695, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 176, Loss: 0.2907, Val Acc: 0.7500, Test Acc: 0.7245\n",
      "Seed: 42, Epoch: 177, Loss: 0.2980, Val Acc: 0.7646, Test Acc: 0.7682\n",
      "Seed: 42, Epoch: 178, Loss: 0.3099, Val Acc: 0.7711, Test Acc: 0.7618\n",
      "Seed: 42, Epoch: 179, Loss: 0.3018, Val Acc: 0.7597, Test Acc: 0.7731\n",
      "Seed: 42, Epoch: 180, Loss: 0.2875, Val Acc: 0.7646, Test Acc: 0.7585\n",
      "Seed: 42, Epoch: 181, Loss: 0.2790, Val Acc: 0.7711, Test Acc: 0.7553\n",
      "Seed: 42, Epoch: 182, Loss: 0.2773, Val Acc: 0.7532, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 183, Loss: 0.2818, Val Acc: 0.7727, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 184, Loss: 0.2931, Val Acc: 0.7581, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 185, Loss: 0.3012, Val Acc: 0.7744, Test Acc: 0.7553\n",
      "Seed: 42, Epoch: 186, Loss: 0.2847, Val Acc: 0.7711, Test Acc: 0.7407\n",
      "Seed: 42, Epoch: 187, Loss: 0.2953, Val Acc: 0.7435, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 188, Loss: 0.2939, Val Acc: 0.7808, Test Acc: 0.7601\n",
      "Seed: 42, Epoch: 189, Loss: 0.2761, Val Acc: 0.7744, Test Acc: 0.7634\n",
      "Seed: 42, Epoch: 190, Loss: 0.2934, Val Acc: 0.7386, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 191, Loss: 0.2869, Val Acc: 0.7597, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 192, Loss: 0.2821, Val Acc: 0.7500, Test Acc: 0.7618\n",
      "Seed: 42, Epoch: 193, Loss: 0.2799, Val Acc: 0.7808, Test Acc: 0.7731\n",
      "Seed: 42, Epoch: 194, Loss: 0.2826, Val Acc: 0.7435, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 195, Loss: 0.2691, Val Acc: 0.7646, Test Acc: 0.7682\n",
      "Seed: 42, Epoch: 196, Loss: 0.2742, Val Acc: 0.7727, Test Acc: 0.7634\n",
      "Seed: 42, Epoch: 197, Loss: 0.2726, Val Acc: 0.7240, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 198, Loss: 0.2933, Val Acc: 0.7516, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 199, Loss: 0.2787, Val Acc: 0.7516, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 200, Loss: 0.2834, Val Acc: 0.7516, Test Acc: 0.7439\n",
      "Seed: 43, Epoch: 001, Loss: 0.6820, Val Acc: 0.5812, Test Acc: 0.5786\n",
      "Seed: 43, Epoch: 002, Loss: 0.6480, Val Acc: 0.5844, Test Acc: 0.6823\n",
      "Seed: 43, Epoch: 003, Loss: 0.6217, Val Acc: 0.6266, Test Acc: 0.6791\n",
      "Seed: 43, Epoch: 004, Loss: 0.6135, Val Acc: 0.6315, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 005, Loss: 0.6068, Val Acc: 0.5974, Test Acc: 0.5964\n",
      "Seed: 43, Epoch: 006, Loss: 0.5974, Val Acc: 0.6737, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 007, Loss: 0.5890, Val Acc: 0.6445, Test Acc: 0.6840\n",
      "Seed: 43, Epoch: 008, Loss: 0.5855, Val Acc: 0.6558, Test Acc: 0.7066\n",
      "Seed: 43, Epoch: 009, Loss: 0.5803, Val Acc: 0.6899, Test Acc: 0.7131\n",
      "Seed: 43, Epoch: 010, Loss: 0.5779, Val Acc: 0.6623, Test Acc: 0.7034\n",
      "Seed: 43, Epoch: 011, Loss: 0.5714, Val Acc: 0.6769, Test Acc: 0.7115\n",
      "Seed: 43, Epoch: 012, Loss: 0.5628, Val Acc: 0.6802, Test Acc: 0.7326\n",
      "Seed: 43, Epoch: 013, Loss: 0.5626, Val Acc: 0.6623, Test Acc: 0.6742\n",
      "Seed: 43, Epoch: 014, Loss: 0.5602, Val Acc: 0.6883, Test Acc: 0.7569\n",
      "Seed: 43, Epoch: 015, Loss: 0.5562, Val Acc: 0.6802, Test Acc: 0.7342\n",
      "Seed: 43, Epoch: 016, Loss: 0.5514, Val Acc: 0.6802, Test Acc: 0.7245\n",
      "Seed: 43, Epoch: 017, Loss: 0.5438, Val Acc: 0.7094, Test Acc: 0.7407\n",
      "Seed: 43, Epoch: 018, Loss: 0.5373, Val Acc: 0.7110, Test Acc: 0.7180\n",
      "Seed: 43, Epoch: 019, Loss: 0.5522, Val Acc: 0.6899, Test Acc: 0.7407\n",
      "Seed: 43, Epoch: 020, Loss: 0.5534, Val Acc: 0.7094, Test Acc: 0.7553\n",
      "Seed: 43, Epoch: 021, Loss: 0.5398, Val Acc: 0.7078, Test Acc: 0.7342\n",
      "Seed: 43, Epoch: 022, Loss: 0.5348, Val Acc: 0.6964, Test Acc: 0.7358\n",
      "Seed: 43, Epoch: 023, Loss: 0.5352, Val Acc: 0.7062, Test Acc: 0.7423\n",
      "Seed: 43, Epoch: 024, Loss: 0.5212, Val Acc: 0.7321, Test Acc: 0.7472\n",
      "Seed: 43, Epoch: 025, Loss: 0.5179, Val Acc: 0.7045, Test Acc: 0.7358\n",
      "Seed: 43, Epoch: 026, Loss: 0.5158, Val Acc: 0.7143, Test Acc: 0.7488\n",
      "Seed: 43, Epoch: 027, Loss: 0.5245, Val Acc: 0.7451, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 028, Loss: 0.5164, Val Acc: 0.7094, Test Acc: 0.7488\n",
      "Seed: 43, Epoch: 029, Loss: 0.5146, Val Acc: 0.7127, Test Acc: 0.7245\n",
      "Seed: 43, Epoch: 030, Loss: 0.5063, Val Acc: 0.7419, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 031, Loss: 0.5038, Val Acc: 0.7159, Test Acc: 0.7504\n",
      "Seed: 43, Epoch: 032, Loss: 0.4975, Val Acc: 0.7192, Test Acc: 0.7245\n",
      "Seed: 43, Epoch: 033, Loss: 0.4977, Val Acc: 0.7240, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 034, Loss: 0.5050, Val Acc: 0.7354, Test Acc: 0.7666\n",
      "Seed: 43, Epoch: 035, Loss: 0.4974, Val Acc: 0.7451, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 036, Loss: 0.5016, Val Acc: 0.7386, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 037, Loss: 0.4943, Val Acc: 0.7224, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 038, Loss: 0.4888, Val Acc: 0.7143, Test Acc: 0.7245\n",
      "Seed: 43, Epoch: 039, Loss: 0.4822, Val Acc: 0.7273, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 040, Loss: 0.4737, Val Acc: 0.7224, Test Acc: 0.7536\n",
      "Seed: 43, Epoch: 041, Loss: 0.4819, Val Acc: 0.7321, Test Acc: 0.7423\n",
      "Seed: 43, Epoch: 042, Loss: 0.4775, Val Acc: 0.7240, Test Acc: 0.7488\n",
      "Seed: 43, Epoch: 043, Loss: 0.4779, Val Acc: 0.7435, Test Acc: 0.7358\n",
      "Seed: 43, Epoch: 044, Loss: 0.4818, Val Acc: 0.7451, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 045, Loss: 0.4711, Val Acc: 0.7370, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 046, Loss: 0.4642, Val Acc: 0.7403, Test Acc: 0.7407\n",
      "Seed: 43, Epoch: 047, Loss: 0.4606, Val Acc: 0.7630, Test Acc: 0.7585\n",
      "Seed: 43, Epoch: 048, Loss: 0.4633, Val Acc: 0.7370, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 049, Loss: 0.4481, Val Acc: 0.7192, Test Acc: 0.7358\n",
      "Seed: 43, Epoch: 050, Loss: 0.4515, Val Acc: 0.7403, Test Acc: 0.7229\n",
      "Seed: 43, Epoch: 051, Loss: 0.4574, Val Acc: 0.7403, Test Acc: 0.7763\n",
      "Seed: 43, Epoch: 052, Loss: 0.4532, Val Acc: 0.7240, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 053, Loss: 0.4353, Val Acc: 0.7338, Test Acc: 0.7585\n",
      "Seed: 43, Epoch: 054, Loss: 0.4527, Val Acc: 0.7403, Test Acc: 0.7569\n",
      "Seed: 43, Epoch: 055, Loss: 0.4517, Val Acc: 0.7532, Test Acc: 0.7715\n",
      "Seed: 43, Epoch: 056, Loss: 0.4459, Val Acc: 0.7468, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 057, Loss: 0.4387, Val Acc: 0.7289, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 058, Loss: 0.4328, Val Acc: 0.7614, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 059, Loss: 0.4315, Val Acc: 0.7419, Test Acc: 0.7569\n",
      "Seed: 43, Epoch: 060, Loss: 0.4266, Val Acc: 0.7451, Test Acc: 0.7796\n",
      "Seed: 43, Epoch: 061, Loss: 0.4400, Val Acc: 0.7338, Test Acc: 0.7423\n",
      "Seed: 43, Epoch: 062, Loss: 0.4318, Val Acc: 0.7468, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 063, Loss: 0.4265, Val Acc: 0.7451, Test Acc: 0.7504\n",
      "Seed: 43, Epoch: 064, Loss: 0.4328, Val Acc: 0.7370, Test Acc: 0.7585\n",
      "Seed: 43, Epoch: 065, Loss: 0.4402, Val Acc: 0.7646, Test Acc: 0.7666\n",
      "Seed: 43, Epoch: 066, Loss: 0.4167, Val Acc: 0.7532, Test Acc: 0.7844\n",
      "Seed: 43, Epoch: 067, Loss: 0.4202, Val Acc: 0.7630, Test Acc: 0.7585\n",
      "Seed: 43, Epoch: 068, Loss: 0.4148, Val Acc: 0.7549, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 069, Loss: 0.4041, Val Acc: 0.7597, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 070, Loss: 0.4193, Val Acc: 0.7159, Test Acc: 0.7310\n",
      "Seed: 43, Epoch: 071, Loss: 0.4197, Val Acc: 0.7532, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 072, Loss: 0.4091, Val Acc: 0.7516, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 073, Loss: 0.4141, Val Acc: 0.7435, Test Acc: 0.7472\n",
      "Seed: 43, Epoch: 074, Loss: 0.4186, Val Acc: 0.7695, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 075, Loss: 0.4186, Val Acc: 0.7386, Test Acc: 0.7715\n",
      "Seed: 43, Epoch: 076, Loss: 0.3949, Val Acc: 0.7646, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 077, Loss: 0.4044, Val Acc: 0.7776, Test Acc: 0.7488\n",
      "Seed: 43, Epoch: 078, Loss: 0.4017, Val Acc: 0.7614, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 079, Loss: 0.3909, Val Acc: 0.7549, Test Acc: 0.7212\n",
      "Seed: 43, Epoch: 080, Loss: 0.4028, Val Acc: 0.7646, Test Acc: 0.7861\n",
      "Seed: 43, Epoch: 081, Loss: 0.3940, Val Acc: 0.7516, Test Acc: 0.6969\n",
      "Seed: 43, Epoch: 082, Loss: 0.4049, Val Acc: 0.7532, Test Acc: 0.7569\n",
      "Seed: 43, Epoch: 083, Loss: 0.4014, Val Acc: 0.7760, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 084, Loss: 0.4011, Val Acc: 0.7532, Test Acc: 0.7439\n",
      "Seed: 43, Epoch: 085, Loss: 0.4025, Val Acc: 0.7727, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 086, Loss: 0.3917, Val Acc: 0.7581, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 087, Loss: 0.3915, Val Acc: 0.7776, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 088, Loss: 0.4049, Val Acc: 0.7386, Test Acc: 0.7293\n",
      "Seed: 43, Epoch: 089, Loss: 0.3974, Val Acc: 0.7614, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 090, Loss: 0.3901, Val Acc: 0.7500, Test Acc: 0.7504\n",
      "Seed: 43, Epoch: 091, Loss: 0.3983, Val Acc: 0.7468, Test Acc: 0.7326\n",
      "Seed: 43, Epoch: 092, Loss: 0.3779, Val Acc: 0.7679, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 093, Loss: 0.3891, Val Acc: 0.7565, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 094, Loss: 0.4022, Val Acc: 0.7370, Test Acc: 0.7229\n",
      "Seed: 43, Epoch: 095, Loss: 0.3936, Val Acc: 0.7614, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 096, Loss: 0.3826, Val Acc: 0.7808, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 097, Loss: 0.3736, Val Acc: 0.7565, Test Acc: 0.7569\n",
      "Seed: 43, Epoch: 098, Loss: 0.3699, Val Acc: 0.7662, Test Acc: 0.7844\n",
      "Seed: 43, Epoch: 099, Loss: 0.3777, Val Acc: 0.7679, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 100, Loss: 0.3876, Val Acc: 0.7565, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 101, Loss: 0.3816, Val Acc: 0.7873, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 102, Loss: 0.3738, Val Acc: 0.7906, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 103, Loss: 0.3650, Val Acc: 0.7516, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 104, Loss: 0.3933, Val Acc: 0.6834, Test Acc: 0.7066\n",
      "Seed: 43, Epoch: 105, Loss: 0.3697, Val Acc: 0.7484, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 106, Loss: 0.3730, Val Acc: 0.7403, Test Acc: 0.7374\n",
      "Seed: 43, Epoch: 107, Loss: 0.3729, Val Acc: 0.7565, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 108, Loss: 0.3775, Val Acc: 0.7468, Test Acc: 0.7342\n",
      "Seed: 43, Epoch: 109, Loss: 0.3669, Val Acc: 0.7597, Test Acc: 0.7407\n",
      "Seed: 43, Epoch: 110, Loss: 0.3607, Val Acc: 0.7321, Test Acc: 0.7423\n",
      "Seed: 43, Epoch: 111, Loss: 0.3701, Val Acc: 0.7630, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 112, Loss: 0.3640, Val Acc: 0.7630, Test Acc: 0.7828\n",
      "Seed: 43, Epoch: 113, Loss: 0.3657, Val Acc: 0.7403, Test Acc: 0.7472\n",
      "Seed: 43, Epoch: 114, Loss: 0.3684, Val Acc: 0.7549, Test Acc: 0.7472\n",
      "Seed: 43, Epoch: 115, Loss: 0.3672, Val Acc: 0.7825, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 116, Loss: 0.3725, Val Acc: 0.7419, Test Acc: 0.7553\n",
      "Seed: 43, Epoch: 117, Loss: 0.3783, Val Acc: 0.7744, Test Acc: 0.7585\n",
      "Seed: 43, Epoch: 118, Loss: 0.3727, Val Acc: 0.7614, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 119, Loss: 0.3703, Val Acc: 0.7484, Test Acc: 0.7536\n",
      "Seed: 43, Epoch: 120, Loss: 0.3521, Val Acc: 0.7565, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 121, Loss: 0.3648, Val Acc: 0.7565, Test Acc: 0.7844\n",
      "Seed: 43, Epoch: 122, Loss: 0.3726, Val Acc: 0.7419, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 123, Loss: 0.3663, Val Acc: 0.7370, Test Acc: 0.7326\n",
      "Seed: 43, Epoch: 124, Loss: 0.3781, Val Acc: 0.7597, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 125, Loss: 0.3747, Val Acc: 0.7744, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 126, Loss: 0.3576, Val Acc: 0.7532, Test Acc: 0.7293\n",
      "Seed: 43, Epoch: 127, Loss: 0.3566, Val Acc: 0.7419, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 128, Loss: 0.3633, Val Acc: 0.7338, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 129, Loss: 0.3534, Val Acc: 0.7646, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 130, Loss: 0.3550, Val Acc: 0.7646, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 131, Loss: 0.3616, Val Acc: 0.7370, Test Acc: 0.7569\n",
      "Seed: 43, Epoch: 132, Loss: 0.3864, Val Acc: 0.7403, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 133, Loss: 0.3571, Val Acc: 0.7614, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 134, Loss: 0.3540, Val Acc: 0.7500, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 135, Loss: 0.3534, Val Acc: 0.7695, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 136, Loss: 0.3569, Val Acc: 0.7565, Test Acc: 0.7358\n",
      "Seed: 43, Epoch: 137, Loss: 0.3501, Val Acc: 0.7451, Test Acc: 0.7666\n",
      "Seed: 43, Epoch: 138, Loss: 0.3567, Val Acc: 0.7614, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 139, Loss: 0.3575, Val Acc: 0.7744, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 140, Loss: 0.3347, Val Acc: 0.7630, Test Acc: 0.7553\n",
      "Seed: 43, Epoch: 141, Loss: 0.3549, Val Acc: 0.7857, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 142, Loss: 0.3445, Val Acc: 0.7597, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 143, Loss: 0.3489, Val Acc: 0.7192, Test Acc: 0.7050\n",
      "Seed: 43, Epoch: 144, Loss: 0.3466, Val Acc: 0.7370, Test Acc: 0.7374\n",
      "Seed: 43, Epoch: 145, Loss: 0.3381, Val Acc: 0.7500, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 146, Loss: 0.3445, Val Acc: 0.7792, Test Acc: 0.7715\n",
      "Seed: 43, Epoch: 147, Loss: 0.3410, Val Acc: 0.7679, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 148, Loss: 0.3354, Val Acc: 0.7597, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 149, Loss: 0.3400, Val Acc: 0.7695, Test Acc: 0.7585\n",
      "Seed: 43, Epoch: 150, Loss: 0.3560, Val Acc: 0.7646, Test Acc: 0.7536\n",
      "Seed: 43, Epoch: 151, Loss: 0.3298, Val Acc: 0.7532, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 152, Loss: 0.3360, Val Acc: 0.7614, Test Acc: 0.7585\n",
      "Seed: 43, Epoch: 153, Loss: 0.3220, Val Acc: 0.7614, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 154, Loss: 0.3444, Val Acc: 0.7581, Test Acc: 0.7828\n",
      "Seed: 43, Epoch: 155, Loss: 0.3377, Val Acc: 0.7695, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 156, Loss: 0.3258, Val Acc: 0.7500, Test Acc: 0.7861\n",
      "Seed: 43, Epoch: 157, Loss: 0.3463, Val Acc: 0.7240, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 158, Loss: 0.3339, Val Acc: 0.7532, Test Acc: 0.7391\n",
      "Seed: 43, Epoch: 159, Loss: 0.3329, Val Acc: 0.7695, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 160, Loss: 0.3323, Val Acc: 0.7597, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 161, Loss: 0.3239, Val Acc: 0.7614, Test Acc: 0.7536\n",
      "Seed: 43, Epoch: 162, Loss: 0.3248, Val Acc: 0.7549, Test Acc: 0.7796\n",
      "Seed: 43, Epoch: 163, Loss: 0.3248, Val Acc: 0.7630, Test Acc: 0.7407\n",
      "Seed: 43, Epoch: 164, Loss: 0.3221, Val Acc: 0.7711, Test Acc: 0.7844\n",
      "Seed: 43, Epoch: 165, Loss: 0.3180, Val Acc: 0.7565, Test Acc: 0.7844\n",
      "Seed: 43, Epoch: 166, Loss: 0.3304, Val Acc: 0.7273, Test Acc: 0.7358\n",
      "Seed: 43, Epoch: 167, Loss: 0.3199, Val Acc: 0.7890, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 168, Loss: 0.3200, Val Acc: 0.7695, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 169, Loss: 0.3151, Val Acc: 0.7451, Test Acc: 0.7488\n",
      "Seed: 43, Epoch: 170, Loss: 0.3171, Val Acc: 0.7549, Test Acc: 0.7763\n",
      "Seed: 43, Epoch: 171, Loss: 0.3178, Val Acc: 0.7370, Test Acc: 0.7715\n",
      "Seed: 43, Epoch: 172, Loss: 0.3235, Val Acc: 0.7857, Test Acc: 0.7974\n",
      "Seed: 43, Epoch: 173, Loss: 0.3327, Val Acc: 0.7792, Test Acc: 0.7877\n",
      "Seed: 43, Epoch: 174, Loss: 0.3087, Val Acc: 0.7468, Test Acc: 0.7472\n",
      "Seed: 43, Epoch: 175, Loss: 0.3195, Val Acc: 0.7565, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 176, Loss: 0.3214, Val Acc: 0.7662, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 177, Loss: 0.3024, Val Acc: 0.7744, Test Acc: 0.7715\n",
      "Seed: 43, Epoch: 178, Loss: 0.3161, Val Acc: 0.7516, Test Acc: 0.7504\n",
      "Seed: 43, Epoch: 179, Loss: 0.3213, Val Acc: 0.7289, Test Acc: 0.7099\n",
      "Seed: 43, Epoch: 180, Loss: 0.3231, Val Acc: 0.7727, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 181, Loss: 0.3121, Val Acc: 0.7614, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 182, Loss: 0.3183, Val Acc: 0.7679, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 183, Loss: 0.3057, Val Acc: 0.7549, Test Acc: 0.7877\n",
      "Seed: 43, Epoch: 184, Loss: 0.2979, Val Acc: 0.7695, Test Acc: 0.7585\n",
      "Seed: 43, Epoch: 185, Loss: 0.3169, Val Acc: 0.7565, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 186, Loss: 0.3020, Val Acc: 0.7516, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 187, Loss: 0.3103, Val Acc: 0.7695, Test Acc: 0.7536\n",
      "Seed: 43, Epoch: 188, Loss: 0.2810, Val Acc: 0.7646, Test Acc: 0.7585\n",
      "Seed: 43, Epoch: 189, Loss: 0.2992, Val Acc: 0.7240, Test Acc: 0.7261\n",
      "Seed: 43, Epoch: 190, Loss: 0.3052, Val Acc: 0.7679, Test Acc: 0.7796\n",
      "Seed: 43, Epoch: 191, Loss: 0.2967, Val Acc: 0.7760, Test Acc: 0.7569\n",
      "Seed: 43, Epoch: 192, Loss: 0.3028, Val Acc: 0.7581, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 193, Loss: 0.2898, Val Acc: 0.7630, Test Acc: 0.7925\n",
      "Seed: 43, Epoch: 194, Loss: 0.2854, Val Acc: 0.7614, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 195, Loss: 0.2998, Val Acc: 0.7597, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 196, Loss: 0.3011, Val Acc: 0.7808, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 197, Loss: 0.2908, Val Acc: 0.7679, Test Acc: 0.7536\n",
      "Seed: 43, Epoch: 198, Loss: 0.2974, Val Acc: 0.7776, Test Acc: 0.7877\n",
      "Seed: 43, Epoch: 199, Loss: 0.3111, Val Acc: 0.7727, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 200, Loss: 0.2952, Val Acc: 0.7451, Test Acc: 0.7682\n",
      "Seed: 44, Epoch: 001, Loss: 0.6906, Val Acc: 0.4919, Test Acc: 0.4895\n",
      "Seed: 44, Epoch: 002, Loss: 0.6541, Val Acc: 0.6023, Test Acc: 0.5851\n",
      "Seed: 44, Epoch: 003, Loss: 0.6242, Val Acc: 0.6347, Test Acc: 0.5981\n",
      "Seed: 44, Epoch: 004, Loss: 0.6171, Val Acc: 0.6445, Test Acc: 0.6370\n",
      "Seed: 44, Epoch: 005, Loss: 0.6057, Val Acc: 0.6656, Test Acc: 0.6386\n",
      "Seed: 44, Epoch: 006, Loss: 0.5980, Val Acc: 0.6705, Test Acc: 0.6467\n",
      "Seed: 44, Epoch: 007, Loss: 0.6034, Val Acc: 0.6818, Test Acc: 0.6661\n",
      "Seed: 44, Epoch: 008, Loss: 0.5941, Val Acc: 0.6315, Test Acc: 0.6240\n",
      "Seed: 44, Epoch: 009, Loss: 0.5869, Val Acc: 0.6656, Test Acc: 0.6807\n",
      "Seed: 44, Epoch: 010, Loss: 0.5905, Val Acc: 0.6688, Test Acc: 0.6856\n",
      "Seed: 44, Epoch: 011, Loss: 0.5793, Val Acc: 0.6883, Test Acc: 0.6742\n",
      "Seed: 44, Epoch: 012, Loss: 0.5757, Val Acc: 0.6964, Test Acc: 0.7018\n",
      "Seed: 44, Epoch: 013, Loss: 0.5689, Val Acc: 0.6883, Test Acc: 0.6888\n",
      "Seed: 44, Epoch: 014, Loss: 0.5651, Val Acc: 0.6932, Test Acc: 0.6775\n",
      "Seed: 44, Epoch: 015, Loss: 0.5582, Val Acc: 0.6721, Test Acc: 0.6694\n",
      "Seed: 44, Epoch: 016, Loss: 0.5570, Val Acc: 0.6981, Test Acc: 0.7050\n",
      "Seed: 44, Epoch: 017, Loss: 0.5563, Val Acc: 0.7029, Test Acc: 0.7099\n",
      "Seed: 44, Epoch: 018, Loss: 0.5511, Val Acc: 0.6769, Test Acc: 0.6759\n",
      "Seed: 44, Epoch: 019, Loss: 0.5384, Val Acc: 0.7110, Test Acc: 0.7066\n",
      "Seed: 44, Epoch: 020, Loss: 0.5373, Val Acc: 0.6883, Test Acc: 0.6888\n",
      "Seed: 44, Epoch: 021, Loss: 0.5418, Val Acc: 0.6477, Test Acc: 0.6159\n",
      "Seed: 44, Epoch: 022, Loss: 0.5430, Val Acc: 0.6997, Test Acc: 0.6791\n",
      "Seed: 44, Epoch: 023, Loss: 0.5270, Val Acc: 0.6899, Test Acc: 0.6953\n",
      "Seed: 44, Epoch: 024, Loss: 0.5276, Val Acc: 0.7094, Test Acc: 0.6759\n",
      "Seed: 44, Epoch: 025, Loss: 0.5240, Val Acc: 0.6997, Test Acc: 0.6969\n",
      "Seed: 44, Epoch: 026, Loss: 0.5173, Val Acc: 0.7062, Test Acc: 0.6888\n",
      "Seed: 44, Epoch: 027, Loss: 0.5238, Val Acc: 0.6932, Test Acc: 0.7018\n",
      "Seed: 44, Epoch: 028, Loss: 0.5092, Val Acc: 0.6867, Test Acc: 0.6856\n",
      "Seed: 44, Epoch: 029, Loss: 0.5100, Val Acc: 0.7224, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 030, Loss: 0.5320, Val Acc: 0.7289, Test Acc: 0.6888\n",
      "Seed: 44, Epoch: 031, Loss: 0.5161, Val Acc: 0.6932, Test Acc: 0.7115\n",
      "Seed: 44, Epoch: 032, Loss: 0.5078, Val Acc: 0.7192, Test Acc: 0.7212\n",
      "Seed: 44, Epoch: 033, Loss: 0.5005, Val Acc: 0.7338, Test Acc: 0.6969\n",
      "Seed: 44, Epoch: 034, Loss: 0.4964, Val Acc: 0.7321, Test Acc: 0.7245\n",
      "Seed: 44, Epoch: 035, Loss: 0.4949, Val Acc: 0.7484, Test Acc: 0.7245\n",
      "Seed: 44, Epoch: 036, Loss: 0.5036, Val Acc: 0.7240, Test Acc: 0.7018\n",
      "Seed: 44, Epoch: 037, Loss: 0.4785, Val Acc: 0.7127, Test Acc: 0.7180\n",
      "Seed: 44, Epoch: 038, Loss: 0.4754, Val Acc: 0.7192, Test Acc: 0.7115\n",
      "Seed: 44, Epoch: 039, Loss: 0.4725, Val Acc: 0.7289, Test Acc: 0.7034\n",
      "Seed: 44, Epoch: 040, Loss: 0.4815, Val Acc: 0.6883, Test Acc: 0.6775\n",
      "Seed: 44, Epoch: 041, Loss: 0.4903, Val Acc: 0.7240, Test Acc: 0.7180\n",
      "Seed: 44, Epoch: 042, Loss: 0.4826, Val Acc: 0.7370, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 043, Loss: 0.4733, Val Acc: 0.7192, Test Acc: 0.7066\n",
      "Seed: 44, Epoch: 044, Loss: 0.4715, Val Acc: 0.7354, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 045, Loss: 0.4536, Val Acc: 0.7370, Test Acc: 0.7374\n",
      "Seed: 44, Epoch: 046, Loss: 0.4685, Val Acc: 0.7468, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 047, Loss: 0.4608, Val Acc: 0.7435, Test Acc: 0.7245\n",
      "Seed: 44, Epoch: 048, Loss: 0.4628, Val Acc: 0.7532, Test Acc: 0.7391\n",
      "Seed: 44, Epoch: 049, Loss: 0.4560, Val Acc: 0.7419, Test Acc: 0.7147\n",
      "Seed: 44, Epoch: 050, Loss: 0.4425, Val Acc: 0.7451, Test Acc: 0.7423\n",
      "Seed: 44, Epoch: 051, Loss: 0.4454, Val Acc: 0.7597, Test Acc: 0.7391\n",
      "Seed: 44, Epoch: 052, Loss: 0.4437, Val Acc: 0.7386, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 053, Loss: 0.4470, Val Acc: 0.7581, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 054, Loss: 0.4406, Val Acc: 0.7386, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 055, Loss: 0.4417, Val Acc: 0.7370, Test Acc: 0.7245\n",
      "Seed: 44, Epoch: 056, Loss: 0.4398, Val Acc: 0.7338, Test Acc: 0.7261\n",
      "Seed: 44, Epoch: 057, Loss: 0.4418, Val Acc: 0.7679, Test Acc: 0.7423\n",
      "Seed: 44, Epoch: 058, Loss: 0.4266, Val Acc: 0.7516, Test Acc: 0.7666\n",
      "Seed: 44, Epoch: 059, Loss: 0.4312, Val Acc: 0.7273, Test Acc: 0.7196\n",
      "Seed: 44, Epoch: 060, Loss: 0.4199, Val Acc: 0.7435, Test Acc: 0.7196\n",
      "Seed: 44, Epoch: 061, Loss: 0.4247, Val Acc: 0.7532, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 062, Loss: 0.4159, Val Acc: 0.7614, Test Acc: 0.7423\n",
      "Seed: 44, Epoch: 063, Loss: 0.4461, Val Acc: 0.7240, Test Acc: 0.7147\n",
      "Seed: 44, Epoch: 064, Loss: 0.4218, Val Acc: 0.7321, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 065, Loss: 0.4427, Val Acc: 0.7435, Test Acc: 0.7358\n",
      "Seed: 44, Epoch: 066, Loss: 0.4168, Val Acc: 0.7386, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 067, Loss: 0.4242, Val Acc: 0.7549, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 068, Loss: 0.4234, Val Acc: 0.7646, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 069, Loss: 0.4132, Val Acc: 0.7614, Test Acc: 0.7423\n",
      "Seed: 44, Epoch: 070, Loss: 0.4107, Val Acc: 0.7808, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 071, Loss: 0.4141, Val Acc: 0.7305, Test Acc: 0.7229\n",
      "Seed: 44, Epoch: 072, Loss: 0.4083, Val Acc: 0.7597, Test Acc: 0.7229\n",
      "Seed: 44, Epoch: 073, Loss: 0.4021, Val Acc: 0.7354, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 074, Loss: 0.3914, Val Acc: 0.7646, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 075, Loss: 0.4045, Val Acc: 0.7873, Test Acc: 0.7358\n",
      "Seed: 44, Epoch: 076, Loss: 0.4068, Val Acc: 0.7224, Test Acc: 0.7261\n",
      "Seed: 44, Epoch: 077, Loss: 0.4010, Val Acc: 0.7516, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 078, Loss: 0.3850, Val Acc: 0.7597, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 079, Loss: 0.3880, Val Acc: 0.7679, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 080, Loss: 0.3887, Val Acc: 0.7614, Test Acc: 0.7358\n",
      "Seed: 44, Epoch: 081, Loss: 0.3925, Val Acc: 0.7403, Test Acc: 0.7618\n",
      "Seed: 44, Epoch: 082, Loss: 0.3906, Val Acc: 0.7597, Test Acc: 0.7553\n",
      "Seed: 44, Epoch: 083, Loss: 0.3716, Val Acc: 0.7338, Test Acc: 0.6969\n",
      "Seed: 44, Epoch: 084, Loss: 0.3804, Val Acc: 0.7354, Test Acc: 0.7196\n",
      "Seed: 44, Epoch: 085, Loss: 0.3749, Val Acc: 0.7776, Test Acc: 0.7455\n",
      "Seed: 44, Epoch: 086, Loss: 0.3870, Val Acc: 0.7679, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 087, Loss: 0.3869, Val Acc: 0.7873, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 088, Loss: 0.3771, Val Acc: 0.7500, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 089, Loss: 0.3764, Val Acc: 0.7808, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 090, Loss: 0.3731, Val Acc: 0.7630, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 091, Loss: 0.3814, Val Acc: 0.7581, Test Acc: 0.7423\n",
      "Seed: 44, Epoch: 092, Loss: 0.3665, Val Acc: 0.7646, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 093, Loss: 0.3667, Val Acc: 0.7565, Test Acc: 0.7131\n",
      "Seed: 44, Epoch: 094, Loss: 0.3756, Val Acc: 0.7679, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 095, Loss: 0.3573, Val Acc: 0.7808, Test Acc: 0.7699\n",
      "Seed: 44, Epoch: 096, Loss: 0.3599, Val Acc: 0.7581, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 097, Loss: 0.3665, Val Acc: 0.7695, Test Acc: 0.7634\n",
      "Seed: 44, Epoch: 098, Loss: 0.3610, Val Acc: 0.7646, Test Acc: 0.7423\n",
      "Seed: 44, Epoch: 099, Loss: 0.3690, Val Acc: 0.6997, Test Acc: 0.7050\n",
      "Seed: 44, Epoch: 100, Loss: 0.3649, Val Acc: 0.7419, Test Acc: 0.7553\n",
      "Seed: 44, Epoch: 101, Loss: 0.3579, Val Acc: 0.7760, Test Acc: 0.7666\n",
      "Seed: 44, Epoch: 102, Loss: 0.3664, Val Acc: 0.7614, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 103, Loss: 0.3688, Val Acc: 0.7662, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 104, Loss: 0.3573, Val Acc: 0.7760, Test Acc: 0.7455\n",
      "Seed: 44, Epoch: 105, Loss: 0.3668, Val Acc: 0.7500, Test Acc: 0.7618\n",
      "Seed: 44, Epoch: 106, Loss: 0.3671, Val Acc: 0.7451, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 107, Loss: 0.3731, Val Acc: 0.7240, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 108, Loss: 0.3575, Val Acc: 0.7695, Test Acc: 0.7634\n",
      "Seed: 44, Epoch: 109, Loss: 0.3527, Val Acc: 0.7760, Test Acc: 0.7585\n",
      "Seed: 44, Epoch: 110, Loss: 0.3595, Val Acc: 0.7630, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 111, Loss: 0.3398, Val Acc: 0.7549, Test Acc: 0.7553\n",
      "Seed: 44, Epoch: 112, Loss: 0.3511, Val Acc: 0.7873, Test Acc: 0.7731\n",
      "Seed: 44, Epoch: 113, Loss: 0.3537, Val Acc: 0.7192, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 114, Loss: 0.3360, Val Acc: 0.7516, Test Acc: 0.7455\n",
      "Seed: 44, Epoch: 115, Loss: 0.3425, Val Acc: 0.7695, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 116, Loss: 0.3465, Val Acc: 0.7841, Test Acc: 0.7585\n",
      "Seed: 44, Epoch: 117, Loss: 0.3544, Val Acc: 0.7760, Test Acc: 0.7715\n",
      "Seed: 44, Epoch: 118, Loss: 0.3374, Val Acc: 0.7825, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 119, Loss: 0.3249, Val Acc: 0.7906, Test Acc: 0.7601\n",
      "Seed: 44, Epoch: 120, Loss: 0.3385, Val Acc: 0.7760, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 121, Loss: 0.3406, Val Acc: 0.7760, Test Acc: 0.7585\n",
      "Seed: 44, Epoch: 122, Loss: 0.3311, Val Acc: 0.7695, Test Acc: 0.7650\n",
      "Seed: 44, Epoch: 123, Loss: 0.3223, Val Acc: 0.7597, Test Acc: 0.7618\n",
      "Seed: 44, Epoch: 124, Loss: 0.3348, Val Acc: 0.7435, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 125, Loss: 0.3411, Val Acc: 0.7711, Test Acc: 0.7391\n",
      "Seed: 44, Epoch: 126, Loss: 0.3247, Val Acc: 0.7662, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 127, Loss: 0.3147, Val Acc: 0.7792, Test Acc: 0.7423\n",
      "Seed: 44, Epoch: 128, Loss: 0.3149, Val Acc: 0.7825, Test Acc: 0.7553\n",
      "Seed: 44, Epoch: 129, Loss: 0.3243, Val Acc: 0.7679, Test Acc: 0.7861\n",
      "Seed: 44, Epoch: 130, Loss: 0.3298, Val Acc: 0.7305, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 131, Loss: 0.3171, Val Acc: 0.7776, Test Acc: 0.7553\n",
      "Seed: 44, Epoch: 132, Loss: 0.3258, Val Acc: 0.7776, Test Acc: 0.7601\n",
      "Seed: 44, Epoch: 133, Loss: 0.3081, Val Acc: 0.7419, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 134, Loss: 0.3247, Val Acc: 0.7679, Test Acc: 0.7553\n",
      "Seed: 44, Epoch: 135, Loss: 0.3314, Val Acc: 0.7354, Test Acc: 0.7147\n",
      "Seed: 44, Epoch: 136, Loss: 0.3352, Val Acc: 0.7695, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 137, Loss: 0.3236, Val Acc: 0.7890, Test Acc: 0.7585\n",
      "Seed: 44, Epoch: 138, Loss: 0.3217, Val Acc: 0.7597, Test Acc: 0.7618\n",
      "Seed: 44, Epoch: 139, Loss: 0.3046, Val Acc: 0.7727, Test Acc: 0.7553\n",
      "Seed: 44, Epoch: 140, Loss: 0.3368, Val Acc: 0.7597, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 141, Loss: 0.3108, Val Acc: 0.7792, Test Acc: 0.7682\n",
      "Seed: 44, Epoch: 142, Loss: 0.3152, Val Acc: 0.7224, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 143, Loss: 0.3185, Val Acc: 0.7370, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 144, Loss: 0.3255, Val Acc: 0.7597, Test Acc: 0.7423\n",
      "Seed: 44, Epoch: 145, Loss: 0.3288, Val Acc: 0.7516, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 146, Loss: 0.3284, Val Acc: 0.7597, Test Acc: 0.7844\n",
      "Seed: 44, Epoch: 147, Loss: 0.3142, Val Acc: 0.7630, Test Acc: 0.7472\n",
      "Seed: 44, Epoch: 148, Loss: 0.2910, Val Acc: 0.7646, Test Acc: 0.7472\n",
      "Seed: 44, Epoch: 149, Loss: 0.3056, Val Acc: 0.7468, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 150, Loss: 0.3075, Val Acc: 0.7662, Test Acc: 0.7990\n",
      "Seed: 44, Epoch: 151, Loss: 0.3025, Val Acc: 0.7565, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 152, Loss: 0.3220, Val Acc: 0.7711, Test Acc: 0.7699\n",
      "Seed: 44, Epoch: 153, Loss: 0.3098, Val Acc: 0.7338, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 154, Loss: 0.3185, Val Acc: 0.7695, Test Acc: 0.7618\n",
      "Seed: 44, Epoch: 155, Loss: 0.2978, Val Acc: 0.7744, Test Acc: 0.7553\n",
      "Seed: 44, Epoch: 156, Loss: 0.3066, Val Acc: 0.7646, Test Acc: 0.7682\n",
      "Seed: 44, Epoch: 157, Loss: 0.3048, Val Acc: 0.7792, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 158, Loss: 0.3043, Val Acc: 0.7630, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 159, Loss: 0.3061, Val Acc: 0.7808, Test Acc: 0.7828\n",
      "Seed: 44, Epoch: 160, Loss: 0.2905, Val Acc: 0.7321, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 161, Loss: 0.2931, Val Acc: 0.7711, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 162, Loss: 0.2915, Val Acc: 0.7435, Test Acc: 0.7358\n",
      "Seed: 44, Epoch: 163, Loss: 0.2913, Val Acc: 0.7532, Test Acc: 0.7180\n",
      "Seed: 44, Epoch: 164, Loss: 0.2931, Val Acc: 0.7760, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 165, Loss: 0.2965, Val Acc: 0.7435, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 166, Loss: 0.2953, Val Acc: 0.7711, Test Acc: 0.7650\n",
      "Seed: 44, Epoch: 167, Loss: 0.3066, Val Acc: 0.7711, Test Acc: 0.7731\n",
      "Seed: 44, Epoch: 168, Loss: 0.2896, Val Acc: 0.7857, Test Acc: 0.7699\n",
      "Seed: 44, Epoch: 169, Loss: 0.2819, Val Acc: 0.7565, Test Acc: 0.7569\n",
      "Seed: 44, Epoch: 170, Loss: 0.3019, Val Acc: 0.7695, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 171, Loss: 0.2968, Val Acc: 0.7873, Test Acc: 0.7666\n",
      "Seed: 44, Epoch: 172, Loss: 0.2933, Val Acc: 0.7727, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 173, Loss: 0.2775, Val Acc: 0.7679, Test Acc: 0.7601\n",
      "Seed: 44, Epoch: 174, Loss: 0.2685, Val Acc: 0.7549, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 175, Loss: 0.2981, Val Acc: 0.7305, Test Acc: 0.7391\n",
      "Seed: 44, Epoch: 176, Loss: 0.2836, Val Acc: 0.7711, Test Acc: 0.7391\n",
      "Seed: 44, Epoch: 177, Loss: 0.2761, Val Acc: 0.7630, Test Acc: 0.7618\n",
      "Seed: 44, Epoch: 178, Loss: 0.2754, Val Acc: 0.7776, Test Acc: 0.7634\n",
      "Seed: 44, Epoch: 179, Loss: 0.2817, Val Acc: 0.7695, Test Acc: 0.7731\n",
      "Seed: 44, Epoch: 180, Loss: 0.2755, Val Acc: 0.7662, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 181, Loss: 0.2898, Val Acc: 0.7630, Test Acc: 0.7618\n",
      "Seed: 44, Epoch: 182, Loss: 0.2881, Val Acc: 0.7646, Test Acc: 0.7715\n",
      "Seed: 44, Epoch: 183, Loss: 0.2991, Val Acc: 0.7744, Test Acc: 0.7358\n",
      "Seed: 44, Epoch: 184, Loss: 0.2897, Val Acc: 0.7744, Test Acc: 0.7763\n",
      "Seed: 44, Epoch: 185, Loss: 0.2851, Val Acc: 0.7614, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 186, Loss: 0.2820, Val Acc: 0.7581, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 187, Loss: 0.2701, Val Acc: 0.7873, Test Acc: 0.7796\n",
      "Seed: 44, Epoch: 188, Loss: 0.2883, Val Acc: 0.7029, Test Acc: 0.6775\n",
      "Seed: 44, Epoch: 189, Loss: 0.2777, Val Acc: 0.7419, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 190, Loss: 0.2724, Val Acc: 0.7597, Test Acc: 0.7569\n",
      "Seed: 44, Epoch: 191, Loss: 0.2764, Val Acc: 0.7646, Test Acc: 0.7569\n",
      "Seed: 44, Epoch: 192, Loss: 0.2813, Val Acc: 0.7711, Test Acc: 0.7601\n",
      "Seed: 44, Epoch: 193, Loss: 0.2844, Val Acc: 0.7679, Test Acc: 0.7455\n",
      "Seed: 44, Epoch: 194, Loss: 0.2610, Val Acc: 0.7873, Test Acc: 0.7666\n",
      "Seed: 44, Epoch: 195, Loss: 0.2789, Val Acc: 0.7727, Test Acc: 0.7601\n",
      "Seed: 44, Epoch: 196, Loss: 0.2657, Val Acc: 0.7646, Test Acc: 0.7618\n",
      "Seed: 44, Epoch: 197, Loss: 0.2673, Val Acc: 0.7711, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 198, Loss: 0.2811, Val Acc: 0.7679, Test Acc: 0.7585\n",
      "Seed: 44, Epoch: 199, Loss: 0.2823, Val Acc: 0.7500, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 200, Loss: 0.2586, Val Acc: 0.7500, Test Acc: 0.7455\n",
      "Average Time: 475.01 seconds\n",
      "Var Time: 5439.40 seconds\n",
      "Average Memory: 436.00 MB\n",
      "Average Best Val Acc: 0.7965\n",
      "Std Best Test Acc: 0.0046\n",
      "Average Test Acc: 0.7634\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "max_nodes = 150\n",
    "data_path = \"/data/Zeyu/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"NCI1\",\n",
    "    transform=T.Compose([T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_justbalance(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        #x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        #x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        #x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_justbalance().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = Net_justbalance().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCI109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6844, Val Acc: 0.4960, Test Acc: 0.5145\n",
      "Seed: 42, Epoch: 002, Loss: 0.6601, Val Acc: 0.6527, Test Acc: 0.6258\n",
      "Seed: 42, Epoch: 003, Loss: 0.6396, Val Acc: 0.6769, Test Acc: 0.6484\n",
      "Seed: 42, Epoch: 004, Loss: 0.6223, Val Acc: 0.6704, Test Acc: 0.6645\n",
      "Seed: 42, Epoch: 005, Loss: 0.6029, Val Acc: 0.6850, Test Acc: 0.6613\n",
      "Seed: 42, Epoch: 006, Loss: 0.5927, Val Acc: 0.7060, Test Acc: 0.6661\n",
      "Seed: 42, Epoch: 007, Loss: 0.5843, Val Acc: 0.6737, Test Acc: 0.6403\n",
      "Seed: 42, Epoch: 008, Loss: 0.5856, Val Acc: 0.7076, Test Acc: 0.6758\n",
      "Seed: 42, Epoch: 009, Loss: 0.5859, Val Acc: 0.7173, Test Acc: 0.6694\n",
      "Seed: 42, Epoch: 010, Loss: 0.5746, Val Acc: 0.7189, Test Acc: 0.6790\n",
      "Seed: 42, Epoch: 011, Loss: 0.5702, Val Acc: 0.6704, Test Acc: 0.6371\n",
      "Seed: 42, Epoch: 012, Loss: 0.5649, Val Acc: 0.7173, Test Acc: 0.6790\n",
      "Seed: 42, Epoch: 013, Loss: 0.5648, Val Acc: 0.6753, Test Acc: 0.6403\n",
      "Seed: 42, Epoch: 014, Loss: 0.5651, Val Acc: 0.7060, Test Acc: 0.6774\n",
      "Seed: 42, Epoch: 015, Loss: 0.5608, Val Acc: 0.7141, Test Acc: 0.7000\n",
      "Seed: 42, Epoch: 016, Loss: 0.5496, Val Acc: 0.7286, Test Acc: 0.6839\n",
      "Seed: 42, Epoch: 017, Loss: 0.5459, Val Acc: 0.6737, Test Acc: 0.6581\n",
      "Seed: 42, Epoch: 018, Loss: 0.5588, Val Acc: 0.7141, Test Acc: 0.6677\n",
      "Seed: 42, Epoch: 019, Loss: 0.5458, Val Acc: 0.7318, Test Acc: 0.7016\n",
      "Seed: 42, Epoch: 020, Loss: 0.5402, Val Acc: 0.7011, Test Acc: 0.6871\n",
      "Seed: 42, Epoch: 021, Loss: 0.5433, Val Acc: 0.7011, Test Acc: 0.6742\n",
      "Seed: 42, Epoch: 022, Loss: 0.5283, Val Acc: 0.6947, Test Acc: 0.6742\n",
      "Seed: 42, Epoch: 023, Loss: 0.5266, Val Acc: 0.7367, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 024, Loss: 0.5139, Val Acc: 0.7383, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 025, Loss: 0.5322, Val Acc: 0.7254, Test Acc: 0.6984\n",
      "Seed: 42, Epoch: 026, Loss: 0.5185, Val Acc: 0.7157, Test Acc: 0.6935\n",
      "Seed: 42, Epoch: 027, Loss: 0.5101, Val Acc: 0.7141, Test Acc: 0.6629\n",
      "Seed: 42, Epoch: 028, Loss: 0.5215, Val Acc: 0.7254, Test Acc: 0.6968\n",
      "Seed: 42, Epoch: 029, Loss: 0.5154, Val Acc: 0.7237, Test Acc: 0.7016\n",
      "Seed: 42, Epoch: 030, Loss: 0.5084, Val Acc: 0.7237, Test Acc: 0.7065\n",
      "Seed: 42, Epoch: 031, Loss: 0.5171, Val Acc: 0.7464, Test Acc: 0.6839\n",
      "Seed: 42, Epoch: 032, Loss: 0.5014, Val Acc: 0.7286, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 033, Loss: 0.5048, Val Acc: 0.7092, Test Acc: 0.6790\n",
      "Seed: 42, Epoch: 034, Loss: 0.4952, Val Acc: 0.7286, Test Acc: 0.6919\n",
      "Seed: 42, Epoch: 035, Loss: 0.4882, Val Acc: 0.7383, Test Acc: 0.7258\n",
      "Seed: 42, Epoch: 036, Loss: 0.4876, Val Acc: 0.7496, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 037, Loss: 0.4875, Val Acc: 0.7447, Test Acc: 0.7016\n",
      "Seed: 42, Epoch: 038, Loss: 0.4885, Val Acc: 0.7302, Test Acc: 0.7274\n",
      "Seed: 42, Epoch: 039, Loss: 0.5121, Val Acc: 0.7286, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 040, Loss: 0.4868, Val Acc: 0.7415, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 041, Loss: 0.4793, Val Acc: 0.7496, Test Acc: 0.7516\n",
      "Seed: 42, Epoch: 042, Loss: 0.4741, Val Acc: 0.7254, Test Acc: 0.6919\n",
      "Seed: 42, Epoch: 043, Loss: 0.4775, Val Acc: 0.7205, Test Acc: 0.7226\n",
      "Seed: 42, Epoch: 044, Loss: 0.4723, Val Acc: 0.7383, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 045, Loss: 0.4708, Val Acc: 0.7480, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 046, Loss: 0.4692, Val Acc: 0.7334, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 047, Loss: 0.4784, Val Acc: 0.7561, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 048, Loss: 0.4654, Val Acc: 0.7383, Test Acc: 0.7177\n",
      "Seed: 42, Epoch: 049, Loss: 0.4663, Val Acc: 0.7447, Test Acc: 0.7113\n",
      "Seed: 42, Epoch: 050, Loss: 0.4671, Val Acc: 0.7512, Test Acc: 0.7355\n",
      "Seed: 42, Epoch: 051, Loss: 0.4801, Val Acc: 0.7447, Test Acc: 0.7403\n",
      "Seed: 42, Epoch: 052, Loss: 0.4536, Val Acc: 0.7431, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 053, Loss: 0.4493, Val Acc: 0.7528, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 054, Loss: 0.4514, Val Acc: 0.7544, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 055, Loss: 0.4516, Val Acc: 0.7625, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 056, Loss: 0.4543, Val Acc: 0.7464, Test Acc: 0.7048\n",
      "Seed: 42, Epoch: 057, Loss: 0.4602, Val Acc: 0.7205, Test Acc: 0.7226\n",
      "Seed: 42, Epoch: 058, Loss: 0.4516, Val Acc: 0.7351, Test Acc: 0.7290\n",
      "Seed: 42, Epoch: 059, Loss: 0.4411, Val Acc: 0.7302, Test Acc: 0.7177\n",
      "Seed: 42, Epoch: 060, Loss: 0.4467, Val Acc: 0.7593, Test Acc: 0.7306\n",
      "Seed: 42, Epoch: 061, Loss: 0.4417, Val Acc: 0.7593, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 062, Loss: 0.4288, Val Acc: 0.7254, Test Acc: 0.7290\n",
      "Seed: 42, Epoch: 063, Loss: 0.4311, Val Acc: 0.7464, Test Acc: 0.7258\n",
      "Seed: 42, Epoch: 064, Loss: 0.4421, Val Acc: 0.7512, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 065, Loss: 0.4360, Val Acc: 0.7528, Test Acc: 0.7403\n",
      "Seed: 42, Epoch: 066, Loss: 0.4392, Val Acc: 0.7561, Test Acc: 0.7323\n",
      "Seed: 42, Epoch: 067, Loss: 0.4314, Val Acc: 0.7367, Test Acc: 0.7306\n",
      "Seed: 42, Epoch: 068, Loss: 0.4247, Val Acc: 0.7690, Test Acc: 0.7113\n",
      "Seed: 42, Epoch: 069, Loss: 0.4326, Val Acc: 0.7512, Test Acc: 0.7355\n",
      "Seed: 42, Epoch: 070, Loss: 0.4273, Val Acc: 0.7415, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 071, Loss: 0.4194, Val Acc: 0.7528, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 072, Loss: 0.4307, Val Acc: 0.7318, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 073, Loss: 0.4202, Val Acc: 0.7431, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 074, Loss: 0.4305, Val Acc: 0.7318, Test Acc: 0.7355\n",
      "Seed: 42, Epoch: 075, Loss: 0.4065, Val Acc: 0.7431, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 076, Loss: 0.4148, Val Acc: 0.7399, Test Acc: 0.7113\n",
      "Seed: 42, Epoch: 077, Loss: 0.4183, Val Acc: 0.7512, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 078, Loss: 0.4146, Val Acc: 0.7754, Test Acc: 0.7548\n",
      "Seed: 42, Epoch: 079, Loss: 0.4108, Val Acc: 0.7399, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 080, Loss: 0.4135, Val Acc: 0.7141, Test Acc: 0.7032\n",
      "Seed: 42, Epoch: 081, Loss: 0.4004, Val Acc: 0.7738, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 082, Loss: 0.3940, Val Acc: 0.7480, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 083, Loss: 0.4020, Val Acc: 0.7577, Test Acc: 0.7355\n",
      "Seed: 42, Epoch: 084, Loss: 0.4042, Val Acc: 0.7754, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 085, Loss: 0.3950, Val Acc: 0.6834, Test Acc: 0.6790\n",
      "Seed: 42, Epoch: 086, Loss: 0.4185, Val Acc: 0.6850, Test Acc: 0.6968\n",
      "Seed: 42, Epoch: 087, Loss: 0.4121, Val Acc: 0.7027, Test Acc: 0.6839\n",
      "Seed: 42, Epoch: 088, Loss: 0.3916, Val Acc: 0.7609, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 089, Loss: 0.3919, Val Acc: 0.7447, Test Acc: 0.7532\n",
      "Seed: 42, Epoch: 090, Loss: 0.4019, Val Acc: 0.7561, Test Acc: 0.7484\n",
      "Seed: 42, Epoch: 091, Loss: 0.3877, Val Acc: 0.7593, Test Acc: 0.7548\n",
      "Seed: 42, Epoch: 092, Loss: 0.3857, Val Acc: 0.7706, Test Acc: 0.7468\n",
      "Seed: 42, Epoch: 093, Loss: 0.3910, Val Acc: 0.7544, Test Acc: 0.7290\n",
      "Seed: 42, Epoch: 094, Loss: 0.3835, Val Acc: 0.7431, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 095, Loss: 0.3886, Val Acc: 0.7561, Test Acc: 0.7274\n",
      "Seed: 42, Epoch: 096, Loss: 0.3911, Val Acc: 0.7577, Test Acc: 0.7323\n",
      "Seed: 42, Epoch: 097, Loss: 0.3789, Val Acc: 0.7706, Test Acc: 0.7323\n",
      "Seed: 42, Epoch: 098, Loss: 0.3888, Val Acc: 0.7674, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 099, Loss: 0.3909, Val Acc: 0.7738, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 100, Loss: 0.3960, Val Acc: 0.7415, Test Acc: 0.7113\n",
      "Seed: 42, Epoch: 101, Loss: 0.3866, Val Acc: 0.7480, Test Acc: 0.7306\n",
      "Seed: 42, Epoch: 102, Loss: 0.3854, Val Acc: 0.7464, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 103, Loss: 0.3690, Val Acc: 0.7399, Test Acc: 0.7226\n",
      "Seed: 42, Epoch: 104, Loss: 0.3755, Val Acc: 0.7383, Test Acc: 0.7323\n",
      "Seed: 42, Epoch: 105, Loss: 0.3758, Val Acc: 0.7625, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 106, Loss: 0.3819, Val Acc: 0.7254, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 107, Loss: 0.3783, Val Acc: 0.7577, Test Acc: 0.7097\n",
      "Seed: 42, Epoch: 108, Loss: 0.3614, Val Acc: 0.7690, Test Acc: 0.7355\n",
      "Seed: 42, Epoch: 109, Loss: 0.3692, Val Acc: 0.7544, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 110, Loss: 0.3587, Val Acc: 0.7577, Test Acc: 0.7306\n",
      "Seed: 42, Epoch: 111, Loss: 0.3778, Val Acc: 0.7738, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 112, Loss: 0.3669, Val Acc: 0.7577, Test Acc: 0.7290\n",
      "Seed: 42, Epoch: 113, Loss: 0.3548, Val Acc: 0.7561, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 114, Loss: 0.3588, Val Acc: 0.7415, Test Acc: 0.7177\n",
      "Seed: 42, Epoch: 115, Loss: 0.3771, Val Acc: 0.7593, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 116, Loss: 0.3691, Val Acc: 0.7464, Test Acc: 0.7355\n",
      "Seed: 42, Epoch: 117, Loss: 0.3637, Val Acc: 0.7480, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 118, Loss: 0.3660, Val Acc: 0.7544, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 119, Loss: 0.3587, Val Acc: 0.7431, Test Acc: 0.7548\n",
      "Seed: 42, Epoch: 120, Loss: 0.3665, Val Acc: 0.7544, Test Acc: 0.7403\n",
      "Seed: 42, Epoch: 121, Loss: 0.3526, Val Acc: 0.7722, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 122, Loss: 0.3656, Val Acc: 0.7383, Test Acc: 0.6903\n",
      "Seed: 42, Epoch: 123, Loss: 0.3599, Val Acc: 0.7690, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 124, Loss: 0.3618, Val Acc: 0.7722, Test Acc: 0.7355\n",
      "Seed: 42, Epoch: 125, Loss: 0.3458, Val Acc: 0.7431, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 126, Loss: 0.3449, Val Acc: 0.7690, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 127, Loss: 0.3527, Val Acc: 0.7593, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 128, Loss: 0.3436, Val Acc: 0.7593, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 129, Loss: 0.3504, Val Acc: 0.7593, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 130, Loss: 0.3327, Val Acc: 0.7577, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 131, Loss: 0.3445, Val Acc: 0.7674, Test Acc: 0.7258\n",
      "Seed: 42, Epoch: 132, Loss: 0.3373, Val Acc: 0.7464, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 133, Loss: 0.3465, Val Acc: 0.7577, Test Acc: 0.7306\n",
      "Seed: 42, Epoch: 134, Loss: 0.3296, Val Acc: 0.7496, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 135, Loss: 0.3446, Val Acc: 0.7706, Test Acc: 0.7355\n",
      "Seed: 42, Epoch: 136, Loss: 0.3327, Val Acc: 0.7496, Test Acc: 0.7258\n",
      "Seed: 42, Epoch: 137, Loss: 0.3322, Val Acc: 0.7464, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 138, Loss: 0.3404, Val Acc: 0.7286, Test Acc: 0.7258\n",
      "Seed: 42, Epoch: 139, Loss: 0.3220, Val Acc: 0.7383, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 140, Loss: 0.3278, Val Acc: 0.7367, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 141, Loss: 0.3579, Val Acc: 0.7948, Test Acc: 0.7403\n",
      "Seed: 42, Epoch: 142, Loss: 0.3343, Val Acc: 0.7722, Test Acc: 0.7306\n",
      "Seed: 42, Epoch: 143, Loss: 0.3369, Val Acc: 0.7528, Test Acc: 0.7355\n",
      "Seed: 42, Epoch: 144, Loss: 0.3268, Val Acc: 0.6995, Test Acc: 0.6823\n",
      "Seed: 42, Epoch: 145, Loss: 0.3465, Val Acc: 0.7512, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 146, Loss: 0.3583, Val Acc: 0.7625, Test Acc: 0.7274\n",
      "Seed: 42, Epoch: 147, Loss: 0.3288, Val Acc: 0.7593, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 148, Loss: 0.3250, Val Acc: 0.7205, Test Acc: 0.7113\n",
      "Seed: 42, Epoch: 149, Loss: 0.3196, Val Acc: 0.7512, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 150, Loss: 0.3135, Val Acc: 0.7641, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 151, Loss: 0.3154, Val Acc: 0.7351, Test Acc: 0.7065\n",
      "Seed: 42, Epoch: 152, Loss: 0.3308, Val Acc: 0.7528, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 153, Loss: 0.3226, Val Acc: 0.7480, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 154, Loss: 0.3228, Val Acc: 0.7383, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 155, Loss: 0.3139, Val Acc: 0.8045, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 156, Loss: 0.3201, Val Acc: 0.7690, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 157, Loss: 0.3033, Val Acc: 0.7383, Test Acc: 0.6968\n",
      "Seed: 42, Epoch: 158, Loss: 0.3160, Val Acc: 0.7205, Test Acc: 0.7065\n",
      "Seed: 42, Epoch: 159, Loss: 0.3195, Val Acc: 0.7318, Test Acc: 0.6726\n",
      "Seed: 42, Epoch: 160, Loss: 0.3079, Val Acc: 0.7512, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 161, Loss: 0.2985, Val Acc: 0.7803, Test Acc: 0.7290\n",
      "Seed: 42, Epoch: 162, Loss: 0.3014, Val Acc: 0.7512, Test Acc: 0.7177\n",
      "Seed: 42, Epoch: 163, Loss: 0.3082, Val Acc: 0.7447, Test Acc: 0.7403\n",
      "Seed: 42, Epoch: 164, Loss: 0.3071, Val Acc: 0.7577, Test Acc: 0.7065\n",
      "Seed: 42, Epoch: 165, Loss: 0.3090, Val Acc: 0.7674, Test Acc: 0.7226\n",
      "Seed: 42, Epoch: 166, Loss: 0.2948, Val Acc: 0.7544, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 167, Loss: 0.2842, Val Acc: 0.7399, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 168, Loss: 0.2977, Val Acc: 0.7512, Test Acc: 0.7306\n",
      "Seed: 42, Epoch: 169, Loss: 0.3038, Val Acc: 0.7367, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 170, Loss: 0.2981, Val Acc: 0.7593, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 171, Loss: 0.2852, Val Acc: 0.7641, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 172, Loss: 0.3012, Val Acc: 0.7690, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 173, Loss: 0.2927, Val Acc: 0.7302, Test Acc: 0.7065\n",
      "Seed: 42, Epoch: 174, Loss: 0.3243, Val Acc: 0.7706, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 175, Loss: 0.3032, Val Acc: 0.7738, Test Acc: 0.7468\n",
      "Seed: 42, Epoch: 176, Loss: 0.3028, Val Acc: 0.7480, Test Acc: 0.7323\n",
      "Seed: 42, Epoch: 177, Loss: 0.2947, Val Acc: 0.7399, Test Acc: 0.7290\n",
      "Seed: 42, Epoch: 178, Loss: 0.2867, Val Acc: 0.7658, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 179, Loss: 0.2937, Val Acc: 0.7528, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 180, Loss: 0.2903, Val Acc: 0.7706, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 181, Loss: 0.2967, Val Acc: 0.7577, Test Acc: 0.7274\n",
      "Seed: 42, Epoch: 182, Loss: 0.3148, Val Acc: 0.7496, Test Acc: 0.7323\n",
      "Seed: 42, Epoch: 183, Loss: 0.3079, Val Acc: 0.7141, Test Acc: 0.6984\n",
      "Seed: 42, Epoch: 184, Loss: 0.2932, Val Acc: 0.7512, Test Acc: 0.7323\n",
      "Seed: 42, Epoch: 185, Loss: 0.2890, Val Acc: 0.7641, Test Acc: 0.7226\n",
      "Seed: 42, Epoch: 186, Loss: 0.2863, Val Acc: 0.7512, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 187, Loss: 0.2967, Val Acc: 0.7577, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 188, Loss: 0.2834, Val Acc: 0.7431, Test Acc: 0.7226\n",
      "Seed: 42, Epoch: 189, Loss: 0.2931, Val Acc: 0.7447, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 190, Loss: 0.2852, Val Acc: 0.7609, Test Acc: 0.7097\n",
      "Seed: 42, Epoch: 191, Loss: 0.2893, Val Acc: 0.7367, Test Acc: 0.7306\n",
      "Seed: 42, Epoch: 192, Loss: 0.2827, Val Acc: 0.7447, Test Acc: 0.6968\n",
      "Seed: 42, Epoch: 193, Loss: 0.2790, Val Acc: 0.7302, Test Acc: 0.6694\n",
      "Seed: 42, Epoch: 194, Loss: 0.2849, Val Acc: 0.7658, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 195, Loss: 0.2794, Val Acc: 0.7302, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 196, Loss: 0.2754, Val Acc: 0.7415, Test Acc: 0.7306\n",
      "Seed: 42, Epoch: 197, Loss: 0.2794, Val Acc: 0.7674, Test Acc: 0.7258\n",
      "Seed: 42, Epoch: 198, Loss: 0.2966, Val Acc: 0.7157, Test Acc: 0.7274\n",
      "Seed: 42, Epoch: 199, Loss: 0.2899, Val Acc: 0.7480, Test Acc: 0.7113\n",
      "Seed: 42, Epoch: 200, Loss: 0.2853, Val Acc: 0.7674, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 001, Loss: 0.6851, Val Acc: 0.5363, Test Acc: 0.5129\n",
      "Seed: 43, Epoch: 002, Loss: 0.6584, Val Acc: 0.6236, Test Acc: 0.6403\n",
      "Seed: 43, Epoch: 003, Loss: 0.6326, Val Acc: 0.6381, Test Acc: 0.6500\n",
      "Seed: 43, Epoch: 004, Loss: 0.6175, Val Acc: 0.6688, Test Acc: 0.6855\n",
      "Seed: 43, Epoch: 005, Loss: 0.6087, Val Acc: 0.6882, Test Acc: 0.6887\n",
      "Seed: 43, Epoch: 006, Loss: 0.6004, Val Acc: 0.6801, Test Acc: 0.6952\n",
      "Seed: 43, Epoch: 007, Loss: 0.5909, Val Acc: 0.6817, Test Acc: 0.6887\n",
      "Seed: 43, Epoch: 008, Loss: 0.5850, Val Acc: 0.6866, Test Acc: 0.6903\n",
      "Seed: 43, Epoch: 009, Loss: 0.5814, Val Acc: 0.6801, Test Acc: 0.6952\n",
      "Seed: 43, Epoch: 010, Loss: 0.5835, Val Acc: 0.6769, Test Acc: 0.6694\n",
      "Seed: 43, Epoch: 011, Loss: 0.5753, Val Acc: 0.7027, Test Acc: 0.6968\n",
      "Seed: 43, Epoch: 012, Loss: 0.5764, Val Acc: 0.6559, Test Acc: 0.6790\n",
      "Seed: 43, Epoch: 013, Loss: 0.5731, Val Acc: 0.6785, Test Acc: 0.6903\n",
      "Seed: 43, Epoch: 014, Loss: 0.5627, Val Acc: 0.7044, Test Acc: 0.6919\n",
      "Seed: 43, Epoch: 015, Loss: 0.5667, Val Acc: 0.6882, Test Acc: 0.6935\n",
      "Seed: 43, Epoch: 016, Loss: 0.5679, Val Acc: 0.7076, Test Acc: 0.6823\n",
      "Seed: 43, Epoch: 017, Loss: 0.5541, Val Acc: 0.6947, Test Acc: 0.7145\n",
      "Seed: 43, Epoch: 018, Loss: 0.5565, Val Acc: 0.6882, Test Acc: 0.6710\n",
      "Seed: 43, Epoch: 019, Loss: 0.5548, Val Acc: 0.7092, Test Acc: 0.7032\n",
      "Seed: 43, Epoch: 020, Loss: 0.5457, Val Acc: 0.7157, Test Acc: 0.7032\n",
      "Seed: 43, Epoch: 021, Loss: 0.5421, Val Acc: 0.6737, Test Acc: 0.6871\n",
      "Seed: 43, Epoch: 022, Loss: 0.5435, Val Acc: 0.7270, Test Acc: 0.7210\n",
      "Seed: 43, Epoch: 023, Loss: 0.5465, Val Acc: 0.7237, Test Acc: 0.7161\n",
      "Seed: 43, Epoch: 024, Loss: 0.5394, Val Acc: 0.7189, Test Acc: 0.7145\n",
      "Seed: 43, Epoch: 025, Loss: 0.5305, Val Acc: 0.7157, Test Acc: 0.7113\n",
      "Seed: 43, Epoch: 026, Loss: 0.5242, Val Acc: 0.7254, Test Acc: 0.6952\n",
      "Seed: 43, Epoch: 027, Loss: 0.5189, Val Acc: 0.6979, Test Acc: 0.7097\n",
      "Seed: 43, Epoch: 028, Loss: 0.5141, Val Acc: 0.6640, Test Acc: 0.6935\n",
      "Seed: 43, Epoch: 029, Loss: 0.5236, Val Acc: 0.7157, Test Acc: 0.7097\n",
      "Seed: 43, Epoch: 030, Loss: 0.5221, Val Acc: 0.6898, Test Acc: 0.7065\n",
      "Seed: 43, Epoch: 031, Loss: 0.5316, Val Acc: 0.7092, Test Acc: 0.6919\n",
      "Seed: 43, Epoch: 032, Loss: 0.5232, Val Acc: 0.7141, Test Acc: 0.7258\n",
      "Seed: 43, Epoch: 033, Loss: 0.5159, Val Acc: 0.7157, Test Acc: 0.7097\n",
      "Seed: 43, Epoch: 034, Loss: 0.5096, Val Acc: 0.7076, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 035, Loss: 0.5073, Val Acc: 0.7318, Test Acc: 0.7113\n",
      "Seed: 43, Epoch: 036, Loss: 0.5110, Val Acc: 0.7189, Test Acc: 0.7048\n",
      "Seed: 43, Epoch: 037, Loss: 0.5053, Val Acc: 0.7011, Test Acc: 0.6935\n",
      "Seed: 43, Epoch: 038, Loss: 0.4927, Val Acc: 0.7124, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 039, Loss: 0.4883, Val Acc: 0.7367, Test Acc: 0.7468\n",
      "Seed: 43, Epoch: 040, Loss: 0.4929, Val Acc: 0.6672, Test Acc: 0.6371\n",
      "Seed: 43, Epoch: 041, Loss: 0.4877, Val Acc: 0.7544, Test Acc: 0.7371\n",
      "Seed: 43, Epoch: 042, Loss: 0.4872, Val Acc: 0.7415, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 043, Loss: 0.4719, Val Acc: 0.7480, Test Acc: 0.7210\n",
      "Seed: 43, Epoch: 044, Loss: 0.4814, Val Acc: 0.7221, Test Acc: 0.7371\n",
      "Seed: 43, Epoch: 045, Loss: 0.4815, Val Acc: 0.7399, Test Acc: 0.7258\n",
      "Seed: 43, Epoch: 046, Loss: 0.4814, Val Acc: 0.7334, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 047, Loss: 0.4680, Val Acc: 0.7060, Test Acc: 0.7081\n",
      "Seed: 43, Epoch: 048, Loss: 0.4796, Val Acc: 0.7561, Test Acc: 0.7629\n",
      "Seed: 43, Epoch: 049, Loss: 0.4609, Val Acc: 0.7027, Test Acc: 0.7065\n",
      "Seed: 43, Epoch: 050, Loss: 0.4629, Val Acc: 0.7044, Test Acc: 0.7339\n",
      "Seed: 43, Epoch: 051, Loss: 0.4704, Val Acc: 0.7334, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 052, Loss: 0.4622, Val Acc: 0.7431, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 053, Loss: 0.4505, Val Acc: 0.7480, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 054, Loss: 0.4463, Val Acc: 0.7480, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 055, Loss: 0.4783, Val Acc: 0.7141, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 056, Loss: 0.4565, Val Acc: 0.7173, Test Acc: 0.7371\n",
      "Seed: 43, Epoch: 057, Loss: 0.4488, Val Acc: 0.7641, Test Acc: 0.7532\n",
      "Seed: 43, Epoch: 058, Loss: 0.4452, Val Acc: 0.7415, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 059, Loss: 0.4344, Val Acc: 0.7415, Test Acc: 0.7532\n",
      "Seed: 43, Epoch: 060, Loss: 0.4327, Val Acc: 0.7318, Test Acc: 0.7532\n",
      "Seed: 43, Epoch: 061, Loss: 0.4357, Val Acc: 0.7399, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 062, Loss: 0.4358, Val Acc: 0.7561, Test Acc: 0.7629\n",
      "Seed: 43, Epoch: 063, Loss: 0.4471, Val Acc: 0.7431, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 064, Loss: 0.4502, Val Acc: 0.7351, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 065, Loss: 0.4269, Val Acc: 0.7205, Test Acc: 0.7371\n",
      "Seed: 43, Epoch: 066, Loss: 0.4350, Val Acc: 0.7480, Test Acc: 0.7468\n",
      "Seed: 43, Epoch: 067, Loss: 0.4478, Val Acc: 0.7464, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 068, Loss: 0.4337, Val Acc: 0.7431, Test Acc: 0.7274\n",
      "Seed: 43, Epoch: 069, Loss: 0.4351, Val Acc: 0.7270, Test Acc: 0.7177\n",
      "Seed: 43, Epoch: 070, Loss: 0.4286, Val Acc: 0.7544, Test Acc: 0.7726\n",
      "Seed: 43, Epoch: 071, Loss: 0.4203, Val Acc: 0.7108, Test Acc: 0.7113\n",
      "Seed: 43, Epoch: 072, Loss: 0.4267, Val Acc: 0.7706, Test Acc: 0.7823\n",
      "Seed: 43, Epoch: 073, Loss: 0.4091, Val Acc: 0.7221, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 074, Loss: 0.4369, Val Acc: 0.7334, Test Acc: 0.7581\n",
      "Seed: 43, Epoch: 075, Loss: 0.4261, Val Acc: 0.7528, Test Acc: 0.7565\n",
      "Seed: 43, Epoch: 076, Loss: 0.4348, Val Acc: 0.7157, Test Acc: 0.7097\n",
      "Seed: 43, Epoch: 077, Loss: 0.4112, Val Acc: 0.7480, Test Acc: 0.7274\n",
      "Seed: 43, Epoch: 078, Loss: 0.4162, Val Acc: 0.7625, Test Acc: 0.7661\n",
      "Seed: 43, Epoch: 079, Loss: 0.4187, Val Acc: 0.7464, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 080, Loss: 0.4121, Val Acc: 0.7674, Test Acc: 0.7565\n",
      "Seed: 43, Epoch: 081, Loss: 0.4066, Val Acc: 0.7237, Test Acc: 0.7032\n",
      "Seed: 43, Epoch: 082, Loss: 0.4029, Val Acc: 0.7351, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 083, Loss: 0.4129, Val Acc: 0.7205, Test Acc: 0.7339\n",
      "Seed: 43, Epoch: 084, Loss: 0.4033, Val Acc: 0.7351, Test Acc: 0.7645\n",
      "Seed: 43, Epoch: 085, Loss: 0.4066, Val Acc: 0.7254, Test Acc: 0.7048\n",
      "Seed: 43, Epoch: 086, Loss: 0.4018, Val Acc: 0.7464, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 087, Loss: 0.3975, Val Acc: 0.7351, Test Acc: 0.7468\n",
      "Seed: 43, Epoch: 088, Loss: 0.4033, Val Acc: 0.7480, Test Acc: 0.7629\n",
      "Seed: 43, Epoch: 089, Loss: 0.3935, Val Acc: 0.7108, Test Acc: 0.7339\n",
      "Seed: 43, Epoch: 090, Loss: 0.3887, Val Acc: 0.7512, Test Acc: 0.7742\n",
      "Seed: 43, Epoch: 091, Loss: 0.3883, Val Acc: 0.7464, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 092, Loss: 0.3845, Val Acc: 0.7431, Test Acc: 0.7258\n",
      "Seed: 43, Epoch: 093, Loss: 0.3679, Val Acc: 0.7334, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 094, Loss: 0.4041, Val Acc: 0.7415, Test Acc: 0.7758\n",
      "Seed: 43, Epoch: 095, Loss: 0.4018, Val Acc: 0.7060, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 096, Loss: 0.3887, Val Acc: 0.7415, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 097, Loss: 0.3810, Val Acc: 0.7415, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 098, Loss: 0.3796, Val Acc: 0.7334, Test Acc: 0.7532\n",
      "Seed: 43, Epoch: 099, Loss: 0.3913, Val Acc: 0.7367, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 100, Loss: 0.3761, Val Acc: 0.7254, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 101, Loss: 0.3838, Val Acc: 0.7351, Test Acc: 0.7581\n",
      "Seed: 43, Epoch: 102, Loss: 0.3747, Val Acc: 0.7496, Test Acc: 0.7871\n",
      "Seed: 43, Epoch: 103, Loss: 0.3755, Val Acc: 0.7512, Test Acc: 0.7565\n",
      "Seed: 43, Epoch: 104, Loss: 0.3810, Val Acc: 0.7464, Test Acc: 0.7452\n",
      "Seed: 43, Epoch: 105, Loss: 0.3889, Val Acc: 0.7270, Test Acc: 0.7177\n",
      "Seed: 43, Epoch: 106, Loss: 0.3858, Val Acc: 0.7076, Test Acc: 0.6968\n",
      "Seed: 43, Epoch: 107, Loss: 0.3812, Val Acc: 0.7383, Test Acc: 0.7597\n",
      "Seed: 43, Epoch: 108, Loss: 0.3723, Val Acc: 0.7431, Test Acc: 0.7435\n",
      "Seed: 43, Epoch: 109, Loss: 0.3727, Val Acc: 0.7270, Test Acc: 0.7597\n",
      "Seed: 43, Epoch: 110, Loss: 0.3729, Val Acc: 0.7480, Test Acc: 0.7952\n",
      "Seed: 43, Epoch: 111, Loss: 0.3701, Val Acc: 0.7577, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 112, Loss: 0.3608, Val Acc: 0.7092, Test Acc: 0.7468\n",
      "Seed: 43, Epoch: 113, Loss: 0.3701, Val Acc: 0.7690, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 114, Loss: 0.3634, Val Acc: 0.7351, Test Acc: 0.7645\n",
      "Seed: 43, Epoch: 115, Loss: 0.3698, Val Acc: 0.7480, Test Acc: 0.7210\n",
      "Seed: 43, Epoch: 116, Loss: 0.3768, Val Acc: 0.7318, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 117, Loss: 0.3547, Val Acc: 0.7625, Test Acc: 0.7839\n",
      "Seed: 43, Epoch: 118, Loss: 0.3618, Val Acc: 0.7302, Test Acc: 0.7484\n",
      "Seed: 43, Epoch: 119, Loss: 0.3560, Val Acc: 0.7561, Test Acc: 0.7758\n",
      "Seed: 43, Epoch: 120, Loss: 0.3586, Val Acc: 0.7286, Test Acc: 0.7452\n",
      "Seed: 43, Epoch: 121, Loss: 0.3560, Val Acc: 0.7383, Test Acc: 0.7694\n",
      "Seed: 43, Epoch: 122, Loss: 0.3553, Val Acc: 0.7383, Test Acc: 0.7484\n",
      "Seed: 43, Epoch: 123, Loss: 0.3613, Val Acc: 0.7399, Test Acc: 0.7565\n",
      "Seed: 43, Epoch: 124, Loss: 0.3674, Val Acc: 0.7367, Test Acc: 0.7484\n",
      "Seed: 43, Epoch: 125, Loss: 0.3517, Val Acc: 0.7189, Test Acc: 0.7210\n",
      "Seed: 43, Epoch: 126, Loss: 0.3482, Val Acc: 0.7577, Test Acc: 0.7629\n",
      "Seed: 43, Epoch: 127, Loss: 0.3547, Val Acc: 0.7625, Test Acc: 0.7726\n",
      "Seed: 43, Epoch: 128, Loss: 0.3504, Val Acc: 0.7027, Test Acc: 0.7048\n",
      "Seed: 43, Epoch: 129, Loss: 0.3610, Val Acc: 0.7738, Test Acc: 0.7645\n",
      "Seed: 43, Epoch: 130, Loss: 0.3396, Val Acc: 0.7270, Test Acc: 0.7726\n",
      "Seed: 43, Epoch: 131, Loss: 0.3487, Val Acc: 0.7512, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 132, Loss: 0.3457, Val Acc: 0.7415, Test Acc: 0.7694\n",
      "Seed: 43, Epoch: 133, Loss: 0.3430, Val Acc: 0.7399, Test Acc: 0.7694\n",
      "Seed: 43, Epoch: 134, Loss: 0.3399, Val Acc: 0.7464, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 135, Loss: 0.3400, Val Acc: 0.7577, Test Acc: 0.7565\n",
      "Seed: 43, Epoch: 136, Loss: 0.3432, Val Acc: 0.7496, Test Acc: 0.7532\n",
      "Seed: 43, Epoch: 137, Loss: 0.3376, Val Acc: 0.7690, Test Acc: 0.7629\n",
      "Seed: 43, Epoch: 138, Loss: 0.3279, Val Acc: 0.7383, Test Acc: 0.7226\n",
      "Seed: 43, Epoch: 139, Loss: 0.3286, Val Acc: 0.7512, Test Acc: 0.7645\n",
      "Seed: 43, Epoch: 140, Loss: 0.3307, Val Acc: 0.7512, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 141, Loss: 0.3588, Val Acc: 0.7351, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 142, Loss: 0.3518, Val Acc: 0.7351, Test Acc: 0.7371\n",
      "Seed: 43, Epoch: 143, Loss: 0.3394, Val Acc: 0.7447, Test Acc: 0.7403\n",
      "Seed: 43, Epoch: 144, Loss: 0.3313, Val Acc: 0.7528, Test Acc: 0.7581\n",
      "Seed: 43, Epoch: 145, Loss: 0.3473, Val Acc: 0.7415, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 146, Loss: 0.3405, Val Acc: 0.7383, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 147, Loss: 0.3339, Val Acc: 0.7577, Test Acc: 0.7484\n",
      "Seed: 43, Epoch: 148, Loss: 0.3385, Val Acc: 0.7431, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 149, Loss: 0.3356, Val Acc: 0.7367, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 150, Loss: 0.3322, Val Acc: 0.7189, Test Acc: 0.7274\n",
      "Seed: 43, Epoch: 151, Loss: 0.3273, Val Acc: 0.7658, Test Acc: 0.7710\n",
      "Seed: 43, Epoch: 152, Loss: 0.3203, Val Acc: 0.7544, Test Acc: 0.7629\n",
      "Seed: 43, Epoch: 153, Loss: 0.3415, Val Acc: 0.7561, Test Acc: 0.7758\n",
      "Seed: 43, Epoch: 154, Loss: 0.3302, Val Acc: 0.7318, Test Acc: 0.7274\n",
      "Seed: 43, Epoch: 155, Loss: 0.3446, Val Acc: 0.7528, Test Acc: 0.7274\n",
      "Seed: 43, Epoch: 156, Loss: 0.3340, Val Acc: 0.7254, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 157, Loss: 0.3332, Val Acc: 0.7464, Test Acc: 0.7645\n",
      "Seed: 43, Epoch: 158, Loss: 0.3312, Val Acc: 0.7447, Test Acc: 0.7403\n",
      "Seed: 43, Epoch: 159, Loss: 0.3341, Val Acc: 0.7496, Test Acc: 0.7661\n",
      "Seed: 43, Epoch: 160, Loss: 0.3403, Val Acc: 0.7286, Test Acc: 0.7161\n",
      "Seed: 43, Epoch: 161, Loss: 0.3255, Val Acc: 0.7771, Test Acc: 0.7823\n",
      "Seed: 43, Epoch: 162, Loss: 0.3280, Val Acc: 0.7286, Test Acc: 0.7758\n",
      "Seed: 43, Epoch: 163, Loss: 0.3243, Val Acc: 0.7270, Test Acc: 0.7758\n",
      "Seed: 43, Epoch: 164, Loss: 0.3198, Val Acc: 0.7464, Test Acc: 0.7677\n",
      "Seed: 43, Epoch: 165, Loss: 0.3123, Val Acc: 0.7399, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 166, Loss: 0.3136, Val Acc: 0.7625, Test Acc: 0.7919\n",
      "Seed: 43, Epoch: 167, Loss: 0.3115, Val Acc: 0.7141, Test Acc: 0.7081\n",
      "Seed: 43, Epoch: 168, Loss: 0.3292, Val Acc: 0.7544, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 169, Loss: 0.3005, Val Acc: 0.7464, Test Acc: 0.7694\n",
      "Seed: 43, Epoch: 170, Loss: 0.3318, Val Acc: 0.7593, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 171, Loss: 0.2980, Val Acc: 0.7512, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 172, Loss: 0.3294, Val Acc: 0.7722, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 173, Loss: 0.3132, Val Acc: 0.7205, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 174, Loss: 0.3120, Val Acc: 0.7512, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 175, Loss: 0.3266, Val Acc: 0.7286, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 176, Loss: 0.3059, Val Acc: 0.7351, Test Acc: 0.7726\n",
      "Seed: 43, Epoch: 177, Loss: 0.3218, Val Acc: 0.7302, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 178, Loss: 0.2988, Val Acc: 0.7625, Test Acc: 0.7532\n",
      "Seed: 43, Epoch: 179, Loss: 0.3200, Val Acc: 0.7415, Test Acc: 0.7258\n",
      "Seed: 43, Epoch: 180, Loss: 0.3089, Val Acc: 0.7577, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 181, Loss: 0.2962, Val Acc: 0.7221, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 182, Loss: 0.3059, Val Acc: 0.7286, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 183, Loss: 0.3285, Val Acc: 0.7447, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 184, Loss: 0.3052, Val Acc: 0.7625, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 185, Loss: 0.3051, Val Acc: 0.7351, Test Acc: 0.7645\n",
      "Seed: 43, Epoch: 186, Loss: 0.3105, Val Acc: 0.7237, Test Acc: 0.7194\n",
      "Seed: 43, Epoch: 187, Loss: 0.3048, Val Acc: 0.7641, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 188, Loss: 0.3064, Val Acc: 0.7318, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 189, Loss: 0.3048, Val Acc: 0.7464, Test Acc: 0.7565\n",
      "Seed: 43, Epoch: 190, Loss: 0.3214, Val Acc: 0.7561, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 191, Loss: 0.3099, Val Acc: 0.7383, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 192, Loss: 0.3010, Val Acc: 0.7141, Test Acc: 0.7048\n",
      "Seed: 43, Epoch: 193, Loss: 0.3294, Val Acc: 0.7351, Test Acc: 0.7258\n",
      "Seed: 43, Epoch: 194, Loss: 0.2974, Val Acc: 0.7286, Test Acc: 0.7177\n",
      "Seed: 43, Epoch: 195, Loss: 0.3069, Val Acc: 0.7415, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 196, Loss: 0.3113, Val Acc: 0.7157, Test Acc: 0.7532\n",
      "Seed: 43, Epoch: 197, Loss: 0.2971, Val Acc: 0.7383, Test Acc: 0.7806\n",
      "Seed: 43, Epoch: 198, Loss: 0.3118, Val Acc: 0.7286, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 199, Loss: 0.3147, Val Acc: 0.7561, Test Acc: 0.7774\n",
      "Seed: 43, Epoch: 200, Loss: 0.3073, Val Acc: 0.7399, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 001, Loss: 0.6811, Val Acc: 0.5250, Test Acc: 0.5371\n",
      "Seed: 44, Epoch: 002, Loss: 0.6588, Val Acc: 0.5994, Test Acc: 0.6210\n",
      "Seed: 44, Epoch: 003, Loss: 0.6356, Val Acc: 0.6187, Test Acc: 0.6500\n",
      "Seed: 44, Epoch: 004, Loss: 0.6192, Val Acc: 0.6381, Test Acc: 0.6758\n",
      "Seed: 44, Epoch: 005, Loss: 0.6046, Val Acc: 0.6640, Test Acc: 0.7161\n",
      "Seed: 44, Epoch: 006, Loss: 0.5960, Val Acc: 0.6624, Test Acc: 0.6984\n",
      "Seed: 44, Epoch: 007, Loss: 0.5930, Val Acc: 0.6801, Test Acc: 0.7129\n",
      "Seed: 44, Epoch: 008, Loss: 0.5913, Val Acc: 0.6624, Test Acc: 0.6952\n",
      "Seed: 44, Epoch: 009, Loss: 0.5837, Val Acc: 0.6866, Test Acc: 0.7274\n",
      "Seed: 44, Epoch: 010, Loss: 0.5822, Val Acc: 0.6914, Test Acc: 0.7129\n",
      "Seed: 44, Epoch: 011, Loss: 0.5752, Val Acc: 0.6284, Test Acc: 0.6500\n",
      "Seed: 44, Epoch: 012, Loss: 0.5810, Val Acc: 0.6527, Test Acc: 0.6968\n",
      "Seed: 44, Epoch: 013, Loss: 0.5697, Val Acc: 0.6559, Test Acc: 0.6806\n",
      "Seed: 44, Epoch: 014, Loss: 0.5646, Val Acc: 0.6704, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 015, Loss: 0.5633, Val Acc: 0.6882, Test Acc: 0.7258\n",
      "Seed: 44, Epoch: 016, Loss: 0.5529, Val Acc: 0.6963, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 017, Loss: 0.5601, Val Acc: 0.6801, Test Acc: 0.7016\n",
      "Seed: 44, Epoch: 018, Loss: 0.5556, Val Acc: 0.7092, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 019, Loss: 0.5447, Val Acc: 0.6882, Test Acc: 0.7274\n",
      "Seed: 44, Epoch: 020, Loss: 0.5380, Val Acc: 0.6494, Test Acc: 0.6855\n",
      "Seed: 44, Epoch: 021, Loss: 0.5331, Val Acc: 0.6850, Test Acc: 0.7194\n",
      "Seed: 44, Epoch: 022, Loss: 0.5252, Val Acc: 0.7173, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 023, Loss: 0.5299, Val Acc: 0.6656, Test Acc: 0.6968\n",
      "Seed: 44, Epoch: 024, Loss: 0.5164, Val Acc: 0.6769, Test Acc: 0.7032\n",
      "Seed: 44, Epoch: 025, Loss: 0.5210, Val Acc: 0.7221, Test Acc: 0.7355\n",
      "Seed: 44, Epoch: 026, Loss: 0.5109, Val Acc: 0.6704, Test Acc: 0.7210\n",
      "Seed: 44, Epoch: 027, Loss: 0.5063, Val Acc: 0.7011, Test Acc: 0.7145\n",
      "Seed: 44, Epoch: 028, Loss: 0.5071, Val Acc: 0.6785, Test Acc: 0.7194\n",
      "Seed: 44, Epoch: 029, Loss: 0.5239, Val Acc: 0.7415, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 030, Loss: 0.5247, Val Acc: 0.6931, Test Acc: 0.7339\n",
      "Seed: 44, Epoch: 031, Loss: 0.5116, Val Acc: 0.7076, Test Acc: 0.7468\n",
      "Seed: 44, Epoch: 032, Loss: 0.5061, Val Acc: 0.6931, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 033, Loss: 0.5035, Val Acc: 0.7221, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 034, Loss: 0.4979, Val Acc: 0.7528, Test Acc: 0.7645\n",
      "Seed: 44, Epoch: 035, Loss: 0.4903, Val Acc: 0.7270, Test Acc: 0.7645\n",
      "Seed: 44, Epoch: 036, Loss: 0.5009, Val Acc: 0.7254, Test Acc: 0.7468\n",
      "Seed: 44, Epoch: 037, Loss: 0.4864, Val Acc: 0.7027, Test Acc: 0.7323\n",
      "Seed: 44, Epoch: 038, Loss: 0.4872, Val Acc: 0.7383, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 039, Loss: 0.4888, Val Acc: 0.7351, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 040, Loss: 0.4882, Val Acc: 0.7254, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 041, Loss: 0.4940, Val Acc: 0.6704, Test Acc: 0.7145\n",
      "Seed: 44, Epoch: 042, Loss: 0.4769, Val Acc: 0.7383, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 043, Loss: 0.4735, Val Acc: 0.7351, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 044, Loss: 0.4701, Val Acc: 0.7270, Test Acc: 0.7339\n",
      "Seed: 44, Epoch: 045, Loss: 0.4628, Val Acc: 0.7318, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 046, Loss: 0.4593, Val Acc: 0.7367, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 047, Loss: 0.4717, Val Acc: 0.7447, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 048, Loss: 0.4665, Val Acc: 0.7544, Test Acc: 0.7677\n",
      "Seed: 44, Epoch: 049, Loss: 0.4629, Val Acc: 0.7108, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 050, Loss: 0.4611, Val Acc: 0.7044, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 051, Loss: 0.4559, Val Acc: 0.7528, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 052, Loss: 0.4495, Val Acc: 0.7286, Test Acc: 0.7274\n",
      "Seed: 44, Epoch: 053, Loss: 0.4427, Val Acc: 0.7189, Test Acc: 0.7468\n",
      "Seed: 44, Epoch: 054, Loss: 0.4507, Val Acc: 0.7173, Test Acc: 0.7403\n",
      "Seed: 44, Epoch: 055, Loss: 0.4416, Val Acc: 0.7561, Test Acc: 0.7774\n",
      "Seed: 44, Epoch: 056, Loss: 0.4468, Val Acc: 0.7399, Test Acc: 0.7758\n",
      "Seed: 44, Epoch: 057, Loss: 0.4436, Val Acc: 0.7205, Test Acc: 0.7419\n",
      "Seed: 44, Epoch: 058, Loss: 0.4598, Val Acc: 0.7431, Test Acc: 0.7645\n",
      "Seed: 44, Epoch: 059, Loss: 0.4375, Val Acc: 0.7431, Test Acc: 0.7677\n",
      "Seed: 44, Epoch: 060, Loss: 0.4398, Val Acc: 0.7221, Test Acc: 0.7177\n",
      "Seed: 44, Epoch: 061, Loss: 0.4436, Val Acc: 0.7447, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 062, Loss: 0.4326, Val Acc: 0.7383, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 063, Loss: 0.4350, Val Acc: 0.6979, Test Acc: 0.7258\n",
      "Seed: 44, Epoch: 064, Loss: 0.4341, Val Acc: 0.7447, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 065, Loss: 0.4303, Val Acc: 0.7431, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 066, Loss: 0.4333, Val Acc: 0.7399, Test Acc: 0.7710\n",
      "Seed: 44, Epoch: 067, Loss: 0.4177, Val Acc: 0.7641, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 068, Loss: 0.4114, Val Acc: 0.7447, Test Acc: 0.7806\n",
      "Seed: 44, Epoch: 069, Loss: 0.4097, Val Acc: 0.7496, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 070, Loss: 0.4267, Val Acc: 0.7399, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 071, Loss: 0.4328, Val Acc: 0.7658, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 072, Loss: 0.4299, Val Acc: 0.7464, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 073, Loss: 0.4172, Val Acc: 0.7334, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 074, Loss: 0.4158, Val Acc: 0.7625, Test Acc: 0.7677\n",
      "Seed: 44, Epoch: 075, Loss: 0.4045, Val Acc: 0.7722, Test Acc: 0.7823\n",
      "Seed: 44, Epoch: 076, Loss: 0.4204, Val Acc: 0.7060, Test Acc: 0.7355\n",
      "Seed: 44, Epoch: 077, Loss: 0.4236, Val Acc: 0.7787, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 078, Loss: 0.4197, Val Acc: 0.7528, Test Acc: 0.7855\n",
      "Seed: 44, Epoch: 079, Loss: 0.3982, Val Acc: 0.7674, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 080, Loss: 0.3989, Val Acc: 0.7221, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 081, Loss: 0.4111, Val Acc: 0.7447, Test Acc: 0.7758\n",
      "Seed: 44, Epoch: 082, Loss: 0.4140, Val Acc: 0.7431, Test Acc: 0.7774\n",
      "Seed: 44, Epoch: 083, Loss: 0.4025, Val Acc: 0.7221, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 084, Loss: 0.4111, Val Acc: 0.7318, Test Acc: 0.7355\n",
      "Seed: 44, Epoch: 085, Loss: 0.3891, Val Acc: 0.7787, Test Acc: 0.7774\n",
      "Seed: 44, Epoch: 086, Loss: 0.4010, Val Acc: 0.7771, Test Acc: 0.7661\n",
      "Seed: 44, Epoch: 087, Loss: 0.3908, Val Acc: 0.7367, Test Acc: 0.7226\n",
      "Seed: 44, Epoch: 088, Loss: 0.4033, Val Acc: 0.7609, Test Acc: 0.7839\n",
      "Seed: 44, Epoch: 089, Loss: 0.3988, Val Acc: 0.7431, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 090, Loss: 0.3970, Val Acc: 0.7674, Test Acc: 0.7790\n",
      "Seed: 44, Epoch: 091, Loss: 0.3989, Val Acc: 0.7060, Test Acc: 0.7048\n",
      "Seed: 44, Epoch: 092, Loss: 0.3843, Val Acc: 0.7496, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 093, Loss: 0.3777, Val Acc: 0.7415, Test Acc: 0.7645\n",
      "Seed: 44, Epoch: 094, Loss: 0.3878, Val Acc: 0.7480, Test Acc: 0.7790\n",
      "Seed: 44, Epoch: 095, Loss: 0.3839, Val Acc: 0.7480, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 096, Loss: 0.3713, Val Acc: 0.7447, Test Acc: 0.7694\n",
      "Seed: 44, Epoch: 097, Loss: 0.3784, Val Acc: 0.7641, Test Acc: 0.7806\n",
      "Seed: 44, Epoch: 098, Loss: 0.4002, Val Acc: 0.7658, Test Acc: 0.7774\n",
      "Seed: 44, Epoch: 099, Loss: 0.3853, Val Acc: 0.7351, Test Acc: 0.7677\n",
      "Seed: 44, Epoch: 100, Loss: 0.3790, Val Acc: 0.7609, Test Acc: 0.7694\n",
      "Seed: 44, Epoch: 101, Loss: 0.3732, Val Acc: 0.6995, Test Acc: 0.7016\n",
      "Seed: 44, Epoch: 102, Loss: 0.3920, Val Acc: 0.7561, Test Acc: 0.7661\n",
      "Seed: 44, Epoch: 103, Loss: 0.3773, Val Acc: 0.7496, Test Acc: 0.7726\n",
      "Seed: 44, Epoch: 104, Loss: 0.3910, Val Acc: 0.7609, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 105, Loss: 0.3770, Val Acc: 0.7625, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 106, Loss: 0.3682, Val Acc: 0.7512, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 107, Loss: 0.3617, Val Acc: 0.7706, Test Acc: 0.7677\n",
      "Seed: 44, Epoch: 108, Loss: 0.3725, Val Acc: 0.7528, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 109, Loss: 0.3630, Val Acc: 0.7464, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 110, Loss: 0.3836, Val Acc: 0.7286, Test Acc: 0.7790\n",
      "Seed: 44, Epoch: 111, Loss: 0.3700, Val Acc: 0.7383, Test Acc: 0.7661\n",
      "Seed: 44, Epoch: 112, Loss: 0.3761, Val Acc: 0.7367, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 113, Loss: 0.3600, Val Acc: 0.7464, Test Acc: 0.7661\n",
      "Seed: 44, Epoch: 114, Loss: 0.3646, Val Acc: 0.7674, Test Acc: 0.7758\n",
      "Seed: 44, Epoch: 115, Loss: 0.3678, Val Acc: 0.7561, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 116, Loss: 0.3631, Val Acc: 0.7480, Test Acc: 0.7677\n",
      "Seed: 44, Epoch: 117, Loss: 0.3647, Val Acc: 0.7528, Test Acc: 0.7742\n",
      "Seed: 44, Epoch: 118, Loss: 0.3536, Val Acc: 0.7609, Test Acc: 0.7758\n",
      "Seed: 44, Epoch: 119, Loss: 0.3454, Val Acc: 0.7431, Test Acc: 0.7581\n",
      "Seed: 44, Epoch: 120, Loss: 0.3610, Val Acc: 0.7431, Test Acc: 0.7694\n",
      "Seed: 44, Epoch: 121, Loss: 0.3615, Val Acc: 0.7658, Test Acc: 0.7823\n",
      "Seed: 44, Epoch: 122, Loss: 0.3501, Val Acc: 0.7060, Test Acc: 0.7290\n",
      "Seed: 44, Epoch: 123, Loss: 0.3534, Val Acc: 0.7593, Test Acc: 0.7661\n",
      "Seed: 44, Epoch: 124, Loss: 0.3473, Val Acc: 0.7496, Test Acc: 0.7677\n",
      "Seed: 44, Epoch: 125, Loss: 0.3447, Val Acc: 0.7302, Test Acc: 0.7403\n",
      "Seed: 44, Epoch: 126, Loss: 0.3623, Val Acc: 0.7528, Test Acc: 0.7306\n",
      "Seed: 44, Epoch: 127, Loss: 0.3557, Val Acc: 0.7431, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 128, Loss: 0.3571, Val Acc: 0.7383, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 129, Loss: 0.3466, Val Acc: 0.7625, Test Acc: 0.7710\n",
      "Seed: 44, Epoch: 130, Loss: 0.3382, Val Acc: 0.7399, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 131, Loss: 0.3428, Val Acc: 0.7512, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 132, Loss: 0.3502, Val Acc: 0.7351, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 133, Loss: 0.3305, Val Acc: 0.7302, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 134, Loss: 0.3305, Val Acc: 0.7609, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 135, Loss: 0.3451, Val Acc: 0.7674, Test Acc: 0.7919\n",
      "Seed: 44, Epoch: 136, Loss: 0.3332, Val Acc: 0.7544, Test Acc: 0.7645\n",
      "Seed: 44, Epoch: 137, Loss: 0.3173, Val Acc: 0.7464, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 138, Loss: 0.3309, Val Acc: 0.7464, Test Acc: 0.7403\n",
      "Seed: 44, Epoch: 139, Loss: 0.3447, Val Acc: 0.7351, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 140, Loss: 0.3453, Val Acc: 0.7544, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 141, Loss: 0.3220, Val Acc: 0.7367, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 142, Loss: 0.3332, Val Acc: 0.7625, Test Acc: 0.7581\n",
      "Seed: 44, Epoch: 143, Loss: 0.3209, Val Acc: 0.7399, Test Acc: 0.7806\n",
      "Seed: 44, Epoch: 144, Loss: 0.3452, Val Acc: 0.7205, Test Acc: 0.7177\n",
      "Seed: 44, Epoch: 145, Loss: 0.3341, Val Acc: 0.7157, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 146, Loss: 0.3267, Val Acc: 0.7367, Test Acc: 0.7419\n",
      "Seed: 44, Epoch: 147, Loss: 0.3351, Val Acc: 0.7593, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 148, Loss: 0.3135, Val Acc: 0.7625, Test Acc: 0.7645\n",
      "Seed: 44, Epoch: 149, Loss: 0.3093, Val Acc: 0.7189, Test Acc: 0.7419\n",
      "Seed: 44, Epoch: 150, Loss: 0.3311, Val Acc: 0.7480, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 151, Loss: 0.3126, Val Acc: 0.7367, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 152, Loss: 0.3354, Val Acc: 0.7641, Test Acc: 0.7742\n",
      "Seed: 44, Epoch: 153, Loss: 0.3141, Val Acc: 0.7464, Test Acc: 0.7645\n",
      "Seed: 44, Epoch: 154, Loss: 0.2954, Val Acc: 0.7512, Test Acc: 0.7677\n",
      "Seed: 44, Epoch: 155, Loss: 0.3053, Val Acc: 0.7237, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 156, Loss: 0.3189, Val Acc: 0.7480, Test Acc: 0.7758\n",
      "Seed: 44, Epoch: 157, Loss: 0.3117, Val Acc: 0.7464, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 158, Loss: 0.3007, Val Acc: 0.7544, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 159, Loss: 0.3201, Val Acc: 0.7512, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 160, Loss: 0.3216, Val Acc: 0.7593, Test Acc: 0.7726\n",
      "Seed: 44, Epoch: 161, Loss: 0.2996, Val Acc: 0.7399, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 162, Loss: 0.2968, Val Acc: 0.7399, Test Acc: 0.7726\n",
      "Seed: 44, Epoch: 163, Loss: 0.3177, Val Acc: 0.7464, Test Acc: 0.7468\n",
      "Seed: 44, Epoch: 164, Loss: 0.3145, Val Acc: 0.7674, Test Acc: 0.7710\n",
      "Seed: 44, Epoch: 165, Loss: 0.3138, Val Acc: 0.7447, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 166, Loss: 0.3065, Val Acc: 0.7625, Test Acc: 0.7694\n",
      "Seed: 44, Epoch: 167, Loss: 0.3160, Val Acc: 0.7221, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 168, Loss: 0.2918, Val Acc: 0.7561, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 169, Loss: 0.2944, Val Acc: 0.7431, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 170, Loss: 0.3104, Val Acc: 0.7512, Test Acc: 0.7774\n",
      "Seed: 44, Epoch: 171, Loss: 0.2962, Val Acc: 0.7754, Test Acc: 0.7661\n",
      "Seed: 44, Epoch: 172, Loss: 0.3120, Val Acc: 0.7383, Test Acc: 0.7274\n",
      "Seed: 44, Epoch: 173, Loss: 0.3021, Val Acc: 0.7561, Test Acc: 0.7758\n",
      "Seed: 44, Epoch: 174, Loss: 0.3029, Val Acc: 0.6931, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 175, Loss: 0.3018, Val Acc: 0.6656, Test Acc: 0.6871\n",
      "Seed: 44, Epoch: 176, Loss: 0.3089, Val Acc: 0.7706, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 177, Loss: 0.2929, Val Acc: 0.7205, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 178, Loss: 0.2913, Val Acc: 0.7415, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 179, Loss: 0.2977, Val Acc: 0.7528, Test Acc: 0.7726\n",
      "Seed: 44, Epoch: 180, Loss: 0.2887, Val Acc: 0.7447, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 181, Loss: 0.3000, Val Acc: 0.7690, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 182, Loss: 0.3047, Val Acc: 0.7609, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 183, Loss: 0.2953, Val Acc: 0.7447, Test Acc: 0.7677\n",
      "Seed: 44, Epoch: 184, Loss: 0.3212, Val Acc: 0.7512, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 185, Loss: 0.2918, Val Acc: 0.7367, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 186, Loss: 0.2839, Val Acc: 0.7690, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 187, Loss: 0.3035, Val Acc: 0.7641, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 188, Loss: 0.2922, Val Acc: 0.7367, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 189, Loss: 0.3195, Val Acc: 0.7431, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 190, Loss: 0.2923, Val Acc: 0.7625, Test Acc: 0.7677\n",
      "Seed: 44, Epoch: 191, Loss: 0.2995, Val Acc: 0.7609, Test Acc: 0.7726\n",
      "Seed: 44, Epoch: 192, Loss: 0.2772, Val Acc: 0.7625, Test Acc: 0.7806\n",
      "Seed: 44, Epoch: 193, Loss: 0.2704, Val Acc: 0.7771, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 194, Loss: 0.2770, Val Acc: 0.7577, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 195, Loss: 0.2860, Val Acc: 0.7609, Test Acc: 0.7645\n",
      "Seed: 44, Epoch: 196, Loss: 0.2771, Val Acc: 0.7577, Test Acc: 0.7290\n",
      "Seed: 44, Epoch: 197, Loss: 0.2762, Val Acc: 0.7496, Test Acc: 0.7823\n",
      "Seed: 44, Epoch: 198, Loss: 0.2884, Val Acc: 0.7124, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 199, Loss: 0.2831, Val Acc: 0.7480, Test Acc: 0.7677\n",
      "Seed: 44, Epoch: 200, Loss: 0.2816, Val Acc: 0.7480, Test Acc: 0.7565\n",
      "Average Time: 437.79 seconds\n",
      "Var Time: 15811.35 seconds\n",
      "Average Memory: 396.67 MB\n",
      "Average Best Val Acc: 0.7868\n",
      "Std Best Test Acc: 0.0151\n",
      "Average Test Acc: 0.7634\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "max_nodes = 150\n",
    "data_path = \"/data/Zeyu/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"NCI109\",\n",
    "    transform=T.Compose([T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_justbalance(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        #x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        #x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        #x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_justbalance().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = Net_justbalance().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MUTAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[150, 7], y=[1], adj=[150, 150], mask=[150])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "data_path = \"/data/Zeyu/Pooling\"\n",
    "max_nodes = 150\n",
    "class ConvertToDenseAdj(BaseTransform):\n",
    "    def __call__(self, data):\n",
    "        # 确保 data.adj 存在且为三维\n",
    "        if hasattr(data, 'adj') and data.adj.dim() == 3:\n",
    "            # 对第三维进行合并操作，这里以求和为例\n",
    "            data.adj = data.adj.sum(dim=-1)\n",
    "            # 你可以选择其他方式，如取最大值：\n",
    "            # data.adj = data.adj.max(dim=-1)[0]\n",
    "\n",
    "        return data\n",
    "\n",
    "# 在加载数据时应用这个变换\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"MUTAG\",\n",
    "    transform=T.Compose([T.ToDense(max_nodes), ConvertToDenseAdj()]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "dataset_dense[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6898, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 002, Loss: 0.6871, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 003, Loss: 0.6844, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 004, Loss: 0.6817, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 005, Loss: 0.6789, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 006, Loss: 0.6762, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 007, Loss: 0.6735, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 008, Loss: 0.6708, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 009, Loss: 0.6678, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 010, Loss: 0.6649, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 011, Loss: 0.6618, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 012, Loss: 0.6585, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 013, Loss: 0.6554, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 014, Loss: 0.6516, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 015, Loss: 0.6479, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 016, Loss: 0.6440, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 017, Loss: 0.6402, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 018, Loss: 0.6364, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 019, Loss: 0.6322, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 020, Loss: 0.6282, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 021, Loss: 0.6237, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 022, Loss: 0.6193, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 023, Loss: 0.6148, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 024, Loss: 0.6102, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 025, Loss: 0.6058, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 026, Loss: 0.6015, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 027, Loss: 0.5975, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 028, Loss: 0.5940, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 029, Loss: 0.5911, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 030, Loss: 0.5878, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 031, Loss: 0.5860, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 032, Loss: 0.5835, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 033, Loss: 0.5813, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 034, Loss: 0.5785, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 035, Loss: 0.5760, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 036, Loss: 0.5730, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 037, Loss: 0.5696, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 038, Loss: 0.5654, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 039, Loss: 0.5609, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 040, Loss: 0.5569, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 041, Loss: 0.5535, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 042, Loss: 0.5482, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 043, Loss: 0.5442, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 044, Loss: 0.5400, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 045, Loss: 0.5356, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 046, Loss: 0.5310, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 047, Loss: 0.5267, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 048, Loss: 0.5223, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 049, Loss: 0.5189, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 050, Loss: 0.5145, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 051, Loss: 0.5081, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 052, Loss: 0.5035, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 053, Loss: 0.4979, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 054, Loss: 0.4919, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 055, Loss: 0.4866, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 056, Loss: 0.4807, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 057, Loss: 0.4751, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 058, Loss: 0.4693, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 059, Loss: 0.4628, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 060, Loss: 0.4566, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 061, Loss: 0.4508, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 062, Loss: 0.4466, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 063, Loss: 0.4399, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 064, Loss: 0.4329, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 065, Loss: 0.4265, Val Acc: 0.8214, Test Acc: 0.6207\n",
      "Seed: 42, Epoch: 066, Loss: 0.4202, Val Acc: 0.8214, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 067, Loss: 0.4139, Val Acc: 0.8214, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 068, Loss: 0.4080, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 069, Loss: 0.4019, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 070, Loss: 0.3963, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 071, Loss: 0.3914, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 072, Loss: 0.3855, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 073, Loss: 0.3803, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 074, Loss: 0.3758, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 075, Loss: 0.3727, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 076, Loss: 0.3664, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 077, Loss: 0.3639, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 078, Loss: 0.3608, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 079, Loss: 0.3576, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 080, Loss: 0.3541, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 081, Loss: 0.3502, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 082, Loss: 0.3468, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 083, Loss: 0.3436, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 084, Loss: 0.3454, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 085, Loss: 0.3454, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 086, Loss: 0.3409, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 087, Loss: 0.3470, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 088, Loss: 0.3392, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 089, Loss: 0.3439, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 090, Loss: 0.3394, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 091, Loss: 0.3372, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 092, Loss: 0.3311, Val Acc: 0.8214, Test Acc: 0.7931\n",
      "Seed: 42, Epoch: 093, Loss: 0.3284, Val Acc: 0.8214, Test Acc: 0.7931\n",
      "Seed: 42, Epoch: 094, Loss: 0.3266, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 42, Epoch: 095, Loss: 0.3231, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 42, Epoch: 096, Loss: 0.3166, Val Acc: 0.8214, Test Acc: 0.7931\n",
      "Seed: 42, Epoch: 097, Loss: 0.3146, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 42, Epoch: 098, Loss: 0.3113, Val Acc: 0.8214, Test Acc: 0.7931\n",
      "Seed: 42, Epoch: 099, Loss: 0.3040, Val Acc: 0.8214, Test Acc: 0.7931\n",
      "Seed: 42, Epoch: 100, Loss: 0.3019, Val Acc: 0.7857, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 101, Loss: 0.3009, Val Acc: 0.7857, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 102, Loss: 0.2980, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 103, Loss: 0.2938, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 42, Epoch: 104, Loss: 0.2916, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 105, Loss: 0.2875, Val Acc: 0.8214, Test Acc: 0.7931\n",
      "Seed: 42, Epoch: 106, Loss: 0.2845, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 107, Loss: 0.2806, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 108, Loss: 0.2783, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 109, Loss: 0.2743, Val Acc: 0.8929, Test Acc: 0.8276\n",
      "Seed: 42, Epoch: 110, Loss: 0.2705, Val Acc: 0.9286, Test Acc: 0.8276\n",
      "Seed: 42, Epoch: 111, Loss: 0.2676, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 112, Loss: 0.2647, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 113, Loss: 0.2628, Val Acc: 0.7857, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 114, Loss: 0.2628, Val Acc: 0.7857, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 115, Loss: 0.2589, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 116, Loss: 0.2558, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 117, Loss: 0.2489, Val Acc: 0.8571, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 118, Loss: 0.2481, Val Acc: 0.7857, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 119, Loss: 0.2526, Val Acc: 0.7857, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 120, Loss: 0.2532, Val Acc: 0.8214, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 121, Loss: 0.2539, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 122, Loss: 0.2465, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 123, Loss: 0.2485, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 124, Loss: 0.2449, Val Acc: 0.8571, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 125, Loss: 0.2410, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 126, Loss: 0.2462, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 42, Epoch: 127, Loss: 0.2706, Val Acc: 0.8571, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 128, Loss: 0.2585, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 129, Loss: 0.2545, Val Acc: 0.7500, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 130, Loss: 0.2483, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 131, Loss: 0.2493, Val Acc: 0.7857, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 132, Loss: 0.2460, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 133, Loss: 0.2459, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 134, Loss: 0.2393, Val Acc: 0.8571, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 135, Loss: 0.2370, Val Acc: 0.8929, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 136, Loss: 0.2388, Val Acc: 0.8214, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 137, Loss: 0.2359, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 138, Loss: 0.2362, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 139, Loss: 0.2330, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 140, Loss: 0.2325, Val Acc: 0.8571, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 141, Loss: 0.2291, Val Acc: 0.8214, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 142, Loss: 0.2285, Val Acc: 0.8214, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 143, Loss: 0.2266, Val Acc: 0.8214, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 144, Loss: 0.2260, Val Acc: 0.8214, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 145, Loss: 0.2264, Val Acc: 0.8214, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 146, Loss: 0.2252, Val Acc: 0.8214, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 147, Loss: 0.2245, Val Acc: 0.7500, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 148, Loss: 0.2233, Val Acc: 0.7500, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 149, Loss: 0.2223, Val Acc: 0.7500, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 150, Loss: 0.2217, Val Acc: 0.7500, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 151, Loss: 0.2213, Val Acc: 0.7500, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 152, Loss: 0.2200, Val Acc: 0.8214, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 153, Loss: 0.2191, Val Acc: 0.8214, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 154, Loss: 0.2158, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 155, Loss: 0.2179, Val Acc: 0.8214, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 156, Loss: 0.2164, Val Acc: 0.8214, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 157, Loss: 0.2200, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 158, Loss: 0.2175, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 42, Epoch: 159, Loss: 0.2226, Val Acc: 0.8571, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 160, Loss: 0.2261, Val Acc: 0.8929, Test Acc: 0.8276\n",
      "Seed: 42, Epoch: 161, Loss: 0.2246, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 42, Epoch: 162, Loss: 0.2537, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 42, Epoch: 163, Loss: 0.2491, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 164, Loss: 0.2323, Val Acc: 0.7500, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 165, Loss: 0.2374, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 166, Loss: 0.2364, Val Acc: 0.8929, Test Acc: 0.7931\n",
      "Seed: 42, Epoch: 167, Loss: 0.2338, Val Acc: 0.8929, Test Acc: 0.7931\n",
      "Seed: 42, Epoch: 168, Loss: 0.2297, Val Acc: 0.8571, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 169, Loss: 0.2251, Val Acc: 0.8571, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 170, Loss: 0.2227, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 171, Loss: 0.2230, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 172, Loss: 0.2220, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 173, Loss: 0.2186, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 174, Loss: 0.2167, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 175, Loss: 0.2127, Val Acc: 0.8929, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 176, Loss: 0.2096, Val Acc: 0.9286, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 177, Loss: 0.2072, Val Acc: 0.8929, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 178, Loss: 0.2048, Val Acc: 0.8929, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 179, Loss: 0.2044, Val Acc: 0.8929, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 180, Loss: 0.2054, Val Acc: 0.8929, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 181, Loss: 0.2148, Val Acc: 0.8929, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 182, Loss: 0.2103, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 183, Loss: 0.1988, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 184, Loss: 0.2193, Val Acc: 0.8929, Test Acc: 0.6552\n",
      "Seed: 42, Epoch: 185, Loss: 0.2006, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 186, Loss: 0.2134, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 187, Loss: 0.2091, Val Acc: 0.7857, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 188, Loss: 0.2105, Val Acc: 0.8929, Test Acc: 0.8276\n",
      "Seed: 42, Epoch: 189, Loss: 0.2096, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 190, Loss: 0.2018, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 191, Loss: 0.2005, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 42, Epoch: 192, Loss: 0.1996, Val Acc: 0.8929, Test Acc: 0.8276\n",
      "Seed: 42, Epoch: 193, Loss: 0.1957, Val Acc: 0.7857, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 194, Loss: 0.1902, Val Acc: 0.7500, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 195, Loss: 0.1875, Val Acc: 0.7500, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 196, Loss: 0.1959, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 197, Loss: 0.1982, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 198, Loss: 0.2028, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 199, Loss: 0.2050, Val Acc: 0.8214, Test Acc: 0.6897\n",
      "Seed: 42, Epoch: 200, Loss: 0.2011, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 43, Epoch: 001, Loss: 0.7355, Val Acc: 0.4643, Test Acc: 0.3448\n",
      "Seed: 43, Epoch: 002, Loss: 0.7325, Val Acc: 0.4643, Test Acc: 0.3448\n",
      "Seed: 43, Epoch: 003, Loss: 0.7296, Val Acc: 0.4643, Test Acc: 0.3448\n",
      "Seed: 43, Epoch: 004, Loss: 0.7268, Val Acc: 0.4643, Test Acc: 0.3448\n",
      "Seed: 43, Epoch: 005, Loss: 0.7240, Val Acc: 0.4643, Test Acc: 0.3448\n",
      "Seed: 43, Epoch: 006, Loss: 0.7211, Val Acc: 0.4643, Test Acc: 0.3448\n",
      "Seed: 43, Epoch: 007, Loss: 0.7181, Val Acc: 0.4643, Test Acc: 0.3448\n",
      "Seed: 43, Epoch: 008, Loss: 0.7152, Val Acc: 0.4643, Test Acc: 0.3448\n",
      "Seed: 43, Epoch: 009, Loss: 0.7120, Val Acc: 0.4643, Test Acc: 0.3448\n",
      "Seed: 43, Epoch: 010, Loss: 0.7090, Val Acc: 0.4643, Test Acc: 0.3448\n",
      "Seed: 43, Epoch: 011, Loss: 0.7059, Val Acc: 0.4643, Test Acc: 0.3448\n",
      "Seed: 43, Epoch: 012, Loss: 0.7028, Val Acc: 0.4643, Test Acc: 0.3448\n",
      "Seed: 43, Epoch: 013, Loss: 0.6999, Val Acc: 0.4643, Test Acc: 0.3448\n",
      "Seed: 43, Epoch: 014, Loss: 0.6969, Val Acc: 0.4643, Test Acc: 0.3448\n",
      "Seed: 43, Epoch: 015, Loss: 0.6938, Val Acc: 0.5000, Test Acc: 0.3448\n",
      "Seed: 43, Epoch: 016, Loss: 0.6902, Val Acc: 0.8214, Test Acc: 0.4828\n",
      "Seed: 43, Epoch: 017, Loss: 0.6866, Val Acc: 0.8214, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 018, Loss: 0.6828, Val Acc: 0.6429, Test Acc: 0.7931\n",
      "Seed: 43, Epoch: 019, Loss: 0.6787, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 020, Loss: 0.6746, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 021, Loss: 0.6708, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 022, Loss: 0.6663, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 023, Loss: 0.6620, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 024, Loss: 0.6577, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 025, Loss: 0.6532, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 026, Loss: 0.6484, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 027, Loss: 0.6434, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 028, Loss: 0.6378, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 029, Loss: 0.6337, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 030, Loss: 0.6275, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 031, Loss: 0.6215, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 032, Loss: 0.6150, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 033, Loss: 0.6082, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 034, Loss: 0.6017, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 035, Loss: 0.5951, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 036, Loss: 0.5880, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 037, Loss: 0.5810, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 038, Loss: 0.5741, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 039, Loss: 0.5683, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 040, Loss: 0.5612, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 041, Loss: 0.5558, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 042, Loss: 0.5497, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 043, Loss: 0.5448, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 044, Loss: 0.5397, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 045, Loss: 0.5362, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 046, Loss: 0.5324, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 047, Loss: 0.5296, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 048, Loss: 0.5276, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 049, Loss: 0.5272, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 050, Loss: 0.5274, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 051, Loss: 0.5274, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 052, Loss: 0.5271, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 053, Loss: 0.5259, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 054, Loss: 0.5239, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 055, Loss: 0.5227, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 056, Loss: 0.5200, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 057, Loss: 0.5182, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 058, Loss: 0.5153, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 059, Loss: 0.5139, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 060, Loss: 0.5106, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 061, Loss: 0.5080, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 062, Loss: 0.5053, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 063, Loss: 0.5037, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 064, Loss: 0.5005, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 065, Loss: 0.4989, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 066, Loss: 0.4960, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 067, Loss: 0.4929, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 068, Loss: 0.4916, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 069, Loss: 0.4916, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 070, Loss: 0.4884, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 071, Loss: 0.4849, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 072, Loss: 0.4825, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 073, Loss: 0.4801, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 074, Loss: 0.4774, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 075, Loss: 0.4757, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 076, Loss: 0.4718, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 077, Loss: 0.4686, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 078, Loss: 0.4677, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 079, Loss: 0.4644, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 080, Loss: 0.4653, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 081, Loss: 0.4698, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 082, Loss: 0.4691, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 083, Loss: 0.4640, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 084, Loss: 0.4626, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 085, Loss: 0.4627, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 086, Loss: 0.4611, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 087, Loss: 0.4570, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 088, Loss: 0.4543, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 089, Loss: 0.4509, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 090, Loss: 0.4467, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 091, Loss: 0.4450, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 092, Loss: 0.4413, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 093, Loss: 0.4370, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 094, Loss: 0.4325, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 095, Loss: 0.4300, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 096, Loss: 0.4256, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 097, Loss: 0.4223, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 098, Loss: 0.4176, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 099, Loss: 0.4147, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 100, Loss: 0.4117, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 101, Loss: 0.4073, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 102, Loss: 0.4054, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 103, Loss: 0.4031, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 104, Loss: 0.3994, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 105, Loss: 0.3948, Val Acc: 0.5357, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 106, Loss: 0.3916, Val Acc: 0.5714, Test Acc: 0.6897\n",
      "Seed: 43, Epoch: 107, Loss: 0.3869, Val Acc: 0.6071, Test Acc: 0.6897\n",
      "Seed: 43, Epoch: 108, Loss: 0.3833, Val Acc: 0.6071, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 109, Loss: 0.3795, Val Acc: 0.6071, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 110, Loss: 0.3750, Val Acc: 0.6429, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 111, Loss: 0.3716, Val Acc: 0.6786, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 112, Loss: 0.3711, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 113, Loss: 0.3693, Val Acc: 0.7500, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 114, Loss: 0.3640, Val Acc: 0.7857, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 115, Loss: 0.3619, Val Acc: 0.7857, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 116, Loss: 0.3580, Val Acc: 0.7857, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 117, Loss: 0.3545, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 118, Loss: 0.3510, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 119, Loss: 0.3465, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 120, Loss: 0.3436, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 121, Loss: 0.3402, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 122, Loss: 0.3369, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 123, Loss: 0.3338, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 124, Loss: 0.3300, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 125, Loss: 0.3276, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 43, Epoch: 126, Loss: 0.3242, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 127, Loss: 0.3207, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 128, Loss: 0.3181, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 129, Loss: 0.3146, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 130, Loss: 0.3133, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 43, Epoch: 131, Loss: 0.3227, Val Acc: 0.7857, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 132, Loss: 0.3181, Val Acc: 0.8214, Test Acc: 0.7931\n",
      "Seed: 43, Epoch: 133, Loss: 0.3200, Val Acc: 0.7857, Test Acc: 0.7931\n",
      "Seed: 43, Epoch: 134, Loss: 0.3170, Val Acc: 0.7857, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 135, Loss: 0.3152, Val Acc: 0.7857, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 136, Loss: 0.3121, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 137, Loss: 0.3090, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 138, Loss: 0.3061, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 139, Loss: 0.3045, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 140, Loss: 0.3000, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 141, Loss: 0.2956, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 142, Loss: 0.2932, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 143, Loss: 0.2899, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 144, Loss: 0.2868, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 145, Loss: 0.2838, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 146, Loss: 0.2802, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 147, Loss: 0.2779, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 148, Loss: 0.2765, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 149, Loss: 0.2728, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 150, Loss: 0.2696, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 151, Loss: 0.2672, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 152, Loss: 0.2635, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 153, Loss: 0.2592, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 154, Loss: 0.2553, Val Acc: 0.8214, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 155, Loss: 0.2522, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 156, Loss: 0.2509, Val Acc: 0.8214, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 157, Loss: 0.2504, Val Acc: 0.8214, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 158, Loss: 0.2443, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 159, Loss: 0.2496, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 43, Epoch: 160, Loss: 0.2441, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 161, Loss: 0.2468, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 162, Loss: 0.2406, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 163, Loss: 0.2383, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 164, Loss: 0.2385, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 165, Loss: 0.2329, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 166, Loss: 0.2354, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 167, Loss: 0.2373, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 43, Epoch: 168, Loss: 0.2309, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 43, Epoch: 169, Loss: 0.2319, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 43, Epoch: 170, Loss: 0.2244, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 43, Epoch: 171, Loss: 0.2283, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 172, Loss: 0.2194, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 43, Epoch: 173, Loss: 0.2185, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 43, Epoch: 174, Loss: 0.2179, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 175, Loss: 0.2219, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 176, Loss: 0.2269, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 43, Epoch: 177, Loss: 0.2192, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 178, Loss: 0.2184, Val Acc: 0.9643, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 179, Loss: 0.2152, Val Acc: 0.9286, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 180, Loss: 0.2498, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 181, Loss: 0.2662, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 43, Epoch: 182, Loss: 0.2973, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 183, Loss: 0.2915, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 184, Loss: 0.2841, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 185, Loss: 0.3312, Val Acc: 0.8214, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 186, Loss: 0.3203, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 187, Loss: 0.3134, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 188, Loss: 0.3118, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 189, Loss: 0.3120, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 190, Loss: 0.3083, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 191, Loss: 0.3038, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 192, Loss: 0.3011, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 193, Loss: 0.3009, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 194, Loss: 0.3015, Val Acc: 0.8929, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 195, Loss: 0.3001, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 196, Loss: 0.2930, Val Acc: 0.8571, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 197, Loss: 0.2886, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 198, Loss: 0.2855, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 199, Loss: 0.2828, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 200, Loss: 0.2799, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 44, Epoch: 001, Loss: 0.6612, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 002, Loss: 0.6594, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 003, Loss: 0.6576, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 004, Loss: 0.6559, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 005, Loss: 0.6542, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 006, Loss: 0.6526, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 007, Loss: 0.6511, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 008, Loss: 0.6495, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 009, Loss: 0.6479, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 010, Loss: 0.6462, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 011, Loss: 0.6446, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 012, Loss: 0.6427, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 013, Loss: 0.6406, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 014, Loss: 0.6385, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 015, Loss: 0.6362, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 016, Loss: 0.6338, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 017, Loss: 0.6311, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 018, Loss: 0.6283, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 019, Loss: 0.6252, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 020, Loss: 0.6220, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 021, Loss: 0.6186, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 022, Loss: 0.6149, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 023, Loss: 0.6110, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 024, Loss: 0.6070, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 025, Loss: 0.6026, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 026, Loss: 0.5981, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 027, Loss: 0.5934, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 028, Loss: 0.5919, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 029, Loss: 0.5868, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 030, Loss: 0.5823, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 031, Loss: 0.5773, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 032, Loss: 0.5727, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 033, Loss: 0.5680, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 034, Loss: 0.5638, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 035, Loss: 0.5599, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 036, Loss: 0.5561, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 037, Loss: 0.5533, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 038, Loss: 0.5501, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 039, Loss: 0.5474, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 040, Loss: 0.5451, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 041, Loss: 0.5417, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 042, Loss: 0.5392, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 043, Loss: 0.5361, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 044, Loss: 0.5325, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 045, Loss: 0.5294, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 046, Loss: 0.5255, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 047, Loss: 0.5213, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 048, Loss: 0.5185, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 049, Loss: 0.5139, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 050, Loss: 0.5116, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 051, Loss: 0.5099, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 052, Loss: 0.5043, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 053, Loss: 0.5014, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 054, Loss: 0.4978, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 055, Loss: 0.4926, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 056, Loss: 0.4880, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 057, Loss: 0.4832, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 058, Loss: 0.4784, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 059, Loss: 0.4734, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 060, Loss: 0.4686, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 061, Loss: 0.4635, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 062, Loss: 0.4586, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 063, Loss: 0.4534, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 064, Loss: 0.4479, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 065, Loss: 0.4435, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 066, Loss: 0.4409, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 067, Loss: 0.4351, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 068, Loss: 0.4298, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 069, Loss: 0.4255, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 070, Loss: 0.4201, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 071, Loss: 0.4152, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 072, Loss: 0.4100, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 073, Loss: 0.4048, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 074, Loss: 0.4007, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 075, Loss: 0.3963, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 076, Loss: 0.3917, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 077, Loss: 0.3876, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 078, Loss: 0.3836, Val Acc: 0.6071, Test Acc: 0.6552\n",
      "Seed: 44, Epoch: 079, Loss: 0.3814, Val Acc: 0.6429, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 080, Loss: 0.3819, Val Acc: 0.6429, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 081, Loss: 0.3798, Val Acc: 0.6786, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 082, Loss: 0.3739, Val Acc: 0.7500, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 083, Loss: 0.3784, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 084, Loss: 0.3778, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 085, Loss: 0.3752, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 086, Loss: 0.3719, Val Acc: 0.8214, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 087, Loss: 0.3681, Val Acc: 0.8214, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 088, Loss: 0.3657, Val Acc: 0.8214, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 089, Loss: 0.3634, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 090, Loss: 0.3584, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 091, Loss: 0.3550, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 092, Loss: 0.3522, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 093, Loss: 0.3490, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 094, Loss: 0.3464, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 095, Loss: 0.3432, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 096, Loss: 0.3396, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 097, Loss: 0.3380, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 098, Loss: 0.3393, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 099, Loss: 0.3394, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 100, Loss: 0.3335, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 101, Loss: 0.3295, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 102, Loss: 0.3253, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 103, Loss: 0.3226, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 104, Loss: 0.3210, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 105, Loss: 0.3163, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 106, Loss: 0.3203, Val Acc: 0.8929, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 107, Loss: 0.3245, Val Acc: 0.8929, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 108, Loss: 0.3212, Val Acc: 0.8929, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 109, Loss: 0.3169, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 110, Loss: 0.3203, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 111, Loss: 0.3145, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 112, Loss: 0.3141, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 113, Loss: 0.3105, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 114, Loss: 0.3056, Val Acc: 0.8929, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 115, Loss: 0.3028, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 116, Loss: 0.2997, Val Acc: 0.8929, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 117, Loss: 0.2951, Val Acc: 0.8929, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 118, Loss: 0.2915, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 119, Loss: 0.2879, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 120, Loss: 0.2910, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 121, Loss: 0.2854, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 122, Loss: 0.2809, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 123, Loss: 0.2804, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 124, Loss: 0.2759, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 125, Loss: 0.2744, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 126, Loss: 0.2717, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 127, Loss: 0.2692, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 128, Loss: 0.2628, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 129, Loss: 0.2696, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 130, Loss: 0.2649, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 131, Loss: 0.2588, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 132, Loss: 0.2577, Val Acc: 0.9286, Test Acc: 0.8276\n",
      "Seed: 44, Epoch: 133, Loss: 0.2551, Val Acc: 0.9286, Test Acc: 0.8276\n",
      "Seed: 44, Epoch: 134, Loss: 0.2513, Val Acc: 0.9286, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 135, Loss: 0.2624, Val Acc: 0.9286, Test Acc: 0.8276\n",
      "Seed: 44, Epoch: 136, Loss: 0.2596, Val Acc: 0.9286, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 137, Loss: 0.2662, Val Acc: 0.9286, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 138, Loss: 0.2733, Val Acc: 0.8929, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 139, Loss: 0.2626, Val Acc: 0.8929, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 140, Loss: 0.2620, Val Acc: 0.8929, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 141, Loss: 0.2617, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 142, Loss: 0.2626, Val Acc: 0.8929, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 143, Loss: 0.2611, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 144, Loss: 0.2587, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 145, Loss: 0.2571, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 146, Loss: 0.2559, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 147, Loss: 0.2582, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 148, Loss: 0.2672, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 149, Loss: 0.2624, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 150, Loss: 0.2627, Val Acc: 0.8929, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 151, Loss: 0.2608, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 152, Loss: 0.2603, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 153, Loss: 0.2584, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 154, Loss: 0.2550, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 155, Loss: 0.2522, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 156, Loss: 0.2502, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 157, Loss: 0.2495, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 158, Loss: 0.2480, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 159, Loss: 0.2469, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 160, Loss: 0.2514, Val Acc: 0.8929, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 161, Loss: 0.2430, Val Acc: 0.8929, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 162, Loss: 0.2493, Val Acc: 0.8929, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 163, Loss: 0.2643, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 164, Loss: 0.2603, Val Acc: 0.9286, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 165, Loss: 0.2523, Val Acc: 0.9643, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 166, Loss: 0.2509, Val Acc: 0.9643, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 167, Loss: 0.2582, Val Acc: 0.8929, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 168, Loss: 0.2534, Val Acc: 0.9286, Test Acc: 0.8276\n",
      "Seed: 44, Epoch: 169, Loss: 0.2500, Val Acc: 0.9643, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 170, Loss: 0.2470, Val Acc: 0.8929, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 171, Loss: 0.2498, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 172, Loss: 0.2474, Val Acc: 0.8571, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 173, Loss: 0.2574, Val Acc: 0.8571, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 174, Loss: 0.2498, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 175, Loss: 0.2500, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 176, Loss: 0.2459, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 177, Loss: 0.2454, Val Acc: 0.8929, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 178, Loss: 0.2505, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 179, Loss: 0.2641, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 180, Loss: 0.2505, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 181, Loss: 0.2492, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 182, Loss: 0.2681, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 183, Loss: 0.2529, Val Acc: 0.8214, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 184, Loss: 0.2448, Val Acc: 0.8571, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 185, Loss: 0.2437, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 186, Loss: 0.2429, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 187, Loss: 0.2391, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 188, Loss: 0.2373, Val Acc: 0.8571, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 189, Loss: 0.2357, Val Acc: 0.9286, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 190, Loss: 0.2507, Val Acc: 0.9286, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 191, Loss: 0.2448, Val Acc: 0.8929, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 192, Loss: 0.2590, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 193, Loss: 0.2442, Val Acc: 0.8571, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 194, Loss: 0.2456, Val Acc: 0.8214, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 195, Loss: 0.2443, Val Acc: 0.8571, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 196, Loss: 0.2436, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 197, Loss: 0.2401, Val Acc: 0.8929, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 198, Loss: 0.2406, Val Acc: 0.8571, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 199, Loss: 0.2315, Val Acc: 0.8929, Test Acc: 0.6897\n",
      "Seed: 44, Epoch: 200, Loss: 0.2280, Val Acc: 0.8214, Test Acc: 0.7241\n",
      "Average Time: 19.62 seconds\n",
      "Var Time: 0.06 seconds\n",
      "Average Memory: 294.67 MB\n",
      "Average Best Val Acc: 0.9524\n",
      "Std Best Test Acc: 0.0163\n",
      "Average Test Acc: 0.8161\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_justbalance(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_justbalance().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=512, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "    model = Net_justbalance().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6906, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 002, Loss: 0.6889, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 003, Loss: 0.6877, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 004, Loss: 0.6868, Val Acc: 0.5495, Test Acc: 0.5676\n",
      "Seed: 42, Epoch: 005, Loss: 0.6861, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 006, Loss: 0.6854, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 007, Loss: 0.6847, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 008, Loss: 0.6840, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 009, Loss: 0.6831, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 010, Loss: 0.6820, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 011, Loss: 0.6808, Val Acc: 0.5766, Test Acc: 0.5766\n",
      "Seed: 42, Epoch: 012, Loss: 0.6793, Val Acc: 0.6937, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 013, Loss: 0.6775, Val Acc: 0.7297, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 014, Loss: 0.6752, Val Acc: 0.7748, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 015, Loss: 0.6723, Val Acc: 0.7748, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 016, Loss: 0.6689, Val Acc: 0.7027, Test Acc: 0.6486\n",
      "Seed: 42, Epoch: 017, Loss: 0.6659, Val Acc: 0.7117, Test Acc: 0.6126\n",
      "Seed: 42, Epoch: 018, Loss: 0.6617, Val Acc: 0.6757, Test Acc: 0.6036\n",
      "Seed: 42, Epoch: 019, Loss: 0.6583, Val Acc: 0.6577, Test Acc: 0.5856\n",
      "Seed: 42, Epoch: 020, Loss: 0.6547, Val Acc: 0.6667, Test Acc: 0.6036\n",
      "Seed: 42, Epoch: 021, Loss: 0.6497, Val Acc: 0.6847, Test Acc: 0.5946\n",
      "Seed: 42, Epoch: 022, Loss: 0.6446, Val Acc: 0.7207, Test Acc: 0.6216\n",
      "Seed: 42, Epoch: 023, Loss: 0.6387, Val Acc: 0.7297, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 024, Loss: 0.6346, Val Acc: 0.7928, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 025, Loss: 0.6322, Val Acc: 0.7928, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 026, Loss: 0.6245, Val Acc: 0.7568, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 027, Loss: 0.6138, Val Acc: 0.7117, Test Acc: 0.6306\n",
      "Seed: 42, Epoch: 028, Loss: 0.6070, Val Acc: 0.6667, Test Acc: 0.5946\n",
      "Seed: 42, Epoch: 029, Loss: 0.6070, Val Acc: 0.6486, Test Acc: 0.5766\n",
      "Seed: 42, Epoch: 030, Loss: 0.6080, Val Acc: 0.6667, Test Acc: 0.6036\n",
      "Seed: 42, Epoch: 031, Loss: 0.5982, Val Acc: 0.7117, Test Acc: 0.6396\n",
      "Seed: 42, Epoch: 032, Loss: 0.5837, Val Acc: 0.7748, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 033, Loss: 0.5720, Val Acc: 0.7928, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 034, Loss: 0.5757, Val Acc: 0.7297, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 035, Loss: 0.5830, Val Acc: 0.7748, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 036, Loss: 0.5648, Val Acc: 0.7748, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 037, Loss: 0.5505, Val Acc: 0.7658, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 038, Loss: 0.5414, Val Acc: 0.7568, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 039, Loss: 0.5332, Val Acc: 0.7477, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 040, Loss: 0.5296, Val Acc: 0.7027, Test Acc: 0.6486\n",
      "Seed: 42, Epoch: 041, Loss: 0.5318, Val Acc: 0.6937, Test Acc: 0.6396\n",
      "Seed: 42, Epoch: 042, Loss: 0.5341, Val Acc: 0.7027, Test Acc: 0.6486\n",
      "Seed: 42, Epoch: 043, Loss: 0.5260, Val Acc: 0.6937, Test Acc: 0.6577\n",
      "Seed: 42, Epoch: 044, Loss: 0.5204, Val Acc: 0.7027, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 045, Loss: 0.5137, Val Acc: 0.7117, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 046, Loss: 0.5046, Val Acc: 0.7207, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 047, Loss: 0.4966, Val Acc: 0.7387, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 048, Loss: 0.4784, Val Acc: 0.7748, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 049, Loss: 0.4743, Val Acc: 0.7568, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 050, Loss: 0.4870, Val Acc: 0.7568, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 051, Loss: 0.4874, Val Acc: 0.7568, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 052, Loss: 0.4792, Val Acc: 0.7748, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 053, Loss: 0.4611, Val Acc: 0.7748, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 054, Loss: 0.4508, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 055, Loss: 0.4522, Val Acc: 0.7568, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 056, Loss: 0.4795, Val Acc: 0.6757, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 057, Loss: 0.5150, Val Acc: 0.6216, Test Acc: 0.6216\n",
      "Seed: 42, Epoch: 058, Loss: 0.5592, Val Acc: 0.7117, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 059, Loss: 0.5154, Val Acc: 0.7838, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 060, Loss: 0.4428, Val Acc: 0.8018, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 061, Loss: 0.4281, Val Acc: 0.7838, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 062, Loss: 0.4291, Val Acc: 0.7568, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 063, Loss: 0.4279, Val Acc: 0.7207, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 064, Loss: 0.4392, Val Acc: 0.7477, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 065, Loss: 0.4423, Val Acc: 0.7568, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 066, Loss: 0.4225, Val Acc: 0.7928, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 067, Loss: 0.4191, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 068, Loss: 0.4803, Val Acc: 0.7027, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 069, Loss: 0.4906, Val Acc: 0.7117, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 070, Loss: 0.4523, Val Acc: 0.7387, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 071, Loss: 0.4212, Val Acc: 0.7928, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 072, Loss: 0.3983, Val Acc: 0.8378, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 073, Loss: 0.4023, Val Acc: 0.7838, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 074, Loss: 0.4141, Val Acc: 0.7748, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 075, Loss: 0.4203, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 076, Loss: 0.4177, Val Acc: 0.7928, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 077, Loss: 0.3968, Val Acc: 0.7477, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 078, Loss: 0.4123, Val Acc: 0.7117, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 079, Loss: 0.4530, Val Acc: 0.7838, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 080, Loss: 0.4039, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 081, Loss: 0.4037, Val Acc: 0.7387, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 082, Loss: 0.4516, Val Acc: 0.7117, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 083, Loss: 0.4636, Val Acc: 0.7387, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 084, Loss: 0.4541, Val Acc: 0.7477, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 085, Loss: 0.4391, Val Acc: 0.7928, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 086, Loss: 0.4223, Val Acc: 0.7838, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 087, Loss: 0.4176, Val Acc: 0.7838, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 088, Loss: 0.4142, Val Acc: 0.7838, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 089, Loss: 0.4012, Val Acc: 0.8108, Test Acc: 0.7928\n",
      "Seed: 42, Epoch: 090, Loss: 0.3876, Val Acc: 0.7928, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 091, Loss: 0.3808, Val Acc: 0.7748, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 092, Loss: 0.3820, Val Acc: 0.7748, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 093, Loss: 0.3815, Val Acc: 0.7748, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 094, Loss: 0.3723, Val Acc: 0.7928, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 095, Loss: 0.3668, Val Acc: 0.8018, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 096, Loss: 0.3911, Val Acc: 0.7748, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 097, Loss: 0.4048, Val Acc: 0.8018, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 098, Loss: 0.4045, Val Acc: 0.8018, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 099, Loss: 0.3868, Val Acc: 0.7838, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 100, Loss: 0.3690, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 101, Loss: 0.3606, Val Acc: 0.8198, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 102, Loss: 0.3538, Val Acc: 0.8378, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 103, Loss: 0.3528, Val Acc: 0.8108, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 104, Loss: 0.3519, Val Acc: 0.7928, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 105, Loss: 0.3528, Val Acc: 0.8018, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 106, Loss: 0.3478, Val Acc: 0.8108, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 107, Loss: 0.3441, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 108, Loss: 0.3443, Val Acc: 0.8198, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 109, Loss: 0.3458, Val Acc: 0.7928, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 110, Loss: 0.3661, Val Acc: 0.8198, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 111, Loss: 0.3470, Val Acc: 0.7838, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 112, Loss: 0.3432, Val Acc: 0.7658, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 113, Loss: 0.3519, Val Acc: 0.7928, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 114, Loss: 0.3479, Val Acc: 0.7838, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 115, Loss: 0.3481, Val Acc: 0.8288, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 116, Loss: 0.3612, Val Acc: 0.8108, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 117, Loss: 0.3667, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 118, Loss: 0.3536, Val Acc: 0.7838, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 119, Loss: 0.3441, Val Acc: 0.8018, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 120, Loss: 0.3418, Val Acc: 0.8108, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 121, Loss: 0.3483, Val Acc: 0.7928, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 122, Loss: 0.3437, Val Acc: 0.8198, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 123, Loss: 0.3350, Val Acc: 0.7928, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 124, Loss: 0.3651, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 125, Loss: 0.4088, Val Acc: 0.7207, Test Acc: 0.6577\n",
      "Seed: 42, Epoch: 126, Loss: 0.4297, Val Acc: 0.7477, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 127, Loss: 0.4312, Val Acc: 0.7477, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 128, Loss: 0.4221, Val Acc: 0.7658, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 129, Loss: 0.3893, Val Acc: 0.8378, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 130, Loss: 0.3514, Val Acc: 0.8198, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 131, Loss: 0.3351, Val Acc: 0.8018, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 132, Loss: 0.3307, Val Acc: 0.7838, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 133, Loss: 0.3314, Val Acc: 0.8288, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 134, Loss: 0.3324, Val Acc: 0.8288, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 135, Loss: 0.3418, Val Acc: 0.8378, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 136, Loss: 0.3392, Val Acc: 0.8559, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 137, Loss: 0.3386, Val Acc: 0.8559, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 138, Loss: 0.3369, Val Acc: 0.8468, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 139, Loss: 0.3391, Val Acc: 0.8288, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 140, Loss: 0.3349, Val Acc: 0.8108, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 141, Loss: 0.3309, Val Acc: 0.8198, Test Acc: 0.7838\n",
      "Seed: 42, Epoch: 142, Loss: 0.3239, Val Acc: 0.8108, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 143, Loss: 0.3210, Val Acc: 0.8198, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 144, Loss: 0.3198, Val Acc: 0.8108, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 145, Loss: 0.3197, Val Acc: 0.8108, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 146, Loss: 0.3237, Val Acc: 0.8378, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 147, Loss: 0.3370, Val Acc: 0.8018, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 148, Loss: 0.3533, Val Acc: 0.7748, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 149, Loss: 0.3642, Val Acc: 0.7297, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 150, Loss: 0.3722, Val Acc: 0.7207, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 151, Loss: 0.3526, Val Acc: 0.7477, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 152, Loss: 0.3354, Val Acc: 0.7928, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 153, Loss: 0.3590, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 154, Loss: 0.3506, Val Acc: 0.7477, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 155, Loss: 0.3254, Val Acc: 0.7658, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 156, Loss: 0.3379, Val Acc: 0.7117, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 157, Loss: 0.3608, Val Acc: 0.7477, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 158, Loss: 0.3683, Val Acc: 0.7658, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 159, Loss: 0.3548, Val Acc: 0.8018, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 160, Loss: 0.3400, Val Acc: 0.8198, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 161, Loss: 0.3395, Val Acc: 0.8198, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 162, Loss: 0.3427, Val Acc: 0.7748, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 163, Loss: 0.3447, Val Acc: 0.7568, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 164, Loss: 0.3390, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 165, Loss: 0.3182, Val Acc: 0.8108, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 166, Loss: 0.3112, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 167, Loss: 0.3269, Val Acc: 0.7928, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 168, Loss: 0.3431, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 169, Loss: 0.3340, Val Acc: 0.8198, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 170, Loss: 0.3145, Val Acc: 0.8108, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 171, Loss: 0.3027, Val Acc: 0.8198, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 172, Loss: 0.2904, Val Acc: 0.7928, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 173, Loss: 0.2901, Val Acc: 0.7748, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 174, Loss: 0.2811, Val Acc: 0.8198, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 175, Loss: 0.2884, Val Acc: 0.8108, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 176, Loss: 0.3251, Val Acc: 0.8108, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 177, Loss: 0.3468, Val Acc: 0.8198, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 178, Loss: 0.3442, Val Acc: 0.7748, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 179, Loss: 0.3332, Val Acc: 0.7658, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 180, Loss: 0.3177, Val Acc: 0.8018, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 181, Loss: 0.2972, Val Acc: 0.7748, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 182, Loss: 0.2955, Val Acc: 0.7568, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 183, Loss: 0.3050, Val Acc: 0.8018, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 184, Loss: 0.2979, Val Acc: 0.7658, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 185, Loss: 0.2941, Val Acc: 0.7658, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 186, Loss: 0.2933, Val Acc: 0.7477, Test Acc: 0.7838\n",
      "Seed: 42, Epoch: 187, Loss: 0.2920, Val Acc: 0.7568, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 188, Loss: 0.2920, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 189, Loss: 0.3060, Val Acc: 0.7387, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 190, Loss: 0.3506, Val Acc: 0.7387, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 191, Loss: 0.3877, Val Acc: 0.7658, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 192, Loss: 0.3634, Val Acc: 0.8288, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 193, Loss: 0.3093, Val Acc: 0.8378, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 194, Loss: 0.2792, Val Acc: 0.7207, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 195, Loss: 0.3432, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 196, Loss: 0.3983, Val Acc: 0.7477, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 197, Loss: 0.3250, Val Acc: 0.8198, Test Acc: 0.7928\n",
      "Seed: 42, Epoch: 198, Loss: 0.3021, Val Acc: 0.8018, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 199, Loss: 0.3444, Val Acc: 0.7748, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 200, Loss: 0.3883, Val Acc: 0.7748, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 001, Loss: 0.6913, Val Acc: 0.5405, Test Acc: 0.6126\n",
      "Seed: 43, Epoch: 002, Loss: 0.6902, Val Acc: 0.5405, Test Acc: 0.6126\n",
      "Seed: 43, Epoch: 003, Loss: 0.6897, Val Acc: 0.5405, Test Acc: 0.6216\n",
      "Seed: 43, Epoch: 004, Loss: 0.6890, Val Acc: 0.5495, Test Acc: 0.6396\n",
      "Seed: 43, Epoch: 005, Loss: 0.6882, Val Acc: 0.6126, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 006, Loss: 0.6871, Val Acc: 0.7117, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 007, Loss: 0.6860, Val Acc: 0.7297, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 008, Loss: 0.6846, Val Acc: 0.7207, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 009, Loss: 0.6831, Val Acc: 0.7117, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 010, Loss: 0.6811, Val Acc: 0.6757, Test Acc: 0.6486\n",
      "Seed: 43, Epoch: 011, Loss: 0.6789, Val Acc: 0.6306, Test Acc: 0.5856\n",
      "Seed: 43, Epoch: 012, Loss: 0.6761, Val Acc: 0.5946, Test Acc: 0.5766\n",
      "Seed: 43, Epoch: 013, Loss: 0.6725, Val Acc: 0.5495, Test Acc: 0.5405\n",
      "Seed: 43, Epoch: 014, Loss: 0.6688, Val Acc: 0.5315, Test Acc: 0.5405\n",
      "Seed: 43, Epoch: 015, Loss: 0.6646, Val Acc: 0.5315, Test Acc: 0.5315\n",
      "Seed: 43, Epoch: 016, Loss: 0.6599, Val Acc: 0.5225, Test Acc: 0.5135\n",
      "Seed: 43, Epoch: 017, Loss: 0.6553, Val Acc: 0.5315, Test Acc: 0.5135\n",
      "Seed: 43, Epoch: 018, Loss: 0.6502, Val Acc: 0.5225, Test Acc: 0.5225\n",
      "Seed: 43, Epoch: 019, Loss: 0.6438, Val Acc: 0.5315, Test Acc: 0.5405\n",
      "Seed: 43, Epoch: 020, Loss: 0.6366, Val Acc: 0.5856, Test Acc: 0.5586\n",
      "Seed: 43, Epoch: 021, Loss: 0.6296, Val Acc: 0.6036, Test Acc: 0.5856\n",
      "Seed: 43, Epoch: 022, Loss: 0.6229, Val Acc: 0.6486, Test Acc: 0.5766\n",
      "Seed: 43, Epoch: 023, Loss: 0.6168, Val Acc: 0.6847, Test Acc: 0.6396\n",
      "Seed: 43, Epoch: 024, Loss: 0.6158, Val Acc: 0.7387, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 025, Loss: 0.6144, Val Acc: 0.7207, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 026, Loss: 0.6114, Val Acc: 0.7207, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 027, Loss: 0.6032, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 028, Loss: 0.5887, Val Acc: 0.6757, Test Acc: 0.6396\n",
      "Seed: 43, Epoch: 029, Loss: 0.5770, Val Acc: 0.6667, Test Acc: 0.6216\n",
      "Seed: 43, Epoch: 030, Loss: 0.5689, Val Acc: 0.6937, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 031, Loss: 0.5628, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 032, Loss: 0.5566, Val Acc: 0.7207, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 033, Loss: 0.5538, Val Acc: 0.7297, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 034, Loss: 0.5481, Val Acc: 0.6937, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 035, Loss: 0.5358, Val Acc: 0.6667, Test Acc: 0.6036\n",
      "Seed: 43, Epoch: 036, Loss: 0.5355, Val Acc: 0.6577, Test Acc: 0.6036\n",
      "Seed: 43, Epoch: 037, Loss: 0.5338, Val Acc: 0.6577, Test Acc: 0.6126\n",
      "Seed: 43, Epoch: 038, Loss: 0.5266, Val Acc: 0.7027, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 039, Loss: 0.5175, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 040, Loss: 0.5129, Val Acc: 0.7027, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 041, Loss: 0.5105, Val Acc: 0.6757, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 042, Loss: 0.5091, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 043, Loss: 0.4967, Val Acc: 0.7297, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 044, Loss: 0.4862, Val Acc: 0.7117, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 045, Loss: 0.4898, Val Acc: 0.7027, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 046, Loss: 0.4881, Val Acc: 0.6937, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 047, Loss: 0.4747, Val Acc: 0.7387, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 048, Loss: 0.4637, Val Acc: 0.6847, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 049, Loss: 0.4783, Val Acc: 0.6667, Test Acc: 0.6126\n",
      "Seed: 43, Epoch: 050, Loss: 0.5070, Val Acc: 0.6847, Test Acc: 0.6486\n",
      "Seed: 43, Epoch: 051, Loss: 0.4917, Val Acc: 0.7387, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 052, Loss: 0.4509, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 053, Loss: 0.4715, Val Acc: 0.7027, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 054, Loss: 0.4795, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 055, Loss: 0.4478, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 056, Loss: 0.4484, Val Acc: 0.7207, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 057, Loss: 0.4457, Val Acc: 0.7387, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 058, Loss: 0.4458, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 059, Loss: 0.4433, Val Acc: 0.7297, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 060, Loss: 0.4370, Val Acc: 0.6937, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 061, Loss: 0.4418, Val Acc: 0.6937, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 062, Loss: 0.4393, Val Acc: 0.7117, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 063, Loss: 0.4329, Val Acc: 0.7207, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 064, Loss: 0.4257, Val Acc: 0.7207, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 065, Loss: 0.4197, Val Acc: 0.7387, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 066, Loss: 0.4152, Val Acc: 0.7477, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 067, Loss: 0.4077, Val Acc: 0.7387, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 068, Loss: 0.4051, Val Acc: 0.7568, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 069, Loss: 0.4003, Val Acc: 0.7477, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 070, Loss: 0.3968, Val Acc: 0.7477, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 071, Loss: 0.3924, Val Acc: 0.7387, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 072, Loss: 0.3886, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 073, Loss: 0.3945, Val Acc: 0.6937, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 074, Loss: 0.4055, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 075, Loss: 0.3857, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 076, Loss: 0.3922, Val Acc: 0.7387, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 077, Loss: 0.4102, Val Acc: 0.7387, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 078, Loss: 0.4004, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 079, Loss: 0.3954, Val Acc: 0.7117, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 080, Loss: 0.3772, Val Acc: 0.6847, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 081, Loss: 0.3938, Val Acc: 0.7117, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 082, Loss: 0.3841, Val Acc: 0.7117, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 083, Loss: 0.3788, Val Acc: 0.7387, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 084, Loss: 0.3888, Val Acc: 0.7297, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 085, Loss: 0.3903, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 086, Loss: 0.3765, Val Acc: 0.6937, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 087, Loss: 0.3749, Val Acc: 0.6486, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 088, Loss: 0.4534, Val Acc: 0.6396, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 089, Loss: 0.4937, Val Acc: 0.6847, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 090, Loss: 0.4176, Val Acc: 0.6847, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 091, Loss: 0.3646, Val Acc: 0.7027, Test Acc: 0.6577\n",
      "Seed: 43, Epoch: 092, Loss: 0.4067, Val Acc: 0.6667, Test Acc: 0.6036\n",
      "Seed: 43, Epoch: 093, Loss: 0.4401, Val Acc: 0.6937, Test Acc: 0.6306\n",
      "Seed: 43, Epoch: 094, Loss: 0.4351, Val Acc: 0.7207, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 095, Loss: 0.4085, Val Acc: 0.7207, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 096, Loss: 0.3783, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 097, Loss: 0.3653, Val Acc: 0.7117, Test Acc: 0.6577\n",
      "Seed: 43, Epoch: 098, Loss: 0.3657, Val Acc: 0.6847, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 099, Loss: 0.3674, Val Acc: 0.6667, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 100, Loss: 0.3623, Val Acc: 0.6937, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 101, Loss: 0.3537, Val Acc: 0.6577, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 102, Loss: 0.3561, Val Acc: 0.6667, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 103, Loss: 0.3623, Val Acc: 0.6937, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 104, Loss: 0.3650, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 105, Loss: 0.3568, Val Acc: 0.6847, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 106, Loss: 0.3510, Val Acc: 0.6757, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 107, Loss: 0.3417, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 108, Loss: 0.3414, Val Acc: 0.6847, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 109, Loss: 0.3614, Val Acc: 0.6577, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 110, Loss: 0.3689, Val Acc: 0.7117, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 111, Loss: 0.3525, Val Acc: 0.7117, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 112, Loss: 0.3292, Val Acc: 0.7117, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 113, Loss: 0.3503, Val Acc: 0.6847, Test Acc: 0.6486\n",
      "Seed: 43, Epoch: 114, Loss: 0.4034, Val Acc: 0.6847, Test Acc: 0.6036\n",
      "Seed: 43, Epoch: 115, Loss: 0.4340, Val Acc: 0.6937, Test Acc: 0.6126\n",
      "Seed: 43, Epoch: 116, Loss: 0.4382, Val Acc: 0.6847, Test Acc: 0.6126\n",
      "Seed: 43, Epoch: 117, Loss: 0.4243, Val Acc: 0.7117, Test Acc: 0.6486\n",
      "Seed: 43, Epoch: 118, Loss: 0.3894, Val Acc: 0.7477, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 119, Loss: 0.3551, Val Acc: 0.7207, Test Acc: 0.6486\n",
      "Seed: 43, Epoch: 120, Loss: 0.3444, Val Acc: 0.6937, Test Acc: 0.6577\n",
      "Seed: 43, Epoch: 121, Loss: 0.3426, Val Acc: 0.7387, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 122, Loss: 0.3396, Val Acc: 0.7297, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 123, Loss: 0.3348, Val Acc: 0.7297, Test Acc: 0.6577\n",
      "Seed: 43, Epoch: 124, Loss: 0.3303, Val Acc: 0.7117, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 125, Loss: 0.3279, Val Acc: 0.7207, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 126, Loss: 0.3264, Val Acc: 0.7207, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 127, Loss: 0.3235, Val Acc: 0.7117, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 128, Loss: 0.3219, Val Acc: 0.7117, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 129, Loss: 0.3228, Val Acc: 0.7207, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 130, Loss: 0.3279, Val Acc: 0.6847, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 131, Loss: 0.3316, Val Acc: 0.6847, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 132, Loss: 0.3289, Val Acc: 0.6847, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 133, Loss: 0.3282, Val Acc: 0.7027, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 134, Loss: 0.3323, Val Acc: 0.7297, Test Acc: 0.6577\n",
      "Seed: 43, Epoch: 135, Loss: 0.3224, Val Acc: 0.7387, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 136, Loss: 0.3213, Val Acc: 0.7297, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 137, Loss: 0.3221, Val Acc: 0.7387, Test Acc: 0.6577\n",
      "Seed: 43, Epoch: 138, Loss: 0.3166, Val Acc: 0.7658, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 139, Loss: 0.3126, Val Acc: 0.7658, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 140, Loss: 0.3151, Val Acc: 0.7477, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 141, Loss: 0.3166, Val Acc: 0.7297, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 142, Loss: 0.3256, Val Acc: 0.7207, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 143, Loss: 0.3325, Val Acc: 0.7297, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 144, Loss: 0.3360, Val Acc: 0.7387, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 145, Loss: 0.3253, Val Acc: 0.7477, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 146, Loss: 0.3183, Val Acc: 0.7568, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 147, Loss: 0.3106, Val Acc: 0.7387, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 148, Loss: 0.3017, Val Acc: 0.7477, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 149, Loss: 0.3001, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 150, Loss: 0.3181, Val Acc: 0.7027, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 151, Loss: 0.3154, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 152, Loss: 0.3003, Val Acc: 0.6847, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 153, Loss: 0.2934, Val Acc: 0.6757, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 154, Loss: 0.2898, Val Acc: 0.6757, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 155, Loss: 0.2891, Val Acc: 0.6757, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 156, Loss: 0.2889, Val Acc: 0.6577, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 157, Loss: 0.2897, Val Acc: 0.6757, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 158, Loss: 0.2975, Val Acc: 0.6847, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 159, Loss: 0.3132, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 160, Loss: 0.3313, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 161, Loss: 0.3340, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 162, Loss: 0.3309, Val Acc: 0.6847, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 163, Loss: 0.3261, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 164, Loss: 0.3086, Val Acc: 0.6847, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 165, Loss: 0.3039, Val Acc: 0.6847, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 166, Loss: 0.2932, Val Acc: 0.7027, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 167, Loss: 0.2874, Val Acc: 0.7117, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 168, Loss: 0.2847, Val Acc: 0.7207, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 169, Loss: 0.2810, Val Acc: 0.7117, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 170, Loss: 0.2780, Val Acc: 0.7117, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 171, Loss: 0.2767, Val Acc: 0.7297, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 172, Loss: 0.2795, Val Acc: 0.7477, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 173, Loss: 0.2780, Val Acc: 0.7207, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 174, Loss: 0.2730, Val Acc: 0.6937, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 175, Loss: 0.2816, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 176, Loss: 0.3116, Val Acc: 0.7027, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 177, Loss: 0.3052, Val Acc: 0.7207, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 178, Loss: 0.2992, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 179, Loss: 0.3280, Val Acc: 0.6847, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 180, Loss: 0.3668, Val Acc: 0.6847, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 181, Loss: 0.3516, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 182, Loss: 0.3201, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 183, Loss: 0.3280, Val Acc: 0.6937, Test Acc: 0.6577\n",
      "Seed: 43, Epoch: 184, Loss: 0.3593, Val Acc: 0.7027, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 185, Loss: 0.3837, Val Acc: 0.6847, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 186, Loss: 0.3797, Val Acc: 0.7027, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 187, Loss: 0.3550, Val Acc: 0.7207, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 188, Loss: 0.3149, Val Acc: 0.7207, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 189, Loss: 0.3003, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 43, Epoch: 190, Loss: 0.3215, Val Acc: 0.6667, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 191, Loss: 0.3357, Val Acc: 0.6667, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 192, Loss: 0.3292, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 193, Loss: 0.3017, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 194, Loss: 0.2810, Val Acc: 0.7387, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 195, Loss: 0.2795, Val Acc: 0.7117, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 196, Loss: 0.2912, Val Acc: 0.7477, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 197, Loss: 0.2889, Val Acc: 0.7387, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 198, Loss: 0.2800, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 199, Loss: 0.2740, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 200, Loss: 0.2678, Val Acc: 0.6306, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 001, Loss: 0.6945, Val Acc: 0.5045, Test Acc: 0.4234\n",
      "Seed: 44, Epoch: 002, Loss: 0.6937, Val Acc: 0.5045, Test Acc: 0.4234\n",
      "Seed: 44, Epoch: 003, Loss: 0.6938, Val Acc: 0.5045, Test Acc: 0.4234\n",
      "Seed: 44, Epoch: 004, Loss: 0.6936, Val Acc: 0.5045, Test Acc: 0.4234\n",
      "Seed: 44, Epoch: 005, Loss: 0.6929, Val Acc: 0.5045, Test Acc: 0.4685\n",
      "Seed: 44, Epoch: 006, Loss: 0.6922, Val Acc: 0.6577, Test Acc: 0.6126\n",
      "Seed: 44, Epoch: 007, Loss: 0.6915, Val Acc: 0.7207, Test Acc: 0.7838\n",
      "Seed: 44, Epoch: 008, Loss: 0.6906, Val Acc: 0.6306, Test Acc: 0.6757\n",
      "Seed: 44, Epoch: 009, Loss: 0.6896, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 010, Loss: 0.6887, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 011, Loss: 0.6881, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 012, Loss: 0.6879, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 013, Loss: 0.6873, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 014, Loss: 0.6865, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 015, Loss: 0.6857, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 016, Loss: 0.6844, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 017, Loss: 0.6830, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 018, Loss: 0.6813, Val Acc: 0.5676, Test Acc: 0.6486\n",
      "Seed: 44, Epoch: 019, Loss: 0.6795, Val Acc: 0.6486, Test Acc: 0.7027\n",
      "Seed: 44, Epoch: 020, Loss: 0.6774, Val Acc: 0.6847, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 021, Loss: 0.6748, Val Acc: 0.7207, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 022, Loss: 0.6714, Val Acc: 0.7027, Test Acc: 0.7117\n",
      "Seed: 44, Epoch: 023, Loss: 0.6673, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 024, Loss: 0.6635, Val Acc: 0.7297, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 025, Loss: 0.6584, Val Acc: 0.7477, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 026, Loss: 0.6538, Val Acc: 0.7207, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 027, Loss: 0.6482, Val Acc: 0.7207, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 028, Loss: 0.6420, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 029, Loss: 0.6358, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 030, Loss: 0.6293, Val Acc: 0.7387, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 031, Loss: 0.6229, Val Acc: 0.7297, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 032, Loss: 0.6142, Val Acc: 0.6757, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 033, Loss: 0.6059, Val Acc: 0.6757, Test Acc: 0.7027\n",
      "Seed: 44, Epoch: 034, Loss: 0.5981, Val Acc: 0.7207, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 035, Loss: 0.5875, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 036, Loss: 0.5839, Val Acc: 0.6847, Test Acc: 0.7027\n",
      "Seed: 44, Epoch: 037, Loss: 0.5884, Val Acc: 0.7027, Test Acc: 0.7117\n",
      "Seed: 44, Epoch: 038, Loss: 0.5671, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 039, Loss: 0.5650, Val Acc: 0.6847, Test Acc: 0.6847\n",
      "Seed: 44, Epoch: 040, Loss: 0.5696, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 041, Loss: 0.5553, Val Acc: 0.7207, Test Acc: 0.7117\n",
      "Seed: 44, Epoch: 042, Loss: 0.5433, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 043, Loss: 0.5378, Val Acc: 0.6937, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 044, Loss: 0.5310, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 045, Loss: 0.5256, Val Acc: 0.6847, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 046, Loss: 0.5205, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 047, Loss: 0.5165, Val Acc: 0.7207, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 048, Loss: 0.5132, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 049, Loss: 0.5205, Val Acc: 0.7117, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 050, Loss: 0.5223, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 051, Loss: 0.5022, Val Acc: 0.7027, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 052, Loss: 0.4900, Val Acc: 0.6216, Test Acc: 0.6847\n",
      "Seed: 44, Epoch: 053, Loss: 0.5282, Val Acc: 0.5676, Test Acc: 0.6306\n",
      "Seed: 44, Epoch: 054, Loss: 0.5856, Val Acc: 0.6216, Test Acc: 0.6847\n",
      "Seed: 44, Epoch: 055, Loss: 0.5387, Val Acc: 0.6757, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 056, Loss: 0.4833, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 057, Loss: 0.4761, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 058, Loss: 0.4755, Val Acc: 0.6757, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 059, Loss: 0.4739, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 060, Loss: 0.4683, Val Acc: 0.6937, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 061, Loss: 0.4660, Val Acc: 0.6486, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 062, Loss: 0.4740, Val Acc: 0.6577, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 063, Loss: 0.4670, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 064, Loss: 0.4517, Val Acc: 0.7207, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 065, Loss: 0.4636, Val Acc: 0.6847, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 066, Loss: 0.4907, Val Acc: 0.7027, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 067, Loss: 0.4945, Val Acc: 0.7207, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 068, Loss: 0.4663, Val Acc: 0.6937, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 069, Loss: 0.4389, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 070, Loss: 0.4397, Val Acc: 0.6757, Test Acc: 0.7027\n",
      "Seed: 44, Epoch: 071, Loss: 0.4523, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 072, Loss: 0.4399, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 073, Loss: 0.4330, Val Acc: 0.7027, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 074, Loss: 0.4646, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 075, Loss: 0.4910, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 076, Loss: 0.4842, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 077, Loss: 0.4589, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 078, Loss: 0.4237, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 079, Loss: 0.4098, Val Acc: 0.6396, Test Acc: 0.7117\n",
      "Seed: 44, Epoch: 080, Loss: 0.4368, Val Acc: 0.6126, Test Acc: 0.6847\n",
      "Seed: 44, Epoch: 081, Loss: 0.4555, Val Acc: 0.6306, Test Acc: 0.6757\n",
      "Seed: 44, Epoch: 082, Loss: 0.4273, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 083, Loss: 0.4002, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 084, Loss: 0.3920, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 085, Loss: 0.3863, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 086, Loss: 0.3830, Val Acc: 0.6937, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 087, Loss: 0.3820, Val Acc: 0.6847, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 088, Loss: 0.3846, Val Acc: 0.6757, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 089, Loss: 0.3849, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 090, Loss: 0.3874, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 091, Loss: 0.3825, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 092, Loss: 0.3850, Val Acc: 0.6757, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 093, Loss: 0.3927, Val Acc: 0.6667, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 094, Loss: 0.3856, Val Acc: 0.6847, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 095, Loss: 0.3876, Val Acc: 0.6757, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 096, Loss: 0.3840, Val Acc: 0.6757, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 097, Loss: 0.3792, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 098, Loss: 0.3809, Val Acc: 0.7297, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 099, Loss: 0.4045, Val Acc: 0.7387, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 100, Loss: 0.4260, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 101, Loss: 0.4190, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 102, Loss: 0.4019, Val Acc: 0.6847, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 103, Loss: 0.3823, Val Acc: 0.6757, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 104, Loss: 0.3660, Val Acc: 0.6847, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 105, Loss: 0.3592, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 106, Loss: 0.3546, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 107, Loss: 0.3510, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 108, Loss: 0.3522, Val Acc: 0.6937, Test Acc: 0.7117\n",
      "Seed: 44, Epoch: 109, Loss: 0.3617, Val Acc: 0.7027, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 110, Loss: 0.3394, Val Acc: 0.7297, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 111, Loss: 0.3586, Val Acc: 0.7207, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 112, Loss: 0.3708, Val Acc: 0.7297, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 113, Loss: 0.3438, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 114, Loss: 0.3413, Val Acc: 0.6757, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 115, Loss: 0.4042, Val Acc: 0.6577, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 116, Loss: 0.3968, Val Acc: 0.6667, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 117, Loss: 0.3397, Val Acc: 0.7027, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 118, Loss: 0.3451, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 119, Loss: 0.3773, Val Acc: 0.6847, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 120, Loss: 0.4057, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 121, Loss: 0.3950, Val Acc: 0.7297, Test Acc: 0.7838\n",
      "Seed: 44, Epoch: 122, Loss: 0.3545, Val Acc: 0.7027, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 123, Loss: 0.3351, Val Acc: 0.6396, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 124, Loss: 0.3442, Val Acc: 0.6486, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 125, Loss: 0.3403, Val Acc: 0.6577, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 126, Loss: 0.3296, Val Acc: 0.6667, Test Acc: 0.7928\n",
      "Seed: 44, Epoch: 127, Loss: 0.3227, Val Acc: 0.7117, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 128, Loss: 0.3187, Val Acc: 0.7207, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 129, Loss: 0.3223, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 130, Loss: 0.3227, Val Acc: 0.7117, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 131, Loss: 0.3213, Val Acc: 0.6937, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 132, Loss: 0.3157, Val Acc: 0.6757, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 133, Loss: 0.3244, Val Acc: 0.7207, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 134, Loss: 0.3338, Val Acc: 0.7297, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 135, Loss: 0.3367, Val Acc: 0.7297, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 136, Loss: 0.3505, Val Acc: 0.7297, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 137, Loss: 0.3453, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 138, Loss: 0.3186, Val Acc: 0.7297, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 139, Loss: 0.3024, Val Acc: 0.6757, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 140, Loss: 0.2989, Val Acc: 0.6757, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 141, Loss: 0.3027, Val Acc: 0.6937, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 142, Loss: 0.2968, Val Acc: 0.6937, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 143, Loss: 0.3086, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 144, Loss: 0.3261, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 145, Loss: 0.3477, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 146, Loss: 0.3686, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 147, Loss: 0.3661, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 148, Loss: 0.3286, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 149, Loss: 0.3073, Val Acc: 0.6847, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 150, Loss: 0.3127, Val Acc: 0.6757, Test Acc: 0.6847\n",
      "Seed: 44, Epoch: 151, Loss: 0.3461, Val Acc: 0.6757, Test Acc: 0.6937\n",
      "Seed: 44, Epoch: 152, Loss: 0.3291, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 153, Loss: 0.2911, Val Acc: 0.6937, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 154, Loss: 0.3066, Val Acc: 0.6937, Test Acc: 0.7838\n",
      "Seed: 44, Epoch: 155, Loss: 0.3685, Val Acc: 0.7207, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 156, Loss: 0.3775, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 157, Loss: 0.3859, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 158, Loss: 0.3575, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 159, Loss: 0.3179, Val Acc: 0.7027, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 160, Loss: 0.2959, Val Acc: 0.6847, Test Acc: 0.6667\n",
      "Seed: 44, Epoch: 161, Loss: 0.2986, Val Acc: 0.6486, Test Acc: 0.6757\n",
      "Seed: 44, Epoch: 162, Loss: 0.3256, Val Acc: 0.6667, Test Acc: 0.7027\n",
      "Seed: 44, Epoch: 163, Loss: 0.3079, Val Acc: 0.6667, Test Acc: 0.7027\n",
      "Seed: 44, Epoch: 164, Loss: 0.2867, Val Acc: 0.6847, Test Acc: 0.7928\n",
      "Seed: 44, Epoch: 165, Loss: 0.2801, Val Acc: 0.6847, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 166, Loss: 0.2927, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 167, Loss: 0.3018, Val Acc: 0.6937, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 168, Loss: 0.3001, Val Acc: 0.7117, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 169, Loss: 0.2939, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 170, Loss: 0.2816, Val Acc: 0.6577, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 171, Loss: 0.2739, Val Acc: 0.6577, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 172, Loss: 0.2764, Val Acc: 0.6847, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 173, Loss: 0.2701, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 174, Loss: 0.2610, Val Acc: 0.7117, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 175, Loss: 0.2714, Val Acc: 0.7207, Test Acc: 0.7387\n",
      "Early stopping at epoch 175 for seed 44\n",
      "Average Time: 183.67 seconds\n",
      "Var Time: 170.86 seconds\n",
      "Average Memory: 4124.00 MB\n",
      "Average Best Val Acc: 0.7898\n",
      "Std Best Test Acc: 0.0212\n",
      "Average Test Acc: 0.7177\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "max_nodes = 500\n",
    "data_path = \"/data/Zeyu/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"DD\",\n",
    "    transform=T.Compose([T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_justbalance(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_justbalance().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=512, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "    model = Net_justbalance().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB-BINARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6921, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 002, Loss: 0.6737, Val Acc: 0.7667, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 003, Loss: 0.6334, Val Acc: 0.7933, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 004, Loss: 0.5771, Val Acc: 0.7467, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 005, Loss: 0.5515, Val Acc: 0.7800, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 006, Loss: 0.5379, Val Acc: 0.7867, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 007, Loss: 0.5308, Val Acc: 0.7733, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 008, Loss: 0.5197, Val Acc: 0.7800, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 009, Loss: 0.5096, Val Acc: 0.8067, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 010, Loss: 0.5081, Val Acc: 0.8000, Test Acc: 0.8267\n",
      "Seed: 42, Epoch: 011, Loss: 0.4993, Val Acc: 0.8133, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 012, Loss: 0.4974, Val Acc: 0.8133, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 013, Loss: 0.4821, Val Acc: 0.8000, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 014, Loss: 0.4814, Val Acc: 0.8000, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 015, Loss: 0.4749, Val Acc: 0.7600, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 016, Loss: 0.4829, Val Acc: 0.8067, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 017, Loss: 0.4814, Val Acc: 0.7600, Test Acc: 0.8333\n",
      "Seed: 42, Epoch: 018, Loss: 0.4848, Val Acc: 0.7533, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 019, Loss: 0.4895, Val Acc: 0.8133, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 020, Loss: 0.4746, Val Acc: 0.8000, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 021, Loss: 0.4796, Val Acc: 0.7800, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 022, Loss: 0.4684, Val Acc: 0.8133, Test Acc: 0.8133\n",
      "Seed: 42, Epoch: 023, Loss: 0.4731, Val Acc: 0.8200, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 024, Loss: 0.4655, Val Acc: 0.7867, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 025, Loss: 0.4650, Val Acc: 0.8200, Test Acc: 0.8133\n",
      "Seed: 42, Epoch: 026, Loss: 0.4632, Val Acc: 0.7933, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 027, Loss: 0.4598, Val Acc: 0.7800, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 028, Loss: 0.4548, Val Acc: 0.7933, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 029, Loss: 0.4582, Val Acc: 0.7733, Test Acc: 0.8133\n",
      "Seed: 42, Epoch: 030, Loss: 0.4540, Val Acc: 0.7733, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 031, Loss: 0.4607, Val Acc: 0.7733, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 032, Loss: 0.4697, Val Acc: 0.7600, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 033, Loss: 0.4470, Val Acc: 0.8067, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 034, Loss: 0.4433, Val Acc: 0.7733, Test Acc: 0.8133\n",
      "Seed: 42, Epoch: 035, Loss: 0.4443, Val Acc: 0.7867, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 036, Loss: 0.4377, Val Acc: 0.7533, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 037, Loss: 0.4377, Val Acc: 0.7667, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 038, Loss: 0.4390, Val Acc: 0.7867, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 039, Loss: 0.4570, Val Acc: 0.7533, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 040, Loss: 0.4386, Val Acc: 0.7667, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 041, Loss: 0.4305, Val Acc: 0.7667, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 042, Loss: 0.4418, Val Acc: 0.7467, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 043, Loss: 0.4434, Val Acc: 0.7667, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 044, Loss: 0.4366, Val Acc: 0.7800, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 045, Loss: 0.4303, Val Acc: 0.7467, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 046, Loss: 0.4240, Val Acc: 0.7400, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 047, Loss: 0.4200, Val Acc: 0.7600, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 048, Loss: 0.4274, Val Acc: 0.7200, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 049, Loss: 0.4278, Val Acc: 0.7400, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 050, Loss: 0.4287, Val Acc: 0.8067, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 051, Loss: 0.4340, Val Acc: 0.7733, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 052, Loss: 0.4312, Val Acc: 0.7667, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 053, Loss: 0.4017, Val Acc: 0.7333, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 054, Loss: 0.4109, Val Acc: 0.7600, Test Acc: 0.8133\n",
      "Seed: 42, Epoch: 055, Loss: 0.4041, Val Acc: 0.7400, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 056, Loss: 0.4094, Val Acc: 0.7533, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 057, Loss: 0.4021, Val Acc: 0.7400, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 058, Loss: 0.4127, Val Acc: 0.7600, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 059, Loss: 0.4167, Val Acc: 0.7533, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 060, Loss: 0.4001, Val Acc: 0.7800, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 061, Loss: 0.4010, Val Acc: 0.7400, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 062, Loss: 0.3827, Val Acc: 0.7733, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 063, Loss: 0.4061, Val Acc: 0.7267, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 064, Loss: 0.3997, Val Acc: 0.7333, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 065, Loss: 0.4031, Val Acc: 0.7867, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 066, Loss: 0.3958, Val Acc: 0.7867, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 067, Loss: 0.3885, Val Acc: 0.7667, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 068, Loss: 0.3948, Val Acc: 0.7600, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 069, Loss: 0.3894, Val Acc: 0.7667, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 070, Loss: 0.3812, Val Acc: 0.7600, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 071, Loss: 0.3761, Val Acc: 0.7867, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 072, Loss: 0.4033, Val Acc: 0.7600, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 073, Loss: 0.4122, Val Acc: 0.7800, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 074, Loss: 0.3898, Val Acc: 0.7667, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 075, Loss: 0.3845, Val Acc: 0.7400, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 076, Loss: 0.3882, Val Acc: 0.7800, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 077, Loss: 0.3802, Val Acc: 0.7333, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 078, Loss: 0.3868, Val Acc: 0.7800, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 079, Loss: 0.3814, Val Acc: 0.7467, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 080, Loss: 0.3758, Val Acc: 0.7267, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 081, Loss: 0.3879, Val Acc: 0.7867, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 082, Loss: 0.3787, Val Acc: 0.7733, Test Acc: 0.7000\n",
      "Seed: 42, Epoch: 083, Loss: 0.3862, Val Acc: 0.7600, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 084, Loss: 0.3681, Val Acc: 0.7600, Test Acc: 0.6800\n",
      "Seed: 42, Epoch: 085, Loss: 0.3568, Val Acc: 0.7267, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 086, Loss: 0.3798, Val Acc: 0.7400, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 087, Loss: 0.3879, Val Acc: 0.7333, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 088, Loss: 0.3993, Val Acc: 0.7867, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 089, Loss: 0.3827, Val Acc: 0.7667, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 090, Loss: 0.3732, Val Acc: 0.7200, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 091, Loss: 0.3663, Val Acc: 0.7000, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 092, Loss: 0.3621, Val Acc: 0.7267, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 093, Loss: 0.3642, Val Acc: 0.7200, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 094, Loss: 0.3596, Val Acc: 0.7933, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 095, Loss: 0.3614, Val Acc: 0.7333, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 096, Loss: 0.3412, Val Acc: 0.7400, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 097, Loss: 0.3498, Val Acc: 0.7600, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 098, Loss: 0.3768, Val Acc: 0.7333, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 099, Loss: 0.3754, Val Acc: 0.7600, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 100, Loss: 0.3899, Val Acc: 0.7667, Test Acc: 0.7067\n",
      "Seed: 42, Epoch: 101, Loss: 0.3843, Val Acc: 0.7800, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 102, Loss: 0.3790, Val Acc: 0.7867, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 103, Loss: 0.3908, Val Acc: 0.7667, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 104, Loss: 0.3737, Val Acc: 0.7200, Test Acc: 0.7133\n",
      "Seed: 42, Epoch: 105, Loss: 0.3612, Val Acc: 0.7533, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 106, Loss: 0.3784, Val Acc: 0.7667, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 107, Loss: 0.3783, Val Acc: 0.7867, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 108, Loss: 0.3566, Val Acc: 0.7400, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 109, Loss: 0.3494, Val Acc: 0.7867, Test Acc: 0.6867\n",
      "Seed: 42, Epoch: 110, Loss: 0.3569, Val Acc: 0.7733, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 111, Loss: 0.3448, Val Acc: 0.7533, Test Acc: 0.7000\n",
      "Seed: 42, Epoch: 112, Loss: 0.3461, Val Acc: 0.7400, Test Acc: 0.7133\n",
      "Seed: 42, Epoch: 113, Loss: 0.3509, Val Acc: 0.7333, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 114, Loss: 0.3352, Val Acc: 0.7800, Test Acc: 0.6867\n",
      "Seed: 42, Epoch: 115, Loss: 0.3439, Val Acc: 0.7733, Test Acc: 0.6800\n",
      "Seed: 42, Epoch: 116, Loss: 0.3429, Val Acc: 0.7733, Test Acc: 0.6933\n",
      "Seed: 42, Epoch: 117, Loss: 0.3282, Val Acc: 0.7867, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 118, Loss: 0.3371, Val Acc: 0.7467, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 119, Loss: 0.3430, Val Acc: 0.7533, Test Acc: 0.6867\n",
      "Seed: 42, Epoch: 120, Loss: 0.3476, Val Acc: 0.7200, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 121, Loss: 0.3258, Val Acc: 0.7133, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 122, Loss: 0.3470, Val Acc: 0.7533, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 123, Loss: 0.3800, Val Acc: 0.7600, Test Acc: 0.7067\n",
      "Seed: 42, Epoch: 124, Loss: 0.3324, Val Acc: 0.7200, Test Acc: 0.7067\n",
      "Seed: 42, Epoch: 125, Loss: 0.3475, Val Acc: 0.7600, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 126, Loss: 0.3316, Val Acc: 0.7800, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 127, Loss: 0.3302, Val Acc: 0.7533, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 128, Loss: 0.3227, Val Acc: 0.7600, Test Acc: 0.6733\n",
      "Seed: 42, Epoch: 129, Loss: 0.3389, Val Acc: 0.7267, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 130, Loss: 0.3387, Val Acc: 0.7267, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 131, Loss: 0.3488, Val Acc: 0.7533, Test Acc: 0.6733\n",
      "Seed: 42, Epoch: 132, Loss: 0.3488, Val Acc: 0.7733, Test Acc: 0.7133\n",
      "Seed: 42, Epoch: 133, Loss: 0.3335, Val Acc: 0.7333, Test Acc: 0.7067\n",
      "Seed: 42, Epoch: 134, Loss: 0.3402, Val Acc: 0.7867, Test Acc: 0.7000\n",
      "Seed: 42, Epoch: 135, Loss: 0.3446, Val Acc: 0.7333, Test Acc: 0.7133\n",
      "Seed: 42, Epoch: 136, Loss: 0.3217, Val Acc: 0.7333, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 137, Loss: 0.3372, Val Acc: 0.7200, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 138, Loss: 0.3312, Val Acc: 0.7600, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 139, Loss: 0.3338, Val Acc: 0.7600, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 140, Loss: 0.3400, Val Acc: 0.7267, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 141, Loss: 0.3280, Val Acc: 0.7400, Test Acc: 0.6867\n",
      "Seed: 42, Epoch: 142, Loss: 0.3144, Val Acc: 0.7267, Test Acc: 0.7133\n",
      "Seed: 42, Epoch: 143, Loss: 0.3096, Val Acc: 0.7467, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 144, Loss: 0.3395, Val Acc: 0.7400, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 145, Loss: 0.3350, Val Acc: 0.7667, Test Acc: 0.7067\n",
      "Seed: 42, Epoch: 146, Loss: 0.3144, Val Acc: 0.7333, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 147, Loss: 0.3278, Val Acc: 0.7467, Test Acc: 0.7133\n",
      "Seed: 42, Epoch: 148, Loss: 0.3137, Val Acc: 0.7200, Test Acc: 0.7133\n",
      "Seed: 42, Epoch: 149, Loss: 0.3233, Val Acc: 0.7133, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 150, Loss: 0.3165, Val Acc: 0.7267, Test Acc: 0.7000\n",
      "Seed: 42, Epoch: 151, Loss: 0.3151, Val Acc: 0.7133, Test Acc: 0.6733\n",
      "Seed: 42, Epoch: 152, Loss: 0.3026, Val Acc: 0.7467, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 153, Loss: 0.3039, Val Acc: 0.7067, Test Acc: 0.6733\n",
      "Seed: 42, Epoch: 154, Loss: 0.3207, Val Acc: 0.6933, Test Acc: 0.7133\n",
      "Seed: 42, Epoch: 155, Loss: 0.3009, Val Acc: 0.7467, Test Acc: 0.6533\n",
      "Seed: 42, Epoch: 156, Loss: 0.3102, Val Acc: 0.7667, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 157, Loss: 0.3214, Val Acc: 0.7267, Test Acc: 0.6867\n",
      "Seed: 42, Epoch: 158, Loss: 0.3194, Val Acc: 0.7400, Test Acc: 0.6867\n",
      "Seed: 42, Epoch: 159, Loss: 0.3167, Val Acc: 0.7400, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 160, Loss: 0.3279, Val Acc: 0.7333, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 161, Loss: 0.3151, Val Acc: 0.7333, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 162, Loss: 0.3134, Val Acc: 0.7267, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 163, Loss: 0.3151, Val Acc: 0.7267, Test Acc: 0.7067\n",
      "Seed: 42, Epoch: 164, Loss: 0.3350, Val Acc: 0.7467, Test Acc: 0.7067\n",
      "Seed: 42, Epoch: 165, Loss: 0.3332, Val Acc: 0.7533, Test Acc: 0.7067\n",
      "Seed: 42, Epoch: 166, Loss: 0.3120, Val Acc: 0.7600, Test Acc: 0.6600\n",
      "Seed: 42, Epoch: 167, Loss: 0.3325, Val Acc: 0.7533, Test Acc: 0.6533\n",
      "Seed: 42, Epoch: 168, Loss: 0.3060, Val Acc: 0.7400, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 169, Loss: 0.3102, Val Acc: 0.7133, Test Acc: 0.6933\n",
      "Seed: 42, Epoch: 170, Loss: 0.2981, Val Acc: 0.6933, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 171, Loss: 0.2836, Val Acc: 0.7400, Test Acc: 0.7000\n",
      "Seed: 42, Epoch: 172, Loss: 0.2947, Val Acc: 0.6933, Test Acc: 0.6933\n",
      "Seed: 42, Epoch: 173, Loss: 0.2868, Val Acc: 0.7267, Test Acc: 0.7467\n",
      "Early stopping at epoch 173 for seed 42\n",
      "Seed: 43, Epoch: 001, Loss: 0.6912, Val Acc: 0.6333, Test Acc: 0.5867\n",
      "Seed: 43, Epoch: 002, Loss: 0.6701, Val Acc: 0.6200, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 003, Loss: 0.6182, Val Acc: 0.6333, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 004, Loss: 0.5519, Val Acc: 0.6467, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 005, Loss: 0.5171, Val Acc: 0.6467, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 006, Loss: 0.5025, Val Acc: 0.6600, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 007, Loss: 0.4947, Val Acc: 0.6400, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 008, Loss: 0.4850, Val Acc: 0.6600, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 009, Loss: 0.4872, Val Acc: 0.6267, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 010, Loss: 0.4816, Val Acc: 0.6400, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 011, Loss: 0.4701, Val Acc: 0.6867, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 012, Loss: 0.4697, Val Acc: 0.6333, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 013, Loss: 0.4670, Val Acc: 0.6533, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 014, Loss: 0.4602, Val Acc: 0.6533, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 015, Loss: 0.4574, Val Acc: 0.6600, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 016, Loss: 0.4565, Val Acc: 0.6667, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 017, Loss: 0.4482, Val Acc: 0.6733, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 018, Loss: 0.4454, Val Acc: 0.6600, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 019, Loss: 0.4482, Val Acc: 0.6600, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 020, Loss: 0.4542, Val Acc: 0.6267, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 021, Loss: 0.4477, Val Acc: 0.6533, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 022, Loss: 0.4412, Val Acc: 0.6600, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 023, Loss: 0.4510, Val Acc: 0.6667, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 024, Loss: 0.4464, Val Acc: 0.6600, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 025, Loss: 0.4443, Val Acc: 0.6800, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 026, Loss: 0.4375, Val Acc: 0.6467, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 027, Loss: 0.4281, Val Acc: 0.6467, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 028, Loss: 0.4212, Val Acc: 0.6200, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 029, Loss: 0.4170, Val Acc: 0.6467, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 030, Loss: 0.4219, Val Acc: 0.6467, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 031, Loss: 0.4189, Val Acc: 0.6733, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 032, Loss: 0.4179, Val Acc: 0.6800, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 033, Loss: 0.4199, Val Acc: 0.6467, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 034, Loss: 0.4299, Val Acc: 0.6800, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 035, Loss: 0.4210, Val Acc: 0.6600, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 036, Loss: 0.4250, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 037, Loss: 0.4203, Val Acc: 0.6400, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 038, Loss: 0.4126, Val Acc: 0.6733, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 039, Loss: 0.4060, Val Acc: 0.6400, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 040, Loss: 0.4051, Val Acc: 0.6467, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 041, Loss: 0.4060, Val Acc: 0.6600, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 042, Loss: 0.3981, Val Acc: 0.6533, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 043, Loss: 0.4111, Val Acc: 0.6733, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 044, Loss: 0.4084, Val Acc: 0.6333, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 045, Loss: 0.3946, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 046, Loss: 0.3923, Val Acc: 0.6467, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 047, Loss: 0.3821, Val Acc: 0.6600, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 048, Loss: 0.3916, Val Acc: 0.6600, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 049, Loss: 0.3936, Val Acc: 0.6933, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 050, Loss: 0.3977, Val Acc: 0.6600, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 051, Loss: 0.3996, Val Acc: 0.6333, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 052, Loss: 0.3823, Val Acc: 0.6467, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 053, Loss: 0.3876, Val Acc: 0.6667, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 054, Loss: 0.3784, Val Acc: 0.6667, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 055, Loss: 0.3764, Val Acc: 0.7000, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 056, Loss: 0.3790, Val Acc: 0.6800, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 057, Loss: 0.3737, Val Acc: 0.6867, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 058, Loss: 0.3743, Val Acc: 0.6467, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 059, Loss: 0.3800, Val Acc: 0.6933, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 060, Loss: 0.3694, Val Acc: 0.6467, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 061, Loss: 0.3718, Val Acc: 0.6600, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 062, Loss: 0.3577, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 063, Loss: 0.3693, Val Acc: 0.6467, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 064, Loss: 0.3645, Val Acc: 0.6467, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 065, Loss: 0.3601, Val Acc: 0.6400, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 066, Loss: 0.3672, Val Acc: 0.6600, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 067, Loss: 0.3538, Val Acc: 0.6600, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 068, Loss: 0.3450, Val Acc: 0.6533, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 069, Loss: 0.3411, Val Acc: 0.6667, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 070, Loss: 0.3445, Val Acc: 0.6400, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 071, Loss: 0.3573, Val Acc: 0.6600, Test Acc: 0.6933\n",
      "Seed: 43, Epoch: 072, Loss: 0.3533, Val Acc: 0.6667, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 073, Loss: 0.3673, Val Acc: 0.6600, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 074, Loss: 0.3642, Val Acc: 0.7067, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 075, Loss: 0.3786, Val Acc: 0.6867, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 076, Loss: 0.3667, Val Acc: 0.6867, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 077, Loss: 0.3554, Val Acc: 0.6867, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 078, Loss: 0.3588, Val Acc: 0.6733, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 079, Loss: 0.3649, Val Acc: 0.7200, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 080, Loss: 0.3569, Val Acc: 0.6667, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 081, Loss: 0.3669, Val Acc: 0.7267, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 082, Loss: 0.3633, Val Acc: 0.6867, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 083, Loss: 0.3747, Val Acc: 0.7200, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 084, Loss: 0.3808, Val Acc: 0.6800, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 085, Loss: 0.3767, Val Acc: 0.7133, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 086, Loss: 0.3832, Val Acc: 0.6867, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 087, Loss: 0.3766, Val Acc: 0.6933, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 088, Loss: 0.3618, Val Acc: 0.6667, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 089, Loss: 0.3651, Val Acc: 0.6933, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 090, Loss: 0.3713, Val Acc: 0.7000, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 091, Loss: 0.3648, Val Acc: 0.7067, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 092, Loss: 0.3581, Val Acc: 0.6667, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 093, Loss: 0.3536, Val Acc: 0.6800, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 094, Loss: 0.3593, Val Acc: 0.6733, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 095, Loss: 0.3583, Val Acc: 0.6733, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 096, Loss: 0.3630, Val Acc: 0.6600, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 097, Loss: 0.3586, Val Acc: 0.6467, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 098, Loss: 0.3566, Val Acc: 0.6533, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 099, Loss: 0.3569, Val Acc: 0.6733, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 100, Loss: 0.3573, Val Acc: 0.6733, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 101, Loss: 0.3414, Val Acc: 0.6400, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 102, Loss: 0.3438, Val Acc: 0.6200, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 103, Loss: 0.3522, Val Acc: 0.6467, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 104, Loss: 0.3418, Val Acc: 0.6400, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 105, Loss: 0.3431, Val Acc: 0.6733, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 106, Loss: 0.3309, Val Acc: 0.6333, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 107, Loss: 0.3418, Val Acc: 0.6333, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 108, Loss: 0.3295, Val Acc: 0.6400, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 109, Loss: 0.3377, Val Acc: 0.6600, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 110, Loss: 0.3403, Val Acc: 0.6533, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 111, Loss: 0.3346, Val Acc: 0.6467, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 112, Loss: 0.3382, Val Acc: 0.6733, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 113, Loss: 0.3425, Val Acc: 0.6733, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 114, Loss: 0.3237, Val Acc: 0.6733, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 115, Loss: 0.3374, Val Acc: 0.6600, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 116, Loss: 0.3407, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 117, Loss: 0.3478, Val Acc: 0.6667, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 118, Loss: 0.3693, Val Acc: 0.6667, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 119, Loss: 0.3492, Val Acc: 0.6400, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 120, Loss: 0.3370, Val Acc: 0.6667, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 121, Loss: 0.3292, Val Acc: 0.6400, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 122, Loss: 0.3395, Val Acc: 0.6667, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 123, Loss: 0.3370, Val Acc: 0.6533, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 124, Loss: 0.3299, Val Acc: 0.6733, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 125, Loss: 0.3338, Val Acc: 0.6667, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 126, Loss: 0.3385, Val Acc: 0.6600, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 127, Loss: 0.3262, Val Acc: 0.6600, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 128, Loss: 0.3274, Val Acc: 0.6733, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 129, Loss: 0.3275, Val Acc: 0.6600, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 130, Loss: 0.3164, Val Acc: 0.6467, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 131, Loss: 0.3114, Val Acc: 0.6467, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 132, Loss: 0.3160, Val Acc: 0.6467, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 133, Loss: 0.3149, Val Acc: 0.6533, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 134, Loss: 0.3324, Val Acc: 0.6667, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 135, Loss: 0.3160, Val Acc: 0.6867, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 136, Loss: 0.3048, Val Acc: 0.6533, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 137, Loss: 0.2986, Val Acc: 0.6533, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 138, Loss: 0.2998, Val Acc: 0.6267, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 139, Loss: 0.2929, Val Acc: 0.6000, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 140, Loss: 0.3044, Val Acc: 0.6400, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 141, Loss: 0.2947, Val Acc: 0.6600, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 142, Loss: 0.3101, Val Acc: 0.6333, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 143, Loss: 0.2987, Val Acc: 0.6533, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 144, Loss: 0.2985, Val Acc: 0.6600, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 145, Loss: 0.2931, Val Acc: 0.6933, Test Acc: 0.6933\n",
      "Seed: 43, Epoch: 146, Loss: 0.3173, Val Acc: 0.6467, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 147, Loss: 0.3090, Val Acc: 0.6733, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 148, Loss: 0.3102, Val Acc: 0.6333, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 149, Loss: 0.3117, Val Acc: 0.6800, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 150, Loss: 0.3209, Val Acc: 0.6467, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 151, Loss: 0.3336, Val Acc: 0.6400, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 152, Loss: 0.3031, Val Acc: 0.6733, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 153, Loss: 0.3148, Val Acc: 0.6400, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 154, Loss: 0.3078, Val Acc: 0.6333, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 155, Loss: 0.2983, Val Acc: 0.6333, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 156, Loss: 0.2980, Val Acc: 0.6667, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 157, Loss: 0.3092, Val Acc: 0.6333, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 158, Loss: 0.3119, Val Acc: 0.6467, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 159, Loss: 0.2932, Val Acc: 0.5733, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 160, Loss: 0.2923, Val Acc: 0.6533, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 161, Loss: 0.3048, Val Acc: 0.6400, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 162, Loss: 0.2963, Val Acc: 0.6200, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 163, Loss: 0.3083, Val Acc: 0.6000, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 164, Loss: 0.3205, Val Acc: 0.6200, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 165, Loss: 0.3126, Val Acc: 0.6133, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 166, Loss: 0.3039, Val Acc: 0.5867, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 167, Loss: 0.2999, Val Acc: 0.6000, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 168, Loss: 0.3033, Val Acc: 0.6267, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 169, Loss: 0.2980, Val Acc: 0.6067, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 170, Loss: 0.3044, Val Acc: 0.6333, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 171, Loss: 0.2939, Val Acc: 0.6733, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 172, Loss: 0.2876, Val Acc: 0.6067, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 173, Loss: 0.2932, Val Acc: 0.6400, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 174, Loss: 0.3179, Val Acc: 0.6133, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 175, Loss: 0.2940, Val Acc: 0.6333, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 176, Loss: 0.2867, Val Acc: 0.6400, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 177, Loss: 0.3006, Val Acc: 0.6067, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 178, Loss: 0.3073, Val Acc: 0.6733, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 179, Loss: 0.3418, Val Acc: 0.6267, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 180, Loss: 0.3270, Val Acc: 0.6400, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 181, Loss: 0.3300, Val Acc: 0.6533, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 182, Loss: 0.3036, Val Acc: 0.6733, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 183, Loss: 0.3282, Val Acc: 0.6400, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 184, Loss: 0.3196, Val Acc: 0.6533, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 185, Loss: 0.3128, Val Acc: 0.6400, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 186, Loss: 0.2983, Val Acc: 0.6467, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 187, Loss: 0.3095, Val Acc: 0.6667, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 188, Loss: 0.3107, Val Acc: 0.6200, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 189, Loss: 0.3180, Val Acc: 0.6067, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 190, Loss: 0.3177, Val Acc: 0.6333, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 191, Loss: 0.3006, Val Acc: 0.6333, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 192, Loss: 0.3021, Val Acc: 0.6267, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 193, Loss: 0.2993, Val Acc: 0.6400, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 194, Loss: 0.2926, Val Acc: 0.6400, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 195, Loss: 0.3072, Val Acc: 0.6133, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 196, Loss: 0.2815, Val Acc: 0.6133, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 197, Loss: 0.2837, Val Acc: 0.6133, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 198, Loss: 0.2903, Val Acc: 0.6200, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 199, Loss: 0.2986, Val Acc: 0.6667, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 200, Loss: 0.3067, Val Acc: 0.6267, Test Acc: 0.8000\n",
      "Seed: 44, Epoch: 001, Loss: 0.6884, Val Acc: 0.4600, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 002, Loss: 0.6673, Val Acc: 0.6333, Test Acc: 0.6133\n",
      "Seed: 44, Epoch: 003, Loss: 0.6167, Val Acc: 0.6600, Test Acc: 0.6867\n",
      "Seed: 44, Epoch: 004, Loss: 0.5529, Val Acc: 0.7200, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 005, Loss: 0.5190, Val Acc: 0.7267, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 006, Loss: 0.5069, Val Acc: 0.7533, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 007, Loss: 0.4947, Val Acc: 0.7467, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 008, Loss: 0.4862, Val Acc: 0.7467, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 009, Loss: 0.4838, Val Acc: 0.7600, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 010, Loss: 0.4764, Val Acc: 0.7533, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 011, Loss: 0.4765, Val Acc: 0.7600, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 012, Loss: 0.4674, Val Acc: 0.7667, Test Acc: 0.6800\n",
      "Seed: 44, Epoch: 013, Loss: 0.4613, Val Acc: 0.7733, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 014, Loss: 0.4557, Val Acc: 0.7600, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 015, Loss: 0.4582, Val Acc: 0.7667, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 016, Loss: 0.4569, Val Acc: 0.7600, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 017, Loss: 0.4500, Val Acc: 0.7667, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 018, Loss: 0.4450, Val Acc: 0.7533, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 019, Loss: 0.4434, Val Acc: 0.7467, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 020, Loss: 0.4450, Val Acc: 0.7667, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 021, Loss: 0.4412, Val Acc: 0.7533, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 022, Loss: 0.4328, Val Acc: 0.7533, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 023, Loss: 0.4317, Val Acc: 0.7667, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 024, Loss: 0.4369, Val Acc: 0.7467, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 025, Loss: 0.4309, Val Acc: 0.7533, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 026, Loss: 0.4294, Val Acc: 0.7400, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 027, Loss: 0.4311, Val Acc: 0.7467, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 028, Loss: 0.4227, Val Acc: 0.7467, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 029, Loss: 0.4190, Val Acc: 0.7333, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 030, Loss: 0.4241, Val Acc: 0.7333, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 031, Loss: 0.4149, Val Acc: 0.7200, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 032, Loss: 0.4142, Val Acc: 0.7333, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 033, Loss: 0.4132, Val Acc: 0.7267, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 034, Loss: 0.4086, Val Acc: 0.7133, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 035, Loss: 0.4168, Val Acc: 0.7133, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 036, Loss: 0.4062, Val Acc: 0.7267, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 037, Loss: 0.4054, Val Acc: 0.7333, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 038, Loss: 0.4036, Val Acc: 0.7200, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 039, Loss: 0.4111, Val Acc: 0.7200, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 040, Loss: 0.4056, Val Acc: 0.7400, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 041, Loss: 0.4067, Val Acc: 0.7200, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 042, Loss: 0.3983, Val Acc: 0.7400, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 043, Loss: 0.3909, Val Acc: 0.7200, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 044, Loss: 0.3813, Val Acc: 0.7067, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 045, Loss: 0.3802, Val Acc: 0.7133, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 046, Loss: 0.3885, Val Acc: 0.7067, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 047, Loss: 0.3790, Val Acc: 0.7067, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 048, Loss: 0.3835, Val Acc: 0.7000, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 049, Loss: 0.3697, Val Acc: 0.7133, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 050, Loss: 0.3750, Val Acc: 0.7133, Test Acc: 0.8000\n",
      "Seed: 44, Epoch: 051, Loss: 0.3717, Val Acc: 0.7467, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 052, Loss: 0.3853, Val Acc: 0.7200, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 053, Loss: 0.3759, Val Acc: 0.7067, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 054, Loss: 0.3791, Val Acc: 0.7000, Test Acc: 0.7933\n",
      "Seed: 44, Epoch: 055, Loss: 0.3745, Val Acc: 0.7200, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 056, Loss: 0.3754, Val Acc: 0.7200, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 057, Loss: 0.3784, Val Acc: 0.7067, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 058, Loss: 0.3859, Val Acc: 0.7267, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 059, Loss: 0.3763, Val Acc: 0.7533, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 060, Loss: 0.3633, Val Acc: 0.7200, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 061, Loss: 0.3659, Val Acc: 0.7600, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 062, Loss: 0.3623, Val Acc: 0.7200, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 063, Loss: 0.3511, Val Acc: 0.7400, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 064, Loss: 0.3599, Val Acc: 0.7333, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 065, Loss: 0.3555, Val Acc: 0.7400, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 066, Loss: 0.3573, Val Acc: 0.7267, Test Acc: 0.8067\n",
      "Seed: 44, Epoch: 067, Loss: 0.3504, Val Acc: 0.7067, Test Acc: 0.8267\n",
      "Seed: 44, Epoch: 068, Loss: 0.3558, Val Acc: 0.6867, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 069, Loss: 0.3787, Val Acc: 0.7133, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 070, Loss: 0.3568, Val Acc: 0.7133, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 071, Loss: 0.3540, Val Acc: 0.7067, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 072, Loss: 0.3492, Val Acc: 0.7133, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 073, Loss: 0.3660, Val Acc: 0.6800, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 074, Loss: 0.3492, Val Acc: 0.7067, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 075, Loss: 0.3509, Val Acc: 0.7067, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 076, Loss: 0.3506, Val Acc: 0.6800, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 077, Loss: 0.3441, Val Acc: 0.7000, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 078, Loss: 0.3474, Val Acc: 0.7000, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 079, Loss: 0.3463, Val Acc: 0.7000, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 080, Loss: 0.3602, Val Acc: 0.6800, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 081, Loss: 0.3557, Val Acc: 0.7133, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 082, Loss: 0.3573, Val Acc: 0.7133, Test Acc: 0.8000\n",
      "Seed: 44, Epoch: 083, Loss: 0.3469, Val Acc: 0.7067, Test Acc: 0.8133\n",
      "Seed: 44, Epoch: 084, Loss: 0.3447, Val Acc: 0.6800, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 085, Loss: 0.3311, Val Acc: 0.7067, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 086, Loss: 0.3372, Val Acc: 0.6867, Test Acc: 0.7933\n",
      "Seed: 44, Epoch: 087, Loss: 0.3457, Val Acc: 0.6933, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 088, Loss: 0.3563, Val Acc: 0.7200, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 089, Loss: 0.3350, Val Acc: 0.6933, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 090, Loss: 0.3270, Val Acc: 0.7200, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 091, Loss: 0.3438, Val Acc: 0.7067, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 092, Loss: 0.3346, Val Acc: 0.7200, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 093, Loss: 0.3294, Val Acc: 0.7133, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 094, Loss: 0.3346, Val Acc: 0.7200, Test Acc: 0.8133\n",
      "Seed: 44, Epoch: 095, Loss: 0.3436, Val Acc: 0.6867, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 096, Loss: 0.3310, Val Acc: 0.7067, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 097, Loss: 0.3161, Val Acc: 0.6800, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 098, Loss: 0.3124, Val Acc: 0.7000, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 099, Loss: 0.3255, Val Acc: 0.7133, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 100, Loss: 0.3211, Val Acc: 0.7000, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 101, Loss: 0.3374, Val Acc: 0.7133, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 102, Loss: 0.3335, Val Acc: 0.6800, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 103, Loss: 0.3282, Val Acc: 0.6867, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 104, Loss: 0.3229, Val Acc: 0.6667, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 105, Loss: 0.3084, Val Acc: 0.6800, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 106, Loss: 0.3067, Val Acc: 0.6933, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 107, Loss: 0.3117, Val Acc: 0.7133, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 108, Loss: 0.3088, Val Acc: 0.6933, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 109, Loss: 0.3201, Val Acc: 0.6467, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 110, Loss: 0.3197, Val Acc: 0.6800, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 111, Loss: 0.3331, Val Acc: 0.7067, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 112, Loss: 0.3237, Val Acc: 0.6800, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 113, Loss: 0.3319, Val Acc: 0.7067, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 114, Loss: 0.3221, Val Acc: 0.6667, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 115, Loss: 0.3256, Val Acc: 0.7000, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 116, Loss: 0.3056, Val Acc: 0.7067, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 117, Loss: 0.3064, Val Acc: 0.7067, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 118, Loss: 0.2935, Val Acc: 0.7000, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 119, Loss: 0.3132, Val Acc: 0.6933, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 120, Loss: 0.3115, Val Acc: 0.7067, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 121, Loss: 0.3146, Val Acc: 0.6800, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 122, Loss: 0.3108, Val Acc: 0.7000, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 123, Loss: 0.3192, Val Acc: 0.6867, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 124, Loss: 0.3150, Val Acc: 0.6933, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 125, Loss: 0.3168, Val Acc: 0.6333, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 126, Loss: 0.3203, Val Acc: 0.7067, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 127, Loss: 0.3144, Val Acc: 0.6933, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 128, Loss: 0.3054, Val Acc: 0.6800, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 129, Loss: 0.3048, Val Acc: 0.7067, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 130, Loss: 0.2967, Val Acc: 0.7067, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 131, Loss: 0.3074, Val Acc: 0.6867, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 132, Loss: 0.2976, Val Acc: 0.6733, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 133, Loss: 0.3084, Val Acc: 0.6733, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 134, Loss: 0.3137, Val Acc: 0.7000, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 135, Loss: 0.3066, Val Acc: 0.6800, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 136, Loss: 0.3069, Val Acc: 0.6667, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 137, Loss: 0.3061, Val Acc: 0.6733, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 138, Loss: 0.3075, Val Acc: 0.6800, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 139, Loss: 0.3112, Val Acc: 0.6800, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 140, Loss: 0.3228, Val Acc: 0.6933, Test Acc: 0.6800\n",
      "Seed: 44, Epoch: 141, Loss: 0.3149, Val Acc: 0.7267, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 142, Loss: 0.3091, Val Acc: 0.6733, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 143, Loss: 0.3024, Val Acc: 0.6667, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 144, Loss: 0.2983, Val Acc: 0.7000, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 145, Loss: 0.3327, Val Acc: 0.6733, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 146, Loss: 0.3189, Val Acc: 0.6533, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 147, Loss: 0.3239, Val Acc: 0.6800, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 148, Loss: 0.3040, Val Acc: 0.6400, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 149, Loss: 0.3069, Val Acc: 0.6533, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 150, Loss: 0.2941, Val Acc: 0.6600, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 151, Loss: 0.2926, Val Acc: 0.6867, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 152, Loss: 0.2962, Val Acc: 0.6800, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 153, Loss: 0.2820, Val Acc: 0.6800, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 154, Loss: 0.3059, Val Acc: 0.6733, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 155, Loss: 0.3081, Val Acc: 0.6800, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 156, Loss: 0.2947, Val Acc: 0.6867, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 157, Loss: 0.3023, Val Acc: 0.6933, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 158, Loss: 0.2799, Val Acc: 0.7000, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 159, Loss: 0.2741, Val Acc: 0.6667, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 160, Loss: 0.2786, Val Acc: 0.6533, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 161, Loss: 0.2930, Val Acc: 0.6733, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 162, Loss: 0.2751, Val Acc: 0.6867, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 163, Loss: 0.2738, Val Acc: 0.6667, Test Acc: 0.7600\n",
      "Early stopping at epoch 163 for seed 44\n",
      "Average Time: 239.92 seconds\n",
      "Var Time: 500.06 seconds\n",
      "Average Memory: 1094.00 MB\n",
      "Average Best Val Acc: 0.7733\n",
      "Std Best Test Acc: 0.0409\n",
      "Average Test Acc: 0.7489\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "max_nodes = 500\n",
    "data_path = \"/data/Zeyu/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"IMDB-BINARY\",\n",
    "    transform=T.Compose([T.OneHotDegree(136), T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_justbalance(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        #x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        #x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        #x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_justbalance().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    model = Net_justbalance().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB-MULTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 1.0942, Val Acc: 0.2978, Test Acc: 0.3822\n",
      "Seed: 42, Epoch: 002, Loss: 1.0708, Val Acc: 0.4889, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 003, Loss: 1.0335, Val Acc: 0.4578, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 004, Loss: 1.0001, Val Acc: 0.4800, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 005, Loss: 0.9806, Val Acc: 0.4889, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 006, Loss: 0.9669, Val Acc: 0.4844, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 007, Loss: 0.9596, Val Acc: 0.4711, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 008, Loss: 0.9559, Val Acc: 0.4889, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 009, Loss: 0.9492, Val Acc: 0.4889, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 010, Loss: 0.9469, Val Acc: 0.4889, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 011, Loss: 0.9398, Val Acc: 0.4844, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 012, Loss: 0.9391, Val Acc: 0.4844, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 013, Loss: 0.9457, Val Acc: 0.5022, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 014, Loss: 0.9333, Val Acc: 0.4844, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 015, Loss: 0.9342, Val Acc: 0.4978, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 016, Loss: 0.9328, Val Acc: 0.4844, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 017, Loss: 0.9250, Val Acc: 0.4800, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 018, Loss: 0.9286, Val Acc: 0.4933, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 019, Loss: 0.9227, Val Acc: 0.5111, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 020, Loss: 0.9223, Val Acc: 0.5022, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 021, Loss: 0.9231, Val Acc: 0.4933, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 022, Loss: 0.9205, Val Acc: 0.4933, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 023, Loss: 0.9171, Val Acc: 0.5022, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 024, Loss: 0.9156, Val Acc: 0.4889, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 025, Loss: 0.9157, Val Acc: 0.5022, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 026, Loss: 0.9171, Val Acc: 0.4933, Test Acc: 0.4400\n",
      "Seed: 42, Epoch: 027, Loss: 0.9115, Val Acc: 0.4844, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 028, Loss: 0.9057, Val Acc: 0.5022, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 029, Loss: 0.9061, Val Acc: 0.4800, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 030, Loss: 0.9093, Val Acc: 0.5244, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 031, Loss: 0.9060, Val Acc: 0.4933, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 032, Loss: 0.9124, Val Acc: 0.5111, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 033, Loss: 0.9046, Val Acc: 0.5067, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 034, Loss: 0.9069, Val Acc: 0.4889, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 035, Loss: 0.9015, Val Acc: 0.5022, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 036, Loss: 0.9037, Val Acc: 0.5111, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 037, Loss: 0.8991, Val Acc: 0.5067, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 038, Loss: 0.8992, Val Acc: 0.4933, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 039, Loss: 0.8957, Val Acc: 0.5067, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 040, Loss: 0.8967, Val Acc: 0.5289, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 041, Loss: 0.8934, Val Acc: 0.5156, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 042, Loss: 0.8878, Val Acc: 0.5289, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 043, Loss: 0.8794, Val Acc: 0.5111, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 044, Loss: 0.8810, Val Acc: 0.5200, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 045, Loss: 0.8845, Val Acc: 0.4978, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 046, Loss: 0.8894, Val Acc: 0.4933, Test Acc: 0.4400\n",
      "Seed: 42, Epoch: 047, Loss: 0.8888, Val Acc: 0.5022, Test Acc: 0.4444\n",
      "Seed: 42, Epoch: 048, Loss: 0.8823, Val Acc: 0.5156, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 049, Loss: 0.8815, Val Acc: 0.5333, Test Acc: 0.4400\n",
      "Seed: 42, Epoch: 050, Loss: 0.8799, Val Acc: 0.5156, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 051, Loss: 0.8831, Val Acc: 0.5289, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 052, Loss: 0.8780, Val Acc: 0.5156, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 053, Loss: 0.8740, Val Acc: 0.4933, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 054, Loss: 0.8834, Val Acc: 0.5022, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 055, Loss: 0.8829, Val Acc: 0.5244, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 056, Loss: 0.8735, Val Acc: 0.5244, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 057, Loss: 0.8779, Val Acc: 0.5067, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 058, Loss: 0.8778, Val Acc: 0.4800, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 059, Loss: 0.8831, Val Acc: 0.4800, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 060, Loss: 0.8755, Val Acc: 0.4933, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 061, Loss: 0.8710, Val Acc: 0.5111, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 062, Loss: 0.8756, Val Acc: 0.5022, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 063, Loss: 0.8653, Val Acc: 0.5022, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 064, Loss: 0.8642, Val Acc: 0.5156, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 065, Loss: 0.8737, Val Acc: 0.4978, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 066, Loss: 0.8665, Val Acc: 0.4978, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 067, Loss: 0.8664, Val Acc: 0.4756, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 068, Loss: 0.8695, Val Acc: 0.4800, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 069, Loss: 0.8617, Val Acc: 0.4978, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 070, Loss: 0.8742, Val Acc: 0.4933, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 071, Loss: 0.8637, Val Acc: 0.4844, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 072, Loss: 0.8608, Val Acc: 0.4978, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 073, Loss: 0.8605, Val Acc: 0.5111, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 074, Loss: 0.8590, Val Acc: 0.4933, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 075, Loss: 0.8657, Val Acc: 0.5111, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 076, Loss: 0.8623, Val Acc: 0.5200, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 077, Loss: 0.8572, Val Acc: 0.4978, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 078, Loss: 0.8614, Val Acc: 0.5111, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 079, Loss: 0.8622, Val Acc: 0.4889, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 080, Loss: 0.8637, Val Acc: 0.4800, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 081, Loss: 0.8630, Val Acc: 0.5200, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 082, Loss: 0.8528, Val Acc: 0.5022, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 083, Loss: 0.8569, Val Acc: 0.4978, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 084, Loss: 0.8655, Val Acc: 0.4800, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 085, Loss: 0.8535, Val Acc: 0.4978, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 086, Loss: 0.8531, Val Acc: 0.5067, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 087, Loss: 0.8586, Val Acc: 0.5022, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 088, Loss: 0.8600, Val Acc: 0.5022, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 089, Loss: 0.8602, Val Acc: 0.4889, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 090, Loss: 0.8568, Val Acc: 0.4933, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 091, Loss: 0.8564, Val Acc: 0.4978, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 092, Loss: 0.8497, Val Acc: 0.4978, Test Acc: 0.4444\n",
      "Seed: 42, Epoch: 093, Loss: 0.8517, Val Acc: 0.4933, Test Acc: 0.4356\n",
      "Seed: 42, Epoch: 094, Loss: 0.8475, Val Acc: 0.5156, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 095, Loss: 0.8406, Val Acc: 0.5200, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 096, Loss: 0.8512, Val Acc: 0.5111, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 097, Loss: 0.8512, Val Acc: 0.5156, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 098, Loss: 0.8439, Val Acc: 0.4711, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 099, Loss: 0.8615, Val Acc: 0.5156, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 100, Loss: 0.8519, Val Acc: 0.4844, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 101, Loss: 0.8420, Val Acc: 0.5022, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 102, Loss: 0.8424, Val Acc: 0.5156, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 103, Loss: 0.8388, Val Acc: 0.4933, Test Acc: 0.4356\n",
      "Seed: 42, Epoch: 104, Loss: 0.8382, Val Acc: 0.4756, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 105, Loss: 0.8388, Val Acc: 0.4889, Test Acc: 0.4356\n",
      "Seed: 42, Epoch: 106, Loss: 0.8365, Val Acc: 0.4800, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 107, Loss: 0.8439, Val Acc: 0.4756, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 108, Loss: 0.8425, Val Acc: 0.4844, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 109, Loss: 0.8378, Val Acc: 0.4756, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 110, Loss: 0.8415, Val Acc: 0.4756, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 111, Loss: 0.8471, Val Acc: 0.4889, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 112, Loss: 0.8333, Val Acc: 0.4889, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 113, Loss: 0.8402, Val Acc: 0.4978, Test Acc: 0.4356\n",
      "Seed: 42, Epoch: 114, Loss: 0.8435, Val Acc: 0.4978, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 115, Loss: 0.8446, Val Acc: 0.4711, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 116, Loss: 0.8383, Val Acc: 0.5022, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 117, Loss: 0.8422, Val Acc: 0.4844, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 118, Loss: 0.8426, Val Acc: 0.4756, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 119, Loss: 0.8369, Val Acc: 0.4711, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 120, Loss: 0.8535, Val Acc: 0.4889, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 121, Loss: 0.8478, Val Acc: 0.4889, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 122, Loss: 0.8383, Val Acc: 0.5111, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 123, Loss: 0.8380, Val Acc: 0.4844, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 124, Loss: 0.8406, Val Acc: 0.4800, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 125, Loss: 0.8371, Val Acc: 0.4800, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 126, Loss: 0.8356, Val Acc: 0.5067, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 127, Loss: 0.8459, Val Acc: 0.4800, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 128, Loss: 0.8485, Val Acc: 0.4889, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 129, Loss: 0.8444, Val Acc: 0.4800, Test Acc: 0.4444\n",
      "Seed: 42, Epoch: 130, Loss: 0.8455, Val Acc: 0.4844, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 131, Loss: 0.8375, Val Acc: 0.5111, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 132, Loss: 0.8300, Val Acc: 0.4800, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 133, Loss: 0.8351, Val Acc: 0.5200, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 134, Loss: 0.8342, Val Acc: 0.5022, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 135, Loss: 0.8326, Val Acc: 0.4756, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 136, Loss: 0.8373, Val Acc: 0.5067, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 137, Loss: 0.8464, Val Acc: 0.4800, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 138, Loss: 0.8349, Val Acc: 0.4844, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 139, Loss: 0.8429, Val Acc: 0.4933, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 140, Loss: 0.8447, Val Acc: 0.4889, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 141, Loss: 0.8461, Val Acc: 0.4889, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 142, Loss: 0.8395, Val Acc: 0.4800, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 143, Loss: 0.8335, Val Acc: 0.4756, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 144, Loss: 0.8322, Val Acc: 0.4800, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 145, Loss: 0.8313, Val Acc: 0.4800, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 146, Loss: 0.8332, Val Acc: 0.4800, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 147, Loss: 0.8336, Val Acc: 0.4889, Test Acc: 0.4444\n",
      "Seed: 42, Epoch: 148, Loss: 0.8371, Val Acc: 0.4933, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 149, Loss: 0.8356, Val Acc: 0.4711, Test Acc: 0.4444\n",
      "Seed: 42, Epoch: 150, Loss: 0.8316, Val Acc: 0.4889, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 151, Loss: 0.8460, Val Acc: 0.4800, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 152, Loss: 0.8343, Val Acc: 0.4889, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 153, Loss: 0.8278, Val Acc: 0.4978, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 154, Loss: 0.8387, Val Acc: 0.4800, Test Acc: 0.4400\n",
      "Seed: 42, Epoch: 155, Loss: 0.8302, Val Acc: 0.4978, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 156, Loss: 0.8439, Val Acc: 0.4756, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 157, Loss: 0.8266, Val Acc: 0.4889, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 158, Loss: 0.8372, Val Acc: 0.4889, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 159, Loss: 0.8311, Val Acc: 0.4978, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 160, Loss: 0.8258, Val Acc: 0.4711, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 161, Loss: 0.8360, Val Acc: 0.4622, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 162, Loss: 0.8365, Val Acc: 0.4844, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 163, Loss: 0.8381, Val Acc: 0.4756, Test Acc: 0.4400\n",
      "Seed: 42, Epoch: 164, Loss: 0.8451, Val Acc: 0.4756, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 165, Loss: 0.8486, Val Acc: 0.4756, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 166, Loss: 0.8352, Val Acc: 0.5067, Test Acc: 0.4400\n",
      "Seed: 42, Epoch: 167, Loss: 0.8350, Val Acc: 0.4800, Test Acc: 0.4400\n",
      "Seed: 42, Epoch: 168, Loss: 0.8345, Val Acc: 0.5067, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 169, Loss: 0.8255, Val Acc: 0.5111, Test Acc: 0.4444\n",
      "Seed: 42, Epoch: 170, Loss: 0.8363, Val Acc: 0.5022, Test Acc: 0.4444\n",
      "Seed: 42, Epoch: 171, Loss: 0.8328, Val Acc: 0.5067, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 172, Loss: 0.8287, Val Acc: 0.4933, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 173, Loss: 0.8285, Val Acc: 0.4800, Test Acc: 0.4400\n",
      "Seed: 42, Epoch: 174, Loss: 0.8256, Val Acc: 0.4844, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 175, Loss: 0.8247, Val Acc: 0.5022, Test Acc: 0.4356\n",
      "Seed: 42, Epoch: 176, Loss: 0.8256, Val Acc: 0.4844, Test Acc: 0.4444\n",
      "Seed: 42, Epoch: 177, Loss: 0.8315, Val Acc: 0.4889, Test Acc: 0.4444\n",
      "Seed: 42, Epoch: 178, Loss: 0.8248, Val Acc: 0.5200, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 179, Loss: 0.8292, Val Acc: 0.4756, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 180, Loss: 0.8248, Val Acc: 0.4711, Test Acc: 0.4444\n",
      "Seed: 42, Epoch: 181, Loss: 0.8154, Val Acc: 0.4844, Test Acc: 0.4222\n",
      "Seed: 42, Epoch: 182, Loss: 0.8187, Val Acc: 0.5022, Test Acc: 0.4356\n",
      "Seed: 42, Epoch: 183, Loss: 0.8206, Val Acc: 0.4756, Test Acc: 0.4444\n",
      "Seed: 42, Epoch: 184, Loss: 0.8209, Val Acc: 0.5022, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 185, Loss: 0.8200, Val Acc: 0.4711, Test Acc: 0.4400\n",
      "Seed: 42, Epoch: 186, Loss: 0.8217, Val Acc: 0.4622, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 187, Loss: 0.8153, Val Acc: 0.4978, Test Acc: 0.4267\n",
      "Seed: 42, Epoch: 188, Loss: 0.8140, Val Acc: 0.4844, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 189, Loss: 0.8141, Val Acc: 0.4933, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 190, Loss: 0.8177, Val Acc: 0.4844, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 191, Loss: 0.8263, Val Acc: 0.4933, Test Acc: 0.4400\n",
      "Seed: 42, Epoch: 192, Loss: 0.8253, Val Acc: 0.4844, Test Acc: 0.4444\n",
      "Seed: 42, Epoch: 193, Loss: 0.8135, Val Acc: 0.4933, Test Acc: 0.4400\n",
      "Seed: 42, Epoch: 194, Loss: 0.8222, Val Acc: 0.4667, Test Acc: 0.4400\n",
      "Seed: 42, Epoch: 195, Loss: 0.8144, Val Acc: 0.4756, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 196, Loss: 0.8204, Val Acc: 0.4844, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 197, Loss: 0.8109, Val Acc: 0.4933, Test Acc: 0.4311\n",
      "Seed: 42, Epoch: 198, Loss: 0.8249, Val Acc: 0.5022, Test Acc: 0.4356\n",
      "Seed: 42, Epoch: 199, Loss: 0.8260, Val Acc: 0.4933, Test Acc: 0.4578\n",
      "Early stopping at epoch 199 for seed 42\n",
      "Seed: 43, Epoch: 001, Loss: 1.1019, Val Acc: 0.3822, Test Acc: 0.3422\n",
      "Seed: 43, Epoch: 002, Loss: 1.0875, Val Acc: 0.4400, Test Acc: 0.3911\n",
      "Seed: 43, Epoch: 003, Loss: 1.0567, Val Acc: 0.5289, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 004, Loss: 1.0073, Val Acc: 0.5200, Test Acc: 0.4489\n",
      "Seed: 43, Epoch: 005, Loss: 0.9857, Val Acc: 0.4667, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 006, Loss: 0.9611, Val Acc: 0.5289, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 007, Loss: 0.9517, Val Acc: 0.5067, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 008, Loss: 0.9393, Val Acc: 0.4978, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 009, Loss: 0.9393, Val Acc: 0.5022, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 010, Loss: 0.9305, Val Acc: 0.4978, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 011, Loss: 0.9247, Val Acc: 0.4933, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 012, Loss: 0.9249, Val Acc: 0.5111, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 013, Loss: 0.9239, Val Acc: 0.4978, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 014, Loss: 0.9190, Val Acc: 0.5244, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 015, Loss: 0.9233, Val Acc: 0.4933, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 016, Loss: 0.9155, Val Acc: 0.5022, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 017, Loss: 0.9109, Val Acc: 0.4978, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 018, Loss: 0.9126, Val Acc: 0.4978, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 019, Loss: 0.9118, Val Acc: 0.5111, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 020, Loss: 0.9075, Val Acc: 0.5111, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 021, Loss: 0.9098, Val Acc: 0.5067, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 022, Loss: 0.9053, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 023, Loss: 0.9129, Val Acc: 0.4978, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 024, Loss: 0.9036, Val Acc: 0.4978, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 025, Loss: 0.8984, Val Acc: 0.4978, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 026, Loss: 0.9028, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 027, Loss: 0.9024, Val Acc: 0.5067, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 028, Loss: 0.8962, Val Acc: 0.5200, Test Acc: 0.4489\n",
      "Seed: 43, Epoch: 029, Loss: 0.8954, Val Acc: 0.5200, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 030, Loss: 0.8947, Val Acc: 0.5200, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 031, Loss: 0.9066, Val Acc: 0.5067, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 032, Loss: 0.8943, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 033, Loss: 0.8903, Val Acc: 0.5200, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 034, Loss: 0.8904, Val Acc: 0.5156, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 035, Loss: 0.8853, Val Acc: 0.5156, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 036, Loss: 0.8842, Val Acc: 0.5156, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 037, Loss: 0.8838, Val Acc: 0.5111, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 038, Loss: 0.8779, Val Acc: 0.5156, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 039, Loss: 0.8817, Val Acc: 0.5156, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 040, Loss: 0.8786, Val Acc: 0.5156, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 041, Loss: 0.8811, Val Acc: 0.5244, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 042, Loss: 0.8730, Val Acc: 0.5067, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 043, Loss: 0.8796, Val Acc: 0.5156, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 044, Loss: 0.8800, Val Acc: 0.5200, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 045, Loss: 0.8793, Val Acc: 0.5244, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 046, Loss: 0.8778, Val Acc: 0.5156, Test Acc: 0.4489\n",
      "Seed: 43, Epoch: 047, Loss: 0.8792, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 048, Loss: 0.8718, Val Acc: 0.5156, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 049, Loss: 0.8740, Val Acc: 0.5156, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 050, Loss: 0.8620, Val Acc: 0.5200, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 051, Loss: 0.8721, Val Acc: 0.5244, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 052, Loss: 0.8745, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 053, Loss: 0.8636, Val Acc: 0.5289, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 054, Loss: 0.8691, Val Acc: 0.5289, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 055, Loss: 0.8710, Val Acc: 0.5244, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 056, Loss: 0.8624, Val Acc: 0.5244, Test Acc: 0.4489\n",
      "Seed: 43, Epoch: 057, Loss: 0.8596, Val Acc: 0.5244, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 058, Loss: 0.8732, Val Acc: 0.5333, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 059, Loss: 0.8613, Val Acc: 0.5244, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 060, Loss: 0.8766, Val Acc: 0.5156, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 061, Loss: 0.8720, Val Acc: 0.5289, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 062, Loss: 0.8696, Val Acc: 0.5156, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 063, Loss: 0.8681, Val Acc: 0.5156, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 064, Loss: 0.8642, Val Acc: 0.5067, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 065, Loss: 0.8641, Val Acc: 0.5244, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 066, Loss: 0.8518, Val Acc: 0.5244, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 067, Loss: 0.8629, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 068, Loss: 0.8569, Val Acc: 0.5378, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 069, Loss: 0.8636, Val Acc: 0.5378, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 070, Loss: 0.8582, Val Acc: 0.5289, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 071, Loss: 0.8531, Val Acc: 0.5244, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 072, Loss: 0.8557, Val Acc: 0.5333, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 073, Loss: 0.8476, Val Acc: 0.5200, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 074, Loss: 0.8566, Val Acc: 0.5244, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 075, Loss: 0.8515, Val Acc: 0.5156, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 076, Loss: 0.8532, Val Acc: 0.5244, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 077, Loss: 0.8494, Val Acc: 0.5289, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 078, Loss: 0.8386, Val Acc: 0.5289, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 079, Loss: 0.8463, Val Acc: 0.5200, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 080, Loss: 0.8475, Val Acc: 0.5022, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 081, Loss: 0.8468, Val Acc: 0.5333, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 082, Loss: 0.8463, Val Acc: 0.5244, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 083, Loss: 0.8423, Val Acc: 0.5244, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 084, Loss: 0.8462, Val Acc: 0.5156, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 085, Loss: 0.8376, Val Acc: 0.5422, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 086, Loss: 0.8517, Val Acc: 0.5289, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 087, Loss: 0.8432, Val Acc: 0.5289, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 088, Loss: 0.8472, Val Acc: 0.5200, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 089, Loss: 0.8421, Val Acc: 0.5289, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 090, Loss: 0.8439, Val Acc: 0.5244, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 091, Loss: 0.8451, Val Acc: 0.5111, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 092, Loss: 0.8433, Val Acc: 0.5244, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 093, Loss: 0.8439, Val Acc: 0.5333, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 094, Loss: 0.8408, Val Acc: 0.5244, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 095, Loss: 0.8365, Val Acc: 0.5200, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 096, Loss: 0.8375, Val Acc: 0.5111, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 097, Loss: 0.8345, Val Acc: 0.5289, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 098, Loss: 0.8411, Val Acc: 0.5200, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 099, Loss: 0.8363, Val Acc: 0.5244, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 100, Loss: 0.8340, Val Acc: 0.5333, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 101, Loss: 0.8335, Val Acc: 0.5289, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 102, Loss: 0.8359, Val Acc: 0.5289, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 103, Loss: 0.8292, Val Acc: 0.5289, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 104, Loss: 0.8268, Val Acc: 0.5200, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 105, Loss: 0.8329, Val Acc: 0.5200, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 106, Loss: 0.8281, Val Acc: 0.5333, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 107, Loss: 0.8310, Val Acc: 0.5200, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 108, Loss: 0.8246, Val Acc: 0.5200, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 109, Loss: 0.8363, Val Acc: 0.5156, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 110, Loss: 0.8295, Val Acc: 0.5111, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 111, Loss: 0.8352, Val Acc: 0.5111, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 112, Loss: 0.8308, Val Acc: 0.5111, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 113, Loss: 0.8395, Val Acc: 0.5156, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 114, Loss: 0.8400, Val Acc: 0.5156, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 115, Loss: 0.8405, Val Acc: 0.5156, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 116, Loss: 0.8419, Val Acc: 0.5156, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 117, Loss: 0.8311, Val Acc: 0.5244, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 118, Loss: 0.8339, Val Acc: 0.5200, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 119, Loss: 0.8332, Val Acc: 0.5289, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 120, Loss: 0.8297, Val Acc: 0.5200, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 121, Loss: 0.8236, Val Acc: 0.5244, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 122, Loss: 0.8173, Val Acc: 0.5333, Test Acc: 0.4044\n",
      "Seed: 43, Epoch: 123, Loss: 0.8304, Val Acc: 0.5200, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 124, Loss: 0.8390, Val Acc: 0.5156, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 125, Loss: 0.8325, Val Acc: 0.5200, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 126, Loss: 0.8242, Val Acc: 0.5244, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 127, Loss: 0.8233, Val Acc: 0.5244, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 128, Loss: 0.8294, Val Acc: 0.5200, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 129, Loss: 0.8253, Val Acc: 0.5289, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 130, Loss: 0.8249, Val Acc: 0.5289, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 131, Loss: 0.8205, Val Acc: 0.5378, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 132, Loss: 0.8279, Val Acc: 0.5289, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 133, Loss: 0.8162, Val Acc: 0.5244, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 134, Loss: 0.8180, Val Acc: 0.5378, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 135, Loss: 0.8296, Val Acc: 0.5244, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 136, Loss: 0.8171, Val Acc: 0.5289, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 137, Loss: 0.8213, Val Acc: 0.5244, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 138, Loss: 0.8243, Val Acc: 0.5244, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 139, Loss: 0.8215, Val Acc: 0.5200, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 140, Loss: 0.8207, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 141, Loss: 0.8196, Val Acc: 0.5244, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 142, Loss: 0.8130, Val Acc: 0.5333, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 143, Loss: 0.8119, Val Acc: 0.5244, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 144, Loss: 0.8150, Val Acc: 0.5244, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 145, Loss: 0.8176, Val Acc: 0.5289, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 146, Loss: 0.8119, Val Acc: 0.5244, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 147, Loss: 0.8095, Val Acc: 0.5289, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 148, Loss: 0.8088, Val Acc: 0.5289, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 149, Loss: 0.8067, Val Acc: 0.5200, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 150, Loss: 0.8098, Val Acc: 0.5244, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 151, Loss: 0.8101, Val Acc: 0.5156, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 152, Loss: 0.8092, Val Acc: 0.5333, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 153, Loss: 0.8118, Val Acc: 0.5422, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 154, Loss: 0.8110, Val Acc: 0.5333, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 155, Loss: 0.8159, Val Acc: 0.5333, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 156, Loss: 0.8095, Val Acc: 0.5422, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 157, Loss: 0.8039, Val Acc: 0.5244, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 158, Loss: 0.8131, Val Acc: 0.5156, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 159, Loss: 0.8141, Val Acc: 0.5200, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 160, Loss: 0.8206, Val Acc: 0.5156, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 161, Loss: 0.8184, Val Acc: 0.4844, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 162, Loss: 0.8101, Val Acc: 0.5067, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 163, Loss: 0.8086, Val Acc: 0.5333, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 164, Loss: 0.8139, Val Acc: 0.5378, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 165, Loss: 0.8004, Val Acc: 0.5111, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 166, Loss: 0.8258, Val Acc: 0.5244, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 167, Loss: 0.8160, Val Acc: 0.5156, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 168, Loss: 0.8130, Val Acc: 0.5333, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 169, Loss: 0.8251, Val Acc: 0.5333, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 170, Loss: 0.8165, Val Acc: 0.5289, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 171, Loss: 0.8057, Val Acc: 0.5422, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 172, Loss: 0.8095, Val Acc: 0.5289, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 173, Loss: 0.8099, Val Acc: 0.5378, Test Acc: 0.4044\n",
      "Seed: 43, Epoch: 174, Loss: 0.8081, Val Acc: 0.5333, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 175, Loss: 0.8091, Val Acc: 0.5289, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 176, Loss: 0.8094, Val Acc: 0.5289, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 177, Loss: 0.8112, Val Acc: 0.5289, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 178, Loss: 0.8006, Val Acc: 0.5467, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 179, Loss: 0.7947, Val Acc: 0.5333, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 180, Loss: 0.8012, Val Acc: 0.5156, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 181, Loss: 0.7996, Val Acc: 0.5156, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 182, Loss: 0.8072, Val Acc: 0.5244, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 183, Loss: 0.7978, Val Acc: 0.5067, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 184, Loss: 0.7995, Val Acc: 0.5289, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 185, Loss: 0.7994, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 186, Loss: 0.8054, Val Acc: 0.5289, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 187, Loss: 0.8093, Val Acc: 0.4844, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 188, Loss: 0.8118, Val Acc: 0.5333, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 189, Loss: 0.8101, Val Acc: 0.5289, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 190, Loss: 0.8157, Val Acc: 0.5156, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 191, Loss: 0.7946, Val Acc: 0.5333, Test Acc: 0.4044\n",
      "Seed: 43, Epoch: 192, Loss: 0.8087, Val Acc: 0.5156, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 193, Loss: 0.7962, Val Acc: 0.5067, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 194, Loss: 0.7960, Val Acc: 0.5200, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 195, Loss: 0.8054, Val Acc: 0.5156, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 196, Loss: 0.8046, Val Acc: 0.5333, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 197, Loss: 0.8219, Val Acc: 0.4933, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 198, Loss: 0.8141, Val Acc: 0.5244, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 199, Loss: 0.8017, Val Acc: 0.5289, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 200, Loss: 0.7956, Val Acc: 0.5244, Test Acc: 0.4222\n",
      "Seed: 44, Epoch: 001, Loss: 1.1038, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 002, Loss: 1.0841, Val Acc: 0.4667, Test Acc: 0.4711\n",
      "Seed: 44, Epoch: 003, Loss: 1.0441, Val Acc: 0.4622, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 004, Loss: 1.0054, Val Acc: 0.4933, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 005, Loss: 0.9771, Val Acc: 0.4933, Test Acc: 0.4800\n",
      "Seed: 44, Epoch: 006, Loss: 0.9620, Val Acc: 0.4756, Test Acc: 0.4667\n",
      "Seed: 44, Epoch: 007, Loss: 0.9563, Val Acc: 0.4844, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 008, Loss: 0.9473, Val Acc: 0.4844, Test Acc: 0.4800\n",
      "Seed: 44, Epoch: 009, Loss: 0.9438, Val Acc: 0.5067, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 010, Loss: 0.9432, Val Acc: 0.4889, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 011, Loss: 0.9369, Val Acc: 0.4889, Test Acc: 0.4667\n",
      "Seed: 44, Epoch: 012, Loss: 0.9336, Val Acc: 0.4933, Test Acc: 0.4844\n",
      "Seed: 44, Epoch: 013, Loss: 0.9355, Val Acc: 0.4978, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 014, Loss: 0.9329, Val Acc: 0.5067, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 015, Loss: 0.9340, Val Acc: 0.4978, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 016, Loss: 0.9269, Val Acc: 0.4800, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 017, Loss: 0.9251, Val Acc: 0.5111, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 018, Loss: 0.9259, Val Acc: 0.5156, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 019, Loss: 0.9275, Val Acc: 0.5111, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 020, Loss: 0.9241, Val Acc: 0.5067, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 021, Loss: 0.9199, Val Acc: 0.5289, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 022, Loss: 0.9194, Val Acc: 0.4933, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 023, Loss: 0.9189, Val Acc: 0.5111, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 024, Loss: 0.9159, Val Acc: 0.5067, Test Acc: 0.4800\n",
      "Seed: 44, Epoch: 025, Loss: 0.9133, Val Acc: 0.5200, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 026, Loss: 0.9138, Val Acc: 0.4978, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 027, Loss: 0.9135, Val Acc: 0.5156, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 028, Loss: 0.9138, Val Acc: 0.5333, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 029, Loss: 0.9125, Val Acc: 0.4889, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 030, Loss: 0.9038, Val Acc: 0.5289, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 031, Loss: 0.9040, Val Acc: 0.5067, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 032, Loss: 0.9128, Val Acc: 0.4889, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 033, Loss: 0.9060, Val Acc: 0.5022, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 034, Loss: 0.8998, Val Acc: 0.5111, Test Acc: 0.4756\n",
      "Seed: 44, Epoch: 035, Loss: 0.8965, Val Acc: 0.5289, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 036, Loss: 0.9009, Val Acc: 0.5200, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 037, Loss: 0.8986, Val Acc: 0.5111, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 038, Loss: 0.8954, Val Acc: 0.5156, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 039, Loss: 0.8960, Val Acc: 0.5067, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 040, Loss: 0.9036, Val Acc: 0.5244, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 041, Loss: 0.8976, Val Acc: 0.5289, Test Acc: 0.4756\n",
      "Seed: 44, Epoch: 042, Loss: 0.8917, Val Acc: 0.5111, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 043, Loss: 0.8922, Val Acc: 0.5200, Test Acc: 0.5600\n",
      "Seed: 44, Epoch: 044, Loss: 0.8911, Val Acc: 0.5200, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 045, Loss: 0.8896, Val Acc: 0.5111, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 046, Loss: 0.8869, Val Acc: 0.5156, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 047, Loss: 0.8862, Val Acc: 0.4933, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 048, Loss: 0.8876, Val Acc: 0.4978, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 049, Loss: 0.8809, Val Acc: 0.5333, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 050, Loss: 0.8781, Val Acc: 0.4978, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 051, Loss: 0.8790, Val Acc: 0.5111, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 052, Loss: 0.8874, Val Acc: 0.5156, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 053, Loss: 0.8833, Val Acc: 0.5111, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 054, Loss: 0.8851, Val Acc: 0.5067, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 055, Loss: 0.8834, Val Acc: 0.5289, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 056, Loss: 0.8857, Val Acc: 0.4933, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 057, Loss: 0.8786, Val Acc: 0.5067, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 058, Loss: 0.8725, Val Acc: 0.5022, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 059, Loss: 0.8767, Val Acc: 0.5156, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 060, Loss: 0.8840, Val Acc: 0.5200, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 061, Loss: 0.8870, Val Acc: 0.4889, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 062, Loss: 0.8819, Val Acc: 0.5200, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 063, Loss: 0.8738, Val Acc: 0.5022, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 064, Loss: 0.8742, Val Acc: 0.4933, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 065, Loss: 0.8754, Val Acc: 0.5022, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 066, Loss: 0.8793, Val Acc: 0.5244, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 067, Loss: 0.8751, Val Acc: 0.4622, Test Acc: 0.4844\n",
      "Seed: 44, Epoch: 068, Loss: 0.8769, Val Acc: 0.5111, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 069, Loss: 0.8718, Val Acc: 0.5022, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 070, Loss: 0.8760, Val Acc: 0.5244, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 071, Loss: 0.8702, Val Acc: 0.4889, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 072, Loss: 0.8705, Val Acc: 0.4356, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 073, Loss: 0.8699, Val Acc: 0.4711, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 074, Loss: 0.8769, Val Acc: 0.4978, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 075, Loss: 0.8707, Val Acc: 0.4978, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 076, Loss: 0.8805, Val Acc: 0.5067, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 077, Loss: 0.8764, Val Acc: 0.5111, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 078, Loss: 0.8711, Val Acc: 0.5022, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 079, Loss: 0.8710, Val Acc: 0.4933, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 080, Loss: 0.8620, Val Acc: 0.4933, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 081, Loss: 0.8726, Val Acc: 0.4800, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 082, Loss: 0.8630, Val Acc: 0.4978, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 083, Loss: 0.8640, Val Acc: 0.4756, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 084, Loss: 0.8574, Val Acc: 0.5067, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 085, Loss: 0.8615, Val Acc: 0.4889, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 086, Loss: 0.8603, Val Acc: 0.4933, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 087, Loss: 0.8599, Val Acc: 0.5022, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 088, Loss: 0.8632, Val Acc: 0.4889, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 089, Loss: 0.8728, Val Acc: 0.5022, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 090, Loss: 0.8694, Val Acc: 0.5156, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 091, Loss: 0.8729, Val Acc: 0.4978, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 092, Loss: 0.8671, Val Acc: 0.5111, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 093, Loss: 0.8620, Val Acc: 0.4978, Test Acc: 0.5644\n",
      "Seed: 44, Epoch: 094, Loss: 0.8638, Val Acc: 0.5111, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 095, Loss: 0.8639, Val Acc: 0.5067, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 096, Loss: 0.8582, Val Acc: 0.5067, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 097, Loss: 0.8582, Val Acc: 0.5022, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 098, Loss: 0.8617, Val Acc: 0.5156, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 099, Loss: 0.8652, Val Acc: 0.5200, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 100, Loss: 0.8616, Val Acc: 0.4711, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 101, Loss: 0.8612, Val Acc: 0.4933, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 102, Loss: 0.8645, Val Acc: 0.4978, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 103, Loss: 0.8567, Val Acc: 0.4933, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 104, Loss: 0.8637, Val Acc: 0.4933, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 105, Loss: 0.8666, Val Acc: 0.5067, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 106, Loss: 0.8605, Val Acc: 0.4933, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 107, Loss: 0.8545, Val Acc: 0.4844, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 108, Loss: 0.8688, Val Acc: 0.4978, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 109, Loss: 0.8591, Val Acc: 0.5022, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 110, Loss: 0.8598, Val Acc: 0.4978, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 111, Loss: 0.8610, Val Acc: 0.4978, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 112, Loss: 0.8712, Val Acc: 0.4978, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 113, Loss: 0.8685, Val Acc: 0.5067, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 114, Loss: 0.8642, Val Acc: 0.5111, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 115, Loss: 0.8509, Val Acc: 0.5022, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 116, Loss: 0.8517, Val Acc: 0.5156, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 117, Loss: 0.8576, Val Acc: 0.4844, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 118, Loss: 0.8579, Val Acc: 0.4978, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 119, Loss: 0.8590, Val Acc: 0.5244, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 120, Loss: 0.8547, Val Acc: 0.5111, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 121, Loss: 0.8520, Val Acc: 0.5244, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 122, Loss: 0.8596, Val Acc: 0.5111, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 123, Loss: 0.8440, Val Acc: 0.5111, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 124, Loss: 0.8485, Val Acc: 0.5111, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 125, Loss: 0.8535, Val Acc: 0.5111, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 126, Loss: 0.8510, Val Acc: 0.5022, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 127, Loss: 0.8568, Val Acc: 0.5289, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 128, Loss: 0.8465, Val Acc: 0.4933, Test Acc: 0.5600\n",
      "Seed: 44, Epoch: 129, Loss: 0.8501, Val Acc: 0.5022, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 130, Loss: 0.8543, Val Acc: 0.4978, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 131, Loss: 0.8582, Val Acc: 0.5111, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 132, Loss: 0.8534, Val Acc: 0.5111, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 133, Loss: 0.8418, Val Acc: 0.5111, Test Acc: 0.5644\n",
      "Seed: 44, Epoch: 134, Loss: 0.8493, Val Acc: 0.4978, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 135, Loss: 0.8564, Val Acc: 0.4800, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 136, Loss: 0.8414, Val Acc: 0.5067, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 137, Loss: 0.8487, Val Acc: 0.4978, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 138, Loss: 0.8513, Val Acc: 0.5156, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 139, Loss: 0.8473, Val Acc: 0.4889, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 140, Loss: 0.8452, Val Acc: 0.5067, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 141, Loss: 0.8405, Val Acc: 0.5067, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 142, Loss: 0.8546, Val Acc: 0.4978, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 143, Loss: 0.8477, Val Acc: 0.4978, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 144, Loss: 0.8503, Val Acc: 0.4933, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 145, Loss: 0.8517, Val Acc: 0.5156, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 146, Loss: 0.8470, Val Acc: 0.5111, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 147, Loss: 0.8335, Val Acc: 0.5067, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 148, Loss: 0.8370, Val Acc: 0.5067, Test Acc: 0.4844\n",
      "Seed: 44, Epoch: 149, Loss: 0.8342, Val Acc: 0.4933, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 150, Loss: 0.8483, Val Acc: 0.5067, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 151, Loss: 0.8458, Val Acc: 0.4889, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 152, Loss: 0.8298, Val Acc: 0.5022, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 153, Loss: 0.8338, Val Acc: 0.4800, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 154, Loss: 0.8406, Val Acc: 0.4978, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 155, Loss: 0.8431, Val Acc: 0.4933, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 156, Loss: 0.8456, Val Acc: 0.5244, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 157, Loss: 0.8387, Val Acc: 0.5200, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 158, Loss: 0.8299, Val Acc: 0.5022, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 159, Loss: 0.8416, Val Acc: 0.5200, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 160, Loss: 0.8399, Val Acc: 0.5156, Test Acc: 0.5600\n",
      "Seed: 44, Epoch: 161, Loss: 0.8421, Val Acc: 0.5022, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 162, Loss: 0.8421, Val Acc: 0.4889, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 163, Loss: 0.8369, Val Acc: 0.4978, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 164, Loss: 0.8458, Val Acc: 0.4933, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 165, Loss: 0.8417, Val Acc: 0.4978, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 166, Loss: 0.8411, Val Acc: 0.4978, Test Acc: 0.4844\n",
      "Seed: 44, Epoch: 167, Loss: 0.8399, Val Acc: 0.5067, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 168, Loss: 0.8319, Val Acc: 0.4978, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 169, Loss: 0.8344, Val Acc: 0.5067, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 170, Loss: 0.8415, Val Acc: 0.4756, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 171, Loss: 0.8342, Val Acc: 0.4844, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 172, Loss: 0.8348, Val Acc: 0.4756, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 173, Loss: 0.8290, Val Acc: 0.4933, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 174, Loss: 0.8258, Val Acc: 0.4711, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 175, Loss: 0.8336, Val Acc: 0.4933, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 176, Loss: 0.8299, Val Acc: 0.4844, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 177, Loss: 0.8271, Val Acc: 0.5022, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 178, Loss: 0.8270, Val Acc: 0.4978, Test Acc: 0.5067\n",
      "Early stopping at epoch 178 for seed 44\n",
      "Average Time: 637.72 seconds\n",
      "Var Time: 2211.77 seconds\n",
      "Average Memory: 4450.00 MB\n",
      "Average Best Val Acc: 0.5378\n",
      "Std Best Test Acc: 0.0508\n",
      "Average Test Acc: 0.4593\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "max_nodes = 500\n",
    "data_path = \"/data/Zeyu/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"IMDB-MULTI\",\n",
    "    transform=T.Compose([T.OneHotDegree(88), T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_justbalance(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        #x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        #x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        #x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_justbalance().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    model = Net_justbalance().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 1.1240, Val Acc: 0.3213, Test Acc: 0.3320\n",
      "Seed: 42, Epoch: 002, Loss: 1.1014, Val Acc: 0.3213, Test Acc: 0.3320\n",
      "Seed: 42, Epoch: 003, Loss: 1.0578, Val Acc: 0.3213, Test Acc: 0.3320\n",
      "Seed: 42, Epoch: 004, Loss: 0.9834, Val Acc: 0.4293, Test Acc: 0.4653\n",
      "Seed: 42, Epoch: 005, Loss: 0.8906, Val Acc: 0.6400, Test Acc: 0.6387\n",
      "Seed: 42, Epoch: 006, Loss: 0.7986, Val Acc: 0.6053, Test Acc: 0.6227\n",
      "Seed: 42, Epoch: 007, Loss: 0.7193, Val Acc: 0.6240, Test Acc: 0.6373\n",
      "Seed: 42, Epoch: 008, Loss: 0.6427, Val Acc: 0.6413, Test Acc: 0.6467\n",
      "Seed: 42, Epoch: 009, Loss: 0.5866, Val Acc: 0.6587, Test Acc: 0.6720\n",
      "Seed: 42, Epoch: 010, Loss: 0.5546, Val Acc: 0.6813, Test Acc: 0.6867\n",
      "Seed: 42, Epoch: 011, Loss: 0.5314, Val Acc: 0.6973, Test Acc: 0.6907\n",
      "Seed: 42, Epoch: 012, Loss: 0.5132, Val Acc: 0.7160, Test Acc: 0.7000\n",
      "Seed: 42, Epoch: 013, Loss: 0.4961, Val Acc: 0.7227, Test Acc: 0.7053\n",
      "Seed: 42, Epoch: 014, Loss: 0.4843, Val Acc: 0.7213, Test Acc: 0.7040\n",
      "Seed: 42, Epoch: 015, Loss: 0.4721, Val Acc: 0.7200, Test Acc: 0.7053\n",
      "Seed: 42, Epoch: 016, Loss: 0.4629, Val Acc: 0.7200, Test Acc: 0.7053\n",
      "Seed: 42, Epoch: 017, Loss: 0.4531, Val Acc: 0.7267, Test Acc: 0.7093\n",
      "Seed: 42, Epoch: 018, Loss: 0.4444, Val Acc: 0.7467, Test Acc: 0.7187\n",
      "Seed: 42, Epoch: 019, Loss: 0.4358, Val Acc: 0.7320, Test Acc: 0.7173\n",
      "Seed: 42, Epoch: 020, Loss: 0.4317, Val Acc: 0.7573, Test Acc: 0.7413\n",
      "Seed: 42, Epoch: 021, Loss: 0.4221, Val Acc: 0.7760, Test Acc: 0.7427\n",
      "Seed: 42, Epoch: 022, Loss: 0.4133, Val Acc: 0.7800, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 023, Loss: 0.4065, Val Acc: 0.7867, Test Acc: 0.7480\n",
      "Seed: 42, Epoch: 024, Loss: 0.4033, Val Acc: 0.7853, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 025, Loss: 0.3958, Val Acc: 0.7853, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 026, Loss: 0.3915, Val Acc: 0.7933, Test Acc: 0.7427\n",
      "Seed: 42, Epoch: 027, Loss: 0.3864, Val Acc: 0.7893, Test Acc: 0.7480\n",
      "Seed: 42, Epoch: 028, Loss: 0.3825, Val Acc: 0.7867, Test Acc: 0.7547\n",
      "Seed: 42, Epoch: 029, Loss: 0.3793, Val Acc: 0.7840, Test Acc: 0.7547\n",
      "Seed: 42, Epoch: 030, Loss: 0.3718, Val Acc: 0.7893, Test Acc: 0.7413\n",
      "Seed: 42, Epoch: 031, Loss: 0.3715, Val Acc: 0.7827, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 032, Loss: 0.3622, Val Acc: 0.7880, Test Acc: 0.7573\n",
      "Seed: 42, Epoch: 033, Loss: 0.3578, Val Acc: 0.7987, Test Acc: 0.7573\n",
      "Seed: 42, Epoch: 034, Loss: 0.3496, Val Acc: 0.7907, Test Acc: 0.7587\n",
      "Seed: 42, Epoch: 035, Loss: 0.3472, Val Acc: 0.7880, Test Acc: 0.7547\n",
      "Seed: 42, Epoch: 036, Loss: 0.3397, Val Acc: 0.7880, Test Acc: 0.7573\n",
      "Seed: 42, Epoch: 037, Loss: 0.3379, Val Acc: 0.7853, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 038, Loss: 0.3352, Val Acc: 0.7867, Test Acc: 0.7547\n",
      "Seed: 42, Epoch: 039, Loss: 0.3316, Val Acc: 0.7933, Test Acc: 0.7493\n",
      "Seed: 42, Epoch: 040, Loss: 0.3276, Val Acc: 0.7893, Test Acc: 0.7507\n",
      "Seed: 42, Epoch: 041, Loss: 0.3224, Val Acc: 0.7947, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 042, Loss: 0.3190, Val Acc: 0.7787, Test Acc: 0.7573\n",
      "Seed: 42, Epoch: 043, Loss: 0.3166, Val Acc: 0.7920, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 044, Loss: 0.3176, Val Acc: 0.7827, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 045, Loss: 0.3139, Val Acc: 0.7960, Test Acc: 0.7453\n",
      "Seed: 42, Epoch: 046, Loss: 0.3100, Val Acc: 0.7920, Test Acc: 0.7413\n",
      "Seed: 42, Epoch: 047, Loss: 0.3056, Val Acc: 0.7880, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 048, Loss: 0.3013, Val Acc: 0.7933, Test Acc: 0.7480\n",
      "Seed: 42, Epoch: 049, Loss: 0.3026, Val Acc: 0.7827, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 050, Loss: 0.2964, Val Acc: 0.7787, Test Acc: 0.7453\n",
      "Seed: 42, Epoch: 051, Loss: 0.2939, Val Acc: 0.7880, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 052, Loss: 0.2894, Val Acc: 0.7827, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 053, Loss: 0.2869, Val Acc: 0.7880, Test Acc: 0.7480\n",
      "Seed: 42, Epoch: 054, Loss: 0.2843, Val Acc: 0.7920, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 055, Loss: 0.2864, Val Acc: 0.7800, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 056, Loss: 0.2856, Val Acc: 0.7813, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 057, Loss: 0.2808, Val Acc: 0.7907, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 058, Loss: 0.2794, Val Acc: 0.7933, Test Acc: 0.7493\n",
      "Seed: 42, Epoch: 059, Loss: 0.2748, Val Acc: 0.7920, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 060, Loss: 0.2737, Val Acc: 0.7893, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 061, Loss: 0.2715, Val Acc: 0.7853, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 062, Loss: 0.2665, Val Acc: 0.7960, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 063, Loss: 0.2671, Val Acc: 0.8040, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 064, Loss: 0.2616, Val Acc: 0.7920, Test Acc: 0.7640\n",
      "Seed: 42, Epoch: 065, Loss: 0.2569, Val Acc: 0.7893, Test Acc: 0.7507\n",
      "Seed: 42, Epoch: 066, Loss: 0.2532, Val Acc: 0.7933, Test Acc: 0.7573\n",
      "Seed: 42, Epoch: 067, Loss: 0.2523, Val Acc: 0.7880, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 068, Loss: 0.2476, Val Acc: 0.7973, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 069, Loss: 0.2440, Val Acc: 0.7840, Test Acc: 0.7587\n",
      "Seed: 42, Epoch: 070, Loss: 0.2438, Val Acc: 0.7853, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 071, Loss: 0.2405, Val Acc: 0.7840, Test Acc: 0.7573\n",
      "Seed: 42, Epoch: 072, Loss: 0.2327, Val Acc: 0.7893, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 073, Loss: 0.2268, Val Acc: 0.7933, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 074, Loss: 0.2205, Val Acc: 0.7880, Test Acc: 0.7587\n",
      "Seed: 42, Epoch: 075, Loss: 0.2212, Val Acc: 0.7920, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 076, Loss: 0.2203, Val Acc: 0.7907, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 077, Loss: 0.2120, Val Acc: 0.7880, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 078, Loss: 0.2086, Val Acc: 0.8027, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 079, Loss: 0.2076, Val Acc: 0.7907, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 080, Loss: 0.2130, Val Acc: 0.7973, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 081, Loss: 0.2157, Val Acc: 0.8120, Test Acc: 0.7813\n",
      "Seed: 42, Epoch: 082, Loss: 0.2052, Val Acc: 0.8040, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 083, Loss: 0.2024, Val Acc: 0.8053, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 084, Loss: 0.1957, Val Acc: 0.8040, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 085, Loss: 0.1918, Val Acc: 0.8080, Test Acc: 0.7707\n",
      "Seed: 42, Epoch: 086, Loss: 0.1863, Val Acc: 0.7987, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 087, Loss: 0.1789, Val Acc: 0.7973, Test Acc: 0.7787\n",
      "Seed: 42, Epoch: 088, Loss: 0.1774, Val Acc: 0.7933, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 089, Loss: 0.1719, Val Acc: 0.7880, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 090, Loss: 0.1707, Val Acc: 0.7867, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 091, Loss: 0.1719, Val Acc: 0.7773, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 092, Loss: 0.1712, Val Acc: 0.7907, Test Acc: 0.7707\n",
      "Seed: 42, Epoch: 093, Loss: 0.1758, Val Acc: 0.7893, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 094, Loss: 0.1911, Val Acc: 0.8000, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 095, Loss: 0.1910, Val Acc: 0.7853, Test Acc: 0.7493\n",
      "Seed: 42, Epoch: 096, Loss: 0.1848, Val Acc: 0.7960, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 097, Loss: 0.1811, Val Acc: 0.7920, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 098, Loss: 0.1718, Val Acc: 0.7880, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 099, Loss: 0.1692, Val Acc: 0.7827, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 100, Loss: 0.1595, Val Acc: 0.8013, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 101, Loss: 0.1608, Val Acc: 0.7787, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 102, Loss: 0.1646, Val Acc: 0.7960, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 103, Loss: 0.1604, Val Acc: 0.7947, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 104, Loss: 0.1542, Val Acc: 0.7853, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 105, Loss: 0.1457, Val Acc: 0.7907, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 106, Loss: 0.1369, Val Acc: 0.7893, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 107, Loss: 0.1370, Val Acc: 0.8000, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 108, Loss: 0.1340, Val Acc: 0.7880, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 109, Loss: 0.1330, Val Acc: 0.7947, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 110, Loss: 0.1325, Val Acc: 0.7960, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 111, Loss: 0.1333, Val Acc: 0.7973, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 112, Loss: 0.1368, Val Acc: 0.7947, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 113, Loss: 0.1413, Val Acc: 0.7947, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 114, Loss: 0.1429, Val Acc: 0.7880, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 115, Loss: 0.1360, Val Acc: 0.7893, Test Acc: 0.7827\n",
      "Seed: 42, Epoch: 116, Loss: 0.1318, Val Acc: 0.7920, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 117, Loss: 0.1363, Val Acc: 0.8000, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 118, Loss: 0.1276, Val Acc: 0.8013, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 119, Loss: 0.1311, Val Acc: 0.8000, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 120, Loss: 0.1271, Val Acc: 0.7880, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 121, Loss: 0.1247, Val Acc: 0.7987, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 122, Loss: 0.1284, Val Acc: 0.7933, Test Acc: 0.7707\n",
      "Seed: 42, Epoch: 123, Loss: 0.1201, Val Acc: 0.8027, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 124, Loss: 0.1223, Val Acc: 0.8013, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 125, Loss: 0.1292, Val Acc: 0.7893, Test Acc: 0.7587\n",
      "Seed: 42, Epoch: 126, Loss: 0.1289, Val Acc: 0.8027, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 127, Loss: 0.1273, Val Acc: 0.7813, Test Acc: 0.7880\n",
      "Seed: 42, Epoch: 128, Loss: 0.1250, Val Acc: 0.7840, Test Acc: 0.7880\n",
      "Seed: 42, Epoch: 129, Loss: 0.1223, Val Acc: 0.7773, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 130, Loss: 0.1254, Val Acc: 0.7907, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 131, Loss: 0.1231, Val Acc: 0.8040, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 132, Loss: 0.1291, Val Acc: 0.7840, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 133, Loss: 0.1233, Val Acc: 0.8187, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 134, Loss: 0.1296, Val Acc: 0.7960, Test Acc: 0.7813\n",
      "Seed: 42, Epoch: 135, Loss: 0.1279, Val Acc: 0.7907, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 136, Loss: 0.1277, Val Acc: 0.7960, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 137, Loss: 0.1255, Val Acc: 0.7907, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 138, Loss: 0.1129, Val Acc: 0.7920, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 139, Loss: 0.1154, Val Acc: 0.7947, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 140, Loss: 0.1095, Val Acc: 0.7893, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 141, Loss: 0.1087, Val Acc: 0.7827, Test Acc: 0.7547\n",
      "Seed: 42, Epoch: 142, Loss: 0.1080, Val Acc: 0.7907, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 143, Loss: 0.1129, Val Acc: 0.7987, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 144, Loss: 0.1054, Val Acc: 0.7853, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 145, Loss: 0.0998, Val Acc: 0.7947, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 146, Loss: 0.1040, Val Acc: 0.8120, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 147, Loss: 0.1017, Val Acc: 0.8000, Test Acc: 0.7707\n",
      "Seed: 42, Epoch: 148, Loss: 0.0989, Val Acc: 0.7907, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 149, Loss: 0.1009, Val Acc: 0.8013, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 150, Loss: 0.0956, Val Acc: 0.7973, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 151, Loss: 0.0989, Val Acc: 0.8040, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 152, Loss: 0.0935, Val Acc: 0.8000, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 153, Loss: 0.0961, Val Acc: 0.7933, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 154, Loss: 0.1010, Val Acc: 0.7987, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 155, Loss: 0.1065, Val Acc: 0.7720, Test Acc: 0.7573\n",
      "Seed: 42, Epoch: 156, Loss: 0.1189, Val Acc: 0.7920, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 157, Loss: 0.1182, Val Acc: 0.7840, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 158, Loss: 0.1371, Val Acc: 0.7880, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 159, Loss: 0.1418, Val Acc: 0.8013, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 160, Loss: 0.1382, Val Acc: 0.7693, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 161, Loss: 0.1515, Val Acc: 0.7893, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 162, Loss: 0.1313, Val Acc: 0.7947, Test Acc: 0.7787\n",
      "Seed: 42, Epoch: 163, Loss: 0.1142, Val Acc: 0.7867, Test Acc: 0.7787\n",
      "Seed: 42, Epoch: 164, Loss: 0.1141, Val Acc: 0.7947, Test Acc: 0.7840\n",
      "Seed: 42, Epoch: 165, Loss: 0.1179, Val Acc: 0.7920, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 166, Loss: 0.1115, Val Acc: 0.7960, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 167, Loss: 0.1008, Val Acc: 0.7973, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 168, Loss: 0.1053, Val Acc: 0.8013, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 169, Loss: 0.1135, Val Acc: 0.7880, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 170, Loss: 0.1100, Val Acc: 0.7987, Test Acc: 0.7707\n",
      "Seed: 42, Epoch: 171, Loss: 0.1030, Val Acc: 0.7867, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 172, Loss: 0.1069, Val Acc: 0.7880, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 173, Loss: 0.0971, Val Acc: 0.7960, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 174, Loss: 0.1001, Val Acc: 0.8027, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 175, Loss: 0.0951, Val Acc: 0.7947, Test Acc: 0.7787\n",
      "Seed: 42, Epoch: 176, Loss: 0.1067, Val Acc: 0.7987, Test Acc: 0.7840\n",
      "Seed: 42, Epoch: 177, Loss: 0.1074, Val Acc: 0.7947, Test Acc: 0.7707\n",
      "Seed: 42, Epoch: 178, Loss: 0.1002, Val Acc: 0.7893, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 179, Loss: 0.0964, Val Acc: 0.7947, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 180, Loss: 0.0975, Val Acc: 0.8040, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 181, Loss: 0.0923, Val Acc: 0.8000, Test Acc: 0.7707\n",
      "Seed: 42, Epoch: 182, Loss: 0.0919, Val Acc: 0.8013, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 183, Loss: 0.0918, Val Acc: 0.7960, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 184, Loss: 0.1016, Val Acc: 0.7920, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 185, Loss: 0.0949, Val Acc: 0.7933, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 186, Loss: 0.0970, Val Acc: 0.7933, Test Acc: 0.7787\n",
      "Seed: 42, Epoch: 187, Loss: 0.0905, Val Acc: 0.7947, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 188, Loss: 0.0943, Val Acc: 0.7933, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 189, Loss: 0.0919, Val Acc: 0.8013, Test Acc: 0.7853\n",
      "Seed: 42, Epoch: 190, Loss: 0.0895, Val Acc: 0.7947, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 191, Loss: 0.0911, Val Acc: 0.8093, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 192, Loss: 0.0948, Val Acc: 0.8000, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 193, Loss: 0.0929, Val Acc: 0.7813, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 194, Loss: 0.0877, Val Acc: 0.7827, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 195, Loss: 0.0976, Val Acc: 0.7827, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 196, Loss: 0.0943, Val Acc: 0.7787, Test Acc: 0.7707\n",
      "Seed: 42, Epoch: 197, Loss: 0.0912, Val Acc: 0.7960, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 198, Loss: 0.0941, Val Acc: 0.7907, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 199, Loss: 0.0910, Val Acc: 0.8000, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 200, Loss: 0.0911, Val Acc: 0.8000, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 001, Loss: 1.1350, Val Acc: 0.1507, Test Acc: 0.1533\n",
      "Seed: 43, Epoch: 002, Loss: 1.0961, Val Acc: 0.2973, Test Acc: 0.2920\n",
      "Seed: 43, Epoch: 003, Loss: 1.0316, Val Acc: 0.5560, Test Acc: 0.5627\n",
      "Seed: 43, Epoch: 004, Loss: 0.9401, Val Acc: 0.5667, Test Acc: 0.5760\n",
      "Seed: 43, Epoch: 005, Loss: 0.8410, Val Acc: 0.5760, Test Acc: 0.5813\n",
      "Seed: 43, Epoch: 006, Loss: 0.7653, Val Acc: 0.6413, Test Acc: 0.6293\n",
      "Seed: 43, Epoch: 007, Loss: 0.6973, Val Acc: 0.6693, Test Acc: 0.6453\n",
      "Seed: 43, Epoch: 008, Loss: 0.6372, Val Acc: 0.6800, Test Acc: 0.6720\n",
      "Seed: 43, Epoch: 009, Loss: 0.5991, Val Acc: 0.6880, Test Acc: 0.6933\n",
      "Seed: 43, Epoch: 010, Loss: 0.5707, Val Acc: 0.7187, Test Acc: 0.7240\n",
      "Seed: 43, Epoch: 011, Loss: 0.5500, Val Acc: 0.7267, Test Acc: 0.7307\n",
      "Seed: 43, Epoch: 012, Loss: 0.5295, Val Acc: 0.7227, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 013, Loss: 0.5136, Val Acc: 0.7200, Test Acc: 0.7227\n",
      "Seed: 43, Epoch: 014, Loss: 0.5017, Val Acc: 0.7427, Test Acc: 0.7480\n",
      "Seed: 43, Epoch: 015, Loss: 0.4895, Val Acc: 0.7560, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 016, Loss: 0.4791, Val Acc: 0.7640, Test Acc: 0.7507\n",
      "Seed: 43, Epoch: 017, Loss: 0.4690, Val Acc: 0.7707, Test Acc: 0.7480\n",
      "Seed: 43, Epoch: 018, Loss: 0.4606, Val Acc: 0.7773, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 019, Loss: 0.4528, Val Acc: 0.7760, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 020, Loss: 0.4443, Val Acc: 0.7707, Test Acc: 0.7440\n",
      "Seed: 43, Epoch: 021, Loss: 0.4363, Val Acc: 0.7800, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 022, Loss: 0.4270, Val Acc: 0.7787, Test Acc: 0.7627\n",
      "Seed: 43, Epoch: 023, Loss: 0.4175, Val Acc: 0.7933, Test Acc: 0.7680\n",
      "Seed: 43, Epoch: 024, Loss: 0.4117, Val Acc: 0.7907, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 025, Loss: 0.4090, Val Acc: 0.7880, Test Acc: 0.7653\n",
      "Seed: 43, Epoch: 026, Loss: 0.3985, Val Acc: 0.7907, Test Acc: 0.7787\n",
      "Seed: 43, Epoch: 027, Loss: 0.3988, Val Acc: 0.7933, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 028, Loss: 0.3923, Val Acc: 0.7947, Test Acc: 0.7840\n",
      "Seed: 43, Epoch: 029, Loss: 0.3857, Val Acc: 0.7880, Test Acc: 0.7773\n",
      "Seed: 43, Epoch: 030, Loss: 0.3825, Val Acc: 0.7907, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 031, Loss: 0.3769, Val Acc: 0.7880, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 032, Loss: 0.3725, Val Acc: 0.7960, Test Acc: 0.7760\n",
      "Seed: 43, Epoch: 033, Loss: 0.3648, Val Acc: 0.8067, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 034, Loss: 0.3625, Val Acc: 0.8040, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 035, Loss: 0.3570, Val Acc: 0.8053, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 036, Loss: 0.3556, Val Acc: 0.7960, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 037, Loss: 0.3498, Val Acc: 0.8040, Test Acc: 0.7760\n",
      "Seed: 43, Epoch: 038, Loss: 0.3486, Val Acc: 0.8133, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 039, Loss: 0.3410, Val Acc: 0.8040, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 040, Loss: 0.3390, Val Acc: 0.8013, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 041, Loss: 0.3327, Val Acc: 0.8160, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 042, Loss: 0.3272, Val Acc: 0.8093, Test Acc: 0.7853\n",
      "Seed: 43, Epoch: 043, Loss: 0.3215, Val Acc: 0.8013, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 044, Loss: 0.3176, Val Acc: 0.8040, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 045, Loss: 0.3117, Val Acc: 0.8107, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 046, Loss: 0.3068, Val Acc: 0.8133, Test Acc: 0.7853\n",
      "Seed: 43, Epoch: 047, Loss: 0.3048, Val Acc: 0.8013, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 048, Loss: 0.2993, Val Acc: 0.8040, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 049, Loss: 0.2924, Val Acc: 0.7920, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 050, Loss: 0.2914, Val Acc: 0.8067, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 051, Loss: 0.2907, Val Acc: 0.7920, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 052, Loss: 0.2847, Val Acc: 0.8053, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 053, Loss: 0.2837, Val Acc: 0.8040, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 054, Loss: 0.2802, Val Acc: 0.7973, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 055, Loss: 0.2809, Val Acc: 0.7867, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 056, Loss: 0.2792, Val Acc: 0.8120, Test Acc: 0.8107\n",
      "Seed: 43, Epoch: 057, Loss: 0.2670, Val Acc: 0.8093, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 058, Loss: 0.2660, Val Acc: 0.8067, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 059, Loss: 0.2644, Val Acc: 0.8067, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 060, Loss: 0.2612, Val Acc: 0.8147, Test Acc: 0.8133\n",
      "Seed: 43, Epoch: 061, Loss: 0.2583, Val Acc: 0.8133, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 062, Loss: 0.2560, Val Acc: 0.8093, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 063, Loss: 0.2509, Val Acc: 0.8040, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 064, Loss: 0.2478, Val Acc: 0.8027, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 065, Loss: 0.2458, Val Acc: 0.7987, Test Acc: 0.8093\n",
      "Seed: 43, Epoch: 066, Loss: 0.2377, Val Acc: 0.8053, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 067, Loss: 0.2312, Val Acc: 0.8000, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 068, Loss: 0.2292, Val Acc: 0.7973, Test Acc: 0.8133\n",
      "Seed: 43, Epoch: 069, Loss: 0.2237, Val Acc: 0.8067, Test Acc: 0.7880\n",
      "Seed: 43, Epoch: 070, Loss: 0.2192, Val Acc: 0.7933, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 071, Loss: 0.2188, Val Acc: 0.8013, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 072, Loss: 0.2151, Val Acc: 0.8000, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 073, Loss: 0.2114, Val Acc: 0.7987, Test Acc: 0.8133\n",
      "Seed: 43, Epoch: 074, Loss: 0.2109, Val Acc: 0.7893, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 075, Loss: 0.2055, Val Acc: 0.7733, Test Acc: 0.7840\n",
      "Seed: 43, Epoch: 076, Loss: 0.2036, Val Acc: 0.7907, Test Acc: 0.8173\n",
      "Seed: 43, Epoch: 077, Loss: 0.1984, Val Acc: 0.7933, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 078, Loss: 0.1977, Val Acc: 0.7973, Test Acc: 0.8133\n",
      "Seed: 43, Epoch: 079, Loss: 0.1941, Val Acc: 0.7987, Test Acc: 0.8213\n",
      "Seed: 43, Epoch: 080, Loss: 0.1872, Val Acc: 0.7973, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 081, Loss: 0.1873, Val Acc: 0.7840, Test Acc: 0.8107\n",
      "Seed: 43, Epoch: 082, Loss: 0.1908, Val Acc: 0.7920, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 083, Loss: 0.1979, Val Acc: 0.7827, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 084, Loss: 0.1965, Val Acc: 0.7880, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 085, Loss: 0.1965, Val Acc: 0.7867, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 086, Loss: 0.1947, Val Acc: 0.7880, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 087, Loss: 0.1868, Val Acc: 0.7973, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 088, Loss: 0.1872, Val Acc: 0.7853, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 089, Loss: 0.1820, Val Acc: 0.7840, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 090, Loss: 0.1822, Val Acc: 0.7987, Test Acc: 0.8093\n",
      "Seed: 43, Epoch: 091, Loss: 0.1767, Val Acc: 0.7960, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 092, Loss: 0.1809, Val Acc: 0.7973, Test Acc: 0.8120\n",
      "Seed: 43, Epoch: 093, Loss: 0.1823, Val Acc: 0.7867, Test Acc: 0.8133\n",
      "Seed: 43, Epoch: 094, Loss: 0.1826, Val Acc: 0.7880, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 095, Loss: 0.1809, Val Acc: 0.7920, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 096, Loss: 0.1698, Val Acc: 0.7747, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 097, Loss: 0.1650, Val Acc: 0.7840, Test Acc: 0.8093\n",
      "Seed: 43, Epoch: 098, Loss: 0.1621, Val Acc: 0.7827, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 099, Loss: 0.1630, Val Acc: 0.7813, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 100, Loss: 0.1585, Val Acc: 0.7800, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 101, Loss: 0.1615, Val Acc: 0.7933, Test Acc: 0.8200\n",
      "Seed: 43, Epoch: 102, Loss: 0.1514, Val Acc: 0.7880, Test Acc: 0.8173\n",
      "Seed: 43, Epoch: 103, Loss: 0.1483, Val Acc: 0.7893, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 104, Loss: 0.1462, Val Acc: 0.7880, Test Acc: 0.8120\n",
      "Seed: 43, Epoch: 105, Loss: 0.1484, Val Acc: 0.7787, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 106, Loss: 0.1506, Val Acc: 0.7800, Test Acc: 0.8173\n",
      "Seed: 43, Epoch: 107, Loss: 0.1432, Val Acc: 0.7827, Test Acc: 0.8093\n",
      "Seed: 43, Epoch: 108, Loss: 0.1481, Val Acc: 0.7813, Test Acc: 0.8173\n",
      "Seed: 43, Epoch: 109, Loss: 0.1434, Val Acc: 0.7813, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 110, Loss: 0.1456, Val Acc: 0.7760, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 111, Loss: 0.1497, Val Acc: 0.7867, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 112, Loss: 0.1476, Val Acc: 0.7907, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 113, Loss: 0.1471, Val Acc: 0.7960, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 114, Loss: 0.1446, Val Acc: 0.7773, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 115, Loss: 0.1444, Val Acc: 0.7747, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 116, Loss: 0.1415, Val Acc: 0.7920, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 117, Loss: 0.1429, Val Acc: 0.7880, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 118, Loss: 0.1456, Val Acc: 0.7867, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 119, Loss: 0.1458, Val Acc: 0.7853, Test Acc: 0.8120\n",
      "Seed: 43, Epoch: 120, Loss: 0.1428, Val Acc: 0.7880, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 121, Loss: 0.1505, Val Acc: 0.7787, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 122, Loss: 0.1598, Val Acc: 0.7973, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 123, Loss: 0.1642, Val Acc: 0.7840, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 124, Loss: 0.1695, Val Acc: 0.7760, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 125, Loss: 0.1577, Val Acc: 0.7813, Test Acc: 0.7827\n",
      "Seed: 43, Epoch: 126, Loss: 0.1514, Val Acc: 0.7893, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 127, Loss: 0.1446, Val Acc: 0.7920, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 128, Loss: 0.1377, Val Acc: 0.7867, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 129, Loss: 0.1344, Val Acc: 0.7827, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 130, Loss: 0.1358, Val Acc: 0.7880, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 131, Loss: 0.1313, Val Acc: 0.7853, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 132, Loss: 0.1314, Val Acc: 0.7747, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 133, Loss: 0.1332, Val Acc: 0.7760, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 134, Loss: 0.1388, Val Acc: 0.7867, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 135, Loss: 0.1314, Val Acc: 0.7933, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 136, Loss: 0.1291, Val Acc: 0.7947, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 137, Loss: 0.1216, Val Acc: 0.7920, Test Acc: 0.8107\n",
      "Seed: 43, Epoch: 138, Loss: 0.1230, Val Acc: 0.7973, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 139, Loss: 0.1230, Val Acc: 0.7773, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 140, Loss: 0.1236, Val Acc: 0.7840, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 141, Loss: 0.1235, Val Acc: 0.7880, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 142, Loss: 0.1184, Val Acc: 0.7813, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 143, Loss: 0.1218, Val Acc: 0.7800, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 144, Loss: 0.1212, Val Acc: 0.7813, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 145, Loss: 0.1159, Val Acc: 0.7720, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 146, Loss: 0.1219, Val Acc: 0.7733, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 147, Loss: 0.1173, Val Acc: 0.7787, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 148, Loss: 0.1169, Val Acc: 0.7800, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 149, Loss: 0.1167, Val Acc: 0.7933, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 150, Loss: 0.1168, Val Acc: 0.7747, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 151, Loss: 0.1157, Val Acc: 0.7813, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 152, Loss: 0.1225, Val Acc: 0.7920, Test Acc: 0.8107\n",
      "Seed: 43, Epoch: 153, Loss: 0.1254, Val Acc: 0.7867, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 154, Loss: 0.1330, Val Acc: 0.7773, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 155, Loss: 0.1266, Val Acc: 0.7773, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 156, Loss: 0.1302, Val Acc: 0.7960, Test Acc: 0.8120\n",
      "Seed: 43, Epoch: 157, Loss: 0.1229, Val Acc: 0.7933, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 158, Loss: 0.1307, Val Acc: 0.7840, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 159, Loss: 0.1275, Val Acc: 0.7853, Test Acc: 0.8120\n",
      "Seed: 43, Epoch: 160, Loss: 0.1228, Val Acc: 0.7880, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 161, Loss: 0.1222, Val Acc: 0.7747, Test Acc: 0.7880\n",
      "Seed: 43, Epoch: 162, Loss: 0.1150, Val Acc: 0.7773, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 163, Loss: 0.1176, Val Acc: 0.7760, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 164, Loss: 0.1116, Val Acc: 0.7773, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 165, Loss: 0.1120, Val Acc: 0.7747, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 166, Loss: 0.1164, Val Acc: 0.7787, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 167, Loss: 0.1161, Val Acc: 0.7960, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 168, Loss: 0.1193, Val Acc: 0.7920, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 169, Loss: 0.1220, Val Acc: 0.7773, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 170, Loss: 0.1178, Val Acc: 0.7933, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 171, Loss: 0.1142, Val Acc: 0.7907, Test Acc: 0.8120\n",
      "Seed: 43, Epoch: 172, Loss: 0.1111, Val Acc: 0.7813, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 173, Loss: 0.1092, Val Acc: 0.7933, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 174, Loss: 0.1069, Val Acc: 0.7987, Test Acc: 0.8107\n",
      "Seed: 43, Epoch: 175, Loss: 0.1053, Val Acc: 0.7893, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 176, Loss: 0.1065, Val Acc: 0.7933, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 177, Loss: 0.1062, Val Acc: 0.7853, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 178, Loss: 0.1042, Val Acc: 0.7840, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 179, Loss: 0.1068, Val Acc: 0.7960, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 180, Loss: 0.1128, Val Acc: 0.7653, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 181, Loss: 0.1230, Val Acc: 0.7907, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 182, Loss: 0.1243, Val Acc: 0.7800, Test Acc: 0.7813\n",
      "Seed: 43, Epoch: 183, Loss: 0.1305, Val Acc: 0.8000, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 184, Loss: 0.1299, Val Acc: 0.7973, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 185, Loss: 0.1313, Val Acc: 0.7813, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 186, Loss: 0.1236, Val Acc: 0.7827, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 187, Loss: 0.1337, Val Acc: 0.7827, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 188, Loss: 0.1304, Val Acc: 0.7787, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 189, Loss: 0.1231, Val Acc: 0.7853, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 190, Loss: 0.1191, Val Acc: 0.7880, Test Acc: 0.8147\n",
      "Seed: 43, Epoch: 191, Loss: 0.1095, Val Acc: 0.7880, Test Acc: 0.8080\n",
      "Early stopping at epoch 191 for seed 43\n",
      "Seed: 44, Epoch: 001, Loss: 1.0857, Val Acc: 0.3587, Test Acc: 0.3320\n",
      "Seed: 44, Epoch: 002, Loss: 1.0649, Val Acc: 0.6413, Test Acc: 0.6200\n",
      "Seed: 44, Epoch: 003, Loss: 1.0320, Val Acc: 0.6160, Test Acc: 0.6347\n",
      "Seed: 44, Epoch: 004, Loss: 0.9833, Val Acc: 0.6320, Test Acc: 0.6453\n",
      "Seed: 44, Epoch: 005, Loss: 0.9178, Val Acc: 0.6387, Test Acc: 0.6587\n",
      "Seed: 44, Epoch: 006, Loss: 0.8417, Val Acc: 0.6427, Test Acc: 0.6640\n",
      "Seed: 44, Epoch: 007, Loss: 0.7610, Val Acc: 0.6467, Test Acc: 0.6640\n",
      "Seed: 44, Epoch: 008, Loss: 0.6921, Val Acc: 0.6627, Test Acc: 0.6707\n",
      "Seed: 44, Epoch: 009, Loss: 0.6454, Val Acc: 0.7107, Test Acc: 0.7093\n",
      "Seed: 44, Epoch: 010, Loss: 0.6082, Val Acc: 0.7187, Test Acc: 0.7147\n",
      "Seed: 44, Epoch: 011, Loss: 0.5821, Val Acc: 0.7280, Test Acc: 0.7147\n",
      "Seed: 44, Epoch: 012, Loss: 0.5594, Val Acc: 0.7293, Test Acc: 0.7173\n",
      "Seed: 44, Epoch: 013, Loss: 0.5396, Val Acc: 0.7307, Test Acc: 0.7187\n",
      "Seed: 44, Epoch: 014, Loss: 0.5238, Val Acc: 0.7253, Test Acc: 0.7213\n",
      "Seed: 44, Epoch: 015, Loss: 0.5135, Val Acc: 0.7280, Test Acc: 0.7120\n",
      "Seed: 44, Epoch: 016, Loss: 0.5025, Val Acc: 0.7280, Test Acc: 0.7173\n",
      "Seed: 44, Epoch: 017, Loss: 0.4907, Val Acc: 0.7267, Test Acc: 0.7147\n",
      "Seed: 44, Epoch: 018, Loss: 0.4792, Val Acc: 0.7253, Test Acc: 0.7173\n",
      "Seed: 44, Epoch: 019, Loss: 0.4722, Val Acc: 0.7387, Test Acc: 0.7227\n",
      "Seed: 44, Epoch: 020, Loss: 0.4640, Val Acc: 0.7347, Test Acc: 0.7253\n",
      "Seed: 44, Epoch: 021, Loss: 0.4552, Val Acc: 0.7400, Test Acc: 0.7240\n",
      "Seed: 44, Epoch: 022, Loss: 0.4456, Val Acc: 0.7320, Test Acc: 0.7147\n",
      "Seed: 44, Epoch: 023, Loss: 0.4357, Val Acc: 0.7347, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 024, Loss: 0.4286, Val Acc: 0.7347, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 025, Loss: 0.4176, Val Acc: 0.7360, Test Acc: 0.7253\n",
      "Seed: 44, Epoch: 026, Loss: 0.4110, Val Acc: 0.7533, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 027, Loss: 0.4016, Val Acc: 0.7520, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 028, Loss: 0.3971, Val Acc: 0.7493, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 029, Loss: 0.3984, Val Acc: 0.7520, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 030, Loss: 0.3903, Val Acc: 0.7533, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 031, Loss: 0.3810, Val Acc: 0.7493, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 032, Loss: 0.3746, Val Acc: 0.7560, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 033, Loss: 0.3741, Val Acc: 0.7653, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 034, Loss: 0.3724, Val Acc: 0.7653, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 035, Loss: 0.3653, Val Acc: 0.7640, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 036, Loss: 0.3621, Val Acc: 0.7707, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 037, Loss: 0.3518, Val Acc: 0.7600, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 038, Loss: 0.3500, Val Acc: 0.7627, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 039, Loss: 0.3459, Val Acc: 0.7693, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 040, Loss: 0.3426, Val Acc: 0.7560, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 041, Loss: 0.3411, Val Acc: 0.7413, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 042, Loss: 0.3415, Val Acc: 0.7547, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 043, Loss: 0.3420, Val Acc: 0.7587, Test Acc: 0.7760\n",
      "Seed: 44, Epoch: 044, Loss: 0.3341, Val Acc: 0.7707, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 045, Loss: 0.3327, Val Acc: 0.7693, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 046, Loss: 0.3262, Val Acc: 0.7653, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 047, Loss: 0.3239, Val Acc: 0.7760, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 048, Loss: 0.3218, Val Acc: 0.7747, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 049, Loss: 0.3169, Val Acc: 0.7667, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 050, Loss: 0.3189, Val Acc: 0.7680, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 051, Loss: 0.3157, Val Acc: 0.7667, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 052, Loss: 0.3103, Val Acc: 0.7733, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 053, Loss: 0.3096, Val Acc: 0.7680, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 054, Loss: 0.3062, Val Acc: 0.7773, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 055, Loss: 0.2990, Val Acc: 0.7600, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 056, Loss: 0.2979, Val Acc: 0.7693, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 057, Loss: 0.2935, Val Acc: 0.7707, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 058, Loss: 0.2895, Val Acc: 0.7653, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 059, Loss: 0.2861, Val Acc: 0.7693, Test Acc: 0.7760\n",
      "Seed: 44, Epoch: 060, Loss: 0.2815, Val Acc: 0.7653, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 061, Loss: 0.2808, Val Acc: 0.7813, Test Acc: 0.7760\n",
      "Seed: 44, Epoch: 062, Loss: 0.2764, Val Acc: 0.7573, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 063, Loss: 0.2764, Val Acc: 0.7707, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 064, Loss: 0.2722, Val Acc: 0.7733, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 065, Loss: 0.2682, Val Acc: 0.7613, Test Acc: 0.7760\n",
      "Seed: 44, Epoch: 066, Loss: 0.2640, Val Acc: 0.7680, Test Acc: 0.7760\n",
      "Seed: 44, Epoch: 067, Loss: 0.2623, Val Acc: 0.7733, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 068, Loss: 0.2613, Val Acc: 0.7640, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 069, Loss: 0.2687, Val Acc: 0.7733, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 070, Loss: 0.2592, Val Acc: 0.7573, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 071, Loss: 0.2554, Val Acc: 0.7773, Test Acc: 0.7787\n",
      "Seed: 44, Epoch: 072, Loss: 0.2514, Val Acc: 0.7653, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 073, Loss: 0.2486, Val Acc: 0.7853, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 074, Loss: 0.2446, Val Acc: 0.7600, Test Acc: 0.7720\n",
      "Seed: 44, Epoch: 075, Loss: 0.2431, Val Acc: 0.7707, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 076, Loss: 0.2371, Val Acc: 0.7640, Test Acc: 0.7760\n",
      "Seed: 44, Epoch: 077, Loss: 0.2433, Val Acc: 0.7627, Test Acc: 0.7760\n",
      "Seed: 44, Epoch: 078, Loss: 0.2408, Val Acc: 0.7653, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 079, Loss: 0.2409, Val Acc: 0.7587, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 080, Loss: 0.2351, Val Acc: 0.7533, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 081, Loss: 0.2315, Val Acc: 0.7587, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 082, Loss: 0.2357, Val Acc: 0.7520, Test Acc: 0.7640\n",
      "Seed: 44, Epoch: 083, Loss: 0.2282, Val Acc: 0.7533, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 084, Loss: 0.2247, Val Acc: 0.7507, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 085, Loss: 0.2231, Val Acc: 0.7453, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 086, Loss: 0.2233, Val Acc: 0.7640, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 087, Loss: 0.2173, Val Acc: 0.7667, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 088, Loss: 0.2199, Val Acc: 0.7707, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 089, Loss: 0.2184, Val Acc: 0.7720, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 090, Loss: 0.2135, Val Acc: 0.7733, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 091, Loss: 0.2071, Val Acc: 0.7453, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 092, Loss: 0.2109, Val Acc: 0.7640, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 093, Loss: 0.2202, Val Acc: 0.7627, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 094, Loss: 0.2135, Val Acc: 0.7747, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 095, Loss: 0.2017, Val Acc: 0.7680, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 096, Loss: 0.1972, Val Acc: 0.7707, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 097, Loss: 0.1962, Val Acc: 0.7813, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 098, Loss: 0.1930, Val Acc: 0.7587, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 099, Loss: 0.1866, Val Acc: 0.7587, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 100, Loss: 0.1835, Val Acc: 0.7547, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 101, Loss: 0.1836, Val Acc: 0.7680, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 102, Loss: 0.1752, Val Acc: 0.7560, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 103, Loss: 0.1864, Val Acc: 0.7480, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 104, Loss: 0.1794, Val Acc: 0.7547, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 105, Loss: 0.1824, Val Acc: 0.7493, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 106, Loss: 0.1744, Val Acc: 0.7600, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 107, Loss: 0.1706, Val Acc: 0.7573, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 108, Loss: 0.1648, Val Acc: 0.7387, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 109, Loss: 0.1623, Val Acc: 0.7413, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 110, Loss: 0.1561, Val Acc: 0.7800, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 111, Loss: 0.1566, Val Acc: 0.7440, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 112, Loss: 0.1567, Val Acc: 0.7720, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 113, Loss: 0.1550, Val Acc: 0.7667, Test Acc: 0.7640\n",
      "Seed: 44, Epoch: 114, Loss: 0.1534, Val Acc: 0.7573, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 115, Loss: 0.1452, Val Acc: 0.7493, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 116, Loss: 0.1499, Val Acc: 0.7733, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 117, Loss: 0.1605, Val Acc: 0.7360, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 118, Loss: 0.1812, Val Acc: 0.7520, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 119, Loss: 0.1740, Val Acc: 0.7773, Test Acc: 0.7720\n",
      "Seed: 44, Epoch: 120, Loss: 0.1671, Val Acc: 0.7493, Test Acc: 0.7640\n",
      "Seed: 44, Epoch: 121, Loss: 0.1697, Val Acc: 0.7587, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 122, Loss: 0.1607, Val Acc: 0.7467, Test Acc: 0.7560\n",
      "Seed: 44, Epoch: 123, Loss: 0.1577, Val Acc: 0.7640, Test Acc: 0.7573\n",
      "Seed: 44, Epoch: 124, Loss: 0.1496, Val Acc: 0.7547, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 125, Loss: 0.1463, Val Acc: 0.7613, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 126, Loss: 0.1436, Val Acc: 0.7653, Test Acc: 0.7720\n",
      "Seed: 44, Epoch: 127, Loss: 0.1351, Val Acc: 0.7653, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 128, Loss: 0.1323, Val Acc: 0.7600, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 129, Loss: 0.1233, Val Acc: 0.7533, Test Acc: 0.7627\n",
      "Seed: 44, Epoch: 130, Loss: 0.1238, Val Acc: 0.7613, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 131, Loss: 0.1204, Val Acc: 0.7707, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 132, Loss: 0.1139, Val Acc: 0.7680, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 133, Loss: 0.1136, Val Acc: 0.7533, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 134, Loss: 0.1121, Val Acc: 0.7707, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 135, Loss: 0.1120, Val Acc: 0.7347, Test Acc: 0.7507\n",
      "Seed: 44, Epoch: 136, Loss: 0.1116, Val Acc: 0.7667, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 137, Loss: 0.1096, Val Acc: 0.7640, Test Acc: 0.7640\n",
      "Seed: 44, Epoch: 138, Loss: 0.1051, Val Acc: 0.7480, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 139, Loss: 0.1059, Val Acc: 0.7613, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 140, Loss: 0.1133, Val Acc: 0.7507, Test Acc: 0.7640\n",
      "Seed: 44, Epoch: 141, Loss: 0.1162, Val Acc: 0.7480, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 142, Loss: 0.1139, Val Acc: 0.7507, Test Acc: 0.7627\n",
      "Seed: 44, Epoch: 143, Loss: 0.1173, Val Acc: 0.7533, Test Acc: 0.7760\n",
      "Seed: 44, Epoch: 144, Loss: 0.1106, Val Acc: 0.7400, Test Acc: 0.7453\n",
      "Seed: 44, Epoch: 145, Loss: 0.1061, Val Acc: 0.7467, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 146, Loss: 0.1029, Val Acc: 0.7627, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 147, Loss: 0.1004, Val Acc: 0.7493, Test Acc: 0.7627\n",
      "Seed: 44, Epoch: 148, Loss: 0.0995, Val Acc: 0.7413, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 149, Loss: 0.1049, Val Acc: 0.7613, Test Acc: 0.7720\n",
      "Seed: 44, Epoch: 150, Loss: 0.1100, Val Acc: 0.7427, Test Acc: 0.7573\n",
      "Seed: 44, Epoch: 151, Loss: 0.1027, Val Acc: 0.7533, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 152, Loss: 0.1038, Val Acc: 0.7573, Test Acc: 0.7547\n",
      "Seed: 44, Epoch: 153, Loss: 0.0989, Val Acc: 0.7667, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 154, Loss: 0.0993, Val Acc: 0.7533, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 155, Loss: 0.1092, Val Acc: 0.7493, Test Acc: 0.7427\n",
      "Seed: 44, Epoch: 156, Loss: 0.1089, Val Acc: 0.7520, Test Acc: 0.7627\n",
      "Seed: 44, Epoch: 157, Loss: 0.1099, Val Acc: 0.7520, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 158, Loss: 0.1190, Val Acc: 0.7467, Test Acc: 0.7587\n",
      "Seed: 44, Epoch: 159, Loss: 0.1200, Val Acc: 0.7587, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 160, Loss: 0.1233, Val Acc: 0.7507, Test Acc: 0.7587\n",
      "Seed: 44, Epoch: 161, Loss: 0.1247, Val Acc: 0.7480, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 162, Loss: 0.1178, Val Acc: 0.7360, Test Acc: 0.7427\n",
      "Seed: 44, Epoch: 163, Loss: 0.1497, Val Acc: 0.7627, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 164, Loss: 0.1618, Val Acc: 0.7507, Test Acc: 0.7640\n",
      "Seed: 44, Epoch: 165, Loss: 0.1550, Val Acc: 0.7560, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 166, Loss: 0.1494, Val Acc: 0.7373, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 167, Loss: 0.1431, Val Acc: 0.7520, Test Acc: 0.7480\n",
      "Seed: 44, Epoch: 168, Loss: 0.1436, Val Acc: 0.7413, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 169, Loss: 0.1474, Val Acc: 0.7440, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 170, Loss: 0.1412, Val Acc: 0.7760, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 171, Loss: 0.1294, Val Acc: 0.7693, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 172, Loss: 0.1203, Val Acc: 0.7853, Test Acc: 0.7720\n",
      "Seed: 44, Epoch: 173, Loss: 0.1180, Val Acc: 0.7613, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 174, Loss: 0.1060, Val Acc: 0.7760, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 175, Loss: 0.1036, Val Acc: 0.7627, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 176, Loss: 0.0966, Val Acc: 0.7667, Test Acc: 0.7573\n",
      "Seed: 44, Epoch: 177, Loss: 0.0933, Val Acc: 0.7613, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 178, Loss: 0.0916, Val Acc: 0.7587, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 179, Loss: 0.0906, Val Acc: 0.7653, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 180, Loss: 0.0897, Val Acc: 0.7773, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 181, Loss: 0.0959, Val Acc: 0.7600, Test Acc: 0.7560\n",
      "Seed: 44, Epoch: 182, Loss: 0.0943, Val Acc: 0.7520, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 183, Loss: 0.0940, Val Acc: 0.7467, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 184, Loss: 0.0927, Val Acc: 0.7453, Test Acc: 0.7573\n",
      "Seed: 44, Epoch: 185, Loss: 0.0880, Val Acc: 0.7653, Test Acc: 0.7573\n",
      "Seed: 44, Epoch: 186, Loss: 0.0912, Val Acc: 0.7467, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 187, Loss: 0.0860, Val Acc: 0.7413, Test Acc: 0.7573\n",
      "Seed: 44, Epoch: 188, Loss: 0.0842, Val Acc: 0.7440, Test Acc: 0.7573\n",
      "Seed: 44, Epoch: 189, Loss: 0.0792, Val Acc: 0.7467, Test Acc: 0.7507\n",
      "Seed: 44, Epoch: 190, Loss: 0.0817, Val Acc: 0.7387, Test Acc: 0.7547\n",
      "Seed: 44, Epoch: 191, Loss: 0.0854, Val Acc: 0.7507, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 192, Loss: 0.0807, Val Acc: 0.7453, Test Acc: 0.7587\n",
      "Seed: 44, Epoch: 193, Loss: 0.0810, Val Acc: 0.7467, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 194, Loss: 0.0845, Val Acc: 0.7440, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 195, Loss: 0.0788, Val Acc: 0.7493, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 196, Loss: 0.0809, Val Acc: 0.7520, Test Acc: 0.7547\n",
      "Seed: 44, Epoch: 197, Loss: 0.0791, Val Acc: 0.7493, Test Acc: 0.7507\n",
      "Seed: 44, Epoch: 198, Loss: 0.0797, Val Acc: 0.7573, Test Acc: 0.7507\n",
      "Seed: 44, Epoch: 199, Loss: 0.0807, Val Acc: 0.7453, Test Acc: 0.7427\n",
      "Seed: 44, Epoch: 200, Loss: 0.0815, Val Acc: 0.7453, Test Acc: 0.7693\n",
      "Average Time: 1923.86 seconds\n",
      "Var Time: 24657.78 seconds\n",
      "Average Memory: 5888.00 MB\n",
      "Average Best Val Acc: 0.8067\n",
      "Std Best Test Acc: 0.0126\n",
      "Average Test Acc: 0.7787\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_nodes = 500\n",
    "data_path = \"/data/Zeyu/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"COLLAB\",\n",
    "    transform=T.Compose([T.OneHotDegree(491), T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_justbalance(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_justbalance().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=512, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "    model = Net_justbalance().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QM7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existed dataset loaded: datasets/processed/qm7.pt\n",
      "\n",
      "Current dataset: qm7, include 6832 molecules and 1 regression tasks\n",
      "\n",
      "Splitting, finish 1/1  \n",
      "Epoch: 1/500Traceback (most recent call last):\n",
      "  File \"/data/Zeyu/Pooling/Graph_Pooling_Benchmark/Regression/run_regression.py\", line 140, in <module>\n",
      "    _, metric_te = trainer.fit_and_test(loader_tr[i], loader_va[i], loader_te[i], log_train_results=args.log_train_results,\n",
      "  File \"/data/Zeyu/Pooling/Graph_Pooling_Benchmark/Regression/process/trainer.py\", line 166, in _train_test_reg\n",
      "    val_loss, val_metric = self._eval_reg(loader_va)\n",
      "  File \"/home/boot/anaconda3/envs/zeyu1/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/data/Zeyu/Pooling/Graph_Pooling_Benchmark/Regression/process/trainer.py\", line 337, in _eval_reg\n",
      "    val = mean_absolute_error(y_true, y_scores) # , multioutput='raw_values'\n",
      "  File \"/home/boot/anaconda3/envs/zeyu1/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/boot/anaconda3/envs/zeyu1/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 216, in mean_absolute_error\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"/home/boot/anaconda3/envs/zeyu1/lib/python3.10/site-packages/sklearn/metrics/_regression.py\", line 113, in _check_reg_targets\n",
      "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
      "  File \"/home/boot/anaconda3/envs/zeyu1/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1064, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/home/boot/anaconda3/envs/zeyu1/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 123, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/home/boot/anaconda3/envs/zeyu1/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 172, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n"
     ]
    }
   ],
   "source": [
    "!python /data/Zeyu/Pooling/Graph_Pooling_Benchmark/Regression/run_regression.py --dataset=qm7 --cuda_num 0 --run_times=5 --patience=150 --epochs=500 --pooling='just_balance'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CG-ODE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
