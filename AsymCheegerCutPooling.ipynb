{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boot/anaconda3/envs/XXX1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import sys\n",
    "import torch\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from typing import Optional\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data.datapipes import functional_transform\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.datasets import WebKB\n",
    "from torch_geometric.datasets import Actor\n",
    "from torch_geometric.datasets import GNNBenchmarkDataset\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from sklearn.metrics import r2_score\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch.nn import Linear\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "from torch_sparse import spspmm\n",
    "from torch_sparse import coalesce\n",
    "from torch_sparse import eye\n",
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter_add\n",
    "from torch_scatter import scatter_max\n",
    "\n",
    "from torch_scatter import scatter_add, scatter\n",
    "from torch_geometric.nn.inits import uniform\n",
    "from torch_geometric.nn.resolver import activation_resolver\n",
    "from torch_geometric.nn import GCNConv, GATConv, LEConv, SAGEConv, GraphConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.utils import add_remaining_self_loops, to_dense_adj, add_self_loops\n",
    "from typing import Callable, Optional, Union\n",
    "from torch_sparse import coalesce, transpose\n",
    "from torch_scatter import scatter\n",
    "from torch import Tensor\n",
    "\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import math\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn.models.mlp import Linear\n",
    "from torch_geometric.nn.resolver import activation_resolver\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "class AsymCheegerCutPool(torch.nn.Module):\n",
    "    r\"\"\"\n",
    "    The asymmetric cheeger cut pooling layer from the `\"Total Variation Graph Neural Networks\"\n",
    "    <https://arxiv.org/abs/2211.06218>`_ paper.\n",
    "\n",
    "    Args:\n",
    "        k (int):\n",
    "            Number of clusters or output nodes\n",
    "        mlp_channels (int, list of int):\n",
    "            Number of hidden units for each hidden layer in the MLP used to\n",
    "            compute cluster assignments. First integer must match the number\n",
    "            of input channels.\n",
    "        mlp_activation (any):\n",
    "            Activation function between hidden layers of the MLP.\n",
    "            Must be compatible with `torch_geometric.nn.resolver`.\n",
    "        return_selection (bool):\n",
    "            Whether to return selection matrix. Cannot not  be False\n",
    "            if `return_pooled_graph` is False. (default: :obj:`False`)\n",
    "        return_pooled_graph (bool):\n",
    "            Whether to return pooled node features and adjacency.\n",
    "            Cannot be False if `return_selection` is False. (default: :obj:`True`)\n",
    "        bias (bool):\n",
    "            whether to add a bias term to the MLP layers. (default: :obj:`True`)\n",
    "        totvar_coeff (float):\n",
    "            Coefficient for graph total variation loss component. (default: :obj:`1.0`)\n",
    "        balance_coeff (float):\n",
    "            Coefficient for asymmetric norm loss component. (default: :obj:`1.0`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 k: int,\n",
    "                 mlp_channels: Union[int, List[int]],\n",
    "                 mlp_activation=\"relu\",\n",
    "                 return_selection: bool = False,\n",
    "                 return_pooled_graph: bool = True,\n",
    "                 bias: bool = True,\n",
    "                 totvar_coeff: float = 1.0,\n",
    "                 balance_coeff: float = 1.0,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        if not return_selection and not return_pooled_graph:\n",
    "            raise ValueError(\"return_selection and return_pooled_graph can not both be False\")\n",
    "\n",
    "        if isinstance(mlp_channels, int):\n",
    "            mlp_channels = [mlp_channels]\n",
    "\n",
    "        act = activation_resolver(mlp_activation)\n",
    "        in_channels = mlp_channels[0]\n",
    "        self.mlp = torch.nn.Sequential()\n",
    "        for channels in mlp_channels[1:]:\n",
    "            self.mlp.append(Linear(in_channels, channels, bias=bias))\n",
    "            in_channels = channels\n",
    "            self.mlp.append(act)\n",
    "\n",
    "\n",
    "        self.mlp.append(Linear(in_channels, k))\n",
    "        self.k = k\n",
    "        self.return_selection = return_selection\n",
    "        self.return_pooled_graph = return_pooled_graph\n",
    "        self.totvar_coeff = totvar_coeff\n",
    "        self.balance_coeff = balance_coeff\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for layer in self.mlp:\n",
    "            if isinstance(layer, Linear):\n",
    "                torch.nn.init.xavier_uniform(layer.weight)\n",
    "                torch.nn.init.zeros_(layer.bias)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        adj: Tensor,\n",
    "        mask: Optional[Tensor] = None,\n",
    "    ) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            x (Tensor):\n",
    "                Node feature tensor :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times N \\times F}`\n",
    "                with batch-size :math:`B`, (maximum) number of nodes :math:`N` for each graph,\n",
    "                and feature dimension :math:`F`. Note that the cluster assignment matrix\n",
    "                :math:`\\mathbf{S} \\in \\mathbb{R}^{B \\times N \\times C}` is\n",
    "                being created within this method.\n",
    "            adj (Tensor):\n",
    "                Adjacency tensor :math:`\\mathbf{A} \\in \\mathbb{R}^{B \\times N \\times N}`.\n",
    "            mask (BoolTensor, optional):\n",
    "                Mask matrix :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}`\n",
    "                indicating the valid nodes for each graph. (default: :obj:`None`)\n",
    "\n",
    "        :rtype: (:class:`Tensor`, :class:`Tensor`, :class:`Tensor`,\n",
    "            :class:`Tensor`, :class:`Tensor`, :class:`Tensor`)\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(0) if x.dim() == 2 else x\n",
    "        adj = adj.unsqueeze(0) if adj.dim() == 2 else adj\n",
    "\n",
    "        s = self.mlp(x)\n",
    "        s = torch.softmax(s, dim=-1)\n",
    "\n",
    "        batch_size, n_nodes, _ = x.size()\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.view(batch_size, n_nodes, 1).to(x.dtype)\n",
    "            x, s = x * mask, s * mask\n",
    "\n",
    "        # Pooled features and adjacency\n",
    "        if self.return_pooled_graph:\n",
    "            x_pool = torch.matmul(s.transpose(1, 2), x)\n",
    "            adj_pool = torch.matmul(torch.matmul(s.transpose(1, 2), adj), s)\n",
    "\n",
    "        # Total variation loss\n",
    "        tv_loss = self.totvar_coeff*torch.mean(self.totvar_loss(adj, s))\n",
    "\n",
    "        # Balance loss\n",
    "        bal_loss = self.balance_coeff*torch.mean(self.balance_loss(s))\n",
    "\n",
    "        if self.return_selection and self.return_pooled_graph:\n",
    "            return s, x_pool, adj_pool, tv_loss, bal_loss\n",
    "        elif self.return_selection and not self.return_pooled_graph:\n",
    "            return s, tv_loss, bal_loss\n",
    "        else:\n",
    "            return x_pool, adj_pool, tv_loss, bal_loss\n",
    "\n",
    "    def totvar_loss(self, adj, s):\n",
    "        l1_norm = torch.sum(torch.abs(s[..., None, :] - s[:, None, ...]), dim=-1)\n",
    "\n",
    "        loss = torch.sum(adj * l1_norm, dim=(-1, -2))\n",
    "\n",
    "        # Normalize loss\n",
    "        n_edges = torch.count_nonzero(adj, dim=(-1, -2))\n",
    "        loss *= 1 / (2 * n_edges)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def balance_loss(self, s):\n",
    "        n_nodes = s.size()[-2]\n",
    "\n",
    "        # k-quantile\n",
    "        idx = int(math.floor(n_nodes / self.k))\n",
    "        quant = torch.sort(s, dim=-2, descending=True)[0][:, idx, :] # shape [B, K]\n",
    "\n",
    "        # Asymmetric l1-norm\n",
    "        loss = s - torch.unsqueeze(quant, dim=1)\n",
    "        loss = (loss >= 0) * (self.k - 1) * loss + (loss < 0) * loss * -1\n",
    "        loss = torch.sum(loss, dim=(-1, -2)) # shape [B]\n",
    "        loss = 1 / (n_nodes * (self.k - 1)) * (n_nodes * (self.k - 1) - loss)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROTEINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6848, Val Acc: 0.6988, Test Acc: 0.7202\n",
      "Seed: 42, Epoch: 002, Loss: 0.6427, Val Acc: 0.7108, Test Acc: 0.7321\n",
      "Seed: 42, Epoch: 003, Loss: 0.6251, Val Acc: 0.6747, Test Acc: 0.7381\n",
      "Seed: 42, Epoch: 004, Loss: 0.6062, Val Acc: 0.7229, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 005, Loss: 0.6061, Val Acc: 0.7229, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 006, Loss: 0.6064, Val Acc: 0.7108, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 007, Loss: 0.5969, Val Acc: 0.7470, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 008, Loss: 0.6008, Val Acc: 0.7289, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 009, Loss: 0.5957, Val Acc: 0.7229, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 010, Loss: 0.5881, Val Acc: 0.7289, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 011, Loss: 0.5860, Val Acc: 0.7470, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 012, Loss: 0.5817, Val Acc: 0.7289, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 013, Loss: 0.5781, Val Acc: 0.7530, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 014, Loss: 0.5802, Val Acc: 0.7470, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 015, Loss: 0.5704, Val Acc: 0.7410, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 016, Loss: 0.5774, Val Acc: 0.7530, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 017, Loss: 0.5724, Val Acc: 0.7410, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 018, Loss: 0.5654, Val Acc: 0.7289, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 019, Loss: 0.5609, Val Acc: 0.7590, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 020, Loss: 0.5677, Val Acc: 0.7349, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 021, Loss: 0.5579, Val Acc: 0.7530, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 022, Loss: 0.5522, Val Acc: 0.7349, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 023, Loss: 0.5558, Val Acc: 0.7470, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 024, Loss: 0.5560, Val Acc: 0.7590, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 025, Loss: 0.5434, Val Acc: 0.7711, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 026, Loss: 0.5524, Val Acc: 0.7771, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 027, Loss: 0.5497, Val Acc: 0.7651, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 028, Loss: 0.5455, Val Acc: 0.7410, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 029, Loss: 0.5418, Val Acc: 0.7590, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 030, Loss: 0.5431, Val Acc: 0.7590, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 031, Loss: 0.5453, Val Acc: 0.7711, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 032, Loss: 0.5331, Val Acc: 0.7771, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 033, Loss: 0.5298, Val Acc: 0.7590, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 034, Loss: 0.5244, Val Acc: 0.7771, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 035, Loss: 0.5245, Val Acc: 0.7410, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 036, Loss: 0.5236, Val Acc: 0.7952, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 037, Loss: 0.5250, Val Acc: 0.7590, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 038, Loss: 0.5369, Val Acc: 0.7530, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 039, Loss: 0.5414, Val Acc: 0.7530, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 040, Loss: 0.5479, Val Acc: 0.7590, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 041, Loss: 0.5354, Val Acc: 0.7470, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 042, Loss: 0.5375, Val Acc: 0.7711, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 043, Loss: 0.5259, Val Acc: 0.7410, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 044, Loss: 0.5261, Val Acc: 0.7590, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 045, Loss: 0.5270, Val Acc: 0.7651, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 046, Loss: 0.5238, Val Acc: 0.7410, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 047, Loss: 0.5235, Val Acc: 0.7771, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 048, Loss: 0.5208, Val Acc: 0.7651, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 049, Loss: 0.5237, Val Acc: 0.8012, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 050, Loss: 0.5159, Val Acc: 0.7711, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 051, Loss: 0.5192, Val Acc: 0.7711, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 052, Loss: 0.5214, Val Acc: 0.7470, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 053, Loss: 0.5186, Val Acc: 0.7410, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 054, Loss: 0.5163, Val Acc: 0.7530, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 055, Loss: 0.5237, Val Acc: 0.7590, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 056, Loss: 0.5152, Val Acc: 0.7892, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 057, Loss: 0.6250, Val Acc: 0.7349, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 058, Loss: 0.5339, Val Acc: 0.7289, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 059, Loss: 0.5405, Val Acc: 0.7349, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 060, Loss: 0.5394, Val Acc: 0.7470, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 061, Loss: 0.5337, Val Acc: 0.7289, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 062, Loss: 0.5338, Val Acc: 0.7590, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 063, Loss: 0.5260, Val Acc: 0.7410, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 064, Loss: 0.5192, Val Acc: 0.7651, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 065, Loss: 0.5175, Val Acc: 0.7651, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 066, Loss: 0.5167, Val Acc: 0.7470, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 067, Loss: 0.5183, Val Acc: 0.7530, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 068, Loss: 0.5346, Val Acc: 0.7530, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 069, Loss: 0.5306, Val Acc: 0.7410, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 070, Loss: 0.5206, Val Acc: 0.7590, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 071, Loss: 0.5324, Val Acc: 0.7590, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 072, Loss: 0.5198, Val Acc: 0.7410, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 073, Loss: 0.5270, Val Acc: 0.7711, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 074, Loss: 0.5167, Val Acc: 0.7530, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 075, Loss: 0.5199, Val Acc: 0.7410, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 076, Loss: 0.5159, Val Acc: 0.7349, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 077, Loss: 0.5226, Val Acc: 0.7470, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 078, Loss: 0.5151, Val Acc: 0.7530, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 079, Loss: 0.5173, Val Acc: 0.7711, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 080, Loss: 0.5157, Val Acc: 0.7470, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 081, Loss: 0.5139, Val Acc: 0.7470, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 082, Loss: 0.5144, Val Acc: 0.7410, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 083, Loss: 0.5155, Val Acc: 0.7470, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 084, Loss: 0.5140, Val Acc: 0.7651, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 085, Loss: 0.5145, Val Acc: 0.7651, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 086, Loss: 0.5099, Val Acc: 0.7952, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 087, Loss: 0.5113, Val Acc: 0.7651, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 088, Loss: 0.5624, Val Acc: 0.7229, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 089, Loss: 0.5510, Val Acc: 0.7289, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 090, Loss: 0.5428, Val Acc: 0.7349, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 091, Loss: 0.5468, Val Acc: 0.7530, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 092, Loss: 0.5422, Val Acc: 0.7530, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 093, Loss: 0.5367, Val Acc: 0.7410, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 094, Loss: 0.5308, Val Acc: 0.7410, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 095, Loss: 0.5293, Val Acc: 0.7590, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 096, Loss: 0.5246, Val Acc: 0.7470, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 097, Loss: 0.5205, Val Acc: 0.7470, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 098, Loss: 0.5252, Val Acc: 0.7470, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 099, Loss: 0.5154, Val Acc: 0.7651, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 100, Loss: 0.5146, Val Acc: 0.7470, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 101, Loss: 0.5155, Val Acc: 0.7530, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 102, Loss: 0.5138, Val Acc: 0.7530, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 103, Loss: 0.5121, Val Acc: 0.7711, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 104, Loss: 0.5200, Val Acc: 0.7470, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 105, Loss: 0.5239, Val Acc: 0.7530, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 106, Loss: 0.5253, Val Acc: 0.7470, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 107, Loss: 0.5171, Val Acc: 0.7410, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 108, Loss: 0.5221, Val Acc: 0.7410, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 109, Loss: 0.5114, Val Acc: 0.7590, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 110, Loss: 0.5087, Val Acc: 0.7651, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 111, Loss: 0.5112, Val Acc: 0.7590, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 112, Loss: 0.5122, Val Acc: 0.7530, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 113, Loss: 0.5124, Val Acc: 0.7590, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 114, Loss: 0.5041, Val Acc: 0.7831, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 115, Loss: 0.5177, Val Acc: 0.7590, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 116, Loss: 0.5165, Val Acc: 0.7711, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 117, Loss: 0.5057, Val Acc: 0.7771, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 118, Loss: 0.5141, Val Acc: 0.7530, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 119, Loss: 0.5164, Val Acc: 0.7530, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 120, Loss: 0.5089, Val Acc: 0.7651, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 121, Loss: 0.5112, Val Acc: 0.7711, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 122, Loss: 0.5045, Val Acc: 0.7651, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 123, Loss: 0.5024, Val Acc: 0.7711, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 124, Loss: 0.5061, Val Acc: 0.7590, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 125, Loss: 0.5216, Val Acc: 0.7229, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 126, Loss: 0.5291, Val Acc: 0.7410, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 127, Loss: 0.5276, Val Acc: 0.7470, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 128, Loss: 0.5280, Val Acc: 0.7349, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 129, Loss: 0.5166, Val Acc: 0.7349, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 130, Loss: 0.5145, Val Acc: 0.7651, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 131, Loss: 0.5107, Val Acc: 0.7771, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 132, Loss: 0.5061, Val Acc: 0.7771, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 133, Loss: 0.5038, Val Acc: 0.7590, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 134, Loss: 0.5031, Val Acc: 0.7590, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 135, Loss: 0.5053, Val Acc: 0.7590, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 136, Loss: 0.5100, Val Acc: 0.7349, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 137, Loss: 0.5103, Val Acc: 0.7470, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 138, Loss: 0.5056, Val Acc: 0.7711, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 139, Loss: 0.5017, Val Acc: 0.7711, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 140, Loss: 0.5036, Val Acc: 0.7771, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 141, Loss: 0.4997, Val Acc: 0.7831, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 142, Loss: 0.4987, Val Acc: 0.7470, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 143, Loss: 0.5087, Val Acc: 0.7590, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 144, Loss: 0.4983, Val Acc: 0.7831, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 145, Loss: 0.4956, Val Acc: 0.7651, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 146, Loss: 0.5120, Val Acc: 0.7410, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 147, Loss: 0.5112, Val Acc: 0.7470, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 148, Loss: 0.5138, Val Acc: 0.7530, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 149, Loss: 0.5108, Val Acc: 0.7530, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 150, Loss: 0.5007, Val Acc: 0.7530, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 151, Loss: 0.5010, Val Acc: 0.7530, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 152, Loss: 0.4990, Val Acc: 0.7711, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 153, Loss: 0.5034, Val Acc: 0.7711, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 154, Loss: 0.4990, Val Acc: 0.7590, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 155, Loss: 0.4991, Val Acc: 0.7590, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 156, Loss: 0.4955, Val Acc: 0.7590, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 157, Loss: 0.4936, Val Acc: 0.7892, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 158, Loss: 0.4974, Val Acc: 0.7831, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 159, Loss: 0.4939, Val Acc: 0.7590, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 160, Loss: 0.4970, Val Acc: 0.7711, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 161, Loss: 0.4936, Val Acc: 0.7530, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 162, Loss: 0.4923, Val Acc: 0.7771, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 163, Loss: 0.5007, Val Acc: 0.7530, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 164, Loss: 0.4943, Val Acc: 0.7831, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 165, Loss: 0.4973, Val Acc: 0.7530, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 166, Loss: 0.4882, Val Acc: 0.7831, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 167, Loss: 0.4885, Val Acc: 0.7831, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 168, Loss: 0.4895, Val Acc: 0.7771, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 169, Loss: 0.4913, Val Acc: 0.7349, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 170, Loss: 0.5107, Val Acc: 0.7590, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 171, Loss: 0.4981, Val Acc: 0.7470, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 172, Loss: 0.4978, Val Acc: 0.7651, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 173, Loss: 0.4985, Val Acc: 0.7711, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 174, Loss: 0.4994, Val Acc: 0.7711, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 175, Loss: 0.4931, Val Acc: 0.7711, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 176, Loss: 0.4902, Val Acc: 0.7470, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 177, Loss: 0.4915, Val Acc: 0.7651, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 178, Loss: 0.4916, Val Acc: 0.7831, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 179, Loss: 0.4955, Val Acc: 0.7410, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 180, Loss: 0.4915, Val Acc: 0.7470, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 181, Loss: 0.4996, Val Acc: 0.7530, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 182, Loss: 0.5453, Val Acc: 0.7349, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 183, Loss: 0.5470, Val Acc: 0.7289, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 184, Loss: 0.5563, Val Acc: 0.7470, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 185, Loss: 0.5493, Val Acc: 0.7229, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 186, Loss: 0.5226, Val Acc: 0.7530, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 187, Loss: 0.5186, Val Acc: 0.7530, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 188, Loss: 0.5084, Val Acc: 0.7651, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 189, Loss: 0.4989, Val Acc: 0.7590, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 190, Loss: 0.4983, Val Acc: 0.7590, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 191, Loss: 0.4998, Val Acc: 0.7651, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 192, Loss: 0.4944, Val Acc: 0.7590, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 193, Loss: 0.4982, Val Acc: 0.7530, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 194, Loss: 0.4948, Val Acc: 0.7530, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 195, Loss: 0.5054, Val Acc: 0.7470, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 196, Loss: 0.5060, Val Acc: 0.7590, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 197, Loss: 0.5006, Val Acc: 0.7530, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 198, Loss: 0.4924, Val Acc: 0.7651, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 199, Loss: 0.5019, Val Acc: 0.7711, Test Acc: 0.7679\n",
      "Early stopping at epoch 199 for seed 42\n",
      "Seed: 43, Epoch: 001, Loss: 0.6830, Val Acc: 0.6988, Test Acc: 0.6429\n",
      "Seed: 43, Epoch: 002, Loss: 0.6403, Val Acc: 0.6988, Test Acc: 0.6786\n",
      "Seed: 43, Epoch: 003, Loss: 0.6161, Val Acc: 0.7229, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 004, Loss: 0.6025, Val Acc: 0.7410, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 005, Loss: 0.5928, Val Acc: 0.7590, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 006, Loss: 0.5902, Val Acc: 0.7711, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 007, Loss: 0.5908, Val Acc: 0.7410, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 008, Loss: 0.5837, Val Acc: 0.7349, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 009, Loss: 0.5826, Val Acc: 0.7530, Test Acc: 0.7440\n",
      "Seed: 43, Epoch: 010, Loss: 0.5733, Val Acc: 0.7229, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 011, Loss: 0.5701, Val Acc: 0.7289, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 012, Loss: 0.5642, Val Acc: 0.7289, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 013, Loss: 0.5649, Val Acc: 0.7229, Test Acc: 0.6964\n",
      "Seed: 43, Epoch: 014, Loss: 0.5684, Val Acc: 0.7349, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 015, Loss: 0.5804, Val Acc: 0.7349, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 016, Loss: 0.5563, Val Acc: 0.7289, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 017, Loss: 0.5578, Val Acc: 0.7410, Test Acc: 0.7024\n",
      "Seed: 43, Epoch: 018, Loss: 0.5600, Val Acc: 0.7349, Test Acc: 0.7024\n",
      "Seed: 43, Epoch: 019, Loss: 0.5520, Val Acc: 0.7108, Test Acc: 0.6905\n",
      "Seed: 43, Epoch: 020, Loss: 0.5526, Val Acc: 0.7289, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 021, Loss: 0.5639, Val Acc: 0.7289, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 022, Loss: 0.5579, Val Acc: 0.7590, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 023, Loss: 0.5485, Val Acc: 0.7289, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 024, Loss: 0.5445, Val Acc: 0.7349, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 025, Loss: 0.5358, Val Acc: 0.7349, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 026, Loss: 0.5372, Val Acc: 0.7349, Test Acc: 0.6964\n",
      "Seed: 43, Epoch: 027, Loss: 0.5278, Val Acc: 0.7229, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 028, Loss: 0.5376, Val Acc: 0.7349, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 029, Loss: 0.5315, Val Acc: 0.7289, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 030, Loss: 0.5301, Val Acc: 0.7349, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 031, Loss: 0.5207, Val Acc: 0.7289, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 032, Loss: 0.5229, Val Acc: 0.7289, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 033, Loss: 0.5153, Val Acc: 0.7289, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 034, Loss: 0.5197, Val Acc: 0.7289, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 035, Loss: 0.5141, Val Acc: 0.7410, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 036, Loss: 0.5103, Val Acc: 0.7410, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 037, Loss: 0.5096, Val Acc: 0.7470, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 038, Loss: 0.5199, Val Acc: 0.7530, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 039, Loss: 0.5041, Val Acc: 0.7349, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 040, Loss: 0.5203, Val Acc: 0.7229, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 041, Loss: 0.5092, Val Acc: 0.7530, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 042, Loss: 0.5073, Val Acc: 0.7289, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 043, Loss: 0.5035, Val Acc: 0.7410, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 044, Loss: 0.5025, Val Acc: 0.7410, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 045, Loss: 0.5013, Val Acc: 0.7349, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 046, Loss: 0.5043, Val Acc: 0.7349, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 047, Loss: 0.5012, Val Acc: 0.7530, Test Acc: 0.7857\n",
      "Seed: 43, Epoch: 048, Loss: 0.4963, Val Acc: 0.7530, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 049, Loss: 0.4950, Val Acc: 0.7530, Test Acc: 0.7976\n",
      "Seed: 43, Epoch: 050, Loss: 0.5029, Val Acc: 0.7470, Test Acc: 0.7440\n",
      "Seed: 43, Epoch: 051, Loss: 0.4978, Val Acc: 0.7470, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 052, Loss: 0.5205, Val Acc: 0.7410, Test Acc: 0.7440\n",
      "Seed: 43, Epoch: 053, Loss: 0.5224, Val Acc: 0.7771, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 054, Loss: 0.5023, Val Acc: 0.7410, Test Acc: 0.7857\n",
      "Seed: 43, Epoch: 055, Loss: 0.5065, Val Acc: 0.7530, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 056, Loss: 0.4970, Val Acc: 0.7470, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 057, Loss: 0.4912, Val Acc: 0.7410, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 058, Loss: 0.4926, Val Acc: 0.7470, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 059, Loss: 0.4946, Val Acc: 0.7410, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 060, Loss: 0.4871, Val Acc: 0.7289, Test Acc: 0.7857\n",
      "Seed: 43, Epoch: 061, Loss: 0.4893, Val Acc: 0.7349, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 062, Loss: 0.4896, Val Acc: 0.7410, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 063, Loss: 0.4898, Val Acc: 0.7349, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 064, Loss: 0.4931, Val Acc: 0.7410, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 065, Loss: 0.5073, Val Acc: 0.7349, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 066, Loss: 0.4946, Val Acc: 0.7349, Test Acc: 0.7857\n",
      "Seed: 43, Epoch: 067, Loss: 0.4916, Val Acc: 0.7530, Test Acc: 0.7857\n",
      "Seed: 43, Epoch: 068, Loss: 0.5088, Val Acc: 0.7470, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 069, Loss: 0.5071, Val Acc: 0.7470, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 070, Loss: 0.5159, Val Acc: 0.7711, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 071, Loss: 0.5147, Val Acc: 0.7530, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 072, Loss: 0.5186, Val Acc: 0.7470, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 073, Loss: 0.4932, Val Acc: 0.7410, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 074, Loss: 0.4903, Val Acc: 0.7470, Test Acc: 0.7976\n",
      "Seed: 43, Epoch: 075, Loss: 0.4942, Val Acc: 0.7410, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 076, Loss: 0.4870, Val Acc: 0.7410, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 077, Loss: 0.4881, Val Acc: 0.7349, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 078, Loss: 0.4815, Val Acc: 0.7410, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 079, Loss: 0.4833, Val Acc: 0.7410, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 080, Loss: 0.4817, Val Acc: 0.7289, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 081, Loss: 0.4789, Val Acc: 0.7410, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 082, Loss: 0.4885, Val Acc: 0.7470, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 083, Loss: 0.4791, Val Acc: 0.7289, Test Acc: 0.7857\n",
      "Seed: 43, Epoch: 084, Loss: 0.4795, Val Acc: 0.7289, Test Acc: 0.7440\n",
      "Seed: 43, Epoch: 085, Loss: 0.4884, Val Acc: 0.7349, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 086, Loss: 0.4863, Val Acc: 0.7349, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 087, Loss: 0.4795, Val Acc: 0.7410, Test Acc: 0.7976\n",
      "Seed: 43, Epoch: 088, Loss: 0.4818, Val Acc: 0.7470, Test Acc: 0.7857\n",
      "Seed: 43, Epoch: 089, Loss: 0.4880, Val Acc: 0.7349, Test Acc: 0.7440\n",
      "Seed: 43, Epoch: 090, Loss: 0.4905, Val Acc: 0.7349, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 091, Loss: 0.4843, Val Acc: 0.7590, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 092, Loss: 0.4800, Val Acc: 0.7410, Test Acc: 0.7857\n",
      "Seed: 43, Epoch: 093, Loss: 0.4774, Val Acc: 0.7410, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 094, Loss: 0.4814, Val Acc: 0.7410, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 095, Loss: 0.4933, Val Acc: 0.7410, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 096, Loss: 0.4802, Val Acc: 0.7530, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 097, Loss: 0.4893, Val Acc: 0.7349, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 098, Loss: 0.4961, Val Acc: 0.7349, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 099, Loss: 0.4819, Val Acc: 0.7470, Test Acc: 0.7857\n",
      "Seed: 43, Epoch: 100, Loss: 0.4919, Val Acc: 0.7349, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 101, Loss: 0.4994, Val Acc: 0.7410, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 102, Loss: 0.4826, Val Acc: 0.7289, Test Acc: 0.7976\n",
      "Seed: 43, Epoch: 103, Loss: 0.4797, Val Acc: 0.7349, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 104, Loss: 0.4797, Val Acc: 0.7410, Test Acc: 0.7976\n",
      "Seed: 43, Epoch: 105, Loss: 0.4852, Val Acc: 0.7470, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 106, Loss: 0.4869, Val Acc: 0.7470, Test Acc: 0.7976\n",
      "Seed: 43, Epoch: 107, Loss: 0.4746, Val Acc: 0.7289, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 108, Loss: 0.4856, Val Acc: 0.7349, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 109, Loss: 0.4804, Val Acc: 0.7530, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 110, Loss: 0.4780, Val Acc: 0.7289, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 111, Loss: 0.4800, Val Acc: 0.7410, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 112, Loss: 0.4795, Val Acc: 0.7470, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 113, Loss: 0.4791, Val Acc: 0.7410, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 114, Loss: 0.4745, Val Acc: 0.7530, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 115, Loss: 0.4727, Val Acc: 0.7410, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 116, Loss: 0.4744, Val Acc: 0.7349, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 117, Loss: 0.4883, Val Acc: 0.7410, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 118, Loss: 0.4835, Val Acc: 0.7349, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 119, Loss: 0.4785, Val Acc: 0.7349, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 120, Loss: 0.4752, Val Acc: 0.7470, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 121, Loss: 0.4716, Val Acc: 0.7410, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 122, Loss: 0.4736, Val Acc: 0.7289, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 123, Loss: 0.4805, Val Acc: 0.7349, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 124, Loss: 0.4695, Val Acc: 0.7410, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 125, Loss: 0.4796, Val Acc: 0.7410, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 126, Loss: 0.4996, Val Acc: 0.7289, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 127, Loss: 0.5047, Val Acc: 0.7410, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 128, Loss: 0.4827, Val Acc: 0.7530, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 129, Loss: 0.4902, Val Acc: 0.7470, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 130, Loss: 0.4750, Val Acc: 0.7289, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 131, Loss: 0.4794, Val Acc: 0.7410, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 132, Loss: 0.4696, Val Acc: 0.7349, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 133, Loss: 0.4772, Val Acc: 0.7410, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 134, Loss: 0.4788, Val Acc: 0.7349, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 135, Loss: 0.4814, Val Acc: 0.7651, Test Acc: 0.7917\n",
      "Seed: 43, Epoch: 136, Loss: 0.4795, Val Acc: 0.7410, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 137, Loss: 0.4766, Val Acc: 0.7530, Test Acc: 0.7857\n",
      "Seed: 43, Epoch: 138, Loss: 0.4733, Val Acc: 0.7349, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 139, Loss: 0.4665, Val Acc: 0.7470, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 140, Loss: 0.4700, Val Acc: 0.7530, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 141, Loss: 0.4745, Val Acc: 0.7530, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 142, Loss: 0.4648, Val Acc: 0.7289, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 143, Loss: 0.4777, Val Acc: 0.7410, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 144, Loss: 0.4725, Val Acc: 0.7530, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 145, Loss: 0.4703, Val Acc: 0.7410, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 146, Loss: 0.4703, Val Acc: 0.7590, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 147, Loss: 0.4944, Val Acc: 0.7349, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 148, Loss: 0.4671, Val Acc: 0.7349, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 149, Loss: 0.4749, Val Acc: 0.7470, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 150, Loss: 0.4742, Val Acc: 0.7410, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 151, Loss: 0.4659, Val Acc: 0.7530, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 152, Loss: 0.4658, Val Acc: 0.7229, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 153, Loss: 0.4642, Val Acc: 0.7289, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 154, Loss: 0.4617, Val Acc: 0.7530, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 155, Loss: 0.4628, Val Acc: 0.7349, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 156, Loss: 0.4630, Val Acc: 0.7289, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 157, Loss: 0.4618, Val Acc: 0.7229, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 158, Loss: 0.4644, Val Acc: 0.7410, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 159, Loss: 0.4622, Val Acc: 0.7470, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 160, Loss: 0.4657, Val Acc: 0.7229, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 161, Loss: 0.4683, Val Acc: 0.7590, Test Acc: 0.7857\n",
      "Seed: 43, Epoch: 162, Loss: 0.4639, Val Acc: 0.7530, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 163, Loss: 0.4722, Val Acc: 0.7349, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 164, Loss: 0.4632, Val Acc: 0.7410, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 165, Loss: 0.4664, Val Acc: 0.7410, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 166, Loss: 0.4611, Val Acc: 0.7410, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 167, Loss: 0.4640, Val Acc: 0.7410, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 168, Loss: 0.4636, Val Acc: 0.7349, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 169, Loss: 0.4597, Val Acc: 0.7410, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 170, Loss: 0.4668, Val Acc: 0.7530, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 171, Loss: 0.4595, Val Acc: 0.7349, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 172, Loss: 0.4673, Val Acc: 0.7229, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 173, Loss: 0.4591, Val Acc: 0.7349, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 174, Loss: 0.4611, Val Acc: 0.7349, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 175, Loss: 0.4572, Val Acc: 0.7289, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 176, Loss: 0.4577, Val Acc: 0.7470, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 177, Loss: 0.4885, Val Acc: 0.7349, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 178, Loss: 0.4647, Val Acc: 0.7349, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 179, Loss: 0.4674, Val Acc: 0.7530, Test Acc: 0.7679\n",
      "Seed: 43, Epoch: 180, Loss: 0.4654, Val Acc: 0.7470, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 181, Loss: 0.4654, Val Acc: 0.7289, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 182, Loss: 0.4689, Val Acc: 0.7349, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 183, Loss: 0.4660, Val Acc: 0.7410, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 184, Loss: 0.4652, Val Acc: 0.7349, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 185, Loss: 0.4639, Val Acc: 0.7289, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 186, Loss: 0.4629, Val Acc: 0.7349, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 187, Loss: 0.4722, Val Acc: 0.7410, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 188, Loss: 0.4688, Val Acc: 0.7410, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 189, Loss: 0.4634, Val Acc: 0.7530, Test Acc: 0.7798\n",
      "Seed: 43, Epoch: 190, Loss: 0.4730, Val Acc: 0.7289, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 191, Loss: 0.4676, Val Acc: 0.7289, Test Acc: 0.7619\n",
      "Seed: 43, Epoch: 192, Loss: 0.4732, Val Acc: 0.7470, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 193, Loss: 0.4759, Val Acc: 0.7651, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 194, Loss: 0.4820, Val Acc: 0.7289, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 195, Loss: 0.4640, Val Acc: 0.7530, Test Acc: 0.7738\n",
      "Seed: 43, Epoch: 196, Loss: 0.4658, Val Acc: 0.7410, Test Acc: 0.7857\n",
      "Seed: 43, Epoch: 197, Loss: 0.4597, Val Acc: 0.7229, Test Acc: 0.7857\n",
      "Seed: 43, Epoch: 198, Loss: 0.4544, Val Acc: 0.7229, Test Acc: 0.7857\n",
      "Seed: 43, Epoch: 199, Loss: 0.4605, Val Acc: 0.7229, Test Acc: 0.7857\n",
      "Seed: 43, Epoch: 200, Loss: 0.4576, Val Acc: 0.7349, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 001, Loss: 0.6823, Val Acc: 0.6988, Test Acc: 0.6786\n",
      "Seed: 44, Epoch: 002, Loss: 0.6421, Val Acc: 0.6988, Test Acc: 0.6310\n",
      "Seed: 44, Epoch: 003, Loss: 0.6175, Val Acc: 0.7229, Test Acc: 0.6488\n",
      "Seed: 44, Epoch: 004, Loss: 0.5989, Val Acc: 0.6687, Test Acc: 0.6012\n",
      "Seed: 44, Epoch: 005, Loss: 0.5919, Val Acc: 0.6386, Test Acc: 0.6131\n",
      "Seed: 44, Epoch: 006, Loss: 0.5939, Val Acc: 0.6928, Test Acc: 0.6548\n",
      "Seed: 44, Epoch: 007, Loss: 0.5897, Val Acc: 0.7470, Test Acc: 0.6726\n",
      "Seed: 44, Epoch: 008, Loss: 0.5835, Val Acc: 0.7410, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 009, Loss: 0.5842, Val Acc: 0.7410, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 010, Loss: 0.5768, Val Acc: 0.7349, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 011, Loss: 0.5744, Val Acc: 0.7229, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 012, Loss: 0.5682, Val Acc: 0.7349, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 013, Loss: 0.5608, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 014, Loss: 0.5616, Val Acc: 0.7349, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 015, Loss: 0.5570, Val Acc: 0.7470, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 016, Loss: 0.5623, Val Acc: 0.7530, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 017, Loss: 0.5532, Val Acc: 0.7410, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 018, Loss: 0.5440, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 019, Loss: 0.5486, Val Acc: 0.7349, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 020, Loss: 0.5469, Val Acc: 0.7530, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 021, Loss: 0.5345, Val Acc: 0.7410, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 022, Loss: 0.5312, Val Acc: 0.7289, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 023, Loss: 0.5289, Val Acc: 0.7289, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 024, Loss: 0.5331, Val Acc: 0.7349, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 025, Loss: 0.5280, Val Acc: 0.7410, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 026, Loss: 0.5184, Val Acc: 0.7349, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 027, Loss: 0.5289, Val Acc: 0.7349, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 028, Loss: 0.5238, Val Acc: 0.7410, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 029, Loss: 0.5191, Val Acc: 0.7530, Test Acc: 0.7738\n",
      "Seed: 44, Epoch: 030, Loss: 0.5247, Val Acc: 0.7349, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 031, Loss: 0.5164, Val Acc: 0.7470, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 032, Loss: 0.5087, Val Acc: 0.7590, Test Acc: 0.7679\n",
      "Seed: 44, Epoch: 033, Loss: 0.5090, Val Acc: 0.7349, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 034, Loss: 0.5105, Val Acc: 0.7590, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 035, Loss: 0.5114, Val Acc: 0.7530, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 036, Loss: 0.5167, Val Acc: 0.7349, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 037, Loss: 0.5274, Val Acc: 0.7169, Test Acc: 0.7679\n",
      "Seed: 44, Epoch: 038, Loss: 0.5370, Val Acc: 0.7289, Test Acc: 0.7619\n",
      "Seed: 44, Epoch: 039, Loss: 0.5268, Val Acc: 0.7470, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 040, Loss: 0.5366, Val Acc: 0.7229, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 041, Loss: 0.5202, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 042, Loss: 0.5158, Val Acc: 0.7349, Test Acc: 0.7560\n",
      "Seed: 44, Epoch: 043, Loss: 0.5075, Val Acc: 0.7470, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 044, Loss: 0.5046, Val Acc: 0.7651, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 045, Loss: 0.5023, Val Acc: 0.7590, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 046, Loss: 0.5049, Val Acc: 0.7590, Test Acc: 0.7679\n",
      "Seed: 44, Epoch: 047, Loss: 0.5003, Val Acc: 0.7530, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 048, Loss: 0.4997, Val Acc: 0.7590, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 049, Loss: 0.5036, Val Acc: 0.7590, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 050, Loss: 0.4963, Val Acc: 0.7711, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 051, Loss: 0.4927, Val Acc: 0.7651, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 052, Loss: 0.4936, Val Acc: 0.7590, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 053, Loss: 0.4940, Val Acc: 0.7530, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 054, Loss: 0.4951, Val Acc: 0.7590, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 055, Loss: 0.4942, Val Acc: 0.7530, Test Acc: 0.7560\n",
      "Seed: 44, Epoch: 056, Loss: 0.5044, Val Acc: 0.7289, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 057, Loss: 0.5086, Val Acc: 0.7470, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 058, Loss: 0.5027, Val Acc: 0.7470, Test Acc: 0.7560\n",
      "Seed: 44, Epoch: 059, Loss: 0.5032, Val Acc: 0.7651, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 060, Loss: 0.4942, Val Acc: 0.7651, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 061, Loss: 0.4930, Val Acc: 0.7771, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 062, Loss: 0.4990, Val Acc: 0.7470, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 063, Loss: 0.4908, Val Acc: 0.7711, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 064, Loss: 0.4880, Val Acc: 0.7530, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 065, Loss: 0.4907, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 066, Loss: 0.4865, Val Acc: 0.7651, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 067, Loss: 0.4899, Val Acc: 0.7289, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 068, Loss: 0.4964, Val Acc: 0.7530, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 069, Loss: 0.4893, Val Acc: 0.7530, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 070, Loss: 0.4929, Val Acc: 0.7410, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 071, Loss: 0.4934, Val Acc: 0.7470, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 072, Loss: 0.4919, Val Acc: 0.7530, Test Acc: 0.7560\n",
      "Seed: 44, Epoch: 073, Loss: 0.4885, Val Acc: 0.7590, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 074, Loss: 0.4867, Val Acc: 0.7651, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 075, Loss: 0.4938, Val Acc: 0.7470, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 076, Loss: 0.4836, Val Acc: 0.7470, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 077, Loss: 0.4881, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 078, Loss: 0.4907, Val Acc: 0.7470, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 079, Loss: 0.4875, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 080, Loss: 0.4972, Val Acc: 0.7410, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 081, Loss: 0.4889, Val Acc: 0.7590, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 082, Loss: 0.4845, Val Acc: 0.7530, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 083, Loss: 0.4815, Val Acc: 0.7590, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 084, Loss: 0.4840, Val Acc: 0.7590, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 085, Loss: 0.4858, Val Acc: 0.7530, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 086, Loss: 0.4802, Val Acc: 0.7651, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 087, Loss: 0.4818, Val Acc: 0.7651, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 088, Loss: 0.4838, Val Acc: 0.7470, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 089, Loss: 0.4794, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 090, Loss: 0.4858, Val Acc: 0.7651, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 091, Loss: 0.5004, Val Acc: 0.7349, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 092, Loss: 0.4990, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 093, Loss: 0.4950, Val Acc: 0.7349, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 094, Loss: 0.4876, Val Acc: 0.7470, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 095, Loss: 0.4891, Val Acc: 0.7651, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 096, Loss: 0.4822, Val Acc: 0.7590, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 097, Loss: 0.4822, Val Acc: 0.7470, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 098, Loss: 0.4824, Val Acc: 0.7590, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 099, Loss: 0.4802, Val Acc: 0.7590, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 100, Loss: 0.4754, Val Acc: 0.7530, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 101, Loss: 0.4798, Val Acc: 0.7651, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 102, Loss: 0.4803, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 103, Loss: 0.4801, Val Acc: 0.7470, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 104, Loss: 0.4777, Val Acc: 0.7349, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 105, Loss: 0.4794, Val Acc: 0.7530, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 106, Loss: 0.4790, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 107, Loss: 0.4773, Val Acc: 0.7651, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 108, Loss: 0.4802, Val Acc: 0.7651, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 109, Loss: 0.4767, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 110, Loss: 0.4742, Val Acc: 0.7470, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 111, Loss: 0.4761, Val Acc: 0.7651, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 112, Loss: 0.4736, Val Acc: 0.7410, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 113, Loss: 0.4717, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 114, Loss: 0.4781, Val Acc: 0.7229, Test Acc: 0.7619\n",
      "Seed: 44, Epoch: 115, Loss: 0.5424, Val Acc: 0.7410, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 116, Loss: 0.5519, Val Acc: 0.7289, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 117, Loss: 0.5251, Val Acc: 0.7289, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 118, Loss: 0.5167, Val Acc: 0.7590, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 119, Loss: 0.5073, Val Acc: 0.7470, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 120, Loss: 0.5018, Val Acc: 0.7410, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 121, Loss: 0.4990, Val Acc: 0.7289, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 122, Loss: 0.4931, Val Acc: 0.7349, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 123, Loss: 0.4937, Val Acc: 0.7349, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 124, Loss: 0.4867, Val Acc: 0.7410, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 125, Loss: 0.4910, Val Acc: 0.7410, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 126, Loss: 0.4843, Val Acc: 0.7349, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 127, Loss: 0.4851, Val Acc: 0.7590, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 128, Loss: 0.4831, Val Acc: 0.7590, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 129, Loss: 0.4822, Val Acc: 0.7289, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 130, Loss: 0.4777, Val Acc: 0.7530, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 131, Loss: 0.4803, Val Acc: 0.7410, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 132, Loss: 0.4870, Val Acc: 0.7651, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 133, Loss: 0.4806, Val Acc: 0.7590, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 134, Loss: 0.4778, Val Acc: 0.7530, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 135, Loss: 0.4776, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 136, Loss: 0.4838, Val Acc: 0.7590, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 137, Loss: 0.4774, Val Acc: 0.7289, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 138, Loss: 0.4769, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 139, Loss: 0.4752, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 140, Loss: 0.4714, Val Acc: 0.7590, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 141, Loss: 0.4737, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 142, Loss: 0.4703, Val Acc: 0.7651, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 143, Loss: 0.4708, Val Acc: 0.7590, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 144, Loss: 0.4752, Val Acc: 0.7590, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 145, Loss: 0.4948, Val Acc: 0.7410, Test Acc: 0.6905\n",
      "Seed: 44, Epoch: 146, Loss: 0.4940, Val Acc: 0.7470, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 147, Loss: 0.4818, Val Acc: 0.7590, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 148, Loss: 0.4895, Val Acc: 0.7590, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 149, Loss: 0.4828, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 150, Loss: 0.4822, Val Acc: 0.7349, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 151, Loss: 0.4877, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 152, Loss: 0.4858, Val Acc: 0.7651, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 153, Loss: 0.4739, Val Acc: 0.7470, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 154, Loss: 0.4734, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 155, Loss: 0.4704, Val Acc: 0.7530, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 156, Loss: 0.4710, Val Acc: 0.7530, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 157, Loss: 0.4810, Val Acc: 0.7470, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 158, Loss: 0.4910, Val Acc: 0.7229, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 159, Loss: 0.4767, Val Acc: 0.7530, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 160, Loss: 0.4757, Val Acc: 0.7470, Test Acc: 0.7560\n",
      "Seed: 44, Epoch: 161, Loss: 0.5125, Val Acc: 0.7470, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 162, Loss: 0.4848, Val Acc: 0.7349, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 163, Loss: 0.4832, Val Acc: 0.7651, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 164, Loss: 0.4789, Val Acc: 0.7651, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 165, Loss: 0.4730, Val Acc: 0.7410, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 166, Loss: 0.4756, Val Acc: 0.7651, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 167, Loss: 0.4726, Val Acc: 0.7590, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 168, Loss: 0.4706, Val Acc: 0.7410, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 169, Loss: 0.4685, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 170, Loss: 0.4774, Val Acc: 0.7711, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 171, Loss: 0.4742, Val Acc: 0.7651, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 172, Loss: 0.4749, Val Acc: 0.7590, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 173, Loss: 0.4692, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 174, Loss: 0.4710, Val Acc: 0.7711, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 175, Loss: 0.4702, Val Acc: 0.7470, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 176, Loss: 0.4689, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 177, Loss: 0.4753, Val Acc: 0.7711, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 178, Loss: 0.4664, Val Acc: 0.7590, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 179, Loss: 0.4618, Val Acc: 0.7651, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 180, Loss: 0.4713, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 181, Loss: 0.4700, Val Acc: 0.7590, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 182, Loss: 0.4692, Val Acc: 0.7711, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 183, Loss: 0.4697, Val Acc: 0.7590, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 184, Loss: 0.4875, Val Acc: 0.7470, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 185, Loss: 0.4756, Val Acc: 0.7711, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 186, Loss: 0.4745, Val Acc: 0.7771, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 187, Loss: 0.4697, Val Acc: 0.7590, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 188, Loss: 0.4633, Val Acc: 0.7651, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 189, Loss: 0.4813, Val Acc: 0.7410, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 190, Loss: 0.4771, Val Acc: 0.7470, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 191, Loss: 0.4689, Val Acc: 0.7590, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 192, Loss: 0.4727, Val Acc: 0.7530, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 193, Loss: 0.4707, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 194, Loss: 0.4666, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 195, Loss: 0.4710, Val Acc: 0.7590, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 196, Loss: 0.4634, Val Acc: 0.7651, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 197, Loss: 0.4640, Val Acc: 0.7590, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 198, Loss: 0.4680, Val Acc: 0.7590, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 199, Loss: 0.4627, Val Acc: 0.7530, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 200, Loss: 0.4662, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Average Time: 516.92 seconds\n",
      "Var Time: 4.56 seconds\n",
      "Average Memory: 50614.00 MB\n",
      "Average Best Val Acc: 0.7851\n",
      "Std Best Test Acc: 0.0196\n",
      "Average Test Acc: 0.7460\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "max_nodes = 800\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"PROTEINS\",\n",
    "    transform=T.Compose([T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "dataset = dataset_dense\n",
    "dataset = dataset.shuffle()\n",
    "N = 150\n",
    "mp_layers = 1\n",
    "mp_channels = 64\n",
    "mp_activation = \"relu\"\n",
    "delta_coeff = 2.0\n",
    "\n",
    "mlp_hidden_layers = 2\n",
    "mlp_hidden_channels = 128\n",
    "mlp_activation = \"relu\"\n",
    "totvar_coeff = 0.5\n",
    "balance_coeff = 0.5\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 5e-4\n",
    "l2_reg_val = 0\n",
    "patience = 10\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        if self.lin is not None:\n",
    "            x = self.lin(x).relu()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_AsymCheegerCut(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset.num_classes)\n",
    "\n",
    "        self.pool1 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "        self.pool2 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool1(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool2(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_AsymCheegerCut().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = Net_AsymCheegerCut().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCI1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6918, Val Acc: 0.4838, Test Acc: 0.4619\n",
      "Seed: 42, Epoch: 002, Loss: 0.6874, Val Acc: 0.4838, Test Acc: 0.4619\n",
      "Seed: 42, Epoch: 003, Loss: 0.6775, Val Acc: 0.5747, Test Acc: 0.5332\n",
      "Seed: 42, Epoch: 004, Loss: 0.6568, Val Acc: 0.5925, Test Acc: 0.6159\n",
      "Seed: 42, Epoch: 005, Loss: 0.6428, Val Acc: 0.6347, Test Acc: 0.5997\n",
      "Seed: 42, Epoch: 006, Loss: 0.6378, Val Acc: 0.6412, Test Acc: 0.5997\n",
      "Seed: 42, Epoch: 007, Loss: 0.6316, Val Acc: 0.6412, Test Acc: 0.6353\n",
      "Seed: 42, Epoch: 008, Loss: 0.6295, Val Acc: 0.6364, Test Acc: 0.6240\n",
      "Seed: 42, Epoch: 009, Loss: 0.6248, Val Acc: 0.6542, Test Acc: 0.6143\n",
      "Seed: 42, Epoch: 010, Loss: 0.6192, Val Acc: 0.6477, Test Acc: 0.6288\n",
      "Seed: 42, Epoch: 011, Loss: 0.6167, Val Acc: 0.6494, Test Acc: 0.6451\n",
      "Seed: 42, Epoch: 012, Loss: 0.6082, Val Acc: 0.6575, Test Acc: 0.6499\n",
      "Seed: 42, Epoch: 013, Loss: 0.6055, Val Acc: 0.6656, Test Acc: 0.6629\n",
      "Seed: 42, Epoch: 014, Loss: 0.5996, Val Acc: 0.6737, Test Acc: 0.6629\n",
      "Seed: 42, Epoch: 015, Loss: 0.5933, Val Acc: 0.6656, Test Acc: 0.6759\n",
      "Seed: 42, Epoch: 016, Loss: 0.5945, Val Acc: 0.6640, Test Acc: 0.6742\n",
      "Seed: 42, Epoch: 017, Loss: 0.5979, Val Acc: 0.6688, Test Acc: 0.6775\n",
      "Seed: 42, Epoch: 018, Loss: 0.5844, Val Acc: 0.6721, Test Acc: 0.6856\n",
      "Seed: 42, Epoch: 019, Loss: 0.5793, Val Acc: 0.6753, Test Acc: 0.6872\n",
      "Seed: 42, Epoch: 020, Loss: 0.5803, Val Acc: 0.6883, Test Acc: 0.6888\n",
      "Seed: 42, Epoch: 021, Loss: 0.5769, Val Acc: 0.6867, Test Acc: 0.6985\n",
      "Seed: 42, Epoch: 022, Loss: 0.5732, Val Acc: 0.6916, Test Acc: 0.6985\n",
      "Seed: 42, Epoch: 023, Loss: 0.5691, Val Acc: 0.6899, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 024, Loss: 0.5644, Val Acc: 0.6948, Test Acc: 0.6969\n",
      "Seed: 42, Epoch: 025, Loss: 0.5675, Val Acc: 0.6932, Test Acc: 0.7002\n",
      "Seed: 42, Epoch: 026, Loss: 0.5674, Val Acc: 0.6786, Test Acc: 0.6742\n",
      "Seed: 42, Epoch: 027, Loss: 0.5651, Val Acc: 0.6867, Test Acc: 0.6888\n",
      "Seed: 42, Epoch: 028, Loss: 0.5659, Val Acc: 0.7062, Test Acc: 0.7131\n",
      "Seed: 42, Epoch: 029, Loss: 0.5556, Val Acc: 0.7159, Test Acc: 0.7050\n",
      "Seed: 42, Epoch: 030, Loss: 0.5556, Val Acc: 0.7094, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 031, Loss: 0.5576, Val Acc: 0.7062, Test Acc: 0.7196\n",
      "Seed: 42, Epoch: 032, Loss: 0.5545, Val Acc: 0.6834, Test Acc: 0.6856\n",
      "Seed: 42, Epoch: 033, Loss: 0.5648, Val Acc: 0.7143, Test Acc: 0.7099\n",
      "Seed: 42, Epoch: 034, Loss: 0.5504, Val Acc: 0.6981, Test Acc: 0.7018\n",
      "Seed: 42, Epoch: 035, Loss: 0.5493, Val Acc: 0.7127, Test Acc: 0.7147\n",
      "Seed: 42, Epoch: 036, Loss: 0.5468, Val Acc: 0.6981, Test Acc: 0.6872\n",
      "Seed: 42, Epoch: 037, Loss: 0.5512, Val Acc: 0.7256, Test Acc: 0.7083\n",
      "Seed: 42, Epoch: 038, Loss: 0.5587, Val Acc: 0.7208, Test Acc: 0.7002\n",
      "Seed: 42, Epoch: 039, Loss: 0.5496, Val Acc: 0.7208, Test Acc: 0.7131\n",
      "Seed: 42, Epoch: 040, Loss: 0.5453, Val Acc: 0.7110, Test Acc: 0.7180\n",
      "Seed: 42, Epoch: 041, Loss: 0.5413, Val Acc: 0.7127, Test Acc: 0.7066\n",
      "Seed: 42, Epoch: 042, Loss: 0.5404, Val Acc: 0.7159, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 043, Loss: 0.5389, Val Acc: 0.7256, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 044, Loss: 0.5379, Val Acc: 0.7354, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 045, Loss: 0.5370, Val Acc: 0.6981, Test Acc: 0.6969\n",
      "Seed: 42, Epoch: 046, Loss: 0.5431, Val Acc: 0.7273, Test Acc: 0.7066\n",
      "Seed: 42, Epoch: 047, Loss: 0.5485, Val Acc: 0.6932, Test Acc: 0.6921\n",
      "Seed: 42, Epoch: 048, Loss: 0.5465, Val Acc: 0.7338, Test Acc: 0.7245\n",
      "Seed: 42, Epoch: 049, Loss: 0.5406, Val Acc: 0.7354, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 050, Loss: 0.5366, Val Acc: 0.7370, Test Acc: 0.7229\n",
      "Seed: 42, Epoch: 051, Loss: 0.5335, Val Acc: 0.7256, Test Acc: 0.7229\n",
      "Seed: 42, Epoch: 052, Loss: 0.5325, Val Acc: 0.7224, Test Acc: 0.7147\n",
      "Seed: 42, Epoch: 053, Loss: 0.5324, Val Acc: 0.7370, Test Acc: 0.7180\n",
      "Seed: 42, Epoch: 054, Loss: 0.5327, Val Acc: 0.7208, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 055, Loss: 0.5344, Val Acc: 0.7451, Test Acc: 0.7196\n",
      "Seed: 42, Epoch: 056, Loss: 0.5317, Val Acc: 0.7289, Test Acc: 0.7229\n",
      "Seed: 42, Epoch: 057, Loss: 0.5370, Val Acc: 0.7273, Test Acc: 0.7147\n",
      "Seed: 42, Epoch: 058, Loss: 0.5319, Val Acc: 0.7370, Test Acc: 0.7229\n",
      "Seed: 42, Epoch: 059, Loss: 0.5318, Val Acc: 0.7256, Test Acc: 0.7066\n",
      "Seed: 42, Epoch: 060, Loss: 0.5272, Val Acc: 0.7354, Test Acc: 0.7310\n",
      "Seed: 42, Epoch: 061, Loss: 0.5282, Val Acc: 0.7468, Test Acc: 0.7229\n",
      "Seed: 42, Epoch: 062, Loss: 0.5250, Val Acc: 0.7451, Test Acc: 0.7229\n",
      "Seed: 42, Epoch: 063, Loss: 0.5256, Val Acc: 0.7354, Test Acc: 0.7147\n",
      "Seed: 42, Epoch: 064, Loss: 0.5258, Val Acc: 0.7451, Test Acc: 0.7147\n",
      "Seed: 42, Epoch: 065, Loss: 0.5249, Val Acc: 0.7370, Test Acc: 0.7131\n",
      "Seed: 42, Epoch: 066, Loss: 0.5332, Val Acc: 0.7321, Test Acc: 0.7147\n",
      "Seed: 42, Epoch: 067, Loss: 0.5332, Val Acc: 0.7403, Test Acc: 0.7131\n",
      "Seed: 42, Epoch: 068, Loss: 0.5277, Val Acc: 0.7419, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 069, Loss: 0.5217, Val Acc: 0.7386, Test Acc: 0.7180\n",
      "Seed: 42, Epoch: 070, Loss: 0.5221, Val Acc: 0.7273, Test Acc: 0.7196\n",
      "Seed: 42, Epoch: 071, Loss: 0.5234, Val Acc: 0.7013, Test Acc: 0.6953\n",
      "Seed: 42, Epoch: 072, Loss: 0.5273, Val Acc: 0.7370, Test Acc: 0.7180\n",
      "Seed: 42, Epoch: 073, Loss: 0.5218, Val Acc: 0.7419, Test Acc: 0.7196\n",
      "Seed: 42, Epoch: 074, Loss: 0.5200, Val Acc: 0.7354, Test Acc: 0.7277\n",
      "Seed: 42, Epoch: 075, Loss: 0.5253, Val Acc: 0.7565, Test Acc: 0.7147\n",
      "Seed: 42, Epoch: 076, Loss: 0.5188, Val Acc: 0.7451, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 077, Loss: 0.5278, Val Acc: 0.7403, Test Acc: 0.7229\n",
      "Seed: 42, Epoch: 078, Loss: 0.5189, Val Acc: 0.7419, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 079, Loss: 0.5245, Val Acc: 0.7516, Test Acc: 0.7180\n",
      "Seed: 42, Epoch: 080, Loss: 0.5214, Val Acc: 0.7516, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 081, Loss: 0.5173, Val Acc: 0.7549, Test Acc: 0.7196\n",
      "Seed: 42, Epoch: 082, Loss: 0.5206, Val Acc: 0.7451, Test Acc: 0.7277\n",
      "Seed: 42, Epoch: 083, Loss: 0.5165, Val Acc: 0.7256, Test Acc: 0.7229\n",
      "Seed: 42, Epoch: 084, Loss: 0.5157, Val Acc: 0.7532, Test Acc: 0.7326\n",
      "Seed: 42, Epoch: 085, Loss: 0.5180, Val Acc: 0.7451, Test Acc: 0.7245\n",
      "Seed: 42, Epoch: 086, Loss: 0.5158, Val Acc: 0.7484, Test Acc: 0.7342\n",
      "Seed: 42, Epoch: 087, Loss: 0.5112, Val Acc: 0.7435, Test Acc: 0.7342\n",
      "Seed: 42, Epoch: 088, Loss: 0.5116, Val Acc: 0.7500, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 089, Loss: 0.5107, Val Acc: 0.7516, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 090, Loss: 0.5143, Val Acc: 0.7581, Test Acc: 0.7342\n",
      "Seed: 42, Epoch: 091, Loss: 0.5151, Val Acc: 0.7370, Test Acc: 0.7326\n",
      "Seed: 42, Epoch: 092, Loss: 0.5128, Val Acc: 0.7565, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 093, Loss: 0.5138, Val Acc: 0.7581, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 094, Loss: 0.5139, Val Acc: 0.7597, Test Acc: 0.7310\n",
      "Seed: 42, Epoch: 095, Loss: 0.5139, Val Acc: 0.7581, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 096, Loss: 0.5132, Val Acc: 0.7581, Test Acc: 0.7407\n",
      "Seed: 42, Epoch: 097, Loss: 0.5097, Val Acc: 0.7500, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 098, Loss: 0.5104, Val Acc: 0.7240, Test Acc: 0.7131\n",
      "Seed: 42, Epoch: 099, Loss: 0.5179, Val Acc: 0.7565, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 100, Loss: 0.5094, Val Acc: 0.7273, Test Acc: 0.7147\n",
      "Seed: 42, Epoch: 101, Loss: 0.5103, Val Acc: 0.7435, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 102, Loss: 0.5215, Val Acc: 0.7062, Test Acc: 0.6969\n",
      "Seed: 42, Epoch: 103, Loss: 0.5326, Val Acc: 0.7451, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 104, Loss: 0.5168, Val Acc: 0.7484, Test Acc: 0.7342\n",
      "Seed: 42, Epoch: 105, Loss: 0.5122, Val Acc: 0.7532, Test Acc: 0.7326\n",
      "Seed: 42, Epoch: 106, Loss: 0.5083, Val Acc: 0.7370, Test Acc: 0.7277\n",
      "Seed: 42, Epoch: 107, Loss: 0.5186, Val Acc: 0.7500, Test Acc: 0.7310\n",
      "Seed: 42, Epoch: 108, Loss: 0.5113, Val Acc: 0.7516, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 109, Loss: 0.5066, Val Acc: 0.7435, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 110, Loss: 0.5096, Val Acc: 0.7565, Test Acc: 0.7536\n",
      "Seed: 42, Epoch: 111, Loss: 0.5090, Val Acc: 0.7321, Test Acc: 0.7245\n",
      "Seed: 42, Epoch: 112, Loss: 0.5091, Val Acc: 0.7354, Test Acc: 0.7147\n",
      "Seed: 42, Epoch: 113, Loss: 0.5104, Val Acc: 0.7516, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 114, Loss: 0.5039, Val Acc: 0.7630, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 115, Loss: 0.5041, Val Acc: 0.7549, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 116, Loss: 0.5007, Val Acc: 0.7614, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 117, Loss: 0.5021, Val Acc: 0.7695, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 118, Loss: 0.5028, Val Acc: 0.7614, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 119, Loss: 0.5043, Val Acc: 0.7386, Test Acc: 0.7180\n",
      "Seed: 42, Epoch: 120, Loss: 0.5042, Val Acc: 0.7581, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 121, Loss: 0.5035, Val Acc: 0.7679, Test Acc: 0.7407\n",
      "Seed: 42, Epoch: 122, Loss: 0.5014, Val Acc: 0.7565, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 123, Loss: 0.4994, Val Acc: 0.7646, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 124, Loss: 0.5042, Val Acc: 0.7597, Test Acc: 0.7536\n",
      "Seed: 42, Epoch: 125, Loss: 0.5050, Val Acc: 0.7192, Test Acc: 0.7002\n",
      "Seed: 42, Epoch: 126, Loss: 0.5052, Val Acc: 0.7532, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 127, Loss: 0.5000, Val Acc: 0.7662, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 128, Loss: 0.5074, Val Acc: 0.7354, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 129, Loss: 0.5063, Val Acc: 0.7500, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 130, Loss: 0.5049, Val Acc: 0.7565, Test Acc: 0.7407\n",
      "Seed: 42, Epoch: 131, Loss: 0.5009, Val Acc: 0.7484, Test Acc: 0.7245\n",
      "Seed: 42, Epoch: 132, Loss: 0.4997, Val Acc: 0.7597, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 133, Loss: 0.5010, Val Acc: 0.7581, Test Acc: 0.7342\n",
      "Seed: 42, Epoch: 134, Loss: 0.5057, Val Acc: 0.7484, Test Acc: 0.7196\n",
      "Seed: 42, Epoch: 135, Loss: 0.5000, Val Acc: 0.7711, Test Acc: 0.7407\n",
      "Seed: 42, Epoch: 136, Loss: 0.5121, Val Acc: 0.7744, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 137, Loss: 0.5044, Val Acc: 0.7646, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 138, Loss: 0.5002, Val Acc: 0.7597, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 139, Loss: 0.5084, Val Acc: 0.7662, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 140, Loss: 0.5015, Val Acc: 0.7403, Test Acc: 0.7131\n",
      "Seed: 42, Epoch: 141, Loss: 0.4989, Val Acc: 0.7630, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 142, Loss: 0.4993, Val Acc: 0.7630, Test Acc: 0.7472\n",
      "Seed: 42, Epoch: 143, Loss: 0.4970, Val Acc: 0.7581, Test Acc: 0.7310\n",
      "Seed: 42, Epoch: 144, Loss: 0.4977, Val Acc: 0.7468, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 145, Loss: 0.5081, Val Acc: 0.7630, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 146, Loss: 0.5050, Val Acc: 0.7597, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 147, Loss: 0.5003, Val Acc: 0.7646, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 148, Loss: 0.4958, Val Acc: 0.7679, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 149, Loss: 0.4945, Val Acc: 0.7565, Test Acc: 0.7310\n",
      "Seed: 42, Epoch: 150, Loss: 0.4895, Val Acc: 0.7500, Test Acc: 0.7261\n",
      "Seed: 42, Epoch: 151, Loss: 0.4880, Val Acc: 0.7646, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 152, Loss: 0.5024, Val Acc: 0.7760, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 153, Loss: 0.4927, Val Acc: 0.7419, Test Acc: 0.7131\n",
      "Seed: 42, Epoch: 154, Loss: 0.4963, Val Acc: 0.7679, Test Acc: 0.7569\n",
      "Seed: 42, Epoch: 155, Loss: 0.4950, Val Acc: 0.7597, Test Acc: 0.7180\n",
      "Seed: 42, Epoch: 156, Loss: 0.4903, Val Acc: 0.7727, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 157, Loss: 0.4901, Val Acc: 0.7435, Test Acc: 0.7147\n",
      "Seed: 42, Epoch: 158, Loss: 0.4898, Val Acc: 0.7695, Test Acc: 0.7585\n",
      "Seed: 42, Epoch: 159, Loss: 0.4970, Val Acc: 0.7614, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 160, Loss: 0.4982, Val Acc: 0.7500, Test Acc: 0.7310\n",
      "Seed: 42, Epoch: 161, Loss: 0.4940, Val Acc: 0.7338, Test Acc: 0.7115\n",
      "Seed: 42, Epoch: 162, Loss: 0.4913, Val Acc: 0.7679, Test Acc: 0.7407\n",
      "Seed: 42, Epoch: 163, Loss: 0.4874, Val Acc: 0.7565, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 164, Loss: 0.4921, Val Acc: 0.7614, Test Acc: 0.7601\n",
      "Seed: 42, Epoch: 165, Loss: 0.4888, Val Acc: 0.7581, Test Acc: 0.7310\n",
      "Seed: 42, Epoch: 166, Loss: 0.4873, Val Acc: 0.7760, Test Acc: 0.7407\n",
      "Seed: 42, Epoch: 167, Loss: 0.4844, Val Acc: 0.7695, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 168, Loss: 0.4927, Val Acc: 0.7711, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 169, Loss: 0.4924, Val Acc: 0.7565, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 170, Loss: 0.4916, Val Acc: 0.7695, Test Acc: 0.7407\n",
      "Seed: 42, Epoch: 171, Loss: 0.4847, Val Acc: 0.7662, Test Acc: 0.7585\n",
      "Seed: 42, Epoch: 172, Loss: 0.4814, Val Acc: 0.7679, Test Acc: 0.7407\n",
      "Seed: 42, Epoch: 173, Loss: 0.4810, Val Acc: 0.7679, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 174, Loss: 0.4854, Val Acc: 0.7646, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 175, Loss: 0.4814, Val Acc: 0.7679, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 176, Loss: 0.4859, Val Acc: 0.7370, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 177, Loss: 0.4952, Val Acc: 0.7646, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 178, Loss: 0.4932, Val Acc: 0.7662, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 179, Loss: 0.4832, Val Acc: 0.7744, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 180, Loss: 0.4833, Val Acc: 0.7646, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 181, Loss: 0.4787, Val Acc: 0.7500, Test Acc: 0.7131\n",
      "Seed: 42, Epoch: 182, Loss: 0.4831, Val Acc: 0.7581, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 183, Loss: 0.4857, Val Acc: 0.7256, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 184, Loss: 0.4986, Val Acc: 0.7662, Test Acc: 0.7326\n",
      "Seed: 42, Epoch: 185, Loss: 0.4843, Val Acc: 0.7760, Test Acc: 0.7472\n",
      "Seed: 42, Epoch: 186, Loss: 0.4816, Val Acc: 0.7630, Test Acc: 0.7472\n",
      "Seed: 42, Epoch: 187, Loss: 0.4773, Val Acc: 0.7662, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 188, Loss: 0.4891, Val Acc: 0.7630, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 189, Loss: 0.4784, Val Acc: 0.7792, Test Acc: 0.7536\n",
      "Seed: 42, Epoch: 190, Loss: 0.4796, Val Acc: 0.7532, Test Acc: 0.7342\n",
      "Seed: 42, Epoch: 191, Loss: 0.4782, Val Acc: 0.7695, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 192, Loss: 0.4807, Val Acc: 0.7630, Test Acc: 0.7245\n",
      "Seed: 42, Epoch: 193, Loss: 0.4759, Val Acc: 0.7760, Test Acc: 0.7618\n",
      "Seed: 42, Epoch: 194, Loss: 0.4746, Val Acc: 0.7532, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 195, Loss: 0.4831, Val Acc: 0.7825, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 196, Loss: 0.4744, Val Acc: 0.7679, Test Acc: 0.7618\n",
      "Seed: 42, Epoch: 197, Loss: 0.4715, Val Acc: 0.7630, Test Acc: 0.7342\n",
      "Seed: 42, Epoch: 198, Loss: 0.4698, Val Acc: 0.7159, Test Acc: 0.7002\n",
      "Seed: 42, Epoch: 199, Loss: 0.4884, Val Acc: 0.7695, Test Acc: 0.7472\n",
      "Seed: 42, Epoch: 200, Loss: 0.4759, Val Acc: 0.7776, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 001, Loss: 0.6913, Val Acc: 0.5325, Test Acc: 0.4571\n",
      "Seed: 43, Epoch: 002, Loss: 0.6852, Val Acc: 0.5666, Test Acc: 0.5041\n",
      "Seed: 43, Epoch: 003, Loss: 0.6712, Val Acc: 0.5812, Test Acc: 0.5867\n",
      "Seed: 43, Epoch: 004, Loss: 0.6510, Val Acc: 0.5877, Test Acc: 0.6207\n",
      "Seed: 43, Epoch: 005, Loss: 0.6466, Val Acc: 0.5860, Test Acc: 0.6564\n",
      "Seed: 43, Epoch: 006, Loss: 0.6413, Val Acc: 0.6088, Test Acc: 0.6921\n",
      "Seed: 43, Epoch: 007, Loss: 0.6394, Val Acc: 0.6104, Test Acc: 0.6953\n",
      "Seed: 43, Epoch: 008, Loss: 0.6320, Val Acc: 0.6153, Test Acc: 0.7002\n",
      "Seed: 43, Epoch: 009, Loss: 0.6312, Val Acc: 0.6169, Test Acc: 0.6888\n",
      "Seed: 43, Epoch: 010, Loss: 0.6258, Val Acc: 0.6234, Test Acc: 0.7002\n",
      "Seed: 43, Epoch: 011, Loss: 0.6241, Val Acc: 0.6169, Test Acc: 0.6904\n",
      "Seed: 43, Epoch: 012, Loss: 0.6212, Val Acc: 0.6201, Test Acc: 0.7066\n",
      "Seed: 43, Epoch: 013, Loss: 0.6170, Val Acc: 0.6364, Test Acc: 0.7196\n",
      "Seed: 43, Epoch: 014, Loss: 0.6190, Val Acc: 0.6412, Test Acc: 0.7245\n",
      "Seed: 43, Epoch: 015, Loss: 0.6162, Val Acc: 0.6477, Test Acc: 0.7180\n",
      "Seed: 43, Epoch: 016, Loss: 0.6082, Val Acc: 0.6575, Test Acc: 0.7131\n",
      "Seed: 43, Epoch: 017, Loss: 0.6027, Val Acc: 0.6542, Test Acc: 0.7131\n",
      "Seed: 43, Epoch: 018, Loss: 0.5954, Val Acc: 0.6575, Test Acc: 0.7066\n",
      "Seed: 43, Epoch: 019, Loss: 0.5976, Val Acc: 0.6640, Test Acc: 0.7180\n",
      "Seed: 43, Epoch: 020, Loss: 0.5854, Val Acc: 0.6818, Test Acc: 0.7391\n",
      "Seed: 43, Epoch: 021, Loss: 0.5863, Val Acc: 0.6688, Test Acc: 0.7261\n",
      "Seed: 43, Epoch: 022, Loss: 0.5821, Val Acc: 0.6721, Test Acc: 0.7310\n",
      "Seed: 43, Epoch: 023, Loss: 0.5786, Val Acc: 0.6948, Test Acc: 0.7439\n",
      "Seed: 43, Epoch: 024, Loss: 0.5737, Val Acc: 0.6883, Test Acc: 0.7326\n",
      "Seed: 43, Epoch: 025, Loss: 0.5690, Val Acc: 0.6964, Test Acc: 0.7180\n",
      "Seed: 43, Epoch: 026, Loss: 0.5699, Val Acc: 0.6981, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 027, Loss: 0.5647, Val Acc: 0.6948, Test Acc: 0.7504\n",
      "Seed: 43, Epoch: 028, Loss: 0.5599, Val Acc: 0.6623, Test Acc: 0.7066\n",
      "Seed: 43, Epoch: 029, Loss: 0.5906, Val Acc: 0.6883, Test Acc: 0.7261\n",
      "Seed: 43, Epoch: 030, Loss: 0.5684, Val Acc: 0.6737, Test Acc: 0.6694\n",
      "Seed: 43, Epoch: 031, Loss: 0.5785, Val Acc: 0.6851, Test Acc: 0.6872\n",
      "Seed: 43, Epoch: 032, Loss: 0.5809, Val Acc: 0.6737, Test Acc: 0.6807\n",
      "Seed: 43, Epoch: 033, Loss: 0.5726, Val Acc: 0.7013, Test Acc: 0.7407\n",
      "Seed: 43, Epoch: 034, Loss: 0.5606, Val Acc: 0.7045, Test Acc: 0.7423\n",
      "Seed: 43, Epoch: 035, Loss: 0.5656, Val Acc: 0.7045, Test Acc: 0.7326\n",
      "Seed: 43, Epoch: 036, Loss: 0.5569, Val Acc: 0.7013, Test Acc: 0.7147\n",
      "Seed: 43, Epoch: 037, Loss: 0.5594, Val Acc: 0.7062, Test Acc: 0.7358\n",
      "Seed: 43, Epoch: 038, Loss: 0.5505, Val Acc: 0.7094, Test Acc: 0.7423\n",
      "Seed: 43, Epoch: 039, Loss: 0.5501, Val Acc: 0.7143, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 040, Loss: 0.5477, Val Acc: 0.7192, Test Acc: 0.7488\n",
      "Seed: 43, Epoch: 041, Loss: 0.5457, Val Acc: 0.7192, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 042, Loss: 0.5475, Val Acc: 0.7110, Test Acc: 0.7407\n",
      "Seed: 43, Epoch: 043, Loss: 0.5452, Val Acc: 0.7159, Test Acc: 0.7472\n",
      "Seed: 43, Epoch: 044, Loss: 0.5457, Val Acc: 0.7094, Test Acc: 0.7472\n",
      "Seed: 43, Epoch: 045, Loss: 0.5404, Val Acc: 0.7208, Test Acc: 0.7536\n",
      "Seed: 43, Epoch: 046, Loss: 0.5417, Val Acc: 0.7224, Test Acc: 0.7407\n",
      "Seed: 43, Epoch: 047, Loss: 0.5394, Val Acc: 0.7159, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 048, Loss: 0.5504, Val Acc: 0.7256, Test Acc: 0.7504\n",
      "Seed: 43, Epoch: 049, Loss: 0.5456, Val Acc: 0.7240, Test Acc: 0.7407\n",
      "Seed: 43, Epoch: 050, Loss: 0.5357, Val Acc: 0.7256, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 051, Loss: 0.5339, Val Acc: 0.7273, Test Acc: 0.7472\n",
      "Seed: 43, Epoch: 052, Loss: 0.5529, Val Acc: 0.7273, Test Acc: 0.7536\n",
      "Seed: 43, Epoch: 053, Loss: 0.5429, Val Acc: 0.7224, Test Acc: 0.7407\n",
      "Seed: 43, Epoch: 054, Loss: 0.5332, Val Acc: 0.7240, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 055, Loss: 0.5287, Val Acc: 0.7305, Test Acc: 0.7391\n",
      "Seed: 43, Epoch: 056, Loss: 0.5320, Val Acc: 0.7208, Test Acc: 0.7536\n",
      "Seed: 43, Epoch: 057, Loss: 0.5257, Val Acc: 0.7419, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 058, Loss: 0.5317, Val Acc: 0.7273, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 059, Loss: 0.5294, Val Acc: 0.7321, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 060, Loss: 0.5220, Val Acc: 0.7224, Test Acc: 0.7358\n",
      "Seed: 43, Epoch: 061, Loss: 0.5266, Val Acc: 0.7208, Test Acc: 0.7715\n",
      "Seed: 43, Epoch: 062, Loss: 0.5353, Val Acc: 0.7386, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 063, Loss: 0.5343, Val Acc: 0.7419, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 064, Loss: 0.5238, Val Acc: 0.7321, Test Acc: 0.7569\n",
      "Seed: 43, Epoch: 065, Loss: 0.5263, Val Acc: 0.7386, Test Acc: 0.7553\n",
      "Seed: 43, Epoch: 066, Loss: 0.5167, Val Acc: 0.7370, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 067, Loss: 0.5228, Val Acc: 0.7468, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 068, Loss: 0.5189, Val Acc: 0.7338, Test Acc: 0.7536\n",
      "Seed: 43, Epoch: 069, Loss: 0.5167, Val Acc: 0.7354, Test Acc: 0.7585\n",
      "Seed: 43, Epoch: 070, Loss: 0.5145, Val Acc: 0.7484, Test Acc: 0.7763\n",
      "Seed: 43, Epoch: 071, Loss: 0.5157, Val Acc: 0.7354, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 072, Loss: 0.5138, Val Acc: 0.7435, Test Acc: 0.7666\n",
      "Seed: 43, Epoch: 073, Loss: 0.5116, Val Acc: 0.7419, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 074, Loss: 0.5134, Val Acc: 0.7354, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 075, Loss: 0.5101, Val Acc: 0.7435, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 076, Loss: 0.5090, Val Acc: 0.7386, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 077, Loss: 0.5076, Val Acc: 0.7321, Test Acc: 0.7585\n",
      "Seed: 43, Epoch: 078, Loss: 0.5081, Val Acc: 0.7468, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 079, Loss: 0.5030, Val Acc: 0.7468, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 080, Loss: 0.5126, Val Acc: 0.7240, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 081, Loss: 0.5206, Val Acc: 0.7468, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 082, Loss: 0.5066, Val Acc: 0.7370, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 083, Loss: 0.5078, Val Acc: 0.7224, Test Acc: 0.7569\n",
      "Seed: 43, Epoch: 084, Loss: 0.5172, Val Acc: 0.7354, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 085, Loss: 0.5062, Val Acc: 0.7403, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 086, Loss: 0.5054, Val Acc: 0.7159, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 087, Loss: 0.5094, Val Acc: 0.7500, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 088, Loss: 0.5157, Val Acc: 0.7435, Test Acc: 0.7877\n",
      "Seed: 43, Epoch: 089, Loss: 0.4984, Val Acc: 0.7435, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 090, Loss: 0.5027, Val Acc: 0.7338, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 091, Loss: 0.4999, Val Acc: 0.7435, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 092, Loss: 0.4966, Val Acc: 0.7338, Test Acc: 0.7536\n",
      "Seed: 43, Epoch: 093, Loss: 0.4979, Val Acc: 0.7500, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 094, Loss: 0.4936, Val Acc: 0.7386, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 095, Loss: 0.4964, Val Acc: 0.7289, Test Acc: 0.7504\n",
      "Seed: 43, Epoch: 096, Loss: 0.5205, Val Acc: 0.7532, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 097, Loss: 0.5099, Val Acc: 0.7451, Test Acc: 0.7828\n",
      "Seed: 43, Epoch: 098, Loss: 0.5001, Val Acc: 0.7386, Test Acc: 0.7666\n",
      "Seed: 43, Epoch: 099, Loss: 0.4948, Val Acc: 0.7451, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 100, Loss: 0.4977, Val Acc: 0.7354, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 101, Loss: 0.4930, Val Acc: 0.7386, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 102, Loss: 0.4976, Val Acc: 0.7208, Test Acc: 0.7423\n",
      "Seed: 43, Epoch: 103, Loss: 0.4952, Val Acc: 0.7403, Test Acc: 0.7666\n",
      "Seed: 43, Epoch: 104, Loss: 0.4942, Val Acc: 0.7419, Test Acc: 0.7763\n",
      "Seed: 43, Epoch: 105, Loss: 0.4898, Val Acc: 0.7273, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 106, Loss: 0.4879, Val Acc: 0.7321, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 107, Loss: 0.4881, Val Acc: 0.7338, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 108, Loss: 0.4864, Val Acc: 0.7451, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 109, Loss: 0.4852, Val Acc: 0.7403, Test Acc: 0.7828\n",
      "Seed: 43, Epoch: 110, Loss: 0.4830, Val Acc: 0.7338, Test Acc: 0.7715\n",
      "Seed: 43, Epoch: 111, Loss: 0.4969, Val Acc: 0.7273, Test Acc: 0.7666\n",
      "Seed: 43, Epoch: 112, Loss: 0.4950, Val Acc: 0.7419, Test Acc: 0.7763\n",
      "Seed: 43, Epoch: 113, Loss: 0.4904, Val Acc: 0.7354, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 114, Loss: 0.4815, Val Acc: 0.7386, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 115, Loss: 0.4789, Val Acc: 0.7468, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 116, Loss: 0.4860, Val Acc: 0.7305, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 117, Loss: 0.4779, Val Acc: 0.7370, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 118, Loss: 0.4871, Val Acc: 0.7516, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 119, Loss: 0.4855, Val Acc: 0.7484, Test Acc: 0.7715\n",
      "Seed: 43, Epoch: 120, Loss: 0.4811, Val Acc: 0.7484, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 121, Loss: 0.4795, Val Acc: 0.7403, Test Acc: 0.7763\n",
      "Seed: 43, Epoch: 122, Loss: 0.4777, Val Acc: 0.7451, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 123, Loss: 0.4765, Val Acc: 0.7419, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 124, Loss: 0.4714, Val Acc: 0.7451, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 125, Loss: 0.4785, Val Acc: 0.7224, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 126, Loss: 0.4757, Val Acc: 0.7386, Test Acc: 0.7536\n",
      "Seed: 43, Epoch: 127, Loss: 0.4753, Val Acc: 0.7435, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 128, Loss: 0.4768, Val Acc: 0.7419, Test Acc: 0.7861\n",
      "Seed: 43, Epoch: 129, Loss: 0.4744, Val Acc: 0.7192, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 130, Loss: 0.4727, Val Acc: 0.7386, Test Acc: 0.7796\n",
      "Seed: 43, Epoch: 131, Loss: 0.4734, Val Acc: 0.7338, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 132, Loss: 0.4782, Val Acc: 0.7532, Test Acc: 0.7909\n",
      "Seed: 43, Epoch: 133, Loss: 0.4710, Val Acc: 0.7289, Test Acc: 0.7569\n",
      "Seed: 43, Epoch: 134, Loss: 0.4747, Val Acc: 0.7435, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 135, Loss: 0.4752, Val Acc: 0.7451, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 136, Loss: 0.4729, Val Acc: 0.7354, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 137, Loss: 0.4818, Val Acc: 0.7321, Test Acc: 0.7358\n",
      "Seed: 43, Epoch: 138, Loss: 0.4732, Val Acc: 0.7435, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 139, Loss: 0.4638, Val Acc: 0.7305, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 140, Loss: 0.4761, Val Acc: 0.7289, Test Acc: 0.7553\n",
      "Seed: 43, Epoch: 141, Loss: 0.4723, Val Acc: 0.7289, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 142, Loss: 0.4740, Val Acc: 0.7256, Test Acc: 0.7666\n",
      "Seed: 43, Epoch: 143, Loss: 0.4718, Val Acc: 0.7484, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 144, Loss: 0.4651, Val Acc: 0.7305, Test Acc: 0.7472\n",
      "Seed: 43, Epoch: 145, Loss: 0.4666, Val Acc: 0.7451, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 146, Loss: 0.4637, Val Acc: 0.7451, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 147, Loss: 0.4635, Val Acc: 0.7305, Test Acc: 0.7569\n",
      "Seed: 43, Epoch: 148, Loss: 0.4663, Val Acc: 0.7549, Test Acc: 0.7763\n",
      "Seed: 43, Epoch: 149, Loss: 0.4549, Val Acc: 0.7468, Test Acc: 0.7585\n",
      "Seed: 43, Epoch: 150, Loss: 0.4538, Val Acc: 0.7370, Test Acc: 0.7828\n",
      "Seed: 43, Epoch: 151, Loss: 0.4615, Val Acc: 0.7468, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 152, Loss: 0.4646, Val Acc: 0.7500, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 153, Loss: 0.4568, Val Acc: 0.7484, Test Acc: 0.7763\n",
      "Seed: 43, Epoch: 154, Loss: 0.4525, Val Acc: 0.7451, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 155, Loss: 0.4571, Val Acc: 0.7338, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 156, Loss: 0.4596, Val Acc: 0.7532, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 157, Loss: 0.4511, Val Acc: 0.7435, Test Acc: 0.7763\n",
      "Seed: 43, Epoch: 158, Loss: 0.4549, Val Acc: 0.7419, Test Acc: 0.7844\n",
      "Seed: 43, Epoch: 159, Loss: 0.4507, Val Acc: 0.7419, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 160, Loss: 0.4547, Val Acc: 0.7354, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 161, Loss: 0.4590, Val Acc: 0.7208, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 162, Loss: 0.4494, Val Acc: 0.7614, Test Acc: 0.7828\n",
      "Seed: 43, Epoch: 163, Loss: 0.4569, Val Acc: 0.7451, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 164, Loss: 0.4556, Val Acc: 0.7354, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 165, Loss: 0.4529, Val Acc: 0.7419, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 166, Loss: 0.4873, Val Acc: 0.7516, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 167, Loss: 0.4742, Val Acc: 0.7419, Test Acc: 0.7796\n",
      "Seed: 43, Epoch: 168, Loss: 0.4590, Val Acc: 0.7468, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 169, Loss: 0.4506, Val Acc: 0.7435, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 170, Loss: 0.4496, Val Acc: 0.7532, Test Acc: 0.7699\n",
      "Seed: 43, Epoch: 171, Loss: 0.4434, Val Acc: 0.7468, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 172, Loss: 0.4461, Val Acc: 0.7354, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 173, Loss: 0.4560, Val Acc: 0.7484, Test Acc: 0.7844\n",
      "Seed: 43, Epoch: 174, Loss: 0.4533, Val Acc: 0.7500, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 175, Loss: 0.4433, Val Acc: 0.7451, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 176, Loss: 0.4394, Val Acc: 0.7516, Test Acc: 0.7796\n",
      "Seed: 43, Epoch: 177, Loss: 0.4478, Val Acc: 0.7354, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 178, Loss: 0.4493, Val Acc: 0.7435, Test Acc: 0.7536\n",
      "Seed: 43, Epoch: 179, Loss: 0.4484, Val Acc: 0.7321, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 180, Loss: 0.4460, Val Acc: 0.7484, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 181, Loss: 0.4439, Val Acc: 0.7419, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 182, Loss: 0.4503, Val Acc: 0.7078, Test Acc: 0.7245\n",
      "Seed: 43, Epoch: 183, Loss: 0.4535, Val Acc: 0.7386, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 184, Loss: 0.4463, Val Acc: 0.7451, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 185, Loss: 0.4366, Val Acc: 0.7468, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 186, Loss: 0.4425, Val Acc: 0.7597, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 187, Loss: 0.4348, Val Acc: 0.7500, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 188, Loss: 0.4366, Val Acc: 0.7468, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 189, Loss: 0.4344, Val Acc: 0.7500, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 190, Loss: 0.4390, Val Acc: 0.7419, Test Acc: 0.7763\n",
      "Seed: 43, Epoch: 191, Loss: 0.4516, Val Acc: 0.7354, Test Acc: 0.7796\n",
      "Seed: 43, Epoch: 192, Loss: 0.4450, Val Acc: 0.7468, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 193, Loss: 0.4418, Val Acc: 0.7370, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 194, Loss: 0.4428, Val Acc: 0.7581, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 195, Loss: 0.4321, Val Acc: 0.7370, Test Acc: 0.7666\n",
      "Seed: 43, Epoch: 196, Loss: 0.4301, Val Acc: 0.7435, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 197, Loss: 0.4353, Val Acc: 0.7435, Test Acc: 0.7909\n",
      "Seed: 43, Epoch: 198, Loss: 0.4288, Val Acc: 0.7419, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 199, Loss: 0.4253, Val Acc: 0.7516, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 200, Loss: 0.4262, Val Acc: 0.7516, Test Acc: 0.7634\n",
      "Seed: 44, Epoch: 001, Loss: 0.7001, Val Acc: 0.4919, Test Acc: 0.4895\n",
      "Seed: 44, Epoch: 002, Loss: 0.6954, Val Acc: 0.4919, Test Acc: 0.4895\n",
      "Seed: 44, Epoch: 003, Loss: 0.6892, Val Acc: 0.4919, Test Acc: 0.4895\n",
      "Seed: 44, Epoch: 004, Loss: 0.6783, Val Acc: 0.5925, Test Acc: 0.5673\n",
      "Seed: 44, Epoch: 005, Loss: 0.6513, Val Acc: 0.6250, Test Acc: 0.5948\n",
      "Seed: 44, Epoch: 006, Loss: 0.6383, Val Acc: 0.6364, Test Acc: 0.5948\n",
      "Seed: 44, Epoch: 007, Loss: 0.6366, Val Acc: 0.6477, Test Acc: 0.6062\n",
      "Seed: 44, Epoch: 008, Loss: 0.6327, Val Acc: 0.6477, Test Acc: 0.6207\n",
      "Seed: 44, Epoch: 009, Loss: 0.6332, Val Acc: 0.6461, Test Acc: 0.6159\n",
      "Seed: 44, Epoch: 010, Loss: 0.6267, Val Acc: 0.6575, Test Acc: 0.6062\n",
      "Seed: 44, Epoch: 011, Loss: 0.6233, Val Acc: 0.6607, Test Acc: 0.6110\n",
      "Seed: 44, Epoch: 012, Loss: 0.6202, Val Acc: 0.6510, Test Acc: 0.6126\n",
      "Seed: 44, Epoch: 013, Loss: 0.6163, Val Acc: 0.6364, Test Acc: 0.6175\n",
      "Seed: 44, Epoch: 014, Loss: 0.6155, Val Acc: 0.6396, Test Acc: 0.5981\n",
      "Seed: 44, Epoch: 015, Loss: 0.6128, Val Acc: 0.6510, Test Acc: 0.6402\n",
      "Seed: 44, Epoch: 016, Loss: 0.6079, Val Acc: 0.6656, Test Acc: 0.6386\n",
      "Seed: 44, Epoch: 017, Loss: 0.6039, Val Acc: 0.6656, Test Acc: 0.6370\n",
      "Seed: 44, Epoch: 018, Loss: 0.5988, Val Acc: 0.6575, Test Acc: 0.6402\n",
      "Seed: 44, Epoch: 019, Loss: 0.6003, Val Acc: 0.6640, Test Acc: 0.6596\n",
      "Seed: 44, Epoch: 020, Loss: 0.5939, Val Acc: 0.6672, Test Acc: 0.6596\n",
      "Seed: 44, Epoch: 021, Loss: 0.5881, Val Acc: 0.6721, Test Acc: 0.6759\n",
      "Seed: 44, Epoch: 022, Loss: 0.5829, Val Acc: 0.6688, Test Acc: 0.6564\n",
      "Seed: 44, Epoch: 023, Loss: 0.5787, Val Acc: 0.6786, Test Acc: 0.6483\n",
      "Seed: 44, Epoch: 024, Loss: 0.5778, Val Acc: 0.6818, Test Acc: 0.6856\n",
      "Seed: 44, Epoch: 025, Loss: 0.5750, Val Acc: 0.6899, Test Acc: 0.6856\n",
      "Seed: 44, Epoch: 026, Loss: 0.5693, Val Acc: 0.6672, Test Acc: 0.6677\n",
      "Seed: 44, Epoch: 027, Loss: 0.5668, Val Acc: 0.6932, Test Acc: 0.6888\n",
      "Seed: 44, Epoch: 028, Loss: 0.5616, Val Acc: 0.6753, Test Acc: 0.6937\n",
      "Seed: 44, Epoch: 029, Loss: 0.5592, Val Acc: 0.6916, Test Acc: 0.7002\n",
      "Seed: 44, Epoch: 030, Loss: 0.5567, Val Acc: 0.6786, Test Acc: 0.6759\n",
      "Seed: 44, Epoch: 031, Loss: 0.5660, Val Acc: 0.6899, Test Acc: 0.6677\n",
      "Seed: 44, Epoch: 032, Loss: 0.5683, Val Acc: 0.6834, Test Acc: 0.6953\n",
      "Seed: 44, Epoch: 033, Loss: 0.5617, Val Acc: 0.6834, Test Acc: 0.7002\n",
      "Seed: 44, Epoch: 034, Loss: 0.5642, Val Acc: 0.6851, Test Acc: 0.6888\n",
      "Seed: 44, Epoch: 035, Loss: 0.5501, Val Acc: 0.6964, Test Acc: 0.6921\n",
      "Seed: 44, Epoch: 036, Loss: 0.5630, Val Acc: 0.6997, Test Acc: 0.6823\n",
      "Seed: 44, Epoch: 037, Loss: 0.5605, Val Acc: 0.6932, Test Acc: 0.6840\n",
      "Seed: 44, Epoch: 038, Loss: 0.5625, Val Acc: 0.7029, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 039, Loss: 0.5482, Val Acc: 0.6916, Test Acc: 0.7034\n",
      "Seed: 44, Epoch: 040, Loss: 0.5458, Val Acc: 0.6997, Test Acc: 0.7066\n",
      "Seed: 44, Epoch: 041, Loss: 0.5510, Val Acc: 0.6964, Test Acc: 0.7066\n",
      "Seed: 44, Epoch: 042, Loss: 0.5454, Val Acc: 0.6997, Test Acc: 0.7018\n",
      "Seed: 44, Epoch: 043, Loss: 0.5426, Val Acc: 0.6899, Test Acc: 0.7131\n",
      "Seed: 44, Epoch: 044, Loss: 0.5446, Val Acc: 0.6932, Test Acc: 0.7115\n",
      "Seed: 44, Epoch: 045, Loss: 0.5420, Val Acc: 0.7062, Test Acc: 0.7002\n",
      "Seed: 44, Epoch: 046, Loss: 0.5446, Val Acc: 0.6964, Test Acc: 0.7180\n",
      "Seed: 44, Epoch: 047, Loss: 0.5415, Val Acc: 0.7062, Test Acc: 0.7050\n",
      "Seed: 44, Epoch: 048, Loss: 0.5462, Val Acc: 0.7062, Test Acc: 0.6921\n",
      "Seed: 44, Epoch: 049, Loss: 0.5682, Val Acc: 0.7045, Test Acc: 0.6953\n",
      "Seed: 44, Epoch: 050, Loss: 0.5447, Val Acc: 0.7062, Test Acc: 0.7196\n",
      "Seed: 44, Epoch: 051, Loss: 0.5361, Val Acc: 0.7110, Test Acc: 0.7115\n",
      "Seed: 44, Epoch: 052, Loss: 0.5348, Val Acc: 0.7029, Test Acc: 0.7115\n",
      "Seed: 44, Epoch: 053, Loss: 0.5398, Val Acc: 0.7013, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 054, Loss: 0.5360, Val Acc: 0.7078, Test Acc: 0.7261\n",
      "Seed: 44, Epoch: 055, Loss: 0.5325, Val Acc: 0.7110, Test Acc: 0.7196\n",
      "Seed: 44, Epoch: 056, Loss: 0.5415, Val Acc: 0.7078, Test Acc: 0.7229\n",
      "Seed: 44, Epoch: 057, Loss: 0.5329, Val Acc: 0.6818, Test Acc: 0.6969\n",
      "Seed: 44, Epoch: 058, Loss: 0.5465, Val Acc: 0.6737, Test Acc: 0.6888\n",
      "Seed: 44, Epoch: 059, Loss: 0.5535, Val Acc: 0.6932, Test Acc: 0.7164\n",
      "Seed: 44, Epoch: 060, Loss: 0.5349, Val Acc: 0.6997, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 061, Loss: 0.5323, Val Acc: 0.7110, Test Acc: 0.7245\n",
      "Seed: 44, Epoch: 062, Loss: 0.5306, Val Acc: 0.7127, Test Acc: 0.7196\n",
      "Seed: 44, Epoch: 063, Loss: 0.5329, Val Acc: 0.7127, Test Acc: 0.7261\n",
      "Seed: 44, Epoch: 064, Loss: 0.5337, Val Acc: 0.6964, Test Acc: 0.7180\n",
      "Seed: 44, Epoch: 065, Loss: 0.5301, Val Acc: 0.7175, Test Acc: 0.7066\n",
      "Seed: 44, Epoch: 066, Loss: 0.5301, Val Acc: 0.7029, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 067, Loss: 0.5270, Val Acc: 0.7110, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 068, Loss: 0.5258, Val Acc: 0.7127, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 069, Loss: 0.5267, Val Acc: 0.7192, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 070, Loss: 0.5257, Val Acc: 0.7110, Test Acc: 0.7229\n",
      "Seed: 44, Epoch: 071, Loss: 0.5199, Val Acc: 0.7094, Test Acc: 0.7245\n",
      "Seed: 44, Epoch: 072, Loss: 0.5196, Val Acc: 0.7175, Test Acc: 0.7358\n",
      "Seed: 44, Epoch: 073, Loss: 0.5184, Val Acc: 0.7094, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 074, Loss: 0.5228, Val Acc: 0.7078, Test Acc: 0.7196\n",
      "Seed: 44, Epoch: 075, Loss: 0.5261, Val Acc: 0.7143, Test Acc: 0.7245\n",
      "Seed: 44, Epoch: 076, Loss: 0.5234, Val Acc: 0.7208, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 077, Loss: 0.5197, Val Acc: 0.7175, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 078, Loss: 0.5167, Val Acc: 0.7143, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 079, Loss: 0.5159, Val Acc: 0.7110, Test Acc: 0.7261\n",
      "Seed: 44, Epoch: 080, Loss: 0.5156, Val Acc: 0.7192, Test Acc: 0.7261\n",
      "Seed: 44, Epoch: 081, Loss: 0.5280, Val Acc: 0.7403, Test Acc: 0.7245\n",
      "Seed: 44, Epoch: 082, Loss: 0.5142, Val Acc: 0.7208, Test Acc: 0.7180\n",
      "Seed: 44, Epoch: 083, Loss: 0.5153, Val Acc: 0.7110, Test Acc: 0.7229\n",
      "Seed: 44, Epoch: 084, Loss: 0.5094, Val Acc: 0.7256, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 085, Loss: 0.5129, Val Acc: 0.7159, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 086, Loss: 0.5167, Val Acc: 0.7240, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 087, Loss: 0.5109, Val Acc: 0.7273, Test Acc: 0.7229\n",
      "Seed: 44, Epoch: 088, Loss: 0.5110, Val Acc: 0.7208, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 089, Loss: 0.5152, Val Acc: 0.7256, Test Acc: 0.7358\n",
      "Seed: 44, Epoch: 090, Loss: 0.5158, Val Acc: 0.7208, Test Acc: 0.7164\n",
      "Seed: 44, Epoch: 091, Loss: 0.5057, Val Acc: 0.7273, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 092, Loss: 0.5022, Val Acc: 0.7289, Test Acc: 0.7229\n",
      "Seed: 44, Epoch: 093, Loss: 0.5081, Val Acc: 0.7240, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 094, Loss: 0.5094, Val Acc: 0.7338, Test Acc: 0.7147\n",
      "Seed: 44, Epoch: 095, Loss: 0.5055, Val Acc: 0.7338, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 096, Loss: 0.5020, Val Acc: 0.7208, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 097, Loss: 0.5031, Val Acc: 0.7289, Test Acc: 0.7196\n",
      "Seed: 44, Epoch: 098, Loss: 0.5011, Val Acc: 0.7338, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 099, Loss: 0.4992, Val Acc: 0.7175, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 100, Loss: 0.4984, Val Acc: 0.7289, Test Acc: 0.7212\n",
      "Seed: 44, Epoch: 101, Loss: 0.4984, Val Acc: 0.7321, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 102, Loss: 0.4995, Val Acc: 0.7159, Test Acc: 0.7196\n",
      "Seed: 44, Epoch: 103, Loss: 0.4965, Val Acc: 0.7386, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 104, Loss: 0.4926, Val Acc: 0.7386, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 105, Loss: 0.4993, Val Acc: 0.7305, Test Acc: 0.7358\n",
      "Seed: 44, Epoch: 106, Loss: 0.4965, Val Acc: 0.7273, Test Acc: 0.7245\n",
      "Seed: 44, Epoch: 107, Loss: 0.4936, Val Acc: 0.7354, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 108, Loss: 0.4892, Val Acc: 0.7354, Test Acc: 0.7374\n",
      "Seed: 44, Epoch: 109, Loss: 0.4961, Val Acc: 0.7419, Test Acc: 0.7358\n",
      "Seed: 44, Epoch: 110, Loss: 0.4905, Val Acc: 0.7273, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 111, Loss: 0.4968, Val Acc: 0.7321, Test Acc: 0.7374\n",
      "Seed: 44, Epoch: 112, Loss: 0.5104, Val Acc: 0.7273, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 113, Loss: 0.4899, Val Acc: 0.7273, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 114, Loss: 0.4865, Val Acc: 0.7419, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 115, Loss: 0.4868, Val Acc: 0.7435, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 116, Loss: 0.4902, Val Acc: 0.7338, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 117, Loss: 0.4914, Val Acc: 0.7354, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 118, Loss: 0.4851, Val Acc: 0.7403, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 119, Loss: 0.4823, Val Acc: 0.7338, Test Acc: 0.7472\n",
      "Seed: 44, Epoch: 120, Loss: 0.4829, Val Acc: 0.7468, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 121, Loss: 0.4914, Val Acc: 0.7468, Test Acc: 0.7391\n",
      "Seed: 44, Epoch: 122, Loss: 0.4852, Val Acc: 0.7224, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 123, Loss: 0.4754, Val Acc: 0.7403, Test Acc: 0.7391\n",
      "Seed: 44, Epoch: 124, Loss: 0.4762, Val Acc: 0.7370, Test Acc: 0.7358\n",
      "Seed: 44, Epoch: 125, Loss: 0.4755, Val Acc: 0.7435, Test Acc: 0.7423\n",
      "Seed: 44, Epoch: 126, Loss: 0.4746, Val Acc: 0.7354, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 127, Loss: 0.4796, Val Acc: 0.7256, Test Acc: 0.7374\n",
      "Seed: 44, Epoch: 128, Loss: 0.4813, Val Acc: 0.7338, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 129, Loss: 0.4698, Val Acc: 0.7321, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 130, Loss: 0.4754, Val Acc: 0.7321, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 131, Loss: 0.4730, Val Acc: 0.7468, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 132, Loss: 0.4791, Val Acc: 0.7549, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 133, Loss: 0.4846, Val Acc: 0.7468, Test Acc: 0.7423\n",
      "Seed: 44, Epoch: 134, Loss: 0.4756, Val Acc: 0.7321, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 135, Loss: 0.4707, Val Acc: 0.7321, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 136, Loss: 0.4648, Val Acc: 0.7500, Test Acc: 0.7391\n",
      "Seed: 44, Epoch: 137, Loss: 0.4679, Val Acc: 0.7500, Test Acc: 0.7212\n",
      "Seed: 44, Epoch: 138, Loss: 0.4732, Val Acc: 0.7468, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 139, Loss: 0.4745, Val Acc: 0.7386, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 140, Loss: 0.4717, Val Acc: 0.7484, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 141, Loss: 0.4753, Val Acc: 0.7500, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 142, Loss: 0.4679, Val Acc: 0.7370, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 143, Loss: 0.4656, Val Acc: 0.7532, Test Acc: 0.7472\n",
      "Seed: 44, Epoch: 144, Loss: 0.4598, Val Acc: 0.7484, Test Acc: 0.7455\n",
      "Seed: 44, Epoch: 145, Loss: 0.4723, Val Acc: 0.7354, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 146, Loss: 0.4614, Val Acc: 0.7419, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 147, Loss: 0.4580, Val Acc: 0.7419, Test Acc: 0.7472\n",
      "Seed: 44, Epoch: 148, Loss: 0.4601, Val Acc: 0.7500, Test Acc: 0.7423\n",
      "Seed: 44, Epoch: 149, Loss: 0.4614, Val Acc: 0.7338, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 150, Loss: 0.4619, Val Acc: 0.7354, Test Acc: 0.7585\n",
      "Seed: 44, Epoch: 151, Loss: 0.4553, Val Acc: 0.7451, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 152, Loss: 0.4595, Val Acc: 0.7305, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 153, Loss: 0.4554, Val Acc: 0.7549, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 154, Loss: 0.4538, Val Acc: 0.7419, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 155, Loss: 0.4557, Val Acc: 0.7484, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 156, Loss: 0.4530, Val Acc: 0.7484, Test Acc: 0.7472\n",
      "Seed: 44, Epoch: 157, Loss: 0.4649, Val Acc: 0.7484, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 158, Loss: 0.4542, Val Acc: 0.7468, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 159, Loss: 0.4682, Val Acc: 0.7451, Test Acc: 0.7455\n",
      "Seed: 44, Epoch: 160, Loss: 0.4530, Val Acc: 0.7500, Test Acc: 0.7391\n",
      "Seed: 44, Epoch: 161, Loss: 0.4578, Val Acc: 0.7240, Test Acc: 0.6985\n",
      "Seed: 44, Epoch: 162, Loss: 0.4888, Val Acc: 0.7386, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 163, Loss: 0.4602, Val Acc: 0.7468, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 164, Loss: 0.4532, Val Acc: 0.7468, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 165, Loss: 0.4487, Val Acc: 0.7565, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 166, Loss: 0.4544, Val Acc: 0.7435, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 167, Loss: 0.4569, Val Acc: 0.7451, Test Acc: 0.7261\n",
      "Seed: 44, Epoch: 168, Loss: 0.4689, Val Acc: 0.7549, Test Acc: 0.7455\n",
      "Seed: 44, Epoch: 169, Loss: 0.4463, Val Acc: 0.7468, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 170, Loss: 0.4439, Val Acc: 0.7435, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 171, Loss: 0.4441, Val Acc: 0.7403, Test Acc: 0.7374\n",
      "Seed: 44, Epoch: 172, Loss: 0.4495, Val Acc: 0.7484, Test Acc: 0.7245\n",
      "Seed: 44, Epoch: 173, Loss: 0.4749, Val Acc: 0.7468, Test Acc: 0.7374\n",
      "Seed: 44, Epoch: 174, Loss: 0.4537, Val Acc: 0.7354, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 175, Loss: 0.4600, Val Acc: 0.7386, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 176, Loss: 0.4556, Val Acc: 0.7419, Test Acc: 0.7553\n",
      "Seed: 44, Epoch: 177, Loss: 0.4424, Val Acc: 0.7468, Test Acc: 0.7374\n",
      "Seed: 44, Epoch: 178, Loss: 0.4547, Val Acc: 0.7468, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 179, Loss: 0.4410, Val Acc: 0.7451, Test Acc: 0.7472\n",
      "Seed: 44, Epoch: 180, Loss: 0.4416, Val Acc: 0.7451, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 181, Loss: 0.4468, Val Acc: 0.7484, Test Acc: 0.7553\n",
      "Seed: 44, Epoch: 182, Loss: 0.4488, Val Acc: 0.7630, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 183, Loss: 0.4457, Val Acc: 0.7549, Test Acc: 0.7553\n",
      "Seed: 44, Epoch: 184, Loss: 0.4387, Val Acc: 0.7549, Test Acc: 0.7423\n",
      "Seed: 44, Epoch: 185, Loss: 0.4399, Val Acc: 0.7484, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 186, Loss: 0.4411, Val Acc: 0.7403, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 187, Loss: 0.4422, Val Acc: 0.7403, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 188, Loss: 0.4339, Val Acc: 0.7435, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 189, Loss: 0.4357, Val Acc: 0.7321, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 190, Loss: 0.4388, Val Acc: 0.7386, Test Acc: 0.7164\n",
      "Seed: 44, Epoch: 191, Loss: 0.4584, Val Acc: 0.7386, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 192, Loss: 0.4476, Val Acc: 0.7435, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 193, Loss: 0.4418, Val Acc: 0.7451, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 194, Loss: 0.4324, Val Acc: 0.7386, Test Acc: 0.7634\n",
      "Seed: 44, Epoch: 195, Loss: 0.4315, Val Acc: 0.7484, Test Acc: 0.7569\n",
      "Seed: 44, Epoch: 196, Loss: 0.4400, Val Acc: 0.7224, Test Acc: 0.7115\n",
      "Seed: 44, Epoch: 197, Loss: 0.4513, Val Acc: 0.7451, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 198, Loss: 0.4439, Val Acc: 0.7435, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 199, Loss: 0.4386, Val Acc: 0.7419, Test Acc: 0.7569\n",
      "Seed: 44, Epoch: 200, Loss: 0.4329, Val Acc: 0.7500, Test Acc: 0.7520\n",
      "Average Time: 287.03 seconds\n",
      "Var Time: 0.90 seconds\n",
      "Average Memory: 4300.00 MB\n",
      "Average Best Val Acc: 0.7689\n",
      "Std Best Test Acc: 0.0169\n",
      "Average Test Acc: 0.7590\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "max_nodes = 150\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"NCI1\",\n",
    "    transform=T.Compose([T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "dataset = dataset_dense\n",
    "dataset = dataset.shuffle()\n",
    "N = 150\n",
    "mp_layers = 1\n",
    "mp_channels = 64\n",
    "mp_activation = \"relu\"\n",
    "delta_coeff = 2.0\n",
    "\n",
    "mlp_hidden_layers = 2\n",
    "mlp_hidden_channels = 128\n",
    "mlp_activation = \"relu\"\n",
    "totvar_coeff = 0.5\n",
    "balance_coeff = 0.5\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 5e-4\n",
    "l2_reg_val = 0\n",
    "patience = 10\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        if self.lin is not None:\n",
    "            x = self.lin(x).relu()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_AsymCheegerCut(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset.num_classes)\n",
    "\n",
    "        self.pool1 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "        self.pool2 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool1(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool2(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_AsymCheegerCut().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "    model = Net_AsymCheegerCut().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCI109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6915, Val Acc: 0.4895, Test Acc: 0.5129\n",
      "Seed: 42, Epoch: 002, Loss: 0.6870, Val Acc: 0.4830, Test Acc: 0.5065\n",
      "Seed: 42, Epoch: 003, Loss: 0.6806, Val Acc: 0.5186, Test Acc: 0.5323\n",
      "Seed: 42, Epoch: 004, Loss: 0.6704, Val Acc: 0.6123, Test Acc: 0.5774\n",
      "Seed: 42, Epoch: 005, Loss: 0.6586, Val Acc: 0.6478, Test Acc: 0.5984\n",
      "Seed: 42, Epoch: 006, Loss: 0.6504, Val Acc: 0.6462, Test Acc: 0.6323\n",
      "Seed: 42, Epoch: 007, Loss: 0.6469, Val Acc: 0.6527, Test Acc: 0.6194\n",
      "Seed: 42, Epoch: 008, Loss: 0.6473, Val Acc: 0.6591, Test Acc: 0.6129\n",
      "Seed: 42, Epoch: 009, Loss: 0.6420, Val Acc: 0.6575, Test Acc: 0.6274\n",
      "Seed: 42, Epoch: 010, Loss: 0.6423, Val Acc: 0.6543, Test Acc: 0.6081\n",
      "Seed: 42, Epoch: 011, Loss: 0.6384, Val Acc: 0.6494, Test Acc: 0.6435\n",
      "Seed: 42, Epoch: 012, Loss: 0.6355, Val Acc: 0.6688, Test Acc: 0.6435\n",
      "Seed: 42, Epoch: 013, Loss: 0.6343, Val Acc: 0.6753, Test Acc: 0.6419\n",
      "Seed: 42, Epoch: 014, Loss: 0.6317, Val Acc: 0.6769, Test Acc: 0.6242\n",
      "Seed: 42, Epoch: 015, Loss: 0.6288, Val Acc: 0.6769, Test Acc: 0.6484\n",
      "Seed: 42, Epoch: 016, Loss: 0.6268, Val Acc: 0.6769, Test Acc: 0.6258\n",
      "Seed: 42, Epoch: 017, Loss: 0.6245, Val Acc: 0.6785, Test Acc: 0.6484\n",
      "Seed: 42, Epoch: 018, Loss: 0.6251, Val Acc: 0.6785, Test Acc: 0.6452\n",
      "Seed: 42, Epoch: 019, Loss: 0.6237, Val Acc: 0.6785, Test Acc: 0.6435\n",
      "Seed: 42, Epoch: 020, Loss: 0.6260, Val Acc: 0.6850, Test Acc: 0.6452\n",
      "Seed: 42, Epoch: 021, Loss: 0.6201, Val Acc: 0.6850, Test Acc: 0.6484\n",
      "Seed: 42, Epoch: 022, Loss: 0.6157, Val Acc: 0.6785, Test Acc: 0.6452\n",
      "Seed: 42, Epoch: 023, Loss: 0.6091, Val Acc: 0.6850, Test Acc: 0.6403\n",
      "Seed: 42, Epoch: 024, Loss: 0.6022, Val Acc: 0.6898, Test Acc: 0.6565\n",
      "Seed: 42, Epoch: 025, Loss: 0.5979, Val Acc: 0.6753, Test Acc: 0.6500\n",
      "Seed: 42, Epoch: 026, Loss: 0.5948, Val Acc: 0.7076, Test Acc: 0.6613\n",
      "Seed: 42, Epoch: 027, Loss: 0.5948, Val Acc: 0.6931, Test Acc: 0.6661\n",
      "Seed: 42, Epoch: 028, Loss: 0.5846, Val Acc: 0.6931, Test Acc: 0.6726\n",
      "Seed: 42, Epoch: 029, Loss: 0.5812, Val Acc: 0.6898, Test Acc: 0.6629\n",
      "Seed: 42, Epoch: 030, Loss: 0.5786, Val Acc: 0.7027, Test Acc: 0.6774\n",
      "Seed: 42, Epoch: 031, Loss: 0.5831, Val Acc: 0.6963, Test Acc: 0.6790\n",
      "Seed: 42, Epoch: 032, Loss: 0.5756, Val Acc: 0.6931, Test Acc: 0.6887\n",
      "Seed: 42, Epoch: 033, Loss: 0.5728, Val Acc: 0.7027, Test Acc: 0.6871\n",
      "Seed: 42, Epoch: 034, Loss: 0.5721, Val Acc: 0.6979, Test Acc: 0.6774\n",
      "Seed: 42, Epoch: 035, Loss: 0.5708, Val Acc: 0.7173, Test Acc: 0.6903\n",
      "Seed: 42, Epoch: 036, Loss: 0.5744, Val Acc: 0.6963, Test Acc: 0.6790\n",
      "Seed: 42, Epoch: 037, Loss: 0.5704, Val Acc: 0.7076, Test Acc: 0.6887\n",
      "Seed: 42, Epoch: 038, Loss: 0.5652, Val Acc: 0.7189, Test Acc: 0.6919\n",
      "Seed: 42, Epoch: 039, Loss: 0.5676, Val Acc: 0.6995, Test Acc: 0.6855\n",
      "Seed: 42, Epoch: 040, Loss: 0.5653, Val Acc: 0.7076, Test Acc: 0.7016\n",
      "Seed: 42, Epoch: 041, Loss: 0.5623, Val Acc: 0.7286, Test Acc: 0.6952\n",
      "Seed: 42, Epoch: 042, Loss: 0.5654, Val Acc: 0.6914, Test Acc: 0.6661\n",
      "Seed: 42, Epoch: 043, Loss: 0.5824, Val Acc: 0.7027, Test Acc: 0.6855\n",
      "Seed: 42, Epoch: 044, Loss: 0.5672, Val Acc: 0.7221, Test Acc: 0.6839\n",
      "Seed: 42, Epoch: 045, Loss: 0.5691, Val Acc: 0.7270, Test Acc: 0.6903\n",
      "Seed: 42, Epoch: 046, Loss: 0.5630, Val Acc: 0.7092, Test Acc: 0.6952\n",
      "Seed: 42, Epoch: 047, Loss: 0.5567, Val Acc: 0.7205, Test Acc: 0.7048\n",
      "Seed: 42, Epoch: 048, Loss: 0.5540, Val Acc: 0.7318, Test Acc: 0.7000\n",
      "Seed: 42, Epoch: 049, Loss: 0.5556, Val Acc: 0.7270, Test Acc: 0.7048\n",
      "Seed: 42, Epoch: 050, Loss: 0.5640, Val Acc: 0.7173, Test Acc: 0.6903\n",
      "Seed: 42, Epoch: 051, Loss: 0.5556, Val Acc: 0.7141, Test Acc: 0.6952\n",
      "Seed: 42, Epoch: 052, Loss: 0.5520, Val Acc: 0.7367, Test Acc: 0.6968\n",
      "Seed: 42, Epoch: 053, Loss: 0.5526, Val Acc: 0.7367, Test Acc: 0.7048\n",
      "Seed: 42, Epoch: 054, Loss: 0.5506, Val Acc: 0.7512, Test Acc: 0.6839\n",
      "Seed: 42, Epoch: 055, Loss: 0.5494, Val Acc: 0.7060, Test Acc: 0.6855\n",
      "Seed: 42, Epoch: 056, Loss: 0.5568, Val Acc: 0.6995, Test Acc: 0.6694\n",
      "Seed: 42, Epoch: 057, Loss: 0.5571, Val Acc: 0.7157, Test Acc: 0.7016\n",
      "Seed: 42, Epoch: 058, Loss: 0.5525, Val Acc: 0.7480, Test Acc: 0.7016\n",
      "Seed: 42, Epoch: 059, Loss: 0.5483, Val Acc: 0.7399, Test Acc: 0.6984\n",
      "Seed: 42, Epoch: 060, Loss: 0.5449, Val Acc: 0.7464, Test Acc: 0.6968\n",
      "Seed: 42, Epoch: 061, Loss: 0.5431, Val Acc: 0.7431, Test Acc: 0.6984\n",
      "Seed: 42, Epoch: 062, Loss: 0.5420, Val Acc: 0.7367, Test Acc: 0.6935\n",
      "Seed: 42, Epoch: 063, Loss: 0.5447, Val Acc: 0.7351, Test Acc: 0.7065\n",
      "Seed: 42, Epoch: 064, Loss: 0.5469, Val Acc: 0.7447, Test Acc: 0.6968\n",
      "Seed: 42, Epoch: 065, Loss: 0.5414, Val Acc: 0.7205, Test Acc: 0.6871\n",
      "Seed: 42, Epoch: 066, Loss: 0.5458, Val Acc: 0.7464, Test Acc: 0.6952\n",
      "Seed: 42, Epoch: 067, Loss: 0.5444, Val Acc: 0.7334, Test Acc: 0.7048\n",
      "Seed: 42, Epoch: 068, Loss: 0.5406, Val Acc: 0.7399, Test Acc: 0.7032\n",
      "Seed: 42, Epoch: 069, Loss: 0.5396, Val Acc: 0.7221, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 070, Loss: 0.5413, Val Acc: 0.7108, Test Acc: 0.6726\n",
      "Seed: 42, Epoch: 071, Loss: 0.5449, Val Acc: 0.7302, Test Acc: 0.7016\n",
      "Seed: 42, Epoch: 072, Loss: 0.5378, Val Acc: 0.7367, Test Acc: 0.6935\n",
      "Seed: 42, Epoch: 073, Loss: 0.5359, Val Acc: 0.7496, Test Acc: 0.7032\n",
      "Seed: 42, Epoch: 074, Loss: 0.5359, Val Acc: 0.7399, Test Acc: 0.6968\n",
      "Seed: 42, Epoch: 075, Loss: 0.5434, Val Acc: 0.7318, Test Acc: 0.7097\n",
      "Seed: 42, Epoch: 076, Loss: 0.5412, Val Acc: 0.7464, Test Acc: 0.7032\n",
      "Seed: 42, Epoch: 077, Loss: 0.5386, Val Acc: 0.7318, Test Acc: 0.7032\n",
      "Seed: 42, Epoch: 078, Loss: 0.5420, Val Acc: 0.7302, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 079, Loss: 0.5373, Val Acc: 0.7431, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 080, Loss: 0.5417, Val Acc: 0.7286, Test Acc: 0.7016\n",
      "Seed: 42, Epoch: 081, Loss: 0.5372, Val Acc: 0.7254, Test Acc: 0.6968\n",
      "Seed: 42, Epoch: 082, Loss: 0.5338, Val Acc: 0.7351, Test Acc: 0.7032\n",
      "Seed: 42, Epoch: 083, Loss: 0.5343, Val Acc: 0.7415, Test Acc: 0.7065\n",
      "Seed: 42, Epoch: 084, Loss: 0.5371, Val Acc: 0.7399, Test Acc: 0.6984\n",
      "Seed: 42, Epoch: 085, Loss: 0.5416, Val Acc: 0.7383, Test Acc: 0.7016\n",
      "Seed: 42, Epoch: 086, Loss: 0.5324, Val Acc: 0.7286, Test Acc: 0.6984\n",
      "Seed: 42, Epoch: 087, Loss: 0.5330, Val Acc: 0.7351, Test Acc: 0.6984\n",
      "Seed: 42, Epoch: 088, Loss: 0.5289, Val Acc: 0.7415, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 089, Loss: 0.5301, Val Acc: 0.7399, Test Acc: 0.7113\n",
      "Seed: 42, Epoch: 090, Loss: 0.5320, Val Acc: 0.7447, Test Acc: 0.7065\n",
      "Seed: 42, Epoch: 091, Loss: 0.5311, Val Acc: 0.7383, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 092, Loss: 0.5274, Val Acc: 0.7367, Test Acc: 0.6968\n",
      "Seed: 42, Epoch: 093, Loss: 0.5291, Val Acc: 0.7383, Test Acc: 0.7032\n",
      "Seed: 42, Epoch: 094, Loss: 0.5284, Val Acc: 0.7383, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 095, Loss: 0.5260, Val Acc: 0.7464, Test Acc: 0.7065\n",
      "Seed: 42, Epoch: 096, Loss: 0.5262, Val Acc: 0.7399, Test Acc: 0.7097\n",
      "Seed: 42, Epoch: 097, Loss: 0.5255, Val Acc: 0.7383, Test Acc: 0.6984\n",
      "Seed: 42, Epoch: 098, Loss: 0.5279, Val Acc: 0.7415, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 099, Loss: 0.5252, Val Acc: 0.7367, Test Acc: 0.6984\n",
      "Seed: 42, Epoch: 100, Loss: 0.5278, Val Acc: 0.7512, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 101, Loss: 0.5246, Val Acc: 0.7431, Test Acc: 0.7177\n",
      "Seed: 42, Epoch: 102, Loss: 0.5262, Val Acc: 0.7431, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 103, Loss: 0.5231, Val Acc: 0.7302, Test Acc: 0.7113\n",
      "Seed: 42, Epoch: 104, Loss: 0.5248, Val Acc: 0.7399, Test Acc: 0.7097\n",
      "Seed: 42, Epoch: 105, Loss: 0.5246, Val Acc: 0.7399, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 106, Loss: 0.5315, Val Acc: 0.7270, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 107, Loss: 0.5267, Val Acc: 0.7480, Test Acc: 0.7113\n",
      "Seed: 42, Epoch: 108, Loss: 0.5182, Val Acc: 0.7447, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 109, Loss: 0.5199, Val Acc: 0.7351, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 110, Loss: 0.5268, Val Acc: 0.7447, Test Acc: 0.7032\n",
      "Seed: 42, Epoch: 111, Loss: 0.5205, Val Acc: 0.7270, Test Acc: 0.7016\n",
      "Seed: 42, Epoch: 112, Loss: 0.5294, Val Acc: 0.7415, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 113, Loss: 0.5236, Val Acc: 0.7286, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 114, Loss: 0.5226, Val Acc: 0.7480, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 115, Loss: 0.5148, Val Acc: 0.7447, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 116, Loss: 0.5182, Val Acc: 0.7464, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 117, Loss: 0.5140, Val Acc: 0.7480, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 118, Loss: 0.5144, Val Acc: 0.7383, Test Acc: 0.7274\n",
      "Seed: 42, Epoch: 119, Loss: 0.5140, Val Acc: 0.7334, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 120, Loss: 0.5120, Val Acc: 0.7367, Test Acc: 0.6952\n",
      "Seed: 42, Epoch: 121, Loss: 0.5281, Val Acc: 0.7544, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 122, Loss: 0.5115, Val Acc: 0.7399, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 123, Loss: 0.5126, Val Acc: 0.7447, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 124, Loss: 0.5145, Val Acc: 0.7415, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 125, Loss: 0.5143, Val Acc: 0.7496, Test Acc: 0.7274\n",
      "Seed: 42, Epoch: 126, Loss: 0.5119, Val Acc: 0.7577, Test Acc: 0.7177\n",
      "Seed: 42, Epoch: 127, Loss: 0.5150, Val Acc: 0.7318, Test Acc: 0.7177\n",
      "Seed: 42, Epoch: 128, Loss: 0.5118, Val Acc: 0.7496, Test Acc: 0.7097\n",
      "Seed: 42, Epoch: 129, Loss: 0.5134, Val Acc: 0.7528, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 130, Loss: 0.5089, Val Acc: 0.7334, Test Acc: 0.7000\n",
      "Seed: 42, Epoch: 131, Loss: 0.5175, Val Acc: 0.7286, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 132, Loss: 0.5214, Val Acc: 0.7334, Test Acc: 0.6952\n",
      "Seed: 42, Epoch: 133, Loss: 0.5204, Val Acc: 0.7561, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 134, Loss: 0.5073, Val Acc: 0.7367, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 135, Loss: 0.5137, Val Acc: 0.7544, Test Acc: 0.7097\n",
      "Seed: 42, Epoch: 136, Loss: 0.5186, Val Acc: 0.7464, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 137, Loss: 0.5052, Val Acc: 0.7447, Test Acc: 0.7274\n",
      "Seed: 42, Epoch: 138, Loss: 0.5063, Val Acc: 0.7561, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 139, Loss: 0.5098, Val Acc: 0.7561, Test Acc: 0.7048\n",
      "Seed: 42, Epoch: 140, Loss: 0.5080, Val Acc: 0.7561, Test Acc: 0.7306\n",
      "Seed: 42, Epoch: 141, Loss: 0.5090, Val Acc: 0.7367, Test Acc: 0.6887\n",
      "Seed: 42, Epoch: 142, Loss: 0.5161, Val Acc: 0.7496, Test Acc: 0.7274\n",
      "Seed: 42, Epoch: 143, Loss: 0.5073, Val Acc: 0.7431, Test Acc: 0.7065\n",
      "Seed: 42, Epoch: 144, Loss: 0.5044, Val Acc: 0.7464, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 145, Loss: 0.5060, Val Acc: 0.7286, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 146, Loss: 0.5162, Val Acc: 0.7658, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 147, Loss: 0.5032, Val Acc: 0.7528, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 148, Loss: 0.5038, Val Acc: 0.7528, Test Acc: 0.7113\n",
      "Seed: 42, Epoch: 149, Loss: 0.5012, Val Acc: 0.7593, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 150, Loss: 0.5077, Val Acc: 0.7415, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 151, Loss: 0.5083, Val Acc: 0.7464, Test Acc: 0.6984\n",
      "Seed: 42, Epoch: 152, Loss: 0.5118, Val Acc: 0.7447, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 153, Loss: 0.5016, Val Acc: 0.7447, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 154, Loss: 0.4985, Val Acc: 0.7447, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 155, Loss: 0.4981, Val Acc: 0.7593, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 156, Loss: 0.5165, Val Acc: 0.7512, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 157, Loss: 0.5027, Val Acc: 0.7561, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 158, Loss: 0.4997, Val Acc: 0.7577, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 159, Loss: 0.4965, Val Acc: 0.7609, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 160, Loss: 0.4974, Val Acc: 0.7593, Test Acc: 0.7226\n",
      "Seed: 42, Epoch: 161, Loss: 0.4988, Val Acc: 0.7625, Test Acc: 0.7177\n",
      "Seed: 42, Epoch: 162, Loss: 0.4968, Val Acc: 0.7528, Test Acc: 0.7226\n",
      "Seed: 42, Epoch: 163, Loss: 0.4998, Val Acc: 0.7431, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 164, Loss: 0.5036, Val Acc: 0.7625, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 165, Loss: 0.5001, Val Acc: 0.7351, Test Acc: 0.6968\n",
      "Seed: 42, Epoch: 166, Loss: 0.5034, Val Acc: 0.7480, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 167, Loss: 0.4975, Val Acc: 0.7544, Test Acc: 0.7258\n",
      "Seed: 42, Epoch: 168, Loss: 0.4926, Val Acc: 0.7561, Test Acc: 0.7048\n",
      "Seed: 42, Epoch: 169, Loss: 0.4944, Val Acc: 0.7512, Test Acc: 0.7290\n",
      "Seed: 42, Epoch: 170, Loss: 0.4909, Val Acc: 0.7512, Test Acc: 0.7097\n",
      "Seed: 42, Epoch: 171, Loss: 0.4991, Val Acc: 0.7561, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 172, Loss: 0.4984, Val Acc: 0.7221, Test Acc: 0.6903\n",
      "Seed: 42, Epoch: 173, Loss: 0.5065, Val Acc: 0.7464, Test Acc: 0.7226\n",
      "Seed: 42, Epoch: 174, Loss: 0.5029, Val Acc: 0.7544, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 175, Loss: 0.4985, Val Acc: 0.7367, Test Acc: 0.6952\n",
      "Seed: 42, Epoch: 176, Loss: 0.5153, Val Acc: 0.7415, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 177, Loss: 0.4995, Val Acc: 0.7593, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 178, Loss: 0.4937, Val Acc: 0.7544, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 179, Loss: 0.4914, Val Acc: 0.7334, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 180, Loss: 0.5050, Val Acc: 0.7544, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 181, Loss: 0.5014, Val Acc: 0.7431, Test Acc: 0.7065\n",
      "Seed: 42, Epoch: 182, Loss: 0.4924, Val Acc: 0.7528, Test Acc: 0.7177\n",
      "Seed: 42, Epoch: 183, Loss: 0.4920, Val Acc: 0.7577, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 184, Loss: 0.4876, Val Acc: 0.7593, Test Acc: 0.7323\n",
      "Seed: 42, Epoch: 185, Loss: 0.4890, Val Acc: 0.7480, Test Acc: 0.7048\n",
      "Seed: 42, Epoch: 186, Loss: 0.4941, Val Acc: 0.7480, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 187, Loss: 0.4932, Val Acc: 0.7561, Test Acc: 0.7306\n",
      "Seed: 42, Epoch: 188, Loss: 0.4915, Val Acc: 0.7641, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 189, Loss: 0.4956, Val Acc: 0.7609, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 190, Loss: 0.4896, Val Acc: 0.7577, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 191, Loss: 0.4945, Val Acc: 0.7561, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 192, Loss: 0.4892, Val Acc: 0.7512, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 193, Loss: 0.4902, Val Acc: 0.7609, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 194, Loss: 0.4857, Val Acc: 0.7528, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 195, Loss: 0.4896, Val Acc: 0.7415, Test Acc: 0.7065\n",
      "Seed: 42, Epoch: 196, Loss: 0.4866, Val Acc: 0.7561, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 197, Loss: 0.4854, Val Acc: 0.7447, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 198, Loss: 0.4980, Val Acc: 0.7561, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 199, Loss: 0.4871, Val Acc: 0.7431, Test Acc: 0.7048\n",
      "Seed: 42, Epoch: 200, Loss: 0.4833, Val Acc: 0.7577, Test Acc: 0.7258\n",
      "Seed: 43, Epoch: 001, Loss: 0.6935, Val Acc: 0.5202, Test Acc: 0.5048\n",
      "Seed: 43, Epoch: 002, Loss: 0.6903, Val Acc: 0.5202, Test Acc: 0.5048\n",
      "Seed: 43, Epoch: 003, Loss: 0.6836, Val Acc: 0.5606, Test Acc: 0.5435\n",
      "Seed: 43, Epoch: 004, Loss: 0.6709, Val Acc: 0.6252, Test Acc: 0.6048\n",
      "Seed: 43, Epoch: 005, Loss: 0.6560, Val Acc: 0.6074, Test Acc: 0.6274\n",
      "Seed: 43, Epoch: 006, Loss: 0.6468, Val Acc: 0.6349, Test Acc: 0.6403\n",
      "Seed: 43, Epoch: 007, Loss: 0.6434, Val Acc: 0.6414, Test Acc: 0.6387\n",
      "Seed: 43, Epoch: 008, Loss: 0.6406, Val Acc: 0.6414, Test Acc: 0.6468\n",
      "Seed: 43, Epoch: 009, Loss: 0.6402, Val Acc: 0.6397, Test Acc: 0.6484\n",
      "Seed: 43, Epoch: 010, Loss: 0.6355, Val Acc: 0.6236, Test Acc: 0.6484\n",
      "Seed: 43, Epoch: 011, Loss: 0.6342, Val Acc: 0.6527, Test Acc: 0.6548\n",
      "Seed: 43, Epoch: 012, Loss: 0.6309, Val Acc: 0.6511, Test Acc: 0.6613\n",
      "Seed: 43, Epoch: 013, Loss: 0.6288, Val Acc: 0.6284, Test Acc: 0.6597\n",
      "Seed: 43, Epoch: 014, Loss: 0.6261, Val Acc: 0.6575, Test Acc: 0.6613\n",
      "Seed: 43, Epoch: 015, Loss: 0.6235, Val Acc: 0.6672, Test Acc: 0.6435\n",
      "Seed: 43, Epoch: 016, Loss: 0.6204, Val Acc: 0.6753, Test Acc: 0.6613\n",
      "Seed: 43, Epoch: 017, Loss: 0.6172, Val Acc: 0.6737, Test Acc: 0.6661\n",
      "Seed: 43, Epoch: 018, Loss: 0.6097, Val Acc: 0.6365, Test Acc: 0.6710\n",
      "Seed: 43, Epoch: 019, Loss: 0.6077, Val Acc: 0.6704, Test Acc: 0.6661\n",
      "Seed: 43, Epoch: 020, Loss: 0.6009, Val Acc: 0.6785, Test Acc: 0.6887\n",
      "Seed: 43, Epoch: 021, Loss: 0.5983, Val Acc: 0.6575, Test Acc: 0.6919\n",
      "Seed: 43, Epoch: 022, Loss: 0.5921, Val Acc: 0.6785, Test Acc: 0.6952\n",
      "Seed: 43, Epoch: 023, Loss: 0.5967, Val Acc: 0.6834, Test Acc: 0.6968\n",
      "Seed: 43, Epoch: 024, Loss: 0.5902, Val Acc: 0.6882, Test Acc: 0.6661\n",
      "Seed: 43, Epoch: 025, Loss: 0.5860, Val Acc: 0.6688, Test Acc: 0.7048\n",
      "Seed: 43, Epoch: 026, Loss: 0.5849, Val Acc: 0.6817, Test Acc: 0.7081\n",
      "Seed: 43, Epoch: 027, Loss: 0.5814, Val Acc: 0.6947, Test Acc: 0.7177\n",
      "Seed: 43, Epoch: 028, Loss: 0.5913, Val Acc: 0.6672, Test Acc: 0.7097\n",
      "Seed: 43, Epoch: 029, Loss: 0.5924, Val Acc: 0.6462, Test Acc: 0.6968\n",
      "Seed: 43, Epoch: 030, Loss: 0.5921, Val Acc: 0.6462, Test Acc: 0.7016\n",
      "Seed: 43, Epoch: 031, Loss: 0.5875, Val Acc: 0.6446, Test Acc: 0.6903\n",
      "Seed: 43, Epoch: 032, Loss: 0.5954, Val Acc: 0.6607, Test Acc: 0.7113\n",
      "Seed: 43, Epoch: 033, Loss: 0.5818, Val Acc: 0.6446, Test Acc: 0.7065\n",
      "Seed: 43, Epoch: 034, Loss: 0.5863, Val Acc: 0.6624, Test Acc: 0.7081\n",
      "Seed: 43, Epoch: 035, Loss: 0.5734, Val Acc: 0.6931, Test Acc: 0.7226\n",
      "Seed: 43, Epoch: 036, Loss: 0.5731, Val Acc: 0.7011, Test Acc: 0.7161\n",
      "Seed: 43, Epoch: 037, Loss: 0.5729, Val Acc: 0.6979, Test Acc: 0.7081\n",
      "Seed: 43, Epoch: 038, Loss: 0.5733, Val Acc: 0.6914, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 039, Loss: 0.5730, Val Acc: 0.7011, Test Acc: 0.7048\n",
      "Seed: 43, Epoch: 040, Loss: 0.5803, Val Acc: 0.7044, Test Acc: 0.7048\n",
      "Seed: 43, Epoch: 041, Loss: 0.5688, Val Acc: 0.6866, Test Acc: 0.7145\n",
      "Seed: 43, Epoch: 042, Loss: 0.5701, Val Acc: 0.6995, Test Acc: 0.7113\n",
      "Seed: 43, Epoch: 043, Loss: 0.5696, Val Acc: 0.6995, Test Acc: 0.7065\n",
      "Seed: 43, Epoch: 044, Loss: 0.5690, Val Acc: 0.7011, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 045, Loss: 0.5685, Val Acc: 0.6914, Test Acc: 0.7274\n",
      "Seed: 43, Epoch: 046, Loss: 0.5701, Val Acc: 0.6995, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 047, Loss: 0.5658, Val Acc: 0.6995, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 048, Loss: 0.5631, Val Acc: 0.6963, Test Acc: 0.7081\n",
      "Seed: 43, Epoch: 049, Loss: 0.5635, Val Acc: 0.6979, Test Acc: 0.7274\n",
      "Seed: 43, Epoch: 050, Loss: 0.5624, Val Acc: 0.6817, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 051, Loss: 0.5678, Val Acc: 0.6753, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 052, Loss: 0.5662, Val Acc: 0.7027, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 053, Loss: 0.5619, Val Acc: 0.7076, Test Acc: 0.7145\n",
      "Seed: 43, Epoch: 054, Loss: 0.5597, Val Acc: 0.7044, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 055, Loss: 0.5609, Val Acc: 0.7027, Test Acc: 0.7274\n",
      "Seed: 43, Epoch: 056, Loss: 0.5585, Val Acc: 0.7076, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 057, Loss: 0.5576, Val Acc: 0.6882, Test Acc: 0.7339\n",
      "Seed: 43, Epoch: 058, Loss: 0.5569, Val Acc: 0.7011, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 059, Loss: 0.5555, Val Acc: 0.7011, Test Acc: 0.7129\n",
      "Seed: 43, Epoch: 060, Loss: 0.5568, Val Acc: 0.6963, Test Acc: 0.7339\n",
      "Seed: 43, Epoch: 061, Loss: 0.5574, Val Acc: 0.6995, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 062, Loss: 0.5524, Val Acc: 0.7027, Test Acc: 0.7339\n",
      "Seed: 43, Epoch: 063, Loss: 0.5524, Val Acc: 0.6995, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 064, Loss: 0.5535, Val Acc: 0.6995, Test Acc: 0.7226\n",
      "Seed: 43, Epoch: 065, Loss: 0.5536, Val Acc: 0.7027, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 066, Loss: 0.5511, Val Acc: 0.7027, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 067, Loss: 0.5534, Val Acc: 0.6995, Test Acc: 0.7210\n",
      "Seed: 43, Epoch: 068, Loss: 0.5499, Val Acc: 0.7011, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 069, Loss: 0.5489, Val Acc: 0.7044, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 070, Loss: 0.5492, Val Acc: 0.6963, Test Acc: 0.7210\n",
      "Seed: 43, Epoch: 071, Loss: 0.5536, Val Acc: 0.7011, Test Acc: 0.7274\n",
      "Seed: 43, Epoch: 072, Loss: 0.5604, Val Acc: 0.6769, Test Acc: 0.7258\n",
      "Seed: 43, Epoch: 073, Loss: 0.5606, Val Acc: 0.7108, Test Acc: 0.7129\n",
      "Seed: 43, Epoch: 074, Loss: 0.5504, Val Acc: 0.6979, Test Acc: 0.7371\n",
      "Seed: 43, Epoch: 075, Loss: 0.5484, Val Acc: 0.7027, Test Acc: 0.7194\n",
      "Seed: 43, Epoch: 076, Loss: 0.5441, Val Acc: 0.7011, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 077, Loss: 0.5455, Val Acc: 0.6995, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 078, Loss: 0.5426, Val Acc: 0.6995, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 079, Loss: 0.5434, Val Acc: 0.6995, Test Acc: 0.7258\n",
      "Seed: 43, Epoch: 080, Loss: 0.5463, Val Acc: 0.7027, Test Acc: 0.7258\n",
      "Seed: 43, Epoch: 081, Loss: 0.5403, Val Acc: 0.7060, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 082, Loss: 0.5409, Val Acc: 0.6947, Test Acc: 0.7097\n",
      "Seed: 43, Epoch: 083, Loss: 0.5462, Val Acc: 0.6898, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 084, Loss: 0.5397, Val Acc: 0.6995, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 085, Loss: 0.5425, Val Acc: 0.6898, Test Acc: 0.7339\n",
      "Seed: 43, Epoch: 086, Loss: 0.5453, Val Acc: 0.6931, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 087, Loss: 0.5408, Val Acc: 0.7044, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 088, Loss: 0.5371, Val Acc: 0.7092, Test Acc: 0.7371\n",
      "Seed: 43, Epoch: 089, Loss: 0.5429, Val Acc: 0.6769, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 090, Loss: 0.5493, Val Acc: 0.7044, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 091, Loss: 0.5413, Val Acc: 0.6931, Test Acc: 0.7258\n",
      "Seed: 43, Epoch: 092, Loss: 0.5432, Val Acc: 0.6979, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 093, Loss: 0.5393, Val Acc: 0.7076, Test Acc: 0.7226\n",
      "Seed: 43, Epoch: 094, Loss: 0.5404, Val Acc: 0.6882, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 095, Loss: 0.5394, Val Acc: 0.7060, Test Acc: 0.7403\n",
      "Seed: 43, Epoch: 096, Loss: 0.5373, Val Acc: 0.6817, Test Acc: 0.7339\n",
      "Seed: 43, Epoch: 097, Loss: 0.5547, Val Acc: 0.7044, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 098, Loss: 0.5386, Val Acc: 0.7060, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 099, Loss: 0.5387, Val Acc: 0.7044, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 100, Loss: 0.5354, Val Acc: 0.6801, Test Acc: 0.7339\n",
      "Seed: 43, Epoch: 101, Loss: 0.5344, Val Acc: 0.6931, Test Acc: 0.7097\n",
      "Seed: 43, Epoch: 102, Loss: 0.5489, Val Acc: 0.7044, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 103, Loss: 0.5328, Val Acc: 0.6947, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 104, Loss: 0.5339, Val Acc: 0.7076, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 105, Loss: 0.5326, Val Acc: 0.7060, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 106, Loss: 0.5379, Val Acc: 0.7044, Test Acc: 0.7403\n",
      "Seed: 43, Epoch: 107, Loss: 0.5314, Val Acc: 0.6963, Test Acc: 0.7097\n",
      "Seed: 43, Epoch: 108, Loss: 0.5383, Val Acc: 0.6898, Test Acc: 0.7371\n",
      "Seed: 43, Epoch: 109, Loss: 0.5423, Val Acc: 0.7011, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 110, Loss: 0.5416, Val Acc: 0.7011, Test Acc: 0.7210\n",
      "Seed: 43, Epoch: 111, Loss: 0.5293, Val Acc: 0.7060, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 112, Loss: 0.5314, Val Acc: 0.7108, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 113, Loss: 0.5344, Val Acc: 0.6963, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 114, Loss: 0.5331, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 115, Loss: 0.5305, Val Acc: 0.7060, Test Acc: 0.7274\n",
      "Seed: 43, Epoch: 116, Loss: 0.5326, Val Acc: 0.6882, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 117, Loss: 0.5297, Val Acc: 0.7108, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 118, Loss: 0.5290, Val Acc: 0.7060, Test Acc: 0.7403\n",
      "Seed: 43, Epoch: 119, Loss: 0.5299, Val Acc: 0.7011, Test Acc: 0.7177\n",
      "Seed: 43, Epoch: 120, Loss: 0.5287, Val Acc: 0.7141, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 121, Loss: 0.5337, Val Acc: 0.7044, Test Acc: 0.7435\n",
      "Seed: 43, Epoch: 122, Loss: 0.5256, Val Acc: 0.6914, Test Acc: 0.6952\n",
      "Seed: 43, Epoch: 123, Loss: 0.5517, Val Acc: 0.7189, Test Acc: 0.7452\n",
      "Seed: 43, Epoch: 124, Loss: 0.5303, Val Acc: 0.6866, Test Acc: 0.7339\n",
      "Seed: 43, Epoch: 125, Loss: 0.5296, Val Acc: 0.7092, Test Acc: 0.7403\n",
      "Seed: 43, Epoch: 126, Loss: 0.5315, Val Acc: 0.6931, Test Acc: 0.7000\n",
      "Seed: 43, Epoch: 127, Loss: 0.5396, Val Acc: 0.7027, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 128, Loss: 0.5421, Val Acc: 0.7076, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 129, Loss: 0.5311, Val Acc: 0.7092, Test Acc: 0.7452\n",
      "Seed: 43, Epoch: 130, Loss: 0.5287, Val Acc: 0.7027, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 131, Loss: 0.5323, Val Acc: 0.6801, Test Acc: 0.7113\n",
      "Seed: 43, Epoch: 132, Loss: 0.5333, Val Acc: 0.7141, Test Acc: 0.7435\n",
      "Seed: 43, Epoch: 133, Loss: 0.5242, Val Acc: 0.7092, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 134, Loss: 0.5326, Val Acc: 0.7092, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 135, Loss: 0.5299, Val Acc: 0.7044, Test Acc: 0.7468\n",
      "Seed: 43, Epoch: 136, Loss: 0.5251, Val Acc: 0.7092, Test Acc: 0.7371\n",
      "Seed: 43, Epoch: 137, Loss: 0.5268, Val Acc: 0.6963, Test Acc: 0.7113\n",
      "Seed: 43, Epoch: 138, Loss: 0.5244, Val Acc: 0.7044, Test Acc: 0.7532\n",
      "Seed: 43, Epoch: 139, Loss: 0.5235, Val Acc: 0.7060, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 140, Loss: 0.5237, Val Acc: 0.7044, Test Acc: 0.7435\n",
      "Seed: 43, Epoch: 141, Loss: 0.5240, Val Acc: 0.7060, Test Acc: 0.7403\n",
      "Seed: 43, Epoch: 142, Loss: 0.5211, Val Acc: 0.7060, Test Acc: 0.7484\n",
      "Seed: 43, Epoch: 143, Loss: 0.5197, Val Acc: 0.6995, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 144, Loss: 0.5175, Val Acc: 0.6979, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 145, Loss: 0.5194, Val Acc: 0.7060, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 146, Loss: 0.5183, Val Acc: 0.7060, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 147, Loss: 0.5189, Val Acc: 0.6834, Test Acc: 0.7065\n",
      "Seed: 43, Epoch: 148, Loss: 0.5295, Val Acc: 0.7092, Test Acc: 0.7435\n",
      "Seed: 43, Epoch: 149, Loss: 0.5261, Val Acc: 0.6511, Test Acc: 0.7081\n",
      "Seed: 43, Epoch: 150, Loss: 0.5343, Val Acc: 0.7060, Test Acc: 0.7452\n",
      "Seed: 43, Epoch: 151, Loss: 0.5200, Val Acc: 0.7027, Test Acc: 0.7468\n",
      "Seed: 43, Epoch: 152, Loss: 0.5166, Val Acc: 0.7092, Test Acc: 0.7484\n",
      "Seed: 43, Epoch: 153, Loss: 0.5181, Val Acc: 0.7027, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 154, Loss: 0.5173, Val Acc: 0.7060, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 155, Loss: 0.5167, Val Acc: 0.7060, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 156, Loss: 0.5241, Val Acc: 0.7044, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 157, Loss: 0.5141, Val Acc: 0.7060, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 158, Loss: 0.5180, Val Acc: 0.6979, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 159, Loss: 0.5200, Val Acc: 0.6963, Test Acc: 0.7194\n",
      "Seed: 43, Epoch: 160, Loss: 0.5238, Val Acc: 0.7011, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 161, Loss: 0.5154, Val Acc: 0.7141, Test Acc: 0.7435\n",
      "Seed: 43, Epoch: 162, Loss: 0.5161, Val Acc: 0.7027, Test Acc: 0.7258\n",
      "Seed: 43, Epoch: 163, Loss: 0.5229, Val Acc: 0.7011, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 164, Loss: 0.5120, Val Acc: 0.7060, Test Acc: 0.7403\n",
      "Seed: 43, Epoch: 165, Loss: 0.5121, Val Acc: 0.7027, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 166, Loss: 0.5329, Val Acc: 0.6995, Test Acc: 0.7339\n",
      "Seed: 43, Epoch: 167, Loss: 0.5263, Val Acc: 0.7011, Test Acc: 0.7339\n",
      "Seed: 43, Epoch: 168, Loss: 0.5264, Val Acc: 0.6914, Test Acc: 0.7065\n",
      "Seed: 43, Epoch: 169, Loss: 0.5319, Val Acc: 0.7044, Test Acc: 0.7452\n",
      "Seed: 43, Epoch: 170, Loss: 0.5219, Val Acc: 0.6688, Test Acc: 0.7145\n",
      "Seed: 43, Epoch: 171, Loss: 0.5174, Val Acc: 0.7076, Test Acc: 0.7468\n",
      "Seed: 43, Epoch: 172, Loss: 0.5208, Val Acc: 0.6979, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 173, Loss: 0.5155, Val Acc: 0.7092, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 174, Loss: 0.5098, Val Acc: 0.7060, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 175, Loss: 0.5133, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 176, Loss: 0.5089, Val Acc: 0.7060, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 177, Loss: 0.5098, Val Acc: 0.7011, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 178, Loss: 0.5139, Val Acc: 0.6817, Test Acc: 0.7032\n",
      "Seed: 43, Epoch: 179, Loss: 0.5210, Val Acc: 0.7060, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 180, Loss: 0.5141, Val Acc: 0.6979, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 181, Loss: 0.5122, Val Acc: 0.7027, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 182, Loss: 0.5090, Val Acc: 0.7076, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 183, Loss: 0.5171, Val Acc: 0.6995, Test Acc: 0.7435\n",
      "Seed: 43, Epoch: 184, Loss: 0.5138, Val Acc: 0.6979, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 185, Loss: 0.5083, Val Acc: 0.7092, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 186, Loss: 0.5093, Val Acc: 0.7044, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 187, Loss: 0.5103, Val Acc: 0.6931, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 188, Loss: 0.5070, Val Acc: 0.7044, Test Acc: 0.7403\n",
      "Seed: 43, Epoch: 189, Loss: 0.5136, Val Acc: 0.6963, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 190, Loss: 0.5118, Val Acc: 0.7076, Test Acc: 0.7484\n",
      "Seed: 43, Epoch: 191, Loss: 0.5057, Val Acc: 0.7141, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 192, Loss: 0.5075, Val Acc: 0.7060, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 193, Loss: 0.5088, Val Acc: 0.6898, Test Acc: 0.7403\n",
      "Seed: 43, Epoch: 194, Loss: 0.5071, Val Acc: 0.6947, Test Acc: 0.7371\n",
      "Seed: 43, Epoch: 195, Loss: 0.5071, Val Acc: 0.7027, Test Acc: 0.7468\n",
      "Seed: 43, Epoch: 196, Loss: 0.5088, Val Acc: 0.6979, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 197, Loss: 0.5121, Val Acc: 0.6575, Test Acc: 0.7065\n",
      "Seed: 43, Epoch: 198, Loss: 0.5298, Val Acc: 0.6979, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 199, Loss: 0.5222, Val Acc: 0.6979, Test Acc: 0.7194\n",
      "Seed: 43, Epoch: 200, Loss: 0.5169, Val Acc: 0.7060, Test Acc: 0.7339\n",
      "Seed: 44, Epoch: 001, Loss: 0.6918, Val Acc: 0.4895, Test Acc: 0.5145\n",
      "Seed: 44, Epoch: 002, Loss: 0.6878, Val Acc: 0.4911, Test Acc: 0.5145\n",
      "Seed: 44, Epoch: 003, Loss: 0.6813, Val Acc: 0.5525, Test Acc: 0.5839\n",
      "Seed: 44, Epoch: 004, Loss: 0.6697, Val Acc: 0.6026, Test Acc: 0.6161\n",
      "Seed: 44, Epoch: 005, Loss: 0.6575, Val Acc: 0.6204, Test Acc: 0.6387\n",
      "Seed: 44, Epoch: 006, Loss: 0.6492, Val Acc: 0.6220, Test Acc: 0.6565\n",
      "Seed: 44, Epoch: 007, Loss: 0.6445, Val Acc: 0.6236, Test Acc: 0.6629\n",
      "Seed: 44, Epoch: 008, Loss: 0.6430, Val Acc: 0.6155, Test Acc: 0.6758\n",
      "Seed: 44, Epoch: 009, Loss: 0.6381, Val Acc: 0.6187, Test Acc: 0.6613\n",
      "Seed: 44, Epoch: 010, Loss: 0.6351, Val Acc: 0.6187, Test Acc: 0.6774\n",
      "Seed: 44, Epoch: 011, Loss: 0.6336, Val Acc: 0.6300, Test Acc: 0.6726\n",
      "Seed: 44, Epoch: 012, Loss: 0.6307, Val Acc: 0.6220, Test Acc: 0.6742\n",
      "Seed: 44, Epoch: 013, Loss: 0.6290, Val Acc: 0.6317, Test Acc: 0.6710\n",
      "Seed: 44, Epoch: 014, Loss: 0.6248, Val Acc: 0.6252, Test Acc: 0.6339\n",
      "Seed: 44, Epoch: 015, Loss: 0.6279, Val Acc: 0.6430, Test Acc: 0.6871\n",
      "Seed: 44, Epoch: 016, Loss: 0.6183, Val Acc: 0.6430, Test Acc: 0.6968\n",
      "Seed: 44, Epoch: 017, Loss: 0.6174, Val Acc: 0.6478, Test Acc: 0.6823\n",
      "Seed: 44, Epoch: 018, Loss: 0.6107, Val Acc: 0.6543, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 019, Loss: 0.6044, Val Acc: 0.6656, Test Acc: 0.6823\n",
      "Seed: 44, Epoch: 020, Loss: 0.6029, Val Acc: 0.6494, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 021, Loss: 0.5951, Val Acc: 0.6511, Test Acc: 0.7048\n",
      "Seed: 44, Epoch: 022, Loss: 0.5960, Val Acc: 0.6704, Test Acc: 0.7081\n",
      "Seed: 44, Epoch: 023, Loss: 0.5904, Val Acc: 0.6640, Test Acc: 0.6903\n",
      "Seed: 44, Epoch: 024, Loss: 0.5865, Val Acc: 0.6640, Test Acc: 0.7081\n",
      "Seed: 44, Epoch: 025, Loss: 0.5820, Val Acc: 0.6624, Test Acc: 0.7065\n",
      "Seed: 44, Epoch: 026, Loss: 0.5821, Val Acc: 0.6688, Test Acc: 0.7210\n",
      "Seed: 44, Epoch: 027, Loss: 0.5830, Val Acc: 0.6721, Test Acc: 0.7113\n",
      "Seed: 44, Epoch: 028, Loss: 0.5753, Val Acc: 0.6834, Test Acc: 0.7145\n",
      "Seed: 44, Epoch: 029, Loss: 0.5744, Val Acc: 0.6737, Test Acc: 0.7129\n",
      "Seed: 44, Epoch: 030, Loss: 0.5724, Val Acc: 0.6785, Test Acc: 0.7145\n",
      "Seed: 44, Epoch: 031, Loss: 0.5717, Val Acc: 0.6817, Test Acc: 0.7177\n",
      "Seed: 44, Epoch: 032, Loss: 0.5687, Val Acc: 0.6737, Test Acc: 0.7210\n",
      "Seed: 44, Epoch: 033, Loss: 0.5677, Val Acc: 0.6850, Test Acc: 0.7274\n",
      "Seed: 44, Epoch: 034, Loss: 0.5737, Val Acc: 0.6672, Test Acc: 0.7161\n",
      "Seed: 44, Epoch: 035, Loss: 0.5670, Val Acc: 0.6737, Test Acc: 0.7161\n",
      "Seed: 44, Epoch: 036, Loss: 0.5641, Val Acc: 0.6801, Test Acc: 0.7226\n",
      "Seed: 44, Epoch: 037, Loss: 0.5645, Val Acc: 0.6769, Test Acc: 0.7194\n",
      "Seed: 44, Epoch: 038, Loss: 0.5654, Val Acc: 0.6817, Test Acc: 0.7274\n",
      "Seed: 44, Epoch: 039, Loss: 0.5649, Val Acc: 0.6559, Test Acc: 0.6903\n",
      "Seed: 44, Epoch: 040, Loss: 0.5677, Val Acc: 0.6801, Test Acc: 0.7290\n",
      "Seed: 44, Epoch: 041, Loss: 0.5629, Val Acc: 0.6850, Test Acc: 0.7258\n",
      "Seed: 44, Epoch: 042, Loss: 0.5610, Val Acc: 0.6866, Test Acc: 0.7242\n",
      "Seed: 44, Epoch: 043, Loss: 0.5696, Val Acc: 0.6801, Test Acc: 0.7274\n",
      "Seed: 44, Epoch: 044, Loss: 0.5622, Val Acc: 0.6834, Test Acc: 0.7242\n",
      "Seed: 44, Epoch: 045, Loss: 0.5604, Val Acc: 0.6688, Test Acc: 0.7177\n",
      "Seed: 44, Epoch: 046, Loss: 0.5649, Val Acc: 0.6898, Test Acc: 0.7194\n",
      "Seed: 44, Epoch: 047, Loss: 0.5628, Val Acc: 0.6430, Test Acc: 0.6887\n",
      "Seed: 44, Epoch: 048, Loss: 0.5669, Val Acc: 0.6914, Test Acc: 0.7323\n",
      "Seed: 44, Epoch: 049, Loss: 0.5731, Val Acc: 0.6931, Test Acc: 0.7290\n",
      "Seed: 44, Epoch: 050, Loss: 0.5595, Val Acc: 0.6898, Test Acc: 0.7226\n",
      "Seed: 44, Epoch: 051, Loss: 0.5612, Val Acc: 0.6914, Test Acc: 0.7258\n",
      "Seed: 44, Epoch: 052, Loss: 0.5546, Val Acc: 0.6850, Test Acc: 0.7274\n",
      "Seed: 44, Epoch: 053, Loss: 0.5535, Val Acc: 0.6947, Test Acc: 0.7274\n",
      "Seed: 44, Epoch: 054, Loss: 0.5678, Val Acc: 0.6656, Test Acc: 0.7097\n",
      "Seed: 44, Epoch: 055, Loss: 0.5620, Val Acc: 0.6817, Test Acc: 0.7194\n",
      "Seed: 44, Epoch: 056, Loss: 0.5600, Val Acc: 0.6914, Test Acc: 0.7306\n",
      "Seed: 44, Epoch: 057, Loss: 0.5537, Val Acc: 0.6624, Test Acc: 0.7129\n",
      "Seed: 44, Epoch: 058, Loss: 0.5575, Val Acc: 0.6947, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 059, Loss: 0.5570, Val Acc: 0.6898, Test Acc: 0.7323\n",
      "Seed: 44, Epoch: 060, Loss: 0.5554, Val Acc: 0.6801, Test Acc: 0.7210\n",
      "Seed: 44, Epoch: 061, Loss: 0.5594, Val Acc: 0.6963, Test Acc: 0.7290\n",
      "Seed: 44, Epoch: 062, Loss: 0.5495, Val Acc: 0.6947, Test Acc: 0.7274\n",
      "Seed: 44, Epoch: 063, Loss: 0.5483, Val Acc: 0.6995, Test Acc: 0.7323\n",
      "Seed: 44, Epoch: 064, Loss: 0.5484, Val Acc: 0.6947, Test Acc: 0.7323\n",
      "Seed: 44, Epoch: 065, Loss: 0.5521, Val Acc: 0.6963, Test Acc: 0.7339\n",
      "Seed: 44, Epoch: 066, Loss: 0.5504, Val Acc: 0.6979, Test Acc: 0.7323\n",
      "Seed: 44, Epoch: 067, Loss: 0.5475, Val Acc: 0.7011, Test Acc: 0.7403\n",
      "Seed: 44, Epoch: 068, Loss: 0.5462, Val Acc: 0.6931, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 069, Loss: 0.5466, Val Acc: 0.6866, Test Acc: 0.7323\n",
      "Seed: 44, Epoch: 070, Loss: 0.5491, Val Acc: 0.6979, Test Acc: 0.7403\n",
      "Seed: 44, Epoch: 071, Loss: 0.5472, Val Acc: 0.6866, Test Acc: 0.7161\n",
      "Seed: 44, Epoch: 072, Loss: 0.5563, Val Acc: 0.6979, Test Acc: 0.7419\n",
      "Seed: 44, Epoch: 073, Loss: 0.5491, Val Acc: 0.7092, Test Acc: 0.7403\n",
      "Seed: 44, Epoch: 074, Loss: 0.5437, Val Acc: 0.7060, Test Acc: 0.7274\n",
      "Seed: 44, Epoch: 075, Loss: 0.5438, Val Acc: 0.6801, Test Acc: 0.7194\n",
      "Seed: 44, Epoch: 076, Loss: 0.5473, Val Acc: 0.7011, Test Acc: 0.7274\n",
      "Seed: 44, Epoch: 077, Loss: 0.5435, Val Acc: 0.6834, Test Acc: 0.7194\n",
      "Seed: 44, Epoch: 078, Loss: 0.5563, Val Acc: 0.7011, Test Acc: 0.7323\n",
      "Seed: 44, Epoch: 079, Loss: 0.5431, Val Acc: 0.6914, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 080, Loss: 0.5450, Val Acc: 0.6931, Test Acc: 0.7355\n",
      "Seed: 44, Epoch: 081, Loss: 0.5450, Val Acc: 0.6931, Test Acc: 0.7355\n",
      "Seed: 44, Epoch: 082, Loss: 0.5543, Val Acc: 0.7027, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 083, Loss: 0.5414, Val Acc: 0.7076, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 084, Loss: 0.5464, Val Acc: 0.6914, Test Acc: 0.7419\n",
      "Seed: 44, Epoch: 085, Loss: 0.5416, Val Acc: 0.7044, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 086, Loss: 0.5445, Val Acc: 0.7060, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 087, Loss: 0.5421, Val Acc: 0.7044, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 088, Loss: 0.5429, Val Acc: 0.7044, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 089, Loss: 0.5386, Val Acc: 0.6882, Test Acc: 0.7274\n",
      "Seed: 44, Epoch: 090, Loss: 0.5459, Val Acc: 0.7060, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 091, Loss: 0.5414, Val Acc: 0.7076, Test Acc: 0.7468\n",
      "Seed: 44, Epoch: 092, Loss: 0.5426, Val Acc: 0.6850, Test Acc: 0.7323\n",
      "Seed: 44, Epoch: 093, Loss: 0.5432, Val Acc: 0.7076, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 094, Loss: 0.5433, Val Acc: 0.6882, Test Acc: 0.7242\n",
      "Seed: 44, Epoch: 095, Loss: 0.5405, Val Acc: 0.6931, Test Acc: 0.7274\n",
      "Seed: 44, Epoch: 096, Loss: 0.5510, Val Acc: 0.7011, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 097, Loss: 0.5413, Val Acc: 0.6947, Test Acc: 0.7355\n",
      "Seed: 44, Epoch: 098, Loss: 0.5385, Val Acc: 0.7060, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 099, Loss: 0.5366, Val Acc: 0.7076, Test Acc: 0.7468\n",
      "Seed: 44, Epoch: 100, Loss: 0.5372, Val Acc: 0.7189, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 101, Loss: 0.5349, Val Acc: 0.7076, Test Acc: 0.7468\n",
      "Seed: 44, Epoch: 102, Loss: 0.5336, Val Acc: 0.7108, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 103, Loss: 0.5333, Val Acc: 0.7011, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 104, Loss: 0.5367, Val Acc: 0.7027, Test Acc: 0.7355\n",
      "Seed: 44, Epoch: 105, Loss: 0.5393, Val Acc: 0.6979, Test Acc: 0.7161\n",
      "Seed: 44, Epoch: 106, Loss: 0.5406, Val Acc: 0.7189, Test Acc: 0.7468\n",
      "Seed: 44, Epoch: 107, Loss: 0.5401, Val Acc: 0.7141, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 108, Loss: 0.5476, Val Acc: 0.7173, Test Acc: 0.7548\n",
      "Seed: 44, Epoch: 109, Loss: 0.5424, Val Acc: 0.7141, Test Acc: 0.7419\n",
      "Seed: 44, Epoch: 110, Loss: 0.5433, Val Acc: 0.6850, Test Acc: 0.7210\n",
      "Seed: 44, Epoch: 111, Loss: 0.5446, Val Acc: 0.7157, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 112, Loss: 0.5343, Val Acc: 0.7076, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 113, Loss: 0.5316, Val Acc: 0.7141, Test Acc: 0.7306\n",
      "Seed: 44, Epoch: 114, Loss: 0.5331, Val Acc: 0.7124, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 115, Loss: 0.5309, Val Acc: 0.7141, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 116, Loss: 0.5313, Val Acc: 0.7092, Test Acc: 0.7403\n",
      "Seed: 44, Epoch: 117, Loss: 0.5347, Val Acc: 0.7108, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 118, Loss: 0.5319, Val Acc: 0.7124, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 119, Loss: 0.5328, Val Acc: 0.7221, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 120, Loss: 0.5279, Val Acc: 0.7124, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 121, Loss: 0.5301, Val Acc: 0.7157, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 122, Loss: 0.5297, Val Acc: 0.7205, Test Acc: 0.7548\n",
      "Seed: 44, Epoch: 123, Loss: 0.5271, Val Acc: 0.7189, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 124, Loss: 0.5303, Val Acc: 0.7076, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 125, Loss: 0.5276, Val Acc: 0.7124, Test Acc: 0.7468\n",
      "Seed: 44, Epoch: 126, Loss: 0.5283, Val Acc: 0.7254, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 127, Loss: 0.5283, Val Acc: 0.7124, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 128, Loss: 0.5299, Val Acc: 0.7141, Test Acc: 0.7548\n",
      "Seed: 44, Epoch: 129, Loss: 0.5269, Val Acc: 0.7237, Test Acc: 0.7581\n",
      "Seed: 44, Epoch: 130, Loss: 0.5281, Val Acc: 0.7173, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 131, Loss: 0.5312, Val Acc: 0.7108, Test Acc: 0.7403\n",
      "Seed: 44, Epoch: 132, Loss: 0.5420, Val Acc: 0.7060, Test Acc: 0.7290\n",
      "Seed: 44, Epoch: 133, Loss: 0.5281, Val Acc: 0.7189, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 134, Loss: 0.5251, Val Acc: 0.7141, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 135, Loss: 0.5228, Val Acc: 0.7108, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 136, Loss: 0.5264, Val Acc: 0.7189, Test Acc: 0.7581\n",
      "Seed: 44, Epoch: 137, Loss: 0.5345, Val Acc: 0.7302, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 138, Loss: 0.5272, Val Acc: 0.7124, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 139, Loss: 0.5243, Val Acc: 0.7254, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 140, Loss: 0.5255, Val Acc: 0.7189, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 141, Loss: 0.5309, Val Acc: 0.7221, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 142, Loss: 0.5228, Val Acc: 0.7221, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 143, Loss: 0.5220, Val Acc: 0.7205, Test Acc: 0.7581\n",
      "Seed: 44, Epoch: 144, Loss: 0.5219, Val Acc: 0.6898, Test Acc: 0.7242\n",
      "Seed: 44, Epoch: 145, Loss: 0.5326, Val Acc: 0.7334, Test Acc: 0.7645\n",
      "Seed: 44, Epoch: 146, Loss: 0.5198, Val Acc: 0.7270, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 147, Loss: 0.5200, Val Acc: 0.7334, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 148, Loss: 0.5219, Val Acc: 0.7221, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 149, Loss: 0.5196, Val Acc: 0.7270, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 150, Loss: 0.5166, Val Acc: 0.7318, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 151, Loss: 0.5152, Val Acc: 0.7157, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 152, Loss: 0.5161, Val Acc: 0.7254, Test Acc: 0.7581\n",
      "Seed: 44, Epoch: 153, Loss: 0.5143, Val Acc: 0.7205, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 154, Loss: 0.5156, Val Acc: 0.7367, Test Acc: 0.7581\n",
      "Seed: 44, Epoch: 155, Loss: 0.5171, Val Acc: 0.7221, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 156, Loss: 0.5191, Val Acc: 0.7108, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 157, Loss: 0.5272, Val Acc: 0.7318, Test Acc: 0.7645\n",
      "Seed: 44, Epoch: 158, Loss: 0.5216, Val Acc: 0.7302, Test Acc: 0.7548\n",
      "Seed: 44, Epoch: 159, Loss: 0.5156, Val Acc: 0.7318, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 160, Loss: 0.5153, Val Acc: 0.7334, Test Acc: 0.7661\n",
      "Seed: 44, Epoch: 161, Loss: 0.5140, Val Acc: 0.7318, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 162, Loss: 0.5151, Val Acc: 0.7270, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 163, Loss: 0.5273, Val Acc: 0.7367, Test Acc: 0.7581\n",
      "Seed: 44, Epoch: 164, Loss: 0.5152, Val Acc: 0.7189, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 165, Loss: 0.5135, Val Acc: 0.7189, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 166, Loss: 0.5125, Val Acc: 0.7351, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 167, Loss: 0.5189, Val Acc: 0.7270, Test Acc: 0.7548\n",
      "Seed: 44, Epoch: 168, Loss: 0.5255, Val Acc: 0.7254, Test Acc: 0.7581\n",
      "Seed: 44, Epoch: 169, Loss: 0.5159, Val Acc: 0.7334, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 170, Loss: 0.5153, Val Acc: 0.7383, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 171, Loss: 0.5208, Val Acc: 0.7270, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 172, Loss: 0.5150, Val Acc: 0.7157, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 173, Loss: 0.5102, Val Acc: 0.7318, Test Acc: 0.7581\n",
      "Seed: 44, Epoch: 174, Loss: 0.5074, Val Acc: 0.7286, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 175, Loss: 0.5125, Val Acc: 0.7334, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 176, Loss: 0.5126, Val Acc: 0.7415, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 177, Loss: 0.5094, Val Acc: 0.7286, Test Acc: 0.7548\n",
      "Seed: 44, Epoch: 178, Loss: 0.5094, Val Acc: 0.7237, Test Acc: 0.7468\n",
      "Seed: 44, Epoch: 179, Loss: 0.5067, Val Acc: 0.7302, Test Acc: 0.7548\n",
      "Seed: 44, Epoch: 180, Loss: 0.5078, Val Acc: 0.7367, Test Acc: 0.7581\n",
      "Seed: 44, Epoch: 181, Loss: 0.5042, Val Acc: 0.7286, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 182, Loss: 0.5074, Val Acc: 0.7254, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 183, Loss: 0.5108, Val Acc: 0.7334, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 184, Loss: 0.5094, Val Acc: 0.7270, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 185, Loss: 0.5076, Val Acc: 0.7286, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 186, Loss: 0.5117, Val Acc: 0.7092, Test Acc: 0.7419\n",
      "Seed: 44, Epoch: 187, Loss: 0.5150, Val Acc: 0.7157, Test Acc: 0.7290\n",
      "Seed: 44, Epoch: 188, Loss: 0.5162, Val Acc: 0.7318, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 189, Loss: 0.5077, Val Acc: 0.7286, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 190, Loss: 0.5048, Val Acc: 0.7367, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 191, Loss: 0.5070, Val Acc: 0.7367, Test Acc: 0.7645\n",
      "Seed: 44, Epoch: 192, Loss: 0.5025, Val Acc: 0.7254, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 193, Loss: 0.5029, Val Acc: 0.7334, Test Acc: 0.7645\n",
      "Seed: 44, Epoch: 194, Loss: 0.5019, Val Acc: 0.7221, Test Acc: 0.7306\n",
      "Seed: 44, Epoch: 195, Loss: 0.5066, Val Acc: 0.7464, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 196, Loss: 0.5028, Val Acc: 0.7286, Test Acc: 0.7468\n",
      "Seed: 44, Epoch: 197, Loss: 0.4995, Val Acc: 0.7318, Test Acc: 0.7548\n",
      "Seed: 44, Epoch: 198, Loss: 0.5011, Val Acc: 0.7221, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 199, Loss: 0.5013, Val Acc: 0.7431, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 200, Loss: 0.5072, Val Acc: 0.7302, Test Acc: 0.7516\n",
      "Average Time: 285.44 seconds\n",
      "Var Time: 1.96 seconds\n",
      "Average Memory: 4300.00 MB\n",
      "Average Best Val Acc: 0.7437\n",
      "Std Best Test Acc: 0.0188\n",
      "Average Test Acc: 0.7398\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "max_nodes = 150\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"NCI109\",\n",
    "    transform=T.Compose([T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "dataset = dataset_dense\n",
    "dataset = dataset.shuffle()\n",
    "N = 150\n",
    "mp_layers = 1\n",
    "mp_channels = 64\n",
    "mp_activation = \"relu\"\n",
    "delta_coeff = 2.0\n",
    "\n",
    "mlp_hidden_layers = 1\n",
    "mlp_hidden_channels = 128\n",
    "mlp_activation = \"relu\"\n",
    "totvar_coeff = 0.5\n",
    "balance_coeff = 0.5\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 5e-4\n",
    "l2_reg_val = 0\n",
    "patience = 10\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        if self.lin is not None:\n",
    "            x = self.lin(x).relu()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_AsymCheegerCut(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset.num_classes)\n",
    "\n",
    "        self.pool1 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "        self.pool2 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool1(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool2(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_AsymCheegerCut().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "    model = Net_AsymCheegerCut().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MUTAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[150, 7], y=[1], adj=[150, 150], mask=[150])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "class ConvertToDenseAdj(BaseTransform):\n",
    "    def __call__(self, data):\n",
    "        # 确保 data.adj 存在且为三维\n",
    "        if hasattr(data, 'adj') and data.adj.dim() == 3:\n",
    "            # 对第三维进行合并操作，这里以求和为例\n",
    "            data.adj = data.adj.sum(dim=-1)\n",
    "            # 你可以选择其他方式，如取最大值：\n",
    "            # data.adj = data.adj.max(dim=-1)[0]\n",
    "\n",
    "        return data\n",
    "\n",
    "# 在加载数据时应用这个变换\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"MUTAG\",\n",
    "    transform=T.Compose([T.ToDense(max_nodes), ConvertToDenseAdj()]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "dataset_dense[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6895, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 002, Loss: 0.6865, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 003, Loss: 0.6835, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 004, Loss: 0.6807, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 005, Loss: 0.6778, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 006, Loss: 0.6749, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 007, Loss: 0.6721, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 008, Loss: 0.6695, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 009, Loss: 0.6667, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 010, Loss: 0.6639, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 011, Loss: 0.6610, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 012, Loss: 0.6580, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 013, Loss: 0.6549, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 014, Loss: 0.6517, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 015, Loss: 0.6484, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 016, Loss: 0.6449, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 017, Loss: 0.6414, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 018, Loss: 0.6379, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 019, Loss: 0.6343, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 020, Loss: 0.6307, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 021, Loss: 0.6270, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 022, Loss: 0.6232, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 023, Loss: 0.6193, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 024, Loss: 0.6154, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 025, Loss: 0.6116, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 026, Loss: 0.6078, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 027, Loss: 0.6041, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 028, Loss: 0.6006, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 029, Loss: 0.5972, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 030, Loss: 0.5940, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 031, Loss: 0.5912, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 032, Loss: 0.5888, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 033, Loss: 0.5869, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 034, Loss: 0.5854, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 035, Loss: 0.5842, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 036, Loss: 0.5833, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 037, Loss: 0.5822, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 038, Loss: 0.5808, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 039, Loss: 0.5795, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 040, Loss: 0.5781, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 041, Loss: 0.5753, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 042, Loss: 0.5704, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 043, Loss: 0.5641, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 044, Loss: 0.5591, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 045, Loss: 0.5562, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 046, Loss: 0.5533, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 047, Loss: 0.5497, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 048, Loss: 0.5464, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 049, Loss: 0.5446, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 050, Loss: 0.5434, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 051, Loss: 0.5416, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 052, Loss: 0.5395, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 053, Loss: 0.5378, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 054, Loss: 0.5365, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 055, Loss: 0.5346, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 056, Loss: 0.5319, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 057, Loss: 0.5295, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 058, Loss: 0.5273, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 059, Loss: 0.5247, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 060, Loss: 0.5216, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 061, Loss: 0.5188, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 062, Loss: 0.5162, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 063, Loss: 0.5132, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 064, Loss: 0.5101, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 065, Loss: 0.5074, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 066, Loss: 0.5048, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 067, Loss: 0.5017, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 068, Loss: 0.4989, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 069, Loss: 0.4961, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 070, Loss: 0.4929, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 071, Loss: 0.4898, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 072, Loss: 0.4866, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 073, Loss: 0.4829, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 074, Loss: 0.4793, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 075, Loss: 0.4754, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 076, Loss: 0.4713, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 077, Loss: 0.4672, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 078, Loss: 0.4628, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 079, Loss: 0.4585, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 080, Loss: 0.4539, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 081, Loss: 0.4495, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 082, Loss: 0.4449, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 083, Loss: 0.4407, Val Acc: 0.5000, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 084, Loss: 0.4367, Val Acc: 0.5357, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 085, Loss: 0.4332, Val Acc: 0.5357, Test Acc: 0.7241\n",
      "Seed: 42, Epoch: 086, Loss: 0.4302, Val Acc: 0.5357, Test Acc: 0.7586\n",
      "Seed: 42, Epoch: 087, Loss: 0.4276, Val Acc: 0.5714, Test Acc: 0.7931\n",
      "Seed: 42, Epoch: 088, Loss: 0.4253, Val Acc: 0.5357, Test Acc: 0.8276\n",
      "Seed: 42, Epoch: 089, Loss: 0.4229, Val Acc: 0.6071, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 090, Loss: 0.4205, Val Acc: 0.7143, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 091, Loss: 0.4179, Val Acc: 0.7500, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 092, Loss: 0.4154, Val Acc: 0.7500, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 093, Loss: 0.4128, Val Acc: 0.7500, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 094, Loss: 0.4105, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 095, Loss: 0.4082, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 096, Loss: 0.4063, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 097, Loss: 0.4045, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 098, Loss: 0.4028, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 099, Loss: 0.4011, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 100, Loss: 0.3995, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 101, Loss: 0.3980, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 102, Loss: 0.3964, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 103, Loss: 0.3948, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 104, Loss: 0.3934, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 105, Loss: 0.3920, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 106, Loss: 0.3907, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 107, Loss: 0.3894, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 108, Loss: 0.3881, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 109, Loss: 0.3869, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 110, Loss: 0.3857, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 111, Loss: 0.3844, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 112, Loss: 0.3832, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 113, Loss: 0.3820, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 114, Loss: 0.3807, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 115, Loss: 0.3795, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 116, Loss: 0.3782, Val Acc: 0.7857, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 117, Loss: 0.3770, Val Acc: 0.7857, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 118, Loss: 0.3761, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 119, Loss: 0.3762, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 120, Loss: 0.3756, Val Acc: 0.7857, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 121, Loss: 0.3723, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 122, Loss: 0.3731, Val Acc: 0.7857, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 123, Loss: 0.3706, Val Acc: 0.7857, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 124, Loss: 0.3698, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 125, Loss: 0.3688, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 126, Loss: 0.3671, Val Acc: 0.7857, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 127, Loss: 0.3667, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 128, Loss: 0.3648, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 129, Loss: 0.3646, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 130, Loss: 0.3626, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 131, Loss: 0.3622, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 132, Loss: 0.3606, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 133, Loss: 0.3601, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 134, Loss: 0.3589, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 135, Loss: 0.3579, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 136, Loss: 0.3571, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 137, Loss: 0.3559, Val Acc: 0.7857, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 138, Loss: 0.3553, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 139, Loss: 0.3541, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 140, Loss: 0.3533, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 141, Loss: 0.3527, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 142, Loss: 0.3516, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 143, Loss: 0.3510, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 144, Loss: 0.3503, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 145, Loss: 0.3494, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 146, Loss: 0.3489, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 147, Loss: 0.3481, Val Acc: 0.7857, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 148, Loss: 0.3475, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 149, Loss: 0.3471, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 150, Loss: 0.3464, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 151, Loss: 0.3459, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 152, Loss: 0.3455, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 153, Loss: 0.3450, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 154, Loss: 0.3445, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 155, Loss: 0.3443, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 156, Loss: 0.3438, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 157, Loss: 0.3434, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 158, Loss: 0.3431, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 159, Loss: 0.3429, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 160, Loss: 0.3426, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 161, Loss: 0.3423, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 162, Loss: 0.3421, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 163, Loss: 0.3420, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 164, Loss: 0.3418, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 165, Loss: 0.3415, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 166, Loss: 0.3412, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 167, Loss: 0.3411, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 168, Loss: 0.3409, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 169, Loss: 0.3406, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 170, Loss: 0.3404, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 171, Loss: 0.3402, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 172, Loss: 0.3400, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 173, Loss: 0.3397, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 174, Loss: 0.3393, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 175, Loss: 0.3391, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 176, Loss: 0.3387, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 177, Loss: 0.3383, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 178, Loss: 0.3379, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 179, Loss: 0.3373, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 180, Loss: 0.3367, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 181, Loss: 0.3361, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 42, Epoch: 182, Loss: 0.3354, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 183, Loss: 0.3345, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 184, Loss: 0.3336, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 185, Loss: 0.3325, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 186, Loss: 0.3317, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 187, Loss: 0.3304, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 188, Loss: 0.3297, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 189, Loss: 0.3351, Val Acc: 0.8214, Test Acc: 0.9655\n",
      "Seed: 42, Epoch: 190, Loss: 0.3351, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 191, Loss: 0.3307, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 192, Loss: 0.3356, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 193, Loss: 0.3307, Val Acc: 0.8214, Test Acc: 0.9655\n",
      "Seed: 42, Epoch: 194, Loss: 0.3364, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 195, Loss: 0.3328, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 196, Loss: 0.3358, Val Acc: 0.8571, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 197, Loss: 0.3309, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 198, Loss: 0.3342, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 199, Loss: 0.3293, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 42, Epoch: 200, Loss: 0.3316, Val Acc: 0.8214, Test Acc: 0.9310\n",
      "Seed: 43, Epoch: 001, Loss: 0.7356, Val Acc: 0.3571, Test Acc: 0.4483\n",
      "Seed: 43, Epoch: 002, Loss: 0.7329, Val Acc: 0.3571, Test Acc: 0.4483\n",
      "Seed: 43, Epoch: 003, Loss: 0.7304, Val Acc: 0.3571, Test Acc: 0.4483\n",
      "Seed: 43, Epoch: 004, Loss: 0.7278, Val Acc: 0.3571, Test Acc: 0.4483\n",
      "Seed: 43, Epoch: 005, Loss: 0.7254, Val Acc: 0.3571, Test Acc: 0.4483\n",
      "Seed: 43, Epoch: 006, Loss: 0.7229, Val Acc: 0.3571, Test Acc: 0.4483\n",
      "Seed: 43, Epoch: 007, Loss: 0.7203, Val Acc: 0.3571, Test Acc: 0.4483\n",
      "Seed: 43, Epoch: 008, Loss: 0.7177, Val Acc: 0.3571, Test Acc: 0.4483\n",
      "Seed: 43, Epoch: 009, Loss: 0.7151, Val Acc: 0.3571, Test Acc: 0.4483\n",
      "Seed: 43, Epoch: 010, Loss: 0.7125, Val Acc: 0.3571, Test Acc: 0.4483\n",
      "Seed: 43, Epoch: 011, Loss: 0.7099, Val Acc: 0.3571, Test Acc: 0.4483\n",
      "Seed: 43, Epoch: 012, Loss: 0.7072, Val Acc: 0.3571, Test Acc: 0.4483\n",
      "Seed: 43, Epoch: 013, Loss: 0.7044, Val Acc: 0.3571, Test Acc: 0.4483\n",
      "Seed: 43, Epoch: 014, Loss: 0.7017, Val Acc: 0.3571, Test Acc: 0.4483\n",
      "Seed: 43, Epoch: 015, Loss: 0.6991, Val Acc: 0.3571, Test Acc: 0.4483\n",
      "Seed: 43, Epoch: 016, Loss: 0.6965, Val Acc: 0.3571, Test Acc: 0.4828\n",
      "Seed: 43, Epoch: 017, Loss: 0.6937, Val Acc: 0.6071, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 018, Loss: 0.6908, Val Acc: 0.7500, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 019, Loss: 0.6878, Val Acc: 0.6429, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 020, Loss: 0.6848, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 021, Loss: 0.6816, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 022, Loss: 0.6783, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 023, Loss: 0.6750, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 024, Loss: 0.6716, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 025, Loss: 0.6682, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 026, Loss: 0.6648, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 027, Loss: 0.6612, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 028, Loss: 0.6576, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 029, Loss: 0.6540, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 030, Loss: 0.6502, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 031, Loss: 0.6463, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 032, Loss: 0.6421, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 033, Loss: 0.6377, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 034, Loss: 0.6332, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 035, Loss: 0.6284, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 036, Loss: 0.6234, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 037, Loss: 0.6182, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 038, Loss: 0.6126, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 039, Loss: 0.6066, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 040, Loss: 0.6000, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 041, Loss: 0.5926, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 042, Loss: 0.5842, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 043, Loss: 0.5748, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 044, Loss: 0.5641, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 045, Loss: 0.5527, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 046, Loss: 0.5448, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 047, Loss: 0.5467, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 048, Loss: 0.5532, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 049, Loss: 0.5570, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 050, Loss: 0.5564, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 051, Loss: 0.5511, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 052, Loss: 0.5424, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 053, Loss: 0.5348, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 054, Loss: 0.5326, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 055, Loss: 0.5340, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 056, Loss: 0.5348, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 057, Loss: 0.5330, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 058, Loss: 0.5285, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 059, Loss: 0.5218, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 060, Loss: 0.5150, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 061, Loss: 0.5109, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 062, Loss: 0.5096, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 063, Loss: 0.5078, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 064, Loss: 0.5037, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 065, Loss: 0.4982, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 066, Loss: 0.4935, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 067, Loss: 0.4911, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 068, Loss: 0.4898, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 069, Loss: 0.4878, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 070, Loss: 0.4846, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 071, Loss: 0.4814, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 072, Loss: 0.4793, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 073, Loss: 0.4784, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 074, Loss: 0.4771, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 075, Loss: 0.4745, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 076, Loss: 0.4716, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 077, Loss: 0.4694, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 078, Loss: 0.4678, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 079, Loss: 0.4657, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 080, Loss: 0.4628, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 081, Loss: 0.4600, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 082, Loss: 0.4577, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 083, Loss: 0.4555, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 084, Loss: 0.4531, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 085, Loss: 0.4504, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 086, Loss: 0.4480, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 087, Loss: 0.4460, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 088, Loss: 0.4439, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 089, Loss: 0.4414, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 090, Loss: 0.4390, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 091, Loss: 0.4368, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 092, Loss: 0.4346, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 093, Loss: 0.4322, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 094, Loss: 0.4299, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 095, Loss: 0.4277, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 096, Loss: 0.4256, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 097, Loss: 0.4234, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 098, Loss: 0.4211, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 099, Loss: 0.4190, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 100, Loss: 0.4169, Val Acc: 0.6429, Test Acc: 0.5517\n",
      "Seed: 43, Epoch: 101, Loss: 0.4148, Val Acc: 0.6429, Test Acc: 0.5862\n",
      "Seed: 43, Epoch: 102, Loss: 0.4128, Val Acc: 0.6429, Test Acc: 0.5862\n",
      "Seed: 43, Epoch: 103, Loss: 0.4108, Val Acc: 0.6786, Test Acc: 0.5862\n",
      "Seed: 43, Epoch: 104, Loss: 0.4089, Val Acc: 0.6786, Test Acc: 0.6207\n",
      "Seed: 43, Epoch: 105, Loss: 0.4069, Val Acc: 0.6786, Test Acc: 0.5862\n",
      "Seed: 43, Epoch: 106, Loss: 0.4050, Val Acc: 0.6786, Test Acc: 0.5862\n",
      "Seed: 43, Epoch: 107, Loss: 0.4031, Val Acc: 0.6786, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 108, Loss: 0.4012, Val Acc: 0.6786, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 109, Loss: 0.3994, Val Acc: 0.7143, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 110, Loss: 0.3977, Val Acc: 0.7143, Test Acc: 0.6552\n",
      "Seed: 43, Epoch: 111, Loss: 0.3959, Val Acc: 0.6786, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 112, Loss: 0.3942, Val Acc: 0.6786, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 113, Loss: 0.3925, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 114, Loss: 0.3907, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 115, Loss: 0.3889, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 116, Loss: 0.3871, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 117, Loss: 0.3852, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 43, Epoch: 118, Loss: 0.3833, Val Acc: 0.7143, Test Acc: 0.7586\n",
      "Seed: 43, Epoch: 119, Loss: 0.3814, Val Acc: 0.7143, Test Acc: 0.7931\n",
      "Seed: 43, Epoch: 120, Loss: 0.3794, Val Acc: 0.7143, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 121, Loss: 0.3774, Val Acc: 0.7143, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 122, Loss: 0.3753, Val Acc: 0.7143, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 123, Loss: 0.3732, Val Acc: 0.7143, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 124, Loss: 0.3711, Val Acc: 0.7143, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 125, Loss: 0.3691, Val Acc: 0.7143, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 126, Loss: 0.3670, Val Acc: 0.7143, Test Acc: 0.8276\n",
      "Seed: 43, Epoch: 127, Loss: 0.3649, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 128, Loss: 0.3627, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 129, Loss: 0.3605, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 130, Loss: 0.3583, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 131, Loss: 0.3560, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 132, Loss: 0.3537, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 133, Loss: 0.3513, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 134, Loss: 0.3490, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 135, Loss: 0.3467, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 136, Loss: 0.3443, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 137, Loss: 0.3419, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 138, Loss: 0.3394, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 139, Loss: 0.3370, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 140, Loss: 0.3345, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 141, Loss: 0.3321, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 142, Loss: 0.3303, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 143, Loss: 0.3290, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 144, Loss: 0.3252, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 145, Loss: 0.3249, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 146, Loss: 0.3202, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 147, Loss: 0.3192, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 148, Loss: 0.3155, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 149, Loss: 0.3150, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 150, Loss: 0.3109, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 151, Loss: 0.3098, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 152, Loss: 0.3067, Val Acc: 0.6786, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 153, Loss: 0.3076, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 154, Loss: 0.3067, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 155, Loss: 0.3040, Val Acc: 0.7143, Test Acc: 0.8966\n",
      "Seed: 43, Epoch: 156, Loss: 0.3076, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 157, Loss: 0.3033, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 158, Loss: 0.3042, Val Acc: 0.7143, Test Acc: 0.8966\n",
      "Seed: 43, Epoch: 159, Loss: 0.3006, Val Acc: 0.7143, Test Acc: 0.8966\n",
      "Seed: 43, Epoch: 160, Loss: 0.3036, Val Acc: 0.7500, Test Acc: 0.8966\n",
      "Seed: 43, Epoch: 161, Loss: 0.3009, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 162, Loss: 0.3028, Val Acc: 0.7143, Test Acc: 0.8621\n",
      "Seed: 43, Epoch: 163, Loss: 0.2994, Val Acc: 0.7143, Test Acc: 0.8966\n",
      "Seed: 43, Epoch: 164, Loss: 0.3027, Val Acc: 0.7500, Test Acc: 0.8966\n",
      "Seed: 43, Epoch: 165, Loss: 0.2990, Val Acc: 0.7500, Test Acc: 0.8966\n",
      "Seed: 43, Epoch: 166, Loss: 0.3009, Val Acc: 0.7500, Test Acc: 0.8966\n",
      "Seed: 43, Epoch: 167, Loss: 0.2979, Val Acc: 0.7143, Test Acc: 0.8966\n",
      "Seed: 43, Epoch: 168, Loss: 0.3001, Val Acc: 0.7500, Test Acc: 0.8966\n",
      "Early stopping at epoch 168 for seed 43\n",
      "Seed: 44, Epoch: 001, Loss: 0.6692, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 002, Loss: 0.6679, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 003, Loss: 0.6667, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 004, Loss: 0.6656, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 005, Loss: 0.6644, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 006, Loss: 0.6634, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 007, Loss: 0.6625, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 008, Loss: 0.6615, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 009, Loss: 0.6605, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 010, Loss: 0.6596, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 011, Loss: 0.6587, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 012, Loss: 0.6577, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 013, Loss: 0.6568, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 014, Loss: 0.6557, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 015, Loss: 0.6546, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 016, Loss: 0.6535, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 017, Loss: 0.6523, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 018, Loss: 0.6511, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 019, Loss: 0.6499, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 020, Loss: 0.6486, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 021, Loss: 0.6472, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 022, Loss: 0.6457, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 023, Loss: 0.6442, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 024, Loss: 0.6426, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 025, Loss: 0.6409, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 026, Loss: 0.6392, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 027, Loss: 0.6373, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 028, Loss: 0.6353, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 029, Loss: 0.6332, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 030, Loss: 0.6310, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 031, Loss: 0.6286, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 032, Loss: 0.6260, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 033, Loss: 0.6230, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 034, Loss: 0.6196, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 035, Loss: 0.6157, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 036, Loss: 0.6113, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 037, Loss: 0.6063, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 038, Loss: 0.6001, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 039, Loss: 0.5916, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 040, Loss: 0.5837, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 041, Loss: 0.5817, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 042, Loss: 0.5792, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 043, Loss: 0.5723, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 044, Loss: 0.5633, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 045, Loss: 0.5561, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 046, Loss: 0.5530, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 047, Loss: 0.5507, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 048, Loss: 0.5457, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 049, Loss: 0.5379, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 050, Loss: 0.5302, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 051, Loss: 0.5248, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 052, Loss: 0.5208, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 053, Loss: 0.5158, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 054, Loss: 0.5090, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 055, Loss: 0.5020, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 056, Loss: 0.4968, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 057, Loss: 0.4926, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 058, Loss: 0.4869, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 059, Loss: 0.4801, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 060, Loss: 0.4746, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 061, Loss: 0.4701, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 062, Loss: 0.4649, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 063, Loss: 0.4593, Val Acc: 0.7143, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 064, Loss: 0.4544, Val Acc: 0.6786, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 065, Loss: 0.4506, Val Acc: 0.6786, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 066, Loss: 0.4463, Val Acc: 0.6786, Test Acc: 0.7241\n",
      "Seed: 44, Epoch: 067, Loss: 0.4416, Val Acc: 0.6786, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 068, Loss: 0.4378, Val Acc: 0.7500, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 069, Loss: 0.4348, Val Acc: 0.7500, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 070, Loss: 0.4314, Val Acc: 0.7500, Test Acc: 0.7586\n",
      "Seed: 44, Epoch: 071, Loss: 0.4278, Val Acc: 0.8214, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 072, Loss: 0.4250, Val Acc: 0.8214, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 073, Loss: 0.4224, Val Acc: 0.8214, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 074, Loss: 0.4194, Val Acc: 0.8214, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 075, Loss: 0.4166, Val Acc: 0.8214, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 076, Loss: 0.4142, Val Acc: 0.8214, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 077, Loss: 0.4115, Val Acc: 0.8214, Test Acc: 0.7931\n",
      "Seed: 44, Epoch: 078, Loss: 0.4087, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 44, Epoch: 079, Loss: 0.4064, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 44, Epoch: 080, Loss: 0.4039, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 44, Epoch: 081, Loss: 0.4013, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 44, Epoch: 082, Loss: 0.3990, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 44, Epoch: 083, Loss: 0.3964, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 44, Epoch: 084, Loss: 0.3938, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 44, Epoch: 085, Loss: 0.3914, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 44, Epoch: 086, Loss: 0.3887, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 44, Epoch: 087, Loss: 0.3862, Val Acc: 0.8214, Test Acc: 0.8276\n",
      "Seed: 44, Epoch: 088, Loss: 0.3834, Val Acc: 0.8214, Test Acc: 0.8621\n",
      "Seed: 44, Epoch: 089, Loss: 0.3806, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 090, Loss: 0.3778, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 091, Loss: 0.3748, Val Acc: 0.8214, Test Acc: 0.8621\n",
      "Seed: 44, Epoch: 092, Loss: 0.3719, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 093, Loss: 0.3688, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 094, Loss: 0.3657, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 095, Loss: 0.3624, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 096, Loss: 0.3592, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 097, Loss: 0.3560, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 098, Loss: 0.3527, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 099, Loss: 0.3495, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 100, Loss: 0.3463, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 101, Loss: 0.3431, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 102, Loss: 0.3402, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 103, Loss: 0.3373, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 104, Loss: 0.3346, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 105, Loss: 0.3321, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 106, Loss: 0.3298, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 107, Loss: 0.3278, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 108, Loss: 0.3258, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 109, Loss: 0.3242, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 110, Loss: 0.3227, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 111, Loss: 0.3214, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 112, Loss: 0.3211, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 44, Epoch: 113, Loss: 0.3205, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 114, Loss: 0.3213, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 115, Loss: 0.3177, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 44, Epoch: 116, Loss: 0.3236, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 117, Loss: 0.3218, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 118, Loss: 0.3255, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 119, Loss: 0.3186, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 44, Epoch: 120, Loss: 0.3208, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 44, Epoch: 121, Loss: 0.3168, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 122, Loss: 0.3175, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 123, Loss: 0.3187, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 124, Loss: 0.3149, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 44, Epoch: 125, Loss: 0.3171, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 44, Epoch: 126, Loss: 0.3133, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 127, Loss: 0.3144, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 128, Loss: 0.3129, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 44, Epoch: 129, Loss: 0.3121, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 130, Loss: 0.3106, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 131, Loss: 0.3112, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 132, Loss: 0.3092, Val Acc: 0.8571, Test Acc: 0.8621\n",
      "Seed: 44, Epoch: 133, Loss: 0.3111, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 134, Loss: 0.3091, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 135, Loss: 0.3086, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 136, Loss: 0.3092, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 137, Loss: 0.3069, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 138, Loss: 0.3071, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 139, Loss: 0.3064, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 140, Loss: 0.3053, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 141, Loss: 0.3055, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 142, Loss: 0.3044, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 143, Loss: 0.3042, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 144, Loss: 0.3039, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 145, Loss: 0.3029, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 146, Loss: 0.3031, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 147, Loss: 0.3024, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 148, Loss: 0.3018, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 149, Loss: 0.3019, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 150, Loss: 0.3011, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 151, Loss: 0.3006, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 152, Loss: 0.3007, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 153, Loss: 0.3000, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 154, Loss: 0.2994, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 155, Loss: 0.2995, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 156, Loss: 0.2992, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 157, Loss: 0.2983, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 158, Loss: 0.2981, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 159, Loss: 0.2982, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 160, Loss: 0.2975, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 161, Loss: 0.2969, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 162, Loss: 0.2967, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 163, Loss: 0.2967, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 164, Loss: 0.2964, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 165, Loss: 0.2958, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 166, Loss: 0.2954, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 167, Loss: 0.2951, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 168, Loss: 0.2950, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 169, Loss: 0.2948, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 170, Loss: 0.2945, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 171, Loss: 0.2941, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 172, Loss: 0.2937, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 173, Loss: 0.2934, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 174, Loss: 0.2931, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 175, Loss: 0.2928, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 176, Loss: 0.2925, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 177, Loss: 0.2923, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 178, Loss: 0.2922, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 179, Loss: 0.2922, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 180, Loss: 0.2929, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 181, Loss: 0.2941, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 182, Loss: 0.2977, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 183, Loss: 0.2943, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 184, Loss: 0.2916, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 185, Loss: 0.2906, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 186, Loss: 0.2922, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 187, Loss: 0.2934, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 188, Loss: 0.2903, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 189, Loss: 0.2902, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 190, Loss: 0.2920, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 191, Loss: 0.2903, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 192, Loss: 0.2891, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 193, Loss: 0.2898, Val Acc: 0.8571, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 194, Loss: 0.2897, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 195, Loss: 0.2887, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 196, Loss: 0.2881, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 197, Loss: 0.2885, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 198, Loss: 0.2885, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 199, Loss: 0.2875, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Seed: 44, Epoch: 200, Loss: 0.2872, Val Acc: 0.8214, Test Acc: 0.8966\n",
      "Average Time: 19.08 seconds\n",
      "Var Time: 2.24 seconds\n",
      "Average Memory: 1992.00 MB\n",
      "Average Best Val Acc: 0.8214\n",
      "Std Best Test Acc: 0.0282\n",
      "Average Test Acc: 0.8966\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "\n",
    "dataset = dataset_dense\n",
    "dataset = dataset.shuffle()\n",
    "N = 150\n",
    "mp_layers = 1\n",
    "mp_channels = 64\n",
    "mp_activation = \"relu\"\n",
    "delta_coeff = 2.0\n",
    "\n",
    "mlp_hidden_layers = 3\n",
    "mlp_hidden_channels = 64\n",
    "mlp_activation = \"relu\"\n",
    "totvar_coeff = 0.5\n",
    "balance_coeff = 0.5\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 5e-4\n",
    "l2_reg_val = 0\n",
    "patience = 10\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        if self.lin is not None:\n",
    "            x = self.lin(x).relu()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_AsymCheegerCut(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset.num_classes)\n",
    "\n",
    "        self.pool1 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "        self.pool2 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool1(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool2(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_AsymCheegerCut().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=512, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "    model = Net_AsymCheegerCut().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6902, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 002, Loss: 0.6887, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 003, Loss: 0.6882, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 004, Loss: 0.6877, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 005, Loss: 0.6872, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 006, Loss: 0.6865, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 007, Loss: 0.6856, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 008, Loss: 0.6847, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 009, Loss: 0.6836, Val Acc: 0.5676, Test Acc: 0.5856\n",
      "Seed: 42, Epoch: 010, Loss: 0.6822, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 011, Loss: 0.6810, Val Acc: 0.8018, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 012, Loss: 0.6797, Val Acc: 0.7658, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 013, Loss: 0.6776, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 014, Loss: 0.6746, Val Acc: 0.7387, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 015, Loss: 0.6724, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 016, Loss: 0.6699, Val Acc: 0.6847, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 017, Loss: 0.6664, Val Acc: 0.7568, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 018, Loss: 0.6600, Val Acc: 0.8108, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 019, Loss: 0.6531, Val Acc: 0.7477, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 020, Loss: 0.6482, Val Acc: 0.7207, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 021, Loss: 0.6444, Val Acc: 0.7207, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 022, Loss: 0.6356, Val Acc: 0.8108, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 023, Loss: 0.6278, Val Acc: 0.7658, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 024, Loss: 0.6262, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 025, Loss: 0.6183, Val Acc: 0.7658, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 026, Loss: 0.6153, Val Acc: 0.6937, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 027, Loss: 0.6156, Val Acc: 0.7658, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 028, Loss: 0.5981, Val Acc: 0.8108, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 029, Loss: 0.5879, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 030, Loss: 0.5861, Val Acc: 0.7297, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 031, Loss: 0.5744, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 032, Loss: 0.5769, Val Acc: 0.7297, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 033, Loss: 0.5672, Val Acc: 0.7297, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 034, Loss: 0.5787, Val Acc: 0.7297, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 035, Loss: 0.5795, Val Acc: 0.8198, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 036, Loss: 0.5498, Val Acc: 0.7928, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 037, Loss: 0.5592, Val Acc: 0.7928, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 038, Loss: 0.5522, Val Acc: 0.8198, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 039, Loss: 0.5443, Val Acc: 0.7748, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 040, Loss: 0.5527, Val Acc: 0.7297, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 041, Loss: 0.5677, Val Acc: 0.7297, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 042, Loss: 0.5713, Val Acc: 0.7928, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 043, Loss: 0.5390, Val Acc: 0.7838, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 044, Loss: 0.5426, Val Acc: 0.8108, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 045, Loss: 0.5339, Val Acc: 0.7928, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 046, Loss: 0.5342, Val Acc: 0.8198, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 047, Loss: 0.5309, Val Acc: 0.8198, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 048, Loss: 0.5264, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 049, Loss: 0.5241, Val Acc: 0.7748, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 050, Loss: 0.5377, Val Acc: 0.7658, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 051, Loss: 0.5275, Val Acc: 0.8288, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 052, Loss: 0.5228, Val Acc: 0.8288, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 053, Loss: 0.5175, Val Acc: 0.8288, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 054, Loss: 0.5155, Val Acc: 0.7838, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 055, Loss: 0.5222, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 056, Loss: 0.5294, Val Acc: 0.7477, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 057, Loss: 0.5515, Val Acc: 0.8288, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 058, Loss: 0.5170, Val Acc: 0.7207, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 059, Loss: 0.5334, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 060, Loss: 0.5116, Val Acc: 0.7658, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 061, Loss: 0.5358, Val Acc: 0.7838, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 062, Loss: 0.5100, Val Acc: 0.7838, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 063, Loss: 0.5214, Val Acc: 0.8288, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 064, Loss: 0.5076, Val Acc: 0.8018, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 065, Loss: 0.5239, Val Acc: 0.8018, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 066, Loss: 0.5136, Val Acc: 0.8288, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 067, Loss: 0.5141, Val Acc: 0.7838, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 068, Loss: 0.5207, Val Acc: 0.8288, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 069, Loss: 0.5117, Val Acc: 0.8288, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 070, Loss: 0.5080, Val Acc: 0.8288, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 071, Loss: 0.5062, Val Acc: 0.8288, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 072, Loss: 0.5116, Val Acc: 0.8198, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 073, Loss: 0.5074, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 074, Loss: 0.5070, Val Acc: 0.7658, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 075, Loss: 0.5147, Val Acc: 0.8108, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 076, Loss: 0.5006, Val Acc: 0.7838, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 077, Loss: 0.5340, Val Acc: 0.7387, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 078, Loss: 0.5436, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 079, Loss: 0.5064, Val Acc: 0.8108, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 080, Loss: 0.5027, Val Acc: 0.7838, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 081, Loss: 0.5040, Val Acc: 0.8198, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 082, Loss: 0.5049, Val Acc: 0.7838, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 083, Loss: 0.5148, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 084, Loss: 0.4961, Val Acc: 0.7568, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 085, Loss: 0.5339, Val Acc: 0.7387, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 086, Loss: 0.5523, Val Acc: 0.7748, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 087, Loss: 0.5097, Val Acc: 0.8198, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 088, Loss: 0.5055, Val Acc: 0.8288, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 089, Loss: 0.4997, Val Acc: 0.8108, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 090, Loss: 0.4997, Val Acc: 0.7748, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 091, Loss: 0.5004, Val Acc: 0.8108, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 092, Loss: 0.4964, Val Acc: 0.7928, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 093, Loss: 0.4941, Val Acc: 0.7928, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 094, Loss: 0.4958, Val Acc: 0.7658, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 095, Loss: 0.5164, Val Acc: 0.7568, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 096, Loss: 0.5323, Val Acc: 0.7568, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 097, Loss: 0.5159, Val Acc: 0.8018, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 098, Loss: 0.4894, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 099, Loss: 0.5150, Val Acc: 0.8288, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 100, Loss: 0.4942, Val Acc: 0.7838, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 101, Loss: 0.5138, Val Acc: 0.7838, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 102, Loss: 0.5178, Val Acc: 0.7838, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 103, Loss: 0.4955, Val Acc: 0.8108, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 104, Loss: 0.5164, Val Acc: 0.7928, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 105, Loss: 0.5035, Val Acc: 0.7928, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 106, Loss: 0.4908, Val Acc: 0.7928, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 107, Loss: 0.4929, Val Acc: 0.7928, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 108, Loss: 0.4945, Val Acc: 0.7928, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 109, Loss: 0.4923, Val Acc: 0.8018, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 110, Loss: 0.4899, Val Acc: 0.7928, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 111, Loss: 0.4879, Val Acc: 0.8108, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 112, Loss: 0.4920, Val Acc: 0.8018, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 113, Loss: 0.4908, Val Acc: 0.7838, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 114, Loss: 0.5136, Val Acc: 0.7928, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 115, Loss: 0.5009, Val Acc: 0.8018, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 116, Loss: 0.4928, Val Acc: 0.7748, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 117, Loss: 0.5163, Val Acc: 0.8198, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 118, Loss: 0.4931, Val Acc: 0.7928, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 119, Loss: 0.4841, Val Acc: 0.7928, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 120, Loss: 0.4965, Val Acc: 0.7928, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 121, Loss: 0.5104, Val Acc: 0.8108, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 122, Loss: 0.5032, Val Acc: 0.7928, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 123, Loss: 0.4860, Val Acc: 0.8018, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 124, Loss: 0.4865, Val Acc: 0.8108, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 125, Loss: 0.4855, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 126, Loss: 0.4859, Val Acc: 0.7928, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 127, Loss: 0.5183, Val Acc: 0.7838, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 128, Loss: 0.5143, Val Acc: 0.7928, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 129, Loss: 0.4847, Val Acc: 0.8018, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 130, Loss: 0.4822, Val Acc: 0.8018, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 131, Loss: 0.4892, Val Acc: 0.7838, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 132, Loss: 0.4991, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 133, Loss: 0.4830, Val Acc: 0.7928, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 134, Loss: 0.4825, Val Acc: 0.7928, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 135, Loss: 0.4802, Val Acc: 0.8108, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 136, Loss: 0.4828, Val Acc: 0.7928, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 137, Loss: 0.4797, Val Acc: 0.8018, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 138, Loss: 0.4784, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 139, Loss: 0.4837, Val Acc: 0.7838, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 140, Loss: 0.5100, Val Acc: 0.7928, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 141, Loss: 0.4909, Val Acc: 0.7838, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 142, Loss: 0.4803, Val Acc: 0.8018, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 143, Loss: 0.4999, Val Acc: 0.7928, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 144, Loss: 0.4808, Val Acc: 0.8018, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 145, Loss: 0.4742, Val Acc: 0.8018, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 146, Loss: 0.4757, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 147, Loss: 0.4775, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 148, Loss: 0.4755, Val Acc: 0.8288, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 149, Loss: 0.4876, Val Acc: 0.8018, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 150, Loss: 0.4770, Val Acc: 0.7928, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 151, Loss: 0.4987, Val Acc: 0.7748, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 152, Loss: 0.4940, Val Acc: 0.8018, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 153, Loss: 0.4737, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 154, Loss: 0.4732, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 155, Loss: 0.4768, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 156, Loss: 0.4724, Val Acc: 0.7928, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 157, Loss: 0.4688, Val Acc: 0.8018, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 158, Loss: 0.4689, Val Acc: 0.7838, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 159, Loss: 0.4670, Val Acc: 0.8018, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 160, Loss: 0.4704, Val Acc: 0.8018, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 161, Loss: 0.4703, Val Acc: 0.8108, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 162, Loss: 0.4713, Val Acc: 0.8108, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 163, Loss: 0.4660, Val Acc: 0.7838, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 164, Loss: 0.4678, Val Acc: 0.8108, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 165, Loss: 0.4652, Val Acc: 0.8018, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 166, Loss: 0.4686, Val Acc: 0.8018, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 167, Loss: 0.4698, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 168, Loss: 0.4647, Val Acc: 0.7658, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 169, Loss: 0.4670, Val Acc: 0.7928, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 170, Loss: 0.4690, Val Acc: 0.7748, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 171, Loss: 0.5235, Val Acc: 0.7928, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 172, Loss: 0.4698, Val Acc: 0.7117, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 173, Loss: 0.6236, Val Acc: 0.6306, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 174, Loss: 0.6305, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 175, Loss: 0.4663, Val Acc: 0.7838, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 176, Loss: 0.5071, Val Acc: 0.7748, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 177, Loss: 0.5213, Val Acc: 0.8018, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 178, Loss: 0.4805, Val Acc: 0.7658, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 179, Loss: 0.4823, Val Acc: 0.7838, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 180, Loss: 0.4807, Val Acc: 0.7928, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 181, Loss: 0.4783, Val Acc: 0.8018, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 182, Loss: 0.4782, Val Acc: 0.7928, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 183, Loss: 0.4646, Val Acc: 0.7748, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 184, Loss: 0.4774, Val Acc: 0.7928, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 185, Loss: 0.4690, Val Acc: 0.7928, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 186, Loss: 0.4972, Val Acc: 0.8018, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 187, Loss: 0.4727, Val Acc: 0.8018, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 188, Loss: 0.4778, Val Acc: 0.7838, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 189, Loss: 0.4945, Val Acc: 0.8108, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 190, Loss: 0.4662, Val Acc: 0.8018, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 191, Loss: 0.4685, Val Acc: 0.7928, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 192, Loss: 0.4779, Val Acc: 0.7928, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 193, Loss: 0.4762, Val Acc: 0.8018, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 194, Loss: 0.4630, Val Acc: 0.8108, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 195, Loss: 0.4629, Val Acc: 0.8018, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 196, Loss: 0.4713, Val Acc: 0.8018, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 197, Loss: 0.4556, Val Acc: 0.8018, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 198, Loss: 0.4688, Val Acc: 0.8108, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 199, Loss: 0.4675, Val Acc: 0.8018, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 200, Loss: 0.4529, Val Acc: 0.8018, Test Acc: 0.7658\n",
      "Seed: 43, Epoch: 001, Loss: 0.6910, Val Acc: 0.5405, Test Acc: 0.6126\n",
      "Seed: 43, Epoch: 002, Loss: 0.6895, Val Acc: 0.5676, Test Acc: 0.6396\n",
      "Seed: 43, Epoch: 003, Loss: 0.6886, Val Acc: 0.7297, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 004, Loss: 0.6872, Val Acc: 0.7297, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 005, Loss: 0.6853, Val Acc: 0.7297, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 006, Loss: 0.6830, Val Acc: 0.7297, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 007, Loss: 0.6805, Val Acc: 0.7117, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 008, Loss: 0.6774, Val Acc: 0.7387, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 009, Loss: 0.6738, Val Acc: 0.7207, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 010, Loss: 0.6704, Val Acc: 0.7207, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 011, Loss: 0.6657, Val Acc: 0.7297, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 012, Loss: 0.6610, Val Acc: 0.7297, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 013, Loss: 0.6572, Val Acc: 0.7027, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 014, Loss: 0.6533, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 015, Loss: 0.6480, Val Acc: 0.6667, Test Acc: 0.6486\n",
      "Seed: 43, Epoch: 016, Loss: 0.6433, Val Acc: 0.6757, Test Acc: 0.6396\n",
      "Seed: 43, Epoch: 017, Loss: 0.6371, Val Acc: 0.6937, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 018, Loss: 0.6288, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 019, Loss: 0.6225, Val Acc: 0.6757, Test Acc: 0.6126\n",
      "Seed: 43, Epoch: 020, Loss: 0.6213, Val Acc: 0.6306, Test Acc: 0.5946\n",
      "Seed: 43, Epoch: 021, Loss: 0.6208, Val Acc: 0.6306, Test Acc: 0.5856\n",
      "Seed: 43, Epoch: 022, Loss: 0.6198, Val Acc: 0.6306, Test Acc: 0.6216\n",
      "Seed: 43, Epoch: 023, Loss: 0.6078, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 024, Loss: 0.5912, Val Acc: 0.6757, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 025, Loss: 0.5900, Val Acc: 0.7568, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 026, Loss: 0.5783, Val Acc: 0.7387, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 027, Loss: 0.5717, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 028, Loss: 0.5750, Val Acc: 0.7117, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 029, Loss: 0.5634, Val Acc: 0.6757, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 030, Loss: 0.5705, Val Acc: 0.6757, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 031, Loss: 0.5738, Val Acc: 0.7117, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 032, Loss: 0.5547, Val Acc: 0.7117, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 033, Loss: 0.5698, Val Acc: 0.7207, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 034, Loss: 0.5566, Val Acc: 0.7297, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 035, Loss: 0.5459, Val Acc: 0.6757, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 036, Loss: 0.5512, Val Acc: 0.6937, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 037, Loss: 0.5441, Val Acc: 0.7387, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 038, Loss: 0.5433, Val Acc: 0.7568, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 039, Loss: 0.5382, Val Acc: 0.7117, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 040, Loss: 0.5354, Val Acc: 0.6937, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 041, Loss: 0.5335, Val Acc: 0.7568, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 042, Loss: 0.5312, Val Acc: 0.7297, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 043, Loss: 0.5476, Val Acc: 0.7387, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 044, Loss: 0.5306, Val Acc: 0.6757, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 045, Loss: 0.5290, Val Acc: 0.6757, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 046, Loss: 0.5308, Val Acc: 0.6937, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 047, Loss: 0.5210, Val Acc: 0.7027, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 048, Loss: 0.5209, Val Acc: 0.6757, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 049, Loss: 0.5207, Val Acc: 0.6757, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 050, Loss: 0.5227, Val Acc: 0.6847, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 051, Loss: 0.5172, Val Acc: 0.7387, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 052, Loss: 0.5285, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 053, Loss: 0.5499, Val Acc: 0.7207, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 054, Loss: 0.5154, Val Acc: 0.6036, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 055, Loss: 0.5883, Val Acc: 0.5676, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 056, Loss: 0.5760, Val Acc: 0.7117, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 057, Loss: 0.5117, Val Acc: 0.7387, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 058, Loss: 0.5283, Val Acc: 0.7477, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 059, Loss: 0.5181, Val Acc: 0.7117, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 060, Loss: 0.5115, Val Acc: 0.6667, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 061, Loss: 0.5399, Val Acc: 0.6937, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 062, Loss: 0.5104, Val Acc: 0.7477, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 063, Loss: 0.5173, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 064, Loss: 0.5241, Val Acc: 0.7477, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 065, Loss: 0.5120, Val Acc: 0.7387, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 066, Loss: 0.5011, Val Acc: 0.7207, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 067, Loss: 0.5051, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 068, Loss: 0.5072, Val Acc: 0.6937, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 069, Loss: 0.5197, Val Acc: 0.6937, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 070, Loss: 0.5089, Val Acc: 0.7207, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 071, Loss: 0.5146, Val Acc: 0.6937, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 072, Loss: 0.5518, Val Acc: 0.7117, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 073, Loss: 0.5345, Val Acc: 0.7207, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 074, Loss: 0.5015, Val Acc: 0.7117, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 075, Loss: 0.5090, Val Acc: 0.7117, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 076, Loss: 0.5070, Val Acc: 0.7117, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 077, Loss: 0.5030, Val Acc: 0.7297, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 078, Loss: 0.5000, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 079, Loss: 0.5113, Val Acc: 0.6847, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 080, Loss: 0.5233, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 081, Loss: 0.5081, Val Acc: 0.7117, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 082, Loss: 0.5045, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 083, Loss: 0.5245, Val Acc: 0.7207, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 084, Loss: 0.5231, Val Acc: 0.7477, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 085, Loss: 0.5079, Val Acc: 0.7207, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 086, Loss: 0.5042, Val Acc: 0.7117, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 087, Loss: 0.5055, Val Acc: 0.7297, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 088, Loss: 0.5032, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 089, Loss: 0.5040, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 090, Loss: 0.5013, Val Acc: 0.7297, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 091, Loss: 0.5011, Val Acc: 0.7117, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 092, Loss: 0.4980, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 093, Loss: 0.4972, Val Acc: 0.7117, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 094, Loss: 0.4951, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 095, Loss: 0.4928, Val Acc: 0.7387, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 096, Loss: 0.4902, Val Acc: 0.7297, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 097, Loss: 0.4895, Val Acc: 0.7117, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 098, Loss: 0.4925, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 099, Loss: 0.4910, Val Acc: 0.7297, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 100, Loss: 0.4889, Val Acc: 0.7297, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 101, Loss: 0.4874, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 102, Loss: 0.4831, Val Acc: 0.6847, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 103, Loss: 0.5004, Val Acc: 0.7027, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 104, Loss: 0.5183, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 105, Loss: 0.4988, Val Acc: 0.7207, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 106, Loss: 0.4869, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 107, Loss: 0.5141, Val Acc: 0.7207, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 108, Loss: 0.5031, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 109, Loss: 0.4817, Val Acc: 0.7207, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 110, Loss: 0.4957, Val Acc: 0.6847, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 111, Loss: 0.5252, Val Acc: 0.6937, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 112, Loss: 0.5059, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 113, Loss: 0.4798, Val Acc: 0.7117, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 114, Loss: 0.4800, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 115, Loss: 0.4903, Val Acc: 0.7207, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 116, Loss: 0.4795, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 117, Loss: 0.4753, Val Acc: 0.7117, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 118, Loss: 0.4744, Val Acc: 0.7117, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 119, Loss: 0.4741, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 120, Loss: 0.4739, Val Acc: 0.6847, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 121, Loss: 0.4818, Val Acc: 0.6847, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 122, Loss: 0.4770, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 123, Loss: 0.4719, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 124, Loss: 0.4703, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 125, Loss: 0.4703, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 126, Loss: 0.4718, Val Acc: 0.7207, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 127, Loss: 0.4913, Val Acc: 0.7027, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 128, Loss: 0.4698, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 43, Epoch: 129, Loss: 0.4807, Val Acc: 0.7117, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 130, Loss: 0.4844, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 131, Loss: 0.4747, Val Acc: 0.7207, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 132, Loss: 0.5046, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 133, Loss: 0.4735, Val Acc: 0.6937, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 134, Loss: 0.4984, Val Acc: 0.6847, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 135, Loss: 0.5005, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 43, Epoch: 136, Loss: 0.4755, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 137, Loss: 0.4851, Val Acc: 0.7207, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 138, Loss: 0.4886, Val Acc: 0.6937, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 139, Loss: 0.4712, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 140, Loss: 0.4710, Val Acc: 0.6847, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 141, Loss: 0.4792, Val Acc: 0.6847, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 142, Loss: 0.4761, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 143, Loss: 0.4660, Val Acc: 0.6937, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 144, Loss: 0.4697, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 145, Loss: 0.4648, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 146, Loss: 0.4646, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 147, Loss: 0.4727, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 148, Loss: 0.4890, Val Acc: 0.7117, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 149, Loss: 0.4729, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 150, Loss: 0.4693, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 151, Loss: 0.4891, Val Acc: 0.6937, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 152, Loss: 0.4871, Val Acc: 0.7207, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 153, Loss: 0.4730, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 154, Loss: 0.4695, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 155, Loss: 0.4690, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 156, Loss: 0.4654, Val Acc: 0.7027, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 157, Loss: 0.4700, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 158, Loss: 0.4892, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 159, Loss: 0.4741, Val Acc: 0.6937, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 160, Loss: 0.4620, Val Acc: 0.6847, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 161, Loss: 0.4635, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 162, Loss: 0.4633, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 163, Loss: 0.4782, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 164, Loss: 0.4594, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 165, Loss: 0.4633, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 43, Epoch: 166, Loss: 0.4613, Val Acc: 0.7207, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 167, Loss: 0.4600, Val Acc: 0.7027, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 168, Loss: 0.4591, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 169, Loss: 0.4573, Val Acc: 0.7117, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 170, Loss: 0.4558, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 171, Loss: 0.4537, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 172, Loss: 0.4546, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 173, Loss: 0.4554, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 174, Loss: 0.4555, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 175, Loss: 0.4566, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Early stopping at epoch 175 for seed 43\n",
      "Seed: 44, Epoch: 001, Loss: 0.6940, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 002, Loss: 0.6921, Val Acc: 0.5315, Test Acc: 0.5946\n",
      "Seed: 44, Epoch: 003, Loss: 0.6905, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 004, Loss: 0.6893, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 005, Loss: 0.6883, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 006, Loss: 0.6873, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 007, Loss: 0.6858, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 008, Loss: 0.6843, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 009, Loss: 0.6830, Val Acc: 0.5766, Test Acc: 0.6486\n",
      "Seed: 44, Epoch: 010, Loss: 0.6822, Val Acc: 0.6306, Test Acc: 0.6847\n",
      "Seed: 44, Epoch: 011, Loss: 0.6805, Val Acc: 0.5766, Test Acc: 0.6577\n",
      "Seed: 44, Epoch: 012, Loss: 0.6787, Val Acc: 0.5676, Test Acc: 0.6216\n",
      "Seed: 44, Epoch: 013, Loss: 0.6767, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 014, Loss: 0.6757, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 015, Loss: 0.6756, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 016, Loss: 0.6744, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 017, Loss: 0.6716, Val Acc: 0.5135, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 018, Loss: 0.6664, Val Acc: 0.6486, Test Acc: 0.6937\n",
      "Seed: 44, Epoch: 019, Loss: 0.6610, Val Acc: 0.6757, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 020, Loss: 0.6569, Val Acc: 0.7387, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 021, Loss: 0.6519, Val Acc: 0.7387, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 022, Loss: 0.6429, Val Acc: 0.6667, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 023, Loss: 0.6349, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 024, Loss: 0.6282, Val Acc: 0.7387, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 025, Loss: 0.6232, Val Acc: 0.7297, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 026, Loss: 0.6101, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 027, Loss: 0.6009, Val Acc: 0.7297, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 028, Loss: 0.6026, Val Acc: 0.7297, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 029, Loss: 0.5984, Val Acc: 0.6937, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 030, Loss: 0.5759, Val Acc: 0.6126, Test Acc: 0.6667\n",
      "Seed: 44, Epoch: 031, Loss: 0.6078, Val Acc: 0.6306, Test Acc: 0.6667\n",
      "Seed: 44, Epoch: 032, Loss: 0.5855, Val Acc: 0.6757, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 033, Loss: 0.5584, Val Acc: 0.7207, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 034, Loss: 0.5629, Val Acc: 0.7387, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 035, Loss: 0.6037, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 036, Loss: 0.5614, Val Acc: 0.6667, Test Acc: 0.7117\n",
      "Seed: 44, Epoch: 037, Loss: 0.5561, Val Acc: 0.6667, Test Acc: 0.6847\n",
      "Seed: 44, Epoch: 038, Loss: 0.5466, Val Acc: 0.7207, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 039, Loss: 0.5483, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 040, Loss: 0.5598, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 041, Loss: 0.5243, Val Acc: 0.6577, Test Acc: 0.6757\n",
      "Seed: 44, Epoch: 042, Loss: 0.5701, Val Acc: 0.6216, Test Acc: 0.6667\n",
      "Seed: 44, Epoch: 043, Loss: 0.5610, Val Acc: 0.6667, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 044, Loss: 0.5240, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 045, Loss: 0.5320, Val Acc: 0.7207, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 046, Loss: 0.5302, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 047, Loss: 0.5243, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 048, Loss: 0.5211, Val Acc: 0.6937, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 049, Loss: 0.5187, Val Acc: 0.6757, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 050, Loss: 0.5157, Val Acc: 0.6757, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 051, Loss: 0.5152, Val Acc: 0.6757, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 052, Loss: 0.5126, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 053, Loss: 0.5073, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 054, Loss: 0.5071, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 055, Loss: 0.5061, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 056, Loss: 0.4979, Val Acc: 0.6667, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 057, Loss: 0.4975, Val Acc: 0.6847, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 058, Loss: 0.5086, Val Acc: 0.6757, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 059, Loss: 0.4951, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 060, Loss: 0.5024, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 061, Loss: 0.5246, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 062, Loss: 0.4933, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 063, Loss: 0.4812, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 064, Loss: 0.5007, Val Acc: 0.6847, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 065, Loss: 0.4992, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 066, Loss: 0.5196, Val Acc: 0.6667, Test Acc: 0.6757\n",
      "Seed: 44, Epoch: 067, Loss: 0.5266, Val Acc: 0.6937, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 068, Loss: 0.4818, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 069, Loss: 0.5055, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 070, Loss: 0.4981, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 071, Loss: 0.4828, Val Acc: 0.6486, Test Acc: 0.6847\n",
      "Seed: 44, Epoch: 072, Loss: 0.5613, Val Acc: 0.6757, Test Acc: 0.6937\n",
      "Seed: 44, Epoch: 073, Loss: 0.5032, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 074, Loss: 0.4951, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 075, Loss: 0.5372, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 076, Loss: 0.4831, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 077, Loss: 0.5056, Val Acc: 0.6757, Test Acc: 0.7027\n",
      "Seed: 44, Epoch: 078, Loss: 0.5057, Val Acc: 0.7027, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 079, Loss: 0.4869, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 080, Loss: 0.5012, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 081, Loss: 0.4947, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 082, Loss: 0.4876, Val Acc: 0.7027, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 083, Loss: 0.4777, Val Acc: 0.6937, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 084, Loss: 0.4821, Val Acc: 0.7027, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 085, Loss: 0.4756, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 086, Loss: 0.4712, Val Acc: 0.6937, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 087, Loss: 0.4719, Val Acc: 0.6937, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 088, Loss: 0.4734, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 089, Loss: 0.4825, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 090, Loss: 0.5176, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 091, Loss: 0.4984, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 092, Loss: 0.4697, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 093, Loss: 0.4910, Val Acc: 0.7297, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 094, Loss: 0.4786, Val Acc: 0.7207, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 095, Loss: 0.4666, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 096, Loss: 0.4744, Val Acc: 0.7207, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 097, Loss: 0.4732, Val Acc: 0.7207, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 098, Loss: 0.4832, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 099, Loss: 0.4710, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 100, Loss: 0.4693, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 101, Loss: 0.4592, Val Acc: 0.7117, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 102, Loss: 0.4721, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 103, Loss: 0.4629, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 104, Loss: 0.4802, Val Acc: 0.7027, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 105, Loss: 0.4713, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 106, Loss: 0.4574, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 107, Loss: 0.4630, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 108, Loss: 0.4575, Val Acc: 0.7027, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 109, Loss: 0.4879, Val Acc: 0.7027, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 110, Loss: 0.4932, Val Acc: 0.7027, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 111, Loss: 0.4562, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 112, Loss: 0.4690, Val Acc: 0.7207, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 113, Loss: 0.4848, Val Acc: 0.7117, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 114, Loss: 0.4672, Val Acc: 0.7297, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 115, Loss: 0.4566, Val Acc: 0.7027, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 116, Loss: 0.4550, Val Acc: 0.7027, Test Acc: 0.7838\n",
      "Seed: 44, Epoch: 117, Loss: 0.4653, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 118, Loss: 0.4761, Val Acc: 0.7027, Test Acc: 0.7838\n",
      "Seed: 44, Epoch: 119, Loss: 0.4598, Val Acc: 0.7117, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 120, Loss: 0.4506, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 121, Loss: 0.4528, Val Acc: 0.7117, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 122, Loss: 0.4514, Val Acc: 0.7117, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 123, Loss: 0.4505, Val Acc: 0.7117, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 124, Loss: 0.4491, Val Acc: 0.6937, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 125, Loss: 0.4588, Val Acc: 0.6937, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 126, Loss: 0.4530, Val Acc: 0.7117, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 127, Loss: 0.4504, Val Acc: 0.7027, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 128, Loss: 0.4543, Val Acc: 0.7117, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 129, Loss: 0.4444, Val Acc: 0.6937, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 130, Loss: 0.4517, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 131, Loss: 0.4773, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 132, Loss: 0.4756, Val Acc: 0.7117, Test Acc: 0.7838\n",
      "Seed: 44, Epoch: 133, Loss: 0.4399, Val Acc: 0.7207, Test Acc: 0.7117\n",
      "Seed: 44, Epoch: 134, Loss: 0.4944, Val Acc: 0.7117, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 135, Loss: 0.4582, Val Acc: 0.6937, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 136, Loss: 0.4598, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 137, Loss: 0.4759, Val Acc: 0.7027, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 138, Loss: 0.4413, Val Acc: 0.7207, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 139, Loss: 0.4829, Val Acc: 0.7207, Test Acc: 0.7117\n",
      "Seed: 44, Epoch: 140, Loss: 0.4714, Val Acc: 0.7117, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 141, Loss: 0.4460, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 142, Loss: 0.5046, Val Acc: 0.6937, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 143, Loss: 0.4596, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 144, Loss: 0.4411, Val Acc: 0.6937, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 145, Loss: 0.4679, Val Acc: 0.6757, Test Acc: 0.7838\n",
      "Seed: 44, Epoch: 146, Loss: 0.4458, Val Acc: 0.7117, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 147, Loss: 0.4374, Val Acc: 0.7117, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 148, Loss: 0.4384, Val Acc: 0.7207, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 149, Loss: 0.4359, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 150, Loss: 0.4332, Val Acc: 0.7207, Test Acc: 0.7838\n",
      "Seed: 44, Epoch: 151, Loss: 0.4327, Val Acc: 0.7207, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 152, Loss: 0.4407, Val Acc: 0.7117, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 153, Loss: 0.4373, Val Acc: 0.7117, Test Acc: 0.7838\n",
      "Seed: 44, Epoch: 154, Loss: 0.4386, Val Acc: 0.6937, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 155, Loss: 0.4417, Val Acc: 0.7117, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 156, Loss: 0.4295, Val Acc: 0.7027, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 157, Loss: 0.4444, Val Acc: 0.6937, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 158, Loss: 0.4522, Val Acc: 0.7117, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 159, Loss: 0.4322, Val Acc: 0.6937, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 160, Loss: 0.4709, Val Acc: 0.6847, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 161, Loss: 0.4425, Val Acc: 0.7207, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 162, Loss: 0.4252, Val Acc: 0.6937, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 163, Loss: 0.4491, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 164, Loss: 0.4740, Val Acc: 0.7027, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 165, Loss: 0.4239, Val Acc: 0.6847, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 166, Loss: 0.4451, Val Acc: 0.7207, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 167, Loss: 0.4195, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 168, Loss: 0.4499, Val Acc: 0.7027, Test Acc: 0.7838\n",
      "Seed: 44, Epoch: 169, Loss: 0.4224, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 170, Loss: 0.4502, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Early stopping at epoch 170 for seed 44\n",
      "Average Time: 180.66 seconds\n",
      "Var Time: 398.32 seconds\n",
      "Average Memory: 38817.33 MB\n",
      "Average Best Val Acc: 0.7748\n",
      "Std Best Test Acc: 0.0236\n",
      "Average Test Acc: 0.7447\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "max_nodes = 500\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"DD\",\n",
    "    transform=T.Compose([T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "dataset = dataset_dense\n",
    "dataset = dataset.shuffle()\n",
    "N = 150\n",
    "mp_layers = 1\n",
    "mp_channels = 64\n",
    "mp_activation = \"relu\"\n",
    "delta_coeff = 2.0\n",
    "\n",
    "mlp_hidden_layers = 2\n",
    "mlp_hidden_channels = 32\n",
    "mlp_activation = \"relu\"\n",
    "totvar_coeff = 0.5\n",
    "balance_coeff = 0.5\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 5e-4\n",
    "l2_reg_val = 0\n",
    "patience = 10\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        if self.lin is not None:\n",
    "            x = self.lin(x).relu()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_AsymCheegerCut(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset.num_classes)\n",
    "\n",
    "        self.pool1 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "        self.pool2 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool1(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool2(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB-BINARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6961, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 002, Loss: 0.6955, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 003, Loss: 0.6948, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 004, Loss: 0.6943, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 005, Loss: 0.6935, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 006, Loss: 0.6928, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 007, Loss: 0.6917, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 008, Loss: 0.6904, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 009, Loss: 0.6888, Val Acc: 0.5267, Test Acc: 0.5533\n",
      "Seed: 42, Epoch: 010, Loss: 0.6865, Val Acc: 0.6200, Test Acc: 0.7067\n",
      "Seed: 42, Epoch: 011, Loss: 0.6833, Val Acc: 0.7133, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 012, Loss: 0.6789, Val Acc: 0.7467, Test Acc: 0.8133\n",
      "Seed: 42, Epoch: 013, Loss: 0.6725, Val Acc: 0.7667, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 014, Loss: 0.6652, Val Acc: 0.7800, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 015, Loss: 0.6555, Val Acc: 0.7800, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 016, Loss: 0.6430, Val Acc: 0.7733, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 017, Loss: 0.6278, Val Acc: 0.7733, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 018, Loss: 0.6109, Val Acc: 0.7867, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 019, Loss: 0.5904, Val Acc: 0.7933, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 020, Loss: 0.5718, Val Acc: 0.7933, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 021, Loss: 0.5526, Val Acc: 0.7867, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 022, Loss: 0.5373, Val Acc: 0.7933, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 023, Loss: 0.5276, Val Acc: 0.8000, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 024, Loss: 0.5236, Val Acc: 0.7867, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 025, Loss: 0.5188, Val Acc: 0.8000, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 026, Loss: 0.5104, Val Acc: 0.8000, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 027, Loss: 0.5091, Val Acc: 0.8133, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 028, Loss: 0.5043, Val Acc: 0.8000, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 029, Loss: 0.5042, Val Acc: 0.8133, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 030, Loss: 0.4994, Val Acc: 0.8000, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 031, Loss: 0.4974, Val Acc: 0.8000, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 032, Loss: 0.4946, Val Acc: 0.8000, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 033, Loss: 0.4953, Val Acc: 0.8067, Test Acc: 0.8133\n",
      "Seed: 42, Epoch: 034, Loss: 0.4937, Val Acc: 0.7933, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 035, Loss: 0.4892, Val Acc: 0.8133, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 036, Loss: 0.4879, Val Acc: 0.8067, Test Acc: 0.8133\n",
      "Seed: 42, Epoch: 037, Loss: 0.4859, Val Acc: 0.7933, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 038, Loss: 0.4835, Val Acc: 0.8000, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 039, Loss: 0.4812, Val Acc: 0.8067, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 040, Loss: 0.4791, Val Acc: 0.8000, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 041, Loss: 0.4773, Val Acc: 0.8000, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 042, Loss: 0.4747, Val Acc: 0.8000, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 043, Loss: 0.4728, Val Acc: 0.8000, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 044, Loss: 0.4714, Val Acc: 0.7933, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 045, Loss: 0.4696, Val Acc: 0.8067, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 046, Loss: 0.4685, Val Acc: 0.7933, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 047, Loss: 0.4673, Val Acc: 0.7933, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 048, Loss: 0.4641, Val Acc: 0.7933, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 049, Loss: 0.4640, Val Acc: 0.8133, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 050, Loss: 0.4613, Val Acc: 0.8000, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 051, Loss: 0.4581, Val Acc: 0.8000, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 052, Loss: 0.4576, Val Acc: 0.8000, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 053, Loss: 0.4558, Val Acc: 0.7933, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 054, Loss: 0.4546, Val Acc: 0.8067, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 055, Loss: 0.4520, Val Acc: 0.7933, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 056, Loss: 0.4495, Val Acc: 0.7933, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 057, Loss: 0.4497, Val Acc: 0.7800, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 058, Loss: 0.4496, Val Acc: 0.7933, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 059, Loss: 0.4445, Val Acc: 0.8067, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 060, Loss: 0.4451, Val Acc: 0.7800, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 061, Loss: 0.4465, Val Acc: 0.8133, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 062, Loss: 0.4415, Val Acc: 0.7933, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 063, Loss: 0.4399, Val Acc: 0.7800, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 064, Loss: 0.4360, Val Acc: 0.8133, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 065, Loss: 0.4346, Val Acc: 0.7867, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 066, Loss: 0.4351, Val Acc: 0.8000, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 067, Loss: 0.4430, Val Acc: 0.8000, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 068, Loss: 0.4313, Val Acc: 0.7733, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 069, Loss: 0.4339, Val Acc: 0.8000, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 070, Loss: 0.4313, Val Acc: 0.7800, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 071, Loss: 0.4344, Val Acc: 0.7867, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 072, Loss: 0.4263, Val Acc: 0.7933, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 073, Loss: 0.4263, Val Acc: 0.7800, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 074, Loss: 0.4295, Val Acc: 0.8000, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 075, Loss: 0.4256, Val Acc: 0.7933, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 076, Loss: 0.4270, Val Acc: 0.7800, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 077, Loss: 0.4203, Val Acc: 0.7933, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 078, Loss: 0.4252, Val Acc: 0.7933, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 079, Loss: 0.4198, Val Acc: 0.7800, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 080, Loss: 0.4182, Val Acc: 0.8133, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 081, Loss: 0.4183, Val Acc: 0.7800, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 082, Loss: 0.4151, Val Acc: 0.8067, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 083, Loss: 0.4160, Val Acc: 0.7867, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 084, Loss: 0.4127, Val Acc: 0.7800, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 085, Loss: 0.4134, Val Acc: 0.8067, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 086, Loss: 0.4140, Val Acc: 0.8067, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 087, Loss: 0.4084, Val Acc: 0.7733, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 088, Loss: 0.4127, Val Acc: 0.7733, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 089, Loss: 0.4129, Val Acc: 0.8067, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 090, Loss: 0.4114, Val Acc: 0.7867, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 091, Loss: 0.4070, Val Acc: 0.7800, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 092, Loss: 0.4055, Val Acc: 0.7733, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 093, Loss: 0.4064, Val Acc: 0.7867, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 094, Loss: 0.4032, Val Acc: 0.8000, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 095, Loss: 0.4021, Val Acc: 0.7867, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 096, Loss: 0.4028, Val Acc: 0.7867, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 097, Loss: 0.4005, Val Acc: 0.7867, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 098, Loss: 0.4006, Val Acc: 0.7933, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 099, Loss: 0.3981, Val Acc: 0.7733, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 100, Loss: 0.3979, Val Acc: 0.7867, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 101, Loss: 0.3982, Val Acc: 0.7800, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 102, Loss: 0.3958, Val Acc: 0.7867, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 103, Loss: 0.3965, Val Acc: 0.7800, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 104, Loss: 0.3932, Val Acc: 0.7800, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 105, Loss: 0.3921, Val Acc: 0.7800, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 106, Loss: 0.3937, Val Acc: 0.7800, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 107, Loss: 0.3945, Val Acc: 0.7800, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 108, Loss: 0.3884, Val Acc: 0.7733, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 109, Loss: 0.3911, Val Acc: 0.7667, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 110, Loss: 0.3896, Val Acc: 0.7867, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 111, Loss: 0.3881, Val Acc: 0.7800, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 112, Loss: 0.3856, Val Acc: 0.7800, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 113, Loss: 0.3851, Val Acc: 0.7800, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 114, Loss: 0.3836, Val Acc: 0.7667, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 115, Loss: 0.3835, Val Acc: 0.7733, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 116, Loss: 0.3840, Val Acc: 0.7667, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 117, Loss: 0.3817, Val Acc: 0.7733, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 118, Loss: 0.3798, Val Acc: 0.7667, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 119, Loss: 0.3800, Val Acc: 0.7667, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 120, Loss: 0.3811, Val Acc: 0.7733, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 121, Loss: 0.3772, Val Acc: 0.7733, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 122, Loss: 0.3780, Val Acc: 0.7667, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 123, Loss: 0.3753, Val Acc: 0.7667, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 124, Loss: 0.3743, Val Acc: 0.7667, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 125, Loss: 0.3749, Val Acc: 0.7667, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 126, Loss: 0.3732, Val Acc: 0.7667, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 127, Loss: 0.3717, Val Acc: 0.7667, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 128, Loss: 0.3712, Val Acc: 0.7600, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 129, Loss: 0.3711, Val Acc: 0.7600, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 130, Loss: 0.3709, Val Acc: 0.7667, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 131, Loss: 0.3709, Val Acc: 0.7600, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 132, Loss: 0.3682, Val Acc: 0.7600, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 133, Loss: 0.3667, Val Acc: 0.7533, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 134, Loss: 0.3694, Val Acc: 0.7400, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 135, Loss: 0.3702, Val Acc: 0.7467, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 136, Loss: 0.3720, Val Acc: 0.7333, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 137, Loss: 0.3705, Val Acc: 0.7467, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 138, Loss: 0.3731, Val Acc: 0.7400, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 139, Loss: 0.3757, Val Acc: 0.7533, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 140, Loss: 0.3713, Val Acc: 0.7467, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 141, Loss: 0.3706, Val Acc: 0.7533, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 142, Loss: 0.3631, Val Acc: 0.7600, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 143, Loss: 0.3674, Val Acc: 0.7533, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 144, Loss: 0.3633, Val Acc: 0.7533, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 145, Loss: 0.3562, Val Acc: 0.7267, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 146, Loss: 0.3640, Val Acc: 0.7467, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 147, Loss: 0.3580, Val Acc: 0.7267, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 148, Loss: 0.3647, Val Acc: 0.7467, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 149, Loss: 0.3587, Val Acc: 0.7467, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 150, Loss: 0.3574, Val Acc: 0.7400, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 151, Loss: 0.3532, Val Acc: 0.7400, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 152, Loss: 0.3539, Val Acc: 0.7400, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 153, Loss: 0.3534, Val Acc: 0.7333, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 154, Loss: 0.3509, Val Acc: 0.7467, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 155, Loss: 0.3498, Val Acc: 0.7400, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 156, Loss: 0.3542, Val Acc: 0.7400, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 157, Loss: 0.3545, Val Acc: 0.7267, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 158, Loss: 0.3600, Val Acc: 0.7267, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 159, Loss: 0.3567, Val Acc: 0.7267, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 160, Loss: 0.3559, Val Acc: 0.7467, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 161, Loss: 0.3501, Val Acc: 0.7400, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 162, Loss: 0.3543, Val Acc: 0.7400, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 163, Loss: 0.3463, Val Acc: 0.7267, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 164, Loss: 0.3477, Val Acc: 0.7200, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 165, Loss: 0.3425, Val Acc: 0.7267, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 166, Loss: 0.3421, Val Acc: 0.7267, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 167, Loss: 0.3456, Val Acc: 0.7267, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 168, Loss: 0.3448, Val Acc: 0.7333, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 169, Loss: 0.3411, Val Acc: 0.7267, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 170, Loss: 0.3388, Val Acc: 0.7333, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 171, Loss: 0.3395, Val Acc: 0.7400, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 172, Loss: 0.3421, Val Acc: 0.7400, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 173, Loss: 0.3408, Val Acc: 0.7267, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 174, Loss: 0.3375, Val Acc: 0.7400, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 175, Loss: 0.3343, Val Acc: 0.7333, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 176, Loss: 0.3344, Val Acc: 0.7267, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 177, Loss: 0.3357, Val Acc: 0.7400, Test Acc: 0.7600\n",
      "Early stopping at epoch 177 for seed 42\n",
      "Seed: 43, Epoch: 001, Loss: 0.6983, Val Acc: 0.5867, Test Acc: 0.5400\n",
      "Seed: 43, Epoch: 002, Loss: 0.6967, Val Acc: 0.5867, Test Acc: 0.5400\n",
      "Seed: 43, Epoch: 003, Loss: 0.6953, Val Acc: 0.5867, Test Acc: 0.5400\n",
      "Seed: 43, Epoch: 004, Loss: 0.6937, Val Acc: 0.5867, Test Acc: 0.5400\n",
      "Seed: 43, Epoch: 005, Loss: 0.6921, Val Acc: 0.6000, Test Acc: 0.5333\n",
      "Seed: 43, Epoch: 006, Loss: 0.6908, Val Acc: 0.6867, Test Acc: 0.7000\n",
      "Seed: 43, Epoch: 007, Loss: 0.6892, Val Acc: 0.6333, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 008, Loss: 0.6870, Val Acc: 0.6200, Test Acc: 0.6867\n",
      "Seed: 43, Epoch: 009, Loss: 0.6841, Val Acc: 0.6200, Test Acc: 0.6733\n",
      "Seed: 43, Epoch: 010, Loss: 0.6804, Val Acc: 0.6267, Test Acc: 0.6867\n",
      "Seed: 43, Epoch: 011, Loss: 0.6754, Val Acc: 0.6333, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 012, Loss: 0.6694, Val Acc: 0.6333, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 013, Loss: 0.6615, Val Acc: 0.6467, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 014, Loss: 0.6510, Val Acc: 0.6600, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 015, Loss: 0.6378, Val Acc: 0.6533, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 016, Loss: 0.6205, Val Acc: 0.6600, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 017, Loss: 0.6000, Val Acc: 0.6533, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 018, Loss: 0.5761, Val Acc: 0.6667, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 019, Loss: 0.5516, Val Acc: 0.6800, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 020, Loss: 0.5272, Val Acc: 0.6933, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 021, Loss: 0.5098, Val Acc: 0.6867, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 022, Loss: 0.4976, Val Acc: 0.6933, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 023, Loss: 0.4929, Val Acc: 0.6733, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 024, Loss: 0.4851, Val Acc: 0.6600, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 025, Loss: 0.4813, Val Acc: 0.6667, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 026, Loss: 0.4769, Val Acc: 0.6667, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 027, Loss: 0.4740, Val Acc: 0.6733, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 028, Loss: 0.4720, Val Acc: 0.6733, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 029, Loss: 0.4712, Val Acc: 0.6667, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 030, Loss: 0.4657, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 031, Loss: 0.4670, Val Acc: 0.6667, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 032, Loss: 0.4623, Val Acc: 0.6800, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 033, Loss: 0.4619, Val Acc: 0.6867, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 034, Loss: 0.4572, Val Acc: 0.6667, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 035, Loss: 0.4569, Val Acc: 0.6733, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 036, Loss: 0.4536, Val Acc: 0.6733, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 037, Loss: 0.4520, Val Acc: 0.6733, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 038, Loss: 0.4496, Val Acc: 0.6800, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 039, Loss: 0.4480, Val Acc: 0.6800, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 040, Loss: 0.4472, Val Acc: 0.6667, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 041, Loss: 0.4442, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 042, Loss: 0.4418, Val Acc: 0.6800, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 043, Loss: 0.4392, Val Acc: 0.6667, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 044, Loss: 0.4379, Val Acc: 0.6733, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 045, Loss: 0.4359, Val Acc: 0.6800, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 046, Loss: 0.4372, Val Acc: 0.6733, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 047, Loss: 0.4313, Val Acc: 0.6600, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 048, Loss: 0.4387, Val Acc: 0.6667, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 049, Loss: 0.4369, Val Acc: 0.6800, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 050, Loss: 0.4323, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 051, Loss: 0.4303, Val Acc: 0.6600, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 052, Loss: 0.4270, Val Acc: 0.6867, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 053, Loss: 0.4289, Val Acc: 0.6867, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 054, Loss: 0.4241, Val Acc: 0.6667, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 055, Loss: 0.4259, Val Acc: 0.6667, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 056, Loss: 0.4241, Val Acc: 0.6733, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 057, Loss: 0.4212, Val Acc: 0.6733, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 058, Loss: 0.4204, Val Acc: 0.6667, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 059, Loss: 0.4208, Val Acc: 0.6667, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 060, Loss: 0.4177, Val Acc: 0.6733, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 061, Loss: 0.4165, Val Acc: 0.6667, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 062, Loss: 0.4144, Val Acc: 0.6667, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 063, Loss: 0.4133, Val Acc: 0.6667, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 064, Loss: 0.4117, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 065, Loss: 0.4115, Val Acc: 0.6667, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 066, Loss: 0.4145, Val Acc: 0.6600, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 067, Loss: 0.4113, Val Acc: 0.6867, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 068, Loss: 0.4094, Val Acc: 0.6600, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 069, Loss: 0.4093, Val Acc: 0.6600, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 070, Loss: 0.4096, Val Acc: 0.6800, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 071, Loss: 0.4114, Val Acc: 0.6600, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 072, Loss: 0.4055, Val Acc: 0.6800, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 073, Loss: 0.4056, Val Acc: 0.6733, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 074, Loss: 0.4024, Val Acc: 0.6600, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 075, Loss: 0.4013, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 076, Loss: 0.4017, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 077, Loss: 0.4056, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 078, Loss: 0.3966, Val Acc: 0.6867, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 079, Loss: 0.4032, Val Acc: 0.6867, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 080, Loss: 0.3979, Val Acc: 0.6800, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 081, Loss: 0.3947, Val Acc: 0.6600, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 082, Loss: 0.3957, Val Acc: 0.6667, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 083, Loss: 0.3919, Val Acc: 0.6733, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 084, Loss: 0.3931, Val Acc: 0.6667, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 085, Loss: 0.3918, Val Acc: 0.6667, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 086, Loss: 0.3892, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 087, Loss: 0.3894, Val Acc: 0.6600, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 088, Loss: 0.3878, Val Acc: 0.6667, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 089, Loss: 0.3854, Val Acc: 0.6867, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 090, Loss: 0.3861, Val Acc: 0.6600, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 091, Loss: 0.3848, Val Acc: 0.6667, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 092, Loss: 0.3825, Val Acc: 0.6867, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 093, Loss: 0.3851, Val Acc: 0.6667, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 094, Loss: 0.3856, Val Acc: 0.6600, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 095, Loss: 0.3803, Val Acc: 0.6867, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 096, Loss: 0.3807, Val Acc: 0.6733, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 097, Loss: 0.3794, Val Acc: 0.6800, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 098, Loss: 0.3764, Val Acc: 0.6867, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 099, Loss: 0.3775, Val Acc: 0.6800, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 100, Loss: 0.3782, Val Acc: 0.6933, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 101, Loss: 0.3834, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 102, Loss: 0.3800, Val Acc: 0.6733, Test Acc: 0.6933\n",
      "Seed: 43, Epoch: 103, Loss: 0.3835, Val Acc: 0.6933, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 104, Loss: 0.3702, Val Acc: 0.6733, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 105, Loss: 0.3854, Val Acc: 0.6933, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 106, Loss: 0.3764, Val Acc: 0.6867, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 107, Loss: 0.3741, Val Acc: 0.6800, Test Acc: 0.7000\n",
      "Seed: 43, Epoch: 108, Loss: 0.3685, Val Acc: 0.6867, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 109, Loss: 0.3718, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 110, Loss: 0.3765, Val Acc: 0.6867, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 111, Loss: 0.3681, Val Acc: 0.6933, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 112, Loss: 0.3673, Val Acc: 0.6733, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 113, Loss: 0.3684, Val Acc: 0.6933, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 114, Loss: 0.3683, Val Acc: 0.6933, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 115, Loss: 0.3683, Val Acc: 0.6800, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 116, Loss: 0.3621, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 117, Loss: 0.3610, Val Acc: 0.6867, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 118, Loss: 0.3599, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 119, Loss: 0.3580, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 120, Loss: 0.3562, Val Acc: 0.6800, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 121, Loss: 0.3559, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 122, Loss: 0.3610, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 123, Loss: 0.3547, Val Acc: 0.6733, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 124, Loss: 0.3531, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 125, Loss: 0.3526, Val Acc: 0.6867, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 126, Loss: 0.3518, Val Acc: 0.6867, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 127, Loss: 0.3489, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 128, Loss: 0.3524, Val Acc: 0.6800, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 129, Loss: 0.3522, Val Acc: 0.6867, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 130, Loss: 0.3455, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 131, Loss: 0.3532, Val Acc: 0.6800, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 132, Loss: 0.3468, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 133, Loss: 0.3464, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 134, Loss: 0.3451, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 135, Loss: 0.3464, Val Acc: 0.6733, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 136, Loss: 0.3471, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 137, Loss: 0.3446, Val Acc: 0.6667, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 138, Loss: 0.3461, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 139, Loss: 0.3398, Val Acc: 0.6667, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 140, Loss: 0.3407, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 141, Loss: 0.3410, Val Acc: 0.6733, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 142, Loss: 0.3373, Val Acc: 0.6867, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 143, Loss: 0.3393, Val Acc: 0.6733, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 144, Loss: 0.3377, Val Acc: 0.6867, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 145, Loss: 0.3374, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 146, Loss: 0.3401, Val Acc: 0.6667, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 147, Loss: 0.3346, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 148, Loss: 0.3303, Val Acc: 0.6600, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 149, Loss: 0.3331, Val Acc: 0.6933, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 150, Loss: 0.3354, Val Acc: 0.6800, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 151, Loss: 0.3362, Val Acc: 0.6667, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 152, Loss: 0.3322, Val Acc: 0.6933, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 153, Loss: 0.3318, Val Acc: 0.6667, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 154, Loss: 0.3319, Val Acc: 0.7067, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 155, Loss: 0.3275, Val Acc: 0.6667, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 156, Loss: 0.3319, Val Acc: 0.6800, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 157, Loss: 0.3313, Val Acc: 0.6667, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 158, Loss: 0.3304, Val Acc: 0.6600, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 159, Loss: 0.3280, Val Acc: 0.6933, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 160, Loss: 0.3213, Val Acc: 0.6667, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 161, Loss: 0.3265, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 162, Loss: 0.3233, Val Acc: 0.6533, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 163, Loss: 0.3204, Val Acc: 0.6867, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 164, Loss: 0.3199, Val Acc: 0.6600, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 165, Loss: 0.3178, Val Acc: 0.6533, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 166, Loss: 0.3207, Val Acc: 0.6600, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 167, Loss: 0.3192, Val Acc: 0.6600, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 168, Loss: 0.3151, Val Acc: 0.6867, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 169, Loss: 0.3173, Val Acc: 0.6600, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 170, Loss: 0.3135, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 171, Loss: 0.3149, Val Acc: 0.6600, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 172, Loss: 0.3150, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 173, Loss: 0.3223, Val Acc: 0.6733, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 174, Loss: 0.3233, Val Acc: 0.6800, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 175, Loss: 0.3198, Val Acc: 0.6733, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 176, Loss: 0.3172, Val Acc: 0.6667, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 177, Loss: 0.3134, Val Acc: 0.6867, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 178, Loss: 0.3120, Val Acc: 0.6667, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 179, Loss: 0.3139, Val Acc: 0.7000, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 180, Loss: 0.3110, Val Acc: 0.6733, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 181, Loss: 0.3157, Val Acc: 0.6867, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 182, Loss: 0.3096, Val Acc: 0.6667, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 183, Loss: 0.3051, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 184, Loss: 0.3073, Val Acc: 0.6600, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 185, Loss: 0.3063, Val Acc: 0.6800, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 186, Loss: 0.3036, Val Acc: 0.6600, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 187, Loss: 0.3030, Val Acc: 0.6933, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 188, Loss: 0.3073, Val Acc: 0.6667, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 189, Loss: 0.3037, Val Acc: 0.6733, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 190, Loss: 0.3011, Val Acc: 0.6733, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 191, Loss: 0.2990, Val Acc: 0.6733, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 192, Loss: 0.2981, Val Acc: 0.6933, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 193, Loss: 0.3001, Val Acc: 0.6600, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 194, Loss: 0.3011, Val Acc: 0.6800, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 195, Loss: 0.3015, Val Acc: 0.6733, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 196, Loss: 0.2970, Val Acc: 0.6733, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 197, Loss: 0.2994, Val Acc: 0.6867, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 198, Loss: 0.2973, Val Acc: 0.6533, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 199, Loss: 0.3042, Val Acc: 0.6867, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 200, Loss: 0.3130, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 001, Loss: 0.6938, Val Acc: 0.4600, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 002, Loss: 0.6929, Val Acc: 0.4600, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 003, Loss: 0.6921, Val Acc: 0.4600, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 004, Loss: 0.6910, Val Acc: 0.4600, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 005, Loss: 0.6899, Val Acc: 0.4667, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 006, Loss: 0.6884, Val Acc: 0.4867, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 007, Loss: 0.6862, Val Acc: 0.5533, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 008, Loss: 0.6834, Val Acc: 0.6333, Test Acc: 0.6200\n",
      "Seed: 44, Epoch: 009, Loss: 0.6794, Val Acc: 0.6533, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 010, Loss: 0.6745, Val Acc: 0.6667, Test Acc: 0.6867\n",
      "Seed: 44, Epoch: 011, Loss: 0.6684, Val Acc: 0.6667, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 012, Loss: 0.6609, Val Acc: 0.6933, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 013, Loss: 0.6520, Val Acc: 0.7267, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 014, Loss: 0.6399, Val Acc: 0.7267, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 015, Loss: 0.6253, Val Acc: 0.7333, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 016, Loss: 0.6091, Val Acc: 0.7400, Test Acc: 0.6867\n",
      "Seed: 44, Epoch: 017, Loss: 0.5906, Val Acc: 0.7333, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 018, Loss: 0.5700, Val Acc: 0.7533, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 019, Loss: 0.5493, Val Acc: 0.7400, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 020, Loss: 0.5294, Val Acc: 0.7533, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 021, Loss: 0.5150, Val Acc: 0.7600, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 022, Loss: 0.5041, Val Acc: 0.7800, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 023, Loss: 0.4969, Val Acc: 0.7733, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 024, Loss: 0.4926, Val Acc: 0.7800, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 025, Loss: 0.4852, Val Acc: 0.7867, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 026, Loss: 0.4804, Val Acc: 0.7800, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 027, Loss: 0.4758, Val Acc: 0.7800, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 028, Loss: 0.4728, Val Acc: 0.7733, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 029, Loss: 0.4714, Val Acc: 0.7800, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 030, Loss: 0.4715, Val Acc: 0.7800, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 031, Loss: 0.4690, Val Acc: 0.7533, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 032, Loss: 0.4676, Val Acc: 0.7800, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 033, Loss: 0.4632, Val Acc: 0.7800, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 034, Loss: 0.4627, Val Acc: 0.7733, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 035, Loss: 0.4593, Val Acc: 0.7867, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 036, Loss: 0.4576, Val Acc: 0.7800, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 037, Loss: 0.4561, Val Acc: 0.7800, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 038, Loss: 0.4541, Val Acc: 0.7867, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 039, Loss: 0.4525, Val Acc: 0.7800, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 040, Loss: 0.4511, Val Acc: 0.7933, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 041, Loss: 0.4488, Val Acc: 0.8000, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 042, Loss: 0.4472, Val Acc: 0.7800, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 043, Loss: 0.4492, Val Acc: 0.7800, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 044, Loss: 0.4494, Val Acc: 0.8133, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 045, Loss: 0.4437, Val Acc: 0.7733, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 046, Loss: 0.4456, Val Acc: 0.7867, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 047, Loss: 0.4395, Val Acc: 0.7867, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 048, Loss: 0.4383, Val Acc: 0.7867, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 049, Loss: 0.4407, Val Acc: 0.7800, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 050, Loss: 0.4349, Val Acc: 0.7733, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 051, Loss: 0.4335, Val Acc: 0.7800, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 052, Loss: 0.4326, Val Acc: 0.7867, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 053, Loss: 0.4301, Val Acc: 0.7867, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 054, Loss: 0.4287, Val Acc: 0.7800, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 055, Loss: 0.4276, Val Acc: 0.7867, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 056, Loss: 0.4280, Val Acc: 0.7800, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 057, Loss: 0.4238, Val Acc: 0.7867, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 058, Loss: 0.4233, Val Acc: 0.7800, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 059, Loss: 0.4206, Val Acc: 0.7800, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 060, Loss: 0.4206, Val Acc: 0.7800, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 061, Loss: 0.4173, Val Acc: 0.7800, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 062, Loss: 0.4179, Val Acc: 0.7800, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 063, Loss: 0.4165, Val Acc: 0.7800, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 064, Loss: 0.4150, Val Acc: 0.7867, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 065, Loss: 0.4162, Val Acc: 0.7800, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 066, Loss: 0.4111, Val Acc: 0.7800, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 067, Loss: 0.4117, Val Acc: 0.7867, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 068, Loss: 0.4097, Val Acc: 0.7800, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 069, Loss: 0.4079, Val Acc: 0.7667, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 070, Loss: 0.4062, Val Acc: 0.7733, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 071, Loss: 0.4055, Val Acc: 0.7867, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 072, Loss: 0.4059, Val Acc: 0.7867, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 073, Loss: 0.4083, Val Acc: 0.7867, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 074, Loss: 0.4058, Val Acc: 0.7800, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 075, Loss: 0.4041, Val Acc: 0.7667, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 076, Loss: 0.4031, Val Acc: 0.7933, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 077, Loss: 0.4052, Val Acc: 0.7867, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 078, Loss: 0.3966, Val Acc: 0.7733, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 079, Loss: 0.3993, Val Acc: 0.7867, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 080, Loss: 0.4040, Val Acc: 0.7933, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 081, Loss: 0.3939, Val Acc: 0.7667, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 082, Loss: 0.3968, Val Acc: 0.7800, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 083, Loss: 0.3939, Val Acc: 0.7933, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 084, Loss: 0.3941, Val Acc: 0.7933, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 085, Loss: 0.3936, Val Acc: 0.7800, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 086, Loss: 0.3924, Val Acc: 0.7867, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 087, Loss: 0.3926, Val Acc: 0.7867, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 088, Loss: 0.3886, Val Acc: 0.7800, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 089, Loss: 0.3872, Val Acc: 0.7867, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 090, Loss: 0.3883, Val Acc: 0.7800, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 091, Loss: 0.3877, Val Acc: 0.7800, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 092, Loss: 0.3891, Val Acc: 0.7867, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 093, Loss: 0.3878, Val Acc: 0.7800, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 094, Loss: 0.3836, Val Acc: 0.7800, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 095, Loss: 0.3828, Val Acc: 0.7867, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 096, Loss: 0.3811, Val Acc: 0.7867, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 097, Loss: 0.3795, Val Acc: 0.7800, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 098, Loss: 0.3799, Val Acc: 0.7867, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 099, Loss: 0.3838, Val Acc: 0.7733, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 100, Loss: 0.3777, Val Acc: 0.7867, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 101, Loss: 0.3764, Val Acc: 0.7333, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 102, Loss: 0.3823, Val Acc: 0.7867, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 103, Loss: 0.3838, Val Acc: 0.7867, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 104, Loss: 0.3795, Val Acc: 0.7333, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 105, Loss: 0.3780, Val Acc: 0.7867, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 106, Loss: 0.3864, Val Acc: 0.7733, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 107, Loss: 0.3866, Val Acc: 0.7333, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 108, Loss: 0.3763, Val Acc: 0.7933, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 109, Loss: 0.3816, Val Acc: 0.7867, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 110, Loss: 0.3699, Val Acc: 0.7400, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 111, Loss: 0.3729, Val Acc: 0.7867, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 112, Loss: 0.3765, Val Acc: 0.7667, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 113, Loss: 0.3690, Val Acc: 0.7267, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 114, Loss: 0.3693, Val Acc: 0.7800, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 115, Loss: 0.3696, Val Acc: 0.7733, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 116, Loss: 0.3659, Val Acc: 0.7400, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 117, Loss: 0.3675, Val Acc: 0.7533, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 118, Loss: 0.3652, Val Acc: 0.7467, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 119, Loss: 0.3628, Val Acc: 0.7467, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 120, Loss: 0.3628, Val Acc: 0.7733, Test Acc: 0.6867\n",
      "Seed: 44, Epoch: 121, Loss: 0.3615, Val Acc: 0.7467, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 122, Loss: 0.3614, Val Acc: 0.7467, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 123, Loss: 0.3588, Val Acc: 0.7533, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 124, Loss: 0.3578, Val Acc: 0.7533, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 125, Loss: 0.3570, Val Acc: 0.7467, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 126, Loss: 0.3563, Val Acc: 0.7467, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 127, Loss: 0.3544, Val Acc: 0.7467, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 128, Loss: 0.3585, Val Acc: 0.7467, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 129, Loss: 0.3599, Val Acc: 0.7467, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 130, Loss: 0.3591, Val Acc: 0.7333, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 131, Loss: 0.3534, Val Acc: 0.7533, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 132, Loss: 0.3576, Val Acc: 0.7267, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 133, Loss: 0.3598, Val Acc: 0.7400, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 134, Loss: 0.3654, Val Acc: 0.7467, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 135, Loss: 0.3513, Val Acc: 0.7333, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 136, Loss: 0.3578, Val Acc: 0.7800, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 137, Loss: 0.3573, Val Acc: 0.7267, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 138, Loss: 0.3618, Val Acc: 0.7467, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 139, Loss: 0.3566, Val Acc: 0.7667, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 140, Loss: 0.3473, Val Acc: 0.7333, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 141, Loss: 0.3487, Val Acc: 0.7667, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 142, Loss: 0.3503, Val Acc: 0.7400, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 143, Loss: 0.3550, Val Acc: 0.7400, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 144, Loss: 0.3459, Val Acc: 0.7733, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 145, Loss: 0.3451, Val Acc: 0.7267, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 146, Loss: 0.3500, Val Acc: 0.7267, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 147, Loss: 0.3472, Val Acc: 0.7267, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 148, Loss: 0.3382, Val Acc: 0.7400, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 149, Loss: 0.3433, Val Acc: 0.7400, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 150, Loss: 0.3386, Val Acc: 0.7400, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 151, Loss: 0.3378, Val Acc: 0.7333, Test Acc: 0.6867\n",
      "Seed: 44, Epoch: 152, Loss: 0.3430, Val Acc: 0.7267, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 153, Loss: 0.3362, Val Acc: 0.7267, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 154, Loss: 0.3361, Val Acc: 0.7333, Test Acc: 0.6867\n",
      "Seed: 44, Epoch: 155, Loss: 0.3407, Val Acc: 0.7400, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 156, Loss: 0.3347, Val Acc: 0.7400, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 157, Loss: 0.3327, Val Acc: 0.7333, Test Acc: 0.6800\n",
      "Seed: 44, Epoch: 158, Loss: 0.3312, Val Acc: 0.7333, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 159, Loss: 0.3319, Val Acc: 0.7333, Test Acc: 0.6800\n",
      "Seed: 44, Epoch: 160, Loss: 0.3325, Val Acc: 0.7267, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 161, Loss: 0.3276, Val Acc: 0.7333, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 162, Loss: 0.3294, Val Acc: 0.7467, Test Acc: 0.6800\n",
      "Seed: 44, Epoch: 163, Loss: 0.3288, Val Acc: 0.7400, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 164, Loss: 0.3323, Val Acc: 0.7400, Test Acc: 0.6733\n",
      "Seed: 44, Epoch: 165, Loss: 0.3311, Val Acc: 0.7333, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 166, Loss: 0.3285, Val Acc: 0.7400, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 167, Loss: 0.3229, Val Acc: 0.7400, Test Acc: 0.6667\n",
      "Seed: 44, Epoch: 168, Loss: 0.3359, Val Acc: 0.7467, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 169, Loss: 0.3228, Val Acc: 0.7467, Test Acc: 0.6800\n",
      "Seed: 44, Epoch: 170, Loss: 0.3251, Val Acc: 0.7400, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 171, Loss: 0.3242, Val Acc: 0.7400, Test Acc: 0.6733\n",
      "Seed: 44, Epoch: 172, Loss: 0.3256, Val Acc: 0.7333, Test Acc: 0.6733\n",
      "Seed: 44, Epoch: 173, Loss: 0.3203, Val Acc: 0.7400, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 174, Loss: 0.3215, Val Acc: 0.7333, Test Acc: 0.6867\n",
      "Seed: 44, Epoch: 175, Loss: 0.3220, Val Acc: 0.7333, Test Acc: 0.6867\n",
      "Seed: 44, Epoch: 176, Loss: 0.3201, Val Acc: 0.7333, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 177, Loss: 0.3273, Val Acc: 0.7467, Test Acc: 0.6733\n",
      "Seed: 44, Epoch: 178, Loss: 0.3180, Val Acc: 0.7267, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 179, Loss: 0.3247, Val Acc: 0.7267, Test Acc: 0.6733\n",
      "Seed: 44, Epoch: 180, Loss: 0.3261, Val Acc: 0.7467, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 181, Loss: 0.3149, Val Acc: 0.7267, Test Acc: 0.6867\n",
      "Seed: 44, Epoch: 182, Loss: 0.3341, Val Acc: 0.7400, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 183, Loss: 0.3257, Val Acc: 0.7267, Test Acc: 0.6600\n",
      "Seed: 44, Epoch: 184, Loss: 0.3202, Val Acc: 0.7333, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 185, Loss: 0.3153, Val Acc: 0.7400, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 186, Loss: 0.3143, Val Acc: 0.7333, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 187, Loss: 0.3127, Val Acc: 0.7333, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 188, Loss: 0.3148, Val Acc: 0.7467, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 189, Loss: 0.3128, Val Acc: 0.7467, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 190, Loss: 0.3136, Val Acc: 0.7400, Test Acc: 0.6800\n",
      "Seed: 44, Epoch: 191, Loss: 0.3150, Val Acc: 0.7333, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 192, Loss: 0.3105, Val Acc: 0.7333, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 193, Loss: 0.3104, Val Acc: 0.7400, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 194, Loss: 0.3069, Val Acc: 0.7467, Test Acc: 0.6933\n",
      "Early stopping at epoch 194 for seed 44\n",
      "Average Time: 261.12 seconds\n",
      "Var Time: 79.10 seconds\n",
      "Average Memory: 57170.00 MB\n",
      "Average Best Val Acc: 0.7778\n",
      "Std Best Test Acc: 0.0314\n",
      "Average Test Acc: 0.7489\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "max_nodes = 500\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"IMDB-BINARY\",\n",
    "    transform=T.Compose([T.OneHotDegree(136), T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "dataset = dataset_dense\n",
    "dataset = dataset.shuffle()\n",
    "N = 150\n",
    "mp_layers = 1\n",
    "mp_channels = 64\n",
    "mp_activation = \"relu\"\n",
    "delta_coeff = 2.0\n",
    "\n",
    "mlp_hidden_layers = 1\n",
    "mlp_hidden_channels = 64\n",
    "mlp_activation = \"relu\"\n",
    "totvar_coeff = 0.5\n",
    "balance_coeff = 0.5\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 5e-4\n",
    "l2_reg_val = 0\n",
    "patience = 10\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        if self.lin is not None:\n",
    "            x = self.lin(x).relu()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_AsymCheegerCut(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset.num_classes)\n",
    "\n",
    "        self.pool1 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "        self.pool2 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool1(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool2(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_AsymCheegerCut().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "    model = Net_AsymCheegerCut().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB-MULTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 1.0991, Val Acc: 0.2711, Test Acc: 0.3511\n",
      "Seed: 42, Epoch: 002, Loss: 1.0980, Val Acc: 0.2711, Test Acc: 0.3511\n",
      "Seed: 42, Epoch: 003, Loss: 1.0972, Val Acc: 0.2711, Test Acc: 0.3511\n",
      "Seed: 42, Epoch: 004, Loss: 1.0962, Val Acc: 0.2711, Test Acc: 0.3511\n",
      "Seed: 42, Epoch: 005, Loss: 1.0950, Val Acc: 0.2844, Test Acc: 0.3689\n",
      "Seed: 42, Epoch: 006, Loss: 1.0934, Val Acc: 0.3111, Test Acc: 0.3822\n",
      "Seed: 42, Epoch: 007, Loss: 1.0912, Val Acc: 0.3022, Test Acc: 0.3644\n",
      "Seed: 42, Epoch: 008, Loss: 1.0885, Val Acc: 0.4400, Test Acc: 0.4444\n",
      "Seed: 42, Epoch: 009, Loss: 1.0849, Val Acc: 0.4578, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 010, Loss: 1.0798, Val Acc: 0.4578, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 011, Loss: 1.0722, Val Acc: 0.4844, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 012, Loss: 1.0628, Val Acc: 0.4933, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 013, Loss: 1.0492, Val Acc: 0.4800, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 014, Loss: 1.0323, Val Acc: 0.4889, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 015, Loss: 1.0095, Val Acc: 0.4978, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 016, Loss: 0.9821, Val Acc: 0.4978, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 017, Loss: 0.9705, Val Acc: 0.4800, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 018, Loss: 0.9619, Val Acc: 0.4844, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 019, Loss: 0.9521, Val Acc: 0.4800, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 020, Loss: 0.9517, Val Acc: 0.4800, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 021, Loss: 0.9449, Val Acc: 0.4844, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 022, Loss: 0.9438, Val Acc: 0.4800, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 023, Loss: 0.9392, Val Acc: 0.4800, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 024, Loss: 0.9369, Val Acc: 0.4844, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 025, Loss: 0.9357, Val Acc: 0.4844, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 026, Loss: 0.9341, Val Acc: 0.4844, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 027, Loss: 0.9352, Val Acc: 0.4933, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 028, Loss: 0.9328, Val Acc: 0.4756, Test Acc: 0.5156\n",
      "Seed: 42, Epoch: 029, Loss: 0.9303, Val Acc: 0.4756, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 030, Loss: 0.9283, Val Acc: 0.4756, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 031, Loss: 0.9263, Val Acc: 0.4756, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 032, Loss: 0.9235, Val Acc: 0.4844, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 033, Loss: 0.9225, Val Acc: 0.4889, Test Acc: 0.5244\n",
      "Seed: 42, Epoch: 034, Loss: 0.9227, Val Acc: 0.4889, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 035, Loss: 0.9251, Val Acc: 0.4756, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 036, Loss: 0.9228, Val Acc: 0.4667, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 037, Loss: 0.9250, Val Acc: 0.4800, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 038, Loss: 0.9188, Val Acc: 0.4889, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 039, Loss: 0.9165, Val Acc: 0.4933, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 040, Loss: 0.9169, Val Acc: 0.4756, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 041, Loss: 0.9133, Val Acc: 0.4711, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 042, Loss: 0.9118, Val Acc: 0.4800, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 043, Loss: 0.9117, Val Acc: 0.4800, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 044, Loss: 0.9128, Val Acc: 0.4711, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 045, Loss: 0.9130, Val Acc: 0.4889, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 046, Loss: 0.9092, Val Acc: 0.4711, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 047, Loss: 0.9111, Val Acc: 0.4711, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 048, Loss: 0.9111, Val Acc: 0.4800, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 049, Loss: 0.9081, Val Acc: 0.4933, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 050, Loss: 0.9089, Val Acc: 0.4933, Test Acc: 0.5067\n",
      "Seed: 42, Epoch: 051, Loss: 0.9041, Val Acc: 0.4933, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 052, Loss: 0.9029, Val Acc: 0.4844, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 053, Loss: 0.9036, Val Acc: 0.4933, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 054, Loss: 0.9049, Val Acc: 0.4800, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 055, Loss: 0.9019, Val Acc: 0.4978, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 056, Loss: 0.9009, Val Acc: 0.4889, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 057, Loss: 0.8979, Val Acc: 0.4756, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 058, Loss: 0.8983, Val Acc: 0.4800, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 059, Loss: 0.8989, Val Acc: 0.4933, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 060, Loss: 0.8975, Val Acc: 0.5067, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 061, Loss: 0.8992, Val Acc: 0.4978, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 062, Loss: 0.8951, Val Acc: 0.4889, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 063, Loss: 0.8930, Val Acc: 0.4978, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 064, Loss: 0.8961, Val Acc: 0.4844, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 065, Loss: 0.8926, Val Acc: 0.4844, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 066, Loss: 0.8931, Val Acc: 0.4933, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 067, Loss: 0.8899, Val Acc: 0.4978, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 068, Loss: 0.8931, Val Acc: 0.4978, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 069, Loss: 0.8877, Val Acc: 0.4800, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 070, Loss: 0.8937, Val Acc: 0.4933, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 071, Loss: 0.8902, Val Acc: 0.4756, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 072, Loss: 0.8946, Val Acc: 0.4667, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 073, Loss: 0.8848, Val Acc: 0.4933, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 074, Loss: 0.8889, Val Acc: 0.4889, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 075, Loss: 0.8894, Val Acc: 0.4933, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 076, Loss: 0.8869, Val Acc: 0.4800, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 077, Loss: 0.8854, Val Acc: 0.5022, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 078, Loss: 0.8848, Val Acc: 0.4844, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 079, Loss: 0.8819, Val Acc: 0.4756, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 080, Loss: 0.8837, Val Acc: 0.4844, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 081, Loss: 0.8925, Val Acc: 0.4889, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 082, Loss: 0.8892, Val Acc: 0.4844, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 083, Loss: 0.8822, Val Acc: 0.4800, Test Acc: 0.5067\n",
      "Seed: 42, Epoch: 084, Loss: 0.8813, Val Acc: 0.4933, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 085, Loss: 0.8800, Val Acc: 0.4889, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 086, Loss: 0.8791, Val Acc: 0.4933, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 087, Loss: 0.8771, Val Acc: 0.5022, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 088, Loss: 0.8807, Val Acc: 0.4889, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 089, Loss: 0.8793, Val Acc: 0.4978, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 090, Loss: 0.8809, Val Acc: 0.5022, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 091, Loss: 0.8771, Val Acc: 0.5022, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 092, Loss: 0.8723, Val Acc: 0.4889, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 093, Loss: 0.8748, Val Acc: 0.5022, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 094, Loss: 0.8726, Val Acc: 0.5156, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 095, Loss: 0.8746, Val Acc: 0.5200, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 096, Loss: 0.8756, Val Acc: 0.5111, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 097, Loss: 0.8716, Val Acc: 0.5067, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 098, Loss: 0.8689, Val Acc: 0.4933, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 099, Loss: 0.8703, Val Acc: 0.4889, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 100, Loss: 0.8715, Val Acc: 0.5111, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 101, Loss: 0.8676, Val Acc: 0.4889, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 102, Loss: 0.8681, Val Acc: 0.5067, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 103, Loss: 0.8696, Val Acc: 0.5022, Test Acc: 0.5067\n",
      "Seed: 42, Epoch: 104, Loss: 0.8679, Val Acc: 0.5067, Test Acc: 0.5067\n",
      "Seed: 42, Epoch: 105, Loss: 0.8677, Val Acc: 0.4933, Test Acc: 0.5067\n",
      "Seed: 42, Epoch: 106, Loss: 0.8678, Val Acc: 0.4978, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 107, Loss: 0.8748, Val Acc: 0.4978, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 108, Loss: 0.8658, Val Acc: 0.5022, Test Acc: 0.5111\n",
      "Seed: 42, Epoch: 109, Loss: 0.8685, Val Acc: 0.4933, Test Acc: 0.5067\n",
      "Seed: 42, Epoch: 110, Loss: 0.8605, Val Acc: 0.4978, Test Acc: 0.5111\n",
      "Seed: 42, Epoch: 111, Loss: 0.8618, Val Acc: 0.4800, Test Acc: 0.5111\n",
      "Seed: 42, Epoch: 112, Loss: 0.8635, Val Acc: 0.4756, Test Acc: 0.5156\n",
      "Seed: 42, Epoch: 113, Loss: 0.8633, Val Acc: 0.4844, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 114, Loss: 0.8623, Val Acc: 0.4933, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 115, Loss: 0.8621, Val Acc: 0.5022, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 116, Loss: 0.8601, Val Acc: 0.5111, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 117, Loss: 0.8634, Val Acc: 0.4978, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 118, Loss: 0.8569, Val Acc: 0.4978, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 119, Loss: 0.8576, Val Acc: 0.4933, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 120, Loss: 0.8624, Val Acc: 0.4889, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 121, Loss: 0.8607, Val Acc: 0.4889, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 122, Loss: 0.8607, Val Acc: 0.4844, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 123, Loss: 0.8615, Val Acc: 0.4889, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 124, Loss: 0.8533, Val Acc: 0.4933, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 125, Loss: 0.8596, Val Acc: 0.4978, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 126, Loss: 0.8556, Val Acc: 0.4844, Test Acc: 0.5156\n",
      "Seed: 42, Epoch: 127, Loss: 0.8527, Val Acc: 0.4800, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 128, Loss: 0.8531, Val Acc: 0.4889, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 129, Loss: 0.8506, Val Acc: 0.4933, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 130, Loss: 0.8597, Val Acc: 0.4800, Test Acc: 0.5111\n",
      "Seed: 42, Epoch: 131, Loss: 0.8514, Val Acc: 0.5067, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 132, Loss: 0.8527, Val Acc: 0.4844, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 133, Loss: 0.8472, Val Acc: 0.5022, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 134, Loss: 0.8555, Val Acc: 0.5022, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 135, Loss: 0.8461, Val Acc: 0.5111, Test Acc: 0.5111\n",
      "Seed: 42, Epoch: 136, Loss: 0.8560, Val Acc: 0.5067, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 137, Loss: 0.8487, Val Acc: 0.4844, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 138, Loss: 0.8526, Val Acc: 0.5067, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 139, Loss: 0.8519, Val Acc: 0.4756, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 140, Loss: 0.8495, Val Acc: 0.4756, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 141, Loss: 0.8463, Val Acc: 0.4844, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 142, Loss: 0.8444, Val Acc: 0.4889, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 143, Loss: 0.8421, Val Acc: 0.4978, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 144, Loss: 0.8434, Val Acc: 0.4756, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 145, Loss: 0.8427, Val Acc: 0.4933, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 146, Loss: 0.8441, Val Acc: 0.4978, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 147, Loss: 0.8389, Val Acc: 0.4889, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 148, Loss: 0.8433, Val Acc: 0.4978, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 149, Loss: 0.8433, Val Acc: 0.5022, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 150, Loss: 0.8364, Val Acc: 0.4800, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 151, Loss: 0.8424, Val Acc: 0.4800, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 152, Loss: 0.8389, Val Acc: 0.4800, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 153, Loss: 0.8374, Val Acc: 0.4756, Test Acc: 0.5067\n",
      "Seed: 42, Epoch: 154, Loss: 0.8422, Val Acc: 0.4933, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 155, Loss: 0.8479, Val Acc: 0.5067, Test Acc: 0.5111\n",
      "Seed: 42, Epoch: 156, Loss: 0.8501, Val Acc: 0.4933, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 157, Loss: 0.8517, Val Acc: 0.4844, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 158, Loss: 0.8371, Val Acc: 0.4978, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 159, Loss: 0.8411, Val Acc: 0.4978, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 160, Loss: 0.8405, Val Acc: 0.4844, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 161, Loss: 0.8337, Val Acc: 0.5022, Test Acc: 0.5067\n",
      "Seed: 42, Epoch: 162, Loss: 0.8366, Val Acc: 0.4622, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 163, Loss: 0.8335, Val Acc: 0.4844, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 164, Loss: 0.8299, Val Acc: 0.4800, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 165, Loss: 0.8311, Val Acc: 0.4844, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 166, Loss: 0.8292, Val Acc: 0.4800, Test Acc: 0.5111\n",
      "Seed: 42, Epoch: 167, Loss: 0.8311, Val Acc: 0.4667, Test Acc: 0.5156\n",
      "Seed: 42, Epoch: 168, Loss: 0.8284, Val Acc: 0.4889, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 169, Loss: 0.8370, Val Acc: 0.4756, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 170, Loss: 0.8394, Val Acc: 0.4756, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 171, Loss: 0.8388, Val Acc: 0.4711, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 172, Loss: 0.8342, Val Acc: 0.4756, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 173, Loss: 0.8299, Val Acc: 0.4889, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 174, Loss: 0.8289, Val Acc: 0.4844, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 175, Loss: 0.8319, Val Acc: 0.4978, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 176, Loss: 0.8327, Val Acc: 0.4978, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 177, Loss: 0.8325, Val Acc: 0.4844, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 178, Loss: 0.8275, Val Acc: 0.4756, Test Acc: 0.5067\n",
      "Seed: 42, Epoch: 179, Loss: 0.8271, Val Acc: 0.4756, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 180, Loss: 0.8273, Val Acc: 0.4933, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 181, Loss: 0.8288, Val Acc: 0.4844, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 182, Loss: 0.8262, Val Acc: 0.5022, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 183, Loss: 0.8280, Val Acc: 0.4978, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 184, Loss: 0.8237, Val Acc: 0.4844, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 185, Loss: 0.8259, Val Acc: 0.4800, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 186, Loss: 0.8264, Val Acc: 0.4889, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 187, Loss: 0.8252, Val Acc: 0.4978, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 188, Loss: 0.8239, Val Acc: 0.4978, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 189, Loss: 0.8258, Val Acc: 0.4978, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 190, Loss: 0.8246, Val Acc: 0.4933, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 191, Loss: 0.8246, Val Acc: 0.4622, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 192, Loss: 0.8285, Val Acc: 0.4889, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 193, Loss: 0.8232, Val Acc: 0.4933, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 194, Loss: 0.8237, Val Acc: 0.4933, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 195, Loss: 0.8228, Val Acc: 0.4889, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 196, Loss: 0.8412, Val Acc: 0.4978, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 197, Loss: 0.8208, Val Acc: 0.4800, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 198, Loss: 0.8202, Val Acc: 0.4889, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 199, Loss: 0.8313, Val Acc: 0.4844, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 200, Loss: 0.8254, Val Acc: 0.4800, Test Acc: 0.4978\n",
      "Seed: 43, Epoch: 001, Loss: 1.1057, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 002, Loss: 1.1041, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 003, Loss: 1.1023, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 004, Loss: 1.1011, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 005, Loss: 1.0993, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 006, Loss: 1.0978, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 007, Loss: 1.0961, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 008, Loss: 1.0943, Val Acc: 0.3333, Test Acc: 0.3378\n",
      "Seed: 43, Epoch: 009, Loss: 1.0916, Val Acc: 0.4267, Test Acc: 0.3556\n",
      "Seed: 43, Epoch: 010, Loss: 1.0882, Val Acc: 0.4533, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 011, Loss: 1.0835, Val Acc: 0.4622, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 012, Loss: 1.0767, Val Acc: 0.4667, Test Acc: 0.4578\n",
      "Seed: 43, Epoch: 013, Loss: 1.0660, Val Acc: 0.4889, Test Acc: 0.4533\n",
      "Seed: 43, Epoch: 014, Loss: 1.0496, Val Acc: 0.5378, Test Acc: 0.4533\n",
      "Seed: 43, Epoch: 015, Loss: 1.0273, Val Acc: 0.5467, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 016, Loss: 0.9964, Val Acc: 0.5556, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 017, Loss: 0.9728, Val Acc: 0.5467, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 018, Loss: 0.9649, Val Acc: 0.5289, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 019, Loss: 0.9585, Val Acc: 0.5200, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 020, Loss: 0.9510, Val Acc: 0.5200, Test Acc: 0.4622\n",
      "Seed: 43, Epoch: 021, Loss: 0.9455, Val Acc: 0.5244, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 022, Loss: 0.9412, Val Acc: 0.5200, Test Acc: 0.4578\n",
      "Seed: 43, Epoch: 023, Loss: 0.9371, Val Acc: 0.5111, Test Acc: 0.4533\n",
      "Seed: 43, Epoch: 024, Loss: 0.9348, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 025, Loss: 0.9310, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 026, Loss: 0.9288, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 027, Loss: 0.9264, Val Acc: 0.5111, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 028, Loss: 0.9264, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 029, Loss: 0.9215, Val Acc: 0.5200, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 030, Loss: 0.9229, Val Acc: 0.5156, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 031, Loss: 0.9225, Val Acc: 0.5022, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 032, Loss: 0.9235, Val Acc: 0.5022, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 033, Loss: 0.9226, Val Acc: 0.5022, Test Acc: 0.4533\n",
      "Seed: 43, Epoch: 034, Loss: 0.9165, Val Acc: 0.5022, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 035, Loss: 0.9165, Val Acc: 0.5067, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 036, Loss: 0.9142, Val Acc: 0.5067, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 037, Loss: 0.9210, Val Acc: 0.5067, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 038, Loss: 0.9157, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 039, Loss: 0.9133, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 040, Loss: 0.9131, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 041, Loss: 0.9133, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 042, Loss: 0.9137, Val Acc: 0.5111, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 043, Loss: 0.9113, Val Acc: 0.5156, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 044, Loss: 0.9080, Val Acc: 0.5200, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 045, Loss: 0.9080, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 046, Loss: 0.9073, Val Acc: 0.5156, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 047, Loss: 0.9076, Val Acc: 0.5289, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 048, Loss: 0.9061, Val Acc: 0.4978, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 049, Loss: 0.9061, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 050, Loss: 0.9061, Val Acc: 0.4933, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 051, Loss: 0.9094, Val Acc: 0.5022, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 052, Loss: 0.9023, Val Acc: 0.5156, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 053, Loss: 0.9061, Val Acc: 0.5111, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 054, Loss: 0.9045, Val Acc: 0.5067, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 055, Loss: 0.9084, Val Acc: 0.5111, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 056, Loss: 0.9015, Val Acc: 0.5111, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 057, Loss: 0.9018, Val Acc: 0.5200, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 058, Loss: 0.8993, Val Acc: 0.5067, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 059, Loss: 0.9017, Val Acc: 0.5067, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 060, Loss: 0.8973, Val Acc: 0.5067, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 061, Loss: 0.9002, Val Acc: 0.5156, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 062, Loss: 0.9013, Val Acc: 0.5022, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 063, Loss: 0.8968, Val Acc: 0.5067, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 064, Loss: 0.8968, Val Acc: 0.5067, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 065, Loss: 0.8927, Val Acc: 0.5022, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 066, Loss: 0.8908, Val Acc: 0.5156, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 067, Loss: 0.8920, Val Acc: 0.5111, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 068, Loss: 0.8940, Val Acc: 0.5067, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 069, Loss: 0.8937, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 070, Loss: 0.8939, Val Acc: 0.5022, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 071, Loss: 0.8915, Val Acc: 0.5200, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 072, Loss: 0.8929, Val Acc: 0.5022, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 073, Loss: 0.8885, Val Acc: 0.5111, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 074, Loss: 0.8933, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 075, Loss: 0.8936, Val Acc: 0.4978, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 076, Loss: 0.8880, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 077, Loss: 0.8888, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 078, Loss: 0.8973, Val Acc: 0.5067, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 079, Loss: 0.8887, Val Acc: 0.4978, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 080, Loss: 0.8876, Val Acc: 0.4844, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 081, Loss: 0.8836, Val Acc: 0.5111, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 082, Loss: 0.8867, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 083, Loss: 0.8917, Val Acc: 0.4889, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 084, Loss: 0.8862, Val Acc: 0.4844, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 085, Loss: 0.8915, Val Acc: 0.4978, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 086, Loss: 0.8831, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 087, Loss: 0.8818, Val Acc: 0.5022, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 088, Loss: 0.8832, Val Acc: 0.5022, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 089, Loss: 0.8779, Val Acc: 0.5067, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 090, Loss: 0.8804, Val Acc: 0.5156, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 091, Loss: 0.8779, Val Acc: 0.4978, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 092, Loss: 0.8834, Val Acc: 0.4933, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 093, Loss: 0.8868, Val Acc: 0.4933, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 094, Loss: 0.8790, Val Acc: 0.5022, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 095, Loss: 0.8778, Val Acc: 0.5022, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 096, Loss: 0.8871, Val Acc: 0.4933, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 097, Loss: 0.8822, Val Acc: 0.5022, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 098, Loss: 0.8851, Val Acc: 0.5022, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 099, Loss: 0.8754, Val Acc: 0.4889, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 100, Loss: 0.8778, Val Acc: 0.5111, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 101, Loss: 0.8740, Val Acc: 0.5067, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 102, Loss: 0.8728, Val Acc: 0.5156, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 103, Loss: 0.8740, Val Acc: 0.5156, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 104, Loss: 0.8709, Val Acc: 0.5200, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 105, Loss: 0.8704, Val Acc: 0.4978, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 106, Loss: 0.8706, Val Acc: 0.4978, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 107, Loss: 0.8718, Val Acc: 0.5111, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 108, Loss: 0.8715, Val Acc: 0.5200, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 109, Loss: 0.8826, Val Acc: 0.5067, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 110, Loss: 0.8700, Val Acc: 0.4800, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 111, Loss: 0.8712, Val Acc: 0.5022, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 112, Loss: 0.8692, Val Acc: 0.5067, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 113, Loss: 0.8662, Val Acc: 0.4978, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 114, Loss: 0.8697, Val Acc: 0.5200, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 115, Loss: 0.8675, Val Acc: 0.5022, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 116, Loss: 0.8654, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 117, Loss: 0.8649, Val Acc: 0.5067, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 118, Loss: 0.8634, Val Acc: 0.5156, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 119, Loss: 0.8634, Val Acc: 0.5156, Test Acc: 0.4489\n",
      "Seed: 43, Epoch: 120, Loss: 0.8625, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 121, Loss: 0.8628, Val Acc: 0.5156, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 122, Loss: 0.8673, Val Acc: 0.5200, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 123, Loss: 0.8647, Val Acc: 0.4933, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 124, Loss: 0.8663, Val Acc: 0.5244, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 125, Loss: 0.8600, Val Acc: 0.5067, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 126, Loss: 0.8629, Val Acc: 0.5022, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 127, Loss: 0.8599, Val Acc: 0.5111, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 128, Loss: 0.8730, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 129, Loss: 0.8690, Val Acc: 0.5111, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 130, Loss: 0.8603, Val Acc: 0.5156, Test Acc: 0.4489\n",
      "Seed: 43, Epoch: 131, Loss: 0.8675, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 132, Loss: 0.8566, Val Acc: 0.5022, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 133, Loss: 0.8612, Val Acc: 0.5022, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 134, Loss: 0.8570, Val Acc: 0.5200, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 135, Loss: 0.8597, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 136, Loss: 0.8531, Val Acc: 0.5022, Test Acc: 0.4533\n",
      "Seed: 43, Epoch: 137, Loss: 0.8586, Val Acc: 0.5156, Test Acc: 0.4489\n",
      "Seed: 43, Epoch: 138, Loss: 0.8551, Val Acc: 0.5067, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 139, Loss: 0.8613, Val Acc: 0.5111, Test Acc: 0.4533\n",
      "Seed: 43, Epoch: 140, Loss: 0.8542, Val Acc: 0.5067, Test Acc: 0.4622\n",
      "Seed: 43, Epoch: 141, Loss: 0.8547, Val Acc: 0.5200, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 142, Loss: 0.8538, Val Acc: 0.5067, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 143, Loss: 0.8549, Val Acc: 0.5067, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 144, Loss: 0.8516, Val Acc: 0.5200, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 145, Loss: 0.8518, Val Acc: 0.5333, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 146, Loss: 0.8520, Val Acc: 0.5111, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 147, Loss: 0.8588, Val Acc: 0.4844, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 148, Loss: 0.8532, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 149, Loss: 0.8535, Val Acc: 0.5067, Test Acc: 0.4533\n",
      "Seed: 43, Epoch: 150, Loss: 0.8615, Val Acc: 0.5067, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 151, Loss: 0.8555, Val Acc: 0.5289, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 152, Loss: 0.8495, Val Acc: 0.5111, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 153, Loss: 0.8464, Val Acc: 0.5156, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 154, Loss: 0.8629, Val Acc: 0.5156, Test Acc: 0.4578\n",
      "Seed: 43, Epoch: 155, Loss: 0.8541, Val Acc: 0.5244, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 156, Loss: 0.8508, Val Acc: 0.5022, Test Acc: 0.4489\n",
      "Seed: 43, Epoch: 157, Loss: 0.8465, Val Acc: 0.4978, Test Acc: 0.4533\n",
      "Seed: 43, Epoch: 158, Loss: 0.8449, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 159, Loss: 0.8439, Val Acc: 0.5156, Test Acc: 0.4489\n",
      "Seed: 43, Epoch: 160, Loss: 0.8408, Val Acc: 0.5022, Test Acc: 0.4533\n",
      "Seed: 43, Epoch: 161, Loss: 0.8458, Val Acc: 0.5022, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 162, Loss: 0.8429, Val Acc: 0.5244, Test Acc: 0.4533\n",
      "Seed: 43, Epoch: 163, Loss: 0.8402, Val Acc: 0.5200, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 164, Loss: 0.8371, Val Acc: 0.5067, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 165, Loss: 0.8375, Val Acc: 0.5111, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 166, Loss: 0.8400, Val Acc: 0.4933, Test Acc: 0.4356\n",
      "Early stopping at epoch 166 for seed 43\n",
      "Seed: 44, Epoch: 001, Loss: 1.1090, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 002, Loss: 1.1065, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 003, Loss: 1.1043, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 004, Loss: 1.1020, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 005, Loss: 1.0994, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 006, Loss: 1.0967, Val Acc: 0.3689, Test Acc: 0.3378\n",
      "Seed: 44, Epoch: 007, Loss: 1.0942, Val Acc: 0.4311, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 008, Loss: 1.0906, Val Acc: 0.4400, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 009, Loss: 1.0859, Val Acc: 0.4400, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 010, Loss: 1.0793, Val Acc: 0.4578, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 011, Loss: 1.0711, Val Acc: 0.4578, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 012, Loss: 1.0584, Val Acc: 0.4844, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 013, Loss: 1.0424, Val Acc: 0.4844, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 014, Loss: 1.0203, Val Acc: 0.4756, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 015, Loss: 0.9956, Val Acc: 0.5022, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 016, Loss: 0.9795, Val Acc: 0.4800, Test Acc: 0.4667\n",
      "Seed: 44, Epoch: 017, Loss: 0.9741, Val Acc: 0.4844, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 018, Loss: 0.9641, Val Acc: 0.4933, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 019, Loss: 0.9627, Val Acc: 0.4933, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 020, Loss: 0.9565, Val Acc: 0.4800, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 021, Loss: 0.9530, Val Acc: 0.4844, Test Acc: 0.4844\n",
      "Seed: 44, Epoch: 022, Loss: 0.9517, Val Acc: 0.4756, Test Acc: 0.4844\n",
      "Seed: 44, Epoch: 023, Loss: 0.9479, Val Acc: 0.4667, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 024, Loss: 0.9443, Val Acc: 0.4667, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 025, Loss: 0.9411, Val Acc: 0.4978, Test Acc: 0.4844\n",
      "Seed: 44, Epoch: 026, Loss: 0.9399, Val Acc: 0.5022, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 027, Loss: 0.9360, Val Acc: 0.4756, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 028, Loss: 0.9378, Val Acc: 0.4667, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 029, Loss: 0.9370, Val Acc: 0.5156, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 030, Loss: 0.9365, Val Acc: 0.5200, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 031, Loss: 0.9341, Val Acc: 0.4711, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 032, Loss: 0.9296, Val Acc: 0.5156, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 033, Loss: 0.9290, Val Acc: 0.5200, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 034, Loss: 0.9293, Val Acc: 0.5022, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 035, Loss: 0.9290, Val Acc: 0.5067, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 036, Loss: 0.9249, Val Acc: 0.5111, Test Acc: 0.4844\n",
      "Seed: 44, Epoch: 037, Loss: 0.9291, Val Acc: 0.5200, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 038, Loss: 0.9204, Val Acc: 0.5111, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 039, Loss: 0.9232, Val Acc: 0.5289, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 040, Loss: 0.9210, Val Acc: 0.5111, Test Acc: 0.4800\n",
      "Seed: 44, Epoch: 041, Loss: 0.9206, Val Acc: 0.5156, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 042, Loss: 0.9226, Val Acc: 0.5156, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 043, Loss: 0.9167, Val Acc: 0.5156, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 044, Loss: 0.9179, Val Acc: 0.5244, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 045, Loss: 0.9165, Val Acc: 0.5244, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 046, Loss: 0.9169, Val Acc: 0.5244, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 047, Loss: 0.9142, Val Acc: 0.4933, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 048, Loss: 0.9141, Val Acc: 0.5111, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 049, Loss: 0.9147, Val Acc: 0.5067, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 050, Loss: 0.9082, Val Acc: 0.4978, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 051, Loss: 0.9212, Val Acc: 0.5022, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 052, Loss: 0.9106, Val Acc: 0.5200, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 053, Loss: 0.9129, Val Acc: 0.5244, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 054, Loss: 0.9065, Val Acc: 0.5067, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 055, Loss: 0.9093, Val Acc: 0.5111, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 056, Loss: 0.9030, Val Acc: 0.5067, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 057, Loss: 0.9074, Val Acc: 0.5244, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 058, Loss: 0.9113, Val Acc: 0.5022, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 059, Loss: 0.9120, Val Acc: 0.5244, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 060, Loss: 0.9059, Val Acc: 0.4800, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 061, Loss: 0.9059, Val Acc: 0.5200, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 062, Loss: 0.9028, Val Acc: 0.5333, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 063, Loss: 0.9039, Val Acc: 0.5244, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 064, Loss: 0.8990, Val Acc: 0.5111, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 065, Loss: 0.8980, Val Acc: 0.4978, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 066, Loss: 0.8978, Val Acc: 0.5022, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 067, Loss: 0.8955, Val Acc: 0.5200, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 068, Loss: 0.8957, Val Acc: 0.5022, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 069, Loss: 0.8952, Val Acc: 0.5244, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 070, Loss: 0.8965, Val Acc: 0.5200, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 071, Loss: 0.8951, Val Acc: 0.5200, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 072, Loss: 0.8911, Val Acc: 0.5022, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 073, Loss: 0.8916, Val Acc: 0.5067, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 074, Loss: 0.8915, Val Acc: 0.5244, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 075, Loss: 0.8921, Val Acc: 0.5067, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 076, Loss: 0.8888, Val Acc: 0.5156, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 077, Loss: 0.8933, Val Acc: 0.5244, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 078, Loss: 0.8892, Val Acc: 0.5067, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 079, Loss: 0.8883, Val Acc: 0.5111, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 080, Loss: 0.8900, Val Acc: 0.5111, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 081, Loss: 0.8886, Val Acc: 0.5022, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 082, Loss: 0.8838, Val Acc: 0.5156, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 083, Loss: 0.8843, Val Acc: 0.5156, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 084, Loss: 0.8840, Val Acc: 0.5067, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 085, Loss: 0.8926, Val Acc: 0.4978, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 086, Loss: 0.8878, Val Acc: 0.5067, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 087, Loss: 0.8857, Val Acc: 0.5067, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 088, Loss: 0.8854, Val Acc: 0.5067, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 089, Loss: 0.8819, Val Acc: 0.5111, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 090, Loss: 0.8896, Val Acc: 0.5067, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 091, Loss: 0.8868, Val Acc: 0.5022, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 092, Loss: 0.8844, Val Acc: 0.5111, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 093, Loss: 0.8807, Val Acc: 0.4978, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 094, Loss: 0.8789, Val Acc: 0.4978, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 095, Loss: 0.8861, Val Acc: 0.5022, Test Acc: 0.5644\n",
      "Seed: 44, Epoch: 096, Loss: 0.8778, Val Acc: 0.5067, Test Acc: 0.5644\n",
      "Seed: 44, Epoch: 097, Loss: 0.8752, Val Acc: 0.5022, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 098, Loss: 0.8892, Val Acc: 0.4844, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 099, Loss: 0.8798, Val Acc: 0.5022, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 100, Loss: 0.8770, Val Acc: 0.5111, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 101, Loss: 0.8783, Val Acc: 0.5156, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 102, Loss: 0.8749, Val Acc: 0.4933, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 103, Loss: 0.8761, Val Acc: 0.4978, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 104, Loss: 0.8770, Val Acc: 0.5111, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 105, Loss: 0.8759, Val Acc: 0.5022, Test Acc: 0.5600\n",
      "Seed: 44, Epoch: 106, Loss: 0.8706, Val Acc: 0.5067, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 107, Loss: 0.8779, Val Acc: 0.5111, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 108, Loss: 0.8788, Val Acc: 0.5067, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 109, Loss: 0.8732, Val Acc: 0.5022, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 110, Loss: 0.8782, Val Acc: 0.4978, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 111, Loss: 0.8724, Val Acc: 0.5067, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 112, Loss: 0.8733, Val Acc: 0.5111, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 113, Loss: 0.8815, Val Acc: 0.5022, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 114, Loss: 0.8706, Val Acc: 0.5022, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 115, Loss: 0.8713, Val Acc: 0.5067, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 116, Loss: 0.8686, Val Acc: 0.5067, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 117, Loss: 0.8726, Val Acc: 0.5022, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 118, Loss: 0.8639, Val Acc: 0.5067, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 119, Loss: 0.8665, Val Acc: 0.5022, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 120, Loss: 0.8675, Val Acc: 0.4978, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 121, Loss: 0.8645, Val Acc: 0.5067, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 122, Loss: 0.8725, Val Acc: 0.5156, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 123, Loss: 0.8678, Val Acc: 0.4889, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 124, Loss: 0.8694, Val Acc: 0.5111, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 125, Loss: 0.8650, Val Acc: 0.5111, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 126, Loss: 0.8695, Val Acc: 0.5067, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 127, Loss: 0.8667, Val Acc: 0.5111, Test Acc: 0.5644\n",
      "Seed: 44, Epoch: 128, Loss: 0.8613, Val Acc: 0.5022, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 129, Loss: 0.8605, Val Acc: 0.5111, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 130, Loss: 0.8635, Val Acc: 0.5111, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 131, Loss: 0.8643, Val Acc: 0.5022, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 132, Loss: 0.8587, Val Acc: 0.5022, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 133, Loss: 0.8589, Val Acc: 0.5067, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 134, Loss: 0.8629, Val Acc: 0.5022, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 135, Loss: 0.8593, Val Acc: 0.4978, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 136, Loss: 0.8617, Val Acc: 0.5067, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 137, Loss: 0.8583, Val Acc: 0.5067, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 138, Loss: 0.8567, Val Acc: 0.5067, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 139, Loss: 0.8565, Val Acc: 0.5022, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 140, Loss: 0.8565, Val Acc: 0.5022, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 141, Loss: 0.8576, Val Acc: 0.5022, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 142, Loss: 0.8570, Val Acc: 0.5067, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 143, Loss: 0.8570, Val Acc: 0.4978, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 144, Loss: 0.8561, Val Acc: 0.5022, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 145, Loss: 0.8547, Val Acc: 0.5067, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 146, Loss: 0.8583, Val Acc: 0.4978, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 147, Loss: 0.8593, Val Acc: 0.4933, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 148, Loss: 0.8601, Val Acc: 0.4933, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 149, Loss: 0.8571, Val Acc: 0.5111, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 150, Loss: 0.8524, Val Acc: 0.4978, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 151, Loss: 0.8524, Val Acc: 0.5067, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 152, Loss: 0.8539, Val Acc: 0.4889, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 153, Loss: 0.8565, Val Acc: 0.4933, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 154, Loss: 0.8533, Val Acc: 0.4978, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 155, Loss: 0.8488, Val Acc: 0.5067, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 156, Loss: 0.8519, Val Acc: 0.5111, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 157, Loss: 0.8482, Val Acc: 0.5111, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 158, Loss: 0.8483, Val Acc: 0.5067, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 159, Loss: 0.8522, Val Acc: 0.5156, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 160, Loss: 0.8472, Val Acc: 0.5022, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 161, Loss: 0.8479, Val Acc: 0.5022, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 162, Loss: 0.8513, Val Acc: 0.5200, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 163, Loss: 0.8473, Val Acc: 0.5111, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 164, Loss: 0.8459, Val Acc: 0.5067, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 165, Loss: 0.8470, Val Acc: 0.5111, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 166, Loss: 0.8478, Val Acc: 0.5067, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 167, Loss: 0.8508, Val Acc: 0.5022, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 168, Loss: 0.8445, Val Acc: 0.5156, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 169, Loss: 0.8449, Val Acc: 0.4978, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 170, Loss: 0.8463, Val Acc: 0.4933, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 171, Loss: 0.8493, Val Acc: 0.5067, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 172, Loss: 0.8418, Val Acc: 0.5111, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 173, Loss: 0.8419, Val Acc: 0.4933, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 174, Loss: 0.8376, Val Acc: 0.5067, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 175, Loss: 0.8428, Val Acc: 0.5022, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 176, Loss: 0.8490, Val Acc: 0.5022, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 177, Loss: 0.8418, Val Acc: 0.4844, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 178, Loss: 0.8474, Val Acc: 0.5022, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 179, Loss: 0.8442, Val Acc: 0.5022, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 180, Loss: 0.8429, Val Acc: 0.5067, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 181, Loss: 0.8509, Val Acc: 0.4978, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 182, Loss: 0.8448, Val Acc: 0.4889, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 183, Loss: 0.8499, Val Acc: 0.5022, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 184, Loss: 0.8415, Val Acc: 0.4800, Test Acc: 0.4756\n",
      "Seed: 44, Epoch: 185, Loss: 0.8474, Val Acc: 0.4978, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 186, Loss: 0.8369, Val Acc: 0.5022, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 187, Loss: 0.8390, Val Acc: 0.5200, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 188, Loss: 0.8498, Val Acc: 0.5067, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 189, Loss: 0.8378, Val Acc: 0.4933, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 190, Loss: 0.8459, Val Acc: 0.4933, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 191, Loss: 0.8325, Val Acc: 0.4933, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 192, Loss: 0.8348, Val Acc: 0.4933, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 193, Loss: 0.8318, Val Acc: 0.5022, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 194, Loss: 0.8385, Val Acc: 0.4978, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 195, Loss: 0.8429, Val Acc: 0.4800, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 196, Loss: 0.8393, Val Acc: 0.4933, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 197, Loss: 0.8341, Val Acc: 0.5022, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 198, Loss: 0.8349, Val Acc: 0.5111, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 199, Loss: 0.8312, Val Acc: 0.4800, Test Acc: 0.4800\n",
      "Seed: 44, Epoch: 200, Loss: 0.8384, Val Acc: 0.4933, Test Acc: 0.4844\n",
      "Average Time: 376.76 seconds\n",
      "Var Time: 915.65 seconds\n",
      "Average Memory: 59744.67 MB\n",
      "Average Best Val Acc: 0.5363\n",
      "Std Best Test Acc: 0.0363\n",
      "Average Test Acc: 0.4830\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "max_nodes = 500\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"IMDB-MULTI\",\n",
    "    transform=T.Compose([T.OneHotDegree(88), T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "dataset = dataset_dense\n",
    "dataset = dataset.shuffle()\n",
    "N = 150\n",
    "mp_layers = 1\n",
    "mp_channels = 64\n",
    "mp_activation = \"relu\"\n",
    "delta_coeff = 2.0\n",
    "\n",
    "mlp_hidden_layers = 1\n",
    "mlp_hidden_channels = 64\n",
    "mlp_activation = \"relu\"\n",
    "totvar_coeff = 0.5\n",
    "balance_coeff = 0.5\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 5e-4\n",
    "l2_reg_val = 0\n",
    "patience = 10\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        if self.lin is not None:\n",
    "            x = self.lin(x).relu()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_AsymCheegerCut(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset.num_classes)\n",
    "\n",
    "        self.pool1 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "        self.pool2 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool1(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool2(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_AsymCheegerCut().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "    model = Net_AsymCheegerCut().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 1.1174, Val Acc: 0.3213, Test Acc: 0.3320\n",
      "Seed: 42, Epoch: 002, Loss: 1.0731, Val Acc: 0.6147, Test Acc: 0.5920\n",
      "Seed: 42, Epoch: 003, Loss: 0.9545, Val Acc: 0.6200, Test Acc: 0.6347\n",
      "Seed: 42, Epoch: 004, Loss: 0.7622, Val Acc: 0.6547, Test Acc: 0.6587\n",
      "Seed: 42, Epoch: 005, Loss: 0.6128, Val Acc: 0.7013, Test Acc: 0.6853\n",
      "Seed: 42, Epoch: 006, Loss: 0.5629, Val Acc: 0.6800, Test Acc: 0.6787\n",
      "Seed: 42, Epoch: 007, Loss: 0.5361, Val Acc: 0.6813, Test Acc: 0.6880\n",
      "Seed: 42, Epoch: 008, Loss: 0.5134, Val Acc: 0.7147, Test Acc: 0.7000\n",
      "Seed: 42, Epoch: 009, Loss: 0.4925, Val Acc: 0.7320, Test Acc: 0.7320\n",
      "Seed: 42, Epoch: 010, Loss: 0.4791, Val Acc: 0.7627, Test Acc: 0.7227\n",
      "Seed: 42, Epoch: 011, Loss: 0.4664, Val Acc: 0.7613, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 012, Loss: 0.4536, Val Acc: 0.7867, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 013, Loss: 0.4537, Val Acc: 0.7613, Test Acc: 0.7213\n",
      "Seed: 42, Epoch: 014, Loss: 0.4442, Val Acc: 0.7760, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 015, Loss: 0.4330, Val Acc: 0.7813, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 016, Loss: 0.4278, Val Acc: 0.7893, Test Acc: 0.7413\n",
      "Seed: 42, Epoch: 017, Loss: 0.4187, Val Acc: 0.7867, Test Acc: 0.7493\n",
      "Seed: 42, Epoch: 018, Loss: 0.4138, Val Acc: 0.7880, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 019, Loss: 0.4063, Val Acc: 0.7840, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 020, Loss: 0.4013, Val Acc: 0.7853, Test Acc: 0.7573\n",
      "Seed: 42, Epoch: 021, Loss: 0.3968, Val Acc: 0.7880, Test Acc: 0.7640\n",
      "Seed: 42, Epoch: 022, Loss: 0.3944, Val Acc: 0.7907, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 023, Loss: 0.3888, Val Acc: 0.8013, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 024, Loss: 0.3852, Val Acc: 0.7987, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 025, Loss: 0.3890, Val Acc: 0.7813, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 026, Loss: 0.3856, Val Acc: 0.7933, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 027, Loss: 0.3718, Val Acc: 0.7853, Test Acc: 0.7640\n",
      "Seed: 42, Epoch: 028, Loss: 0.3687, Val Acc: 0.7973, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 029, Loss: 0.3656, Val Acc: 0.7907, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 030, Loss: 0.3592, Val Acc: 0.7640, Test Acc: 0.7507\n",
      "Seed: 42, Epoch: 031, Loss: 0.3538, Val Acc: 0.7813, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 032, Loss: 0.3554, Val Acc: 0.7853, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 033, Loss: 0.3582, Val Acc: 0.7960, Test Acc: 0.7853\n",
      "Seed: 42, Epoch: 034, Loss: 0.3503, Val Acc: 0.7907, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 035, Loss: 0.3400, Val Acc: 0.8093, Test Acc: 0.7813\n",
      "Seed: 42, Epoch: 036, Loss: 0.3372, Val Acc: 0.7973, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 037, Loss: 0.3300, Val Acc: 0.7947, Test Acc: 0.7827\n",
      "Seed: 42, Epoch: 038, Loss: 0.3254, Val Acc: 0.7800, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 039, Loss: 0.3250, Val Acc: 0.7893, Test Acc: 0.7840\n",
      "Seed: 42, Epoch: 040, Loss: 0.3184, Val Acc: 0.8013, Test Acc: 0.7947\n",
      "Seed: 42, Epoch: 041, Loss: 0.3167, Val Acc: 0.7933, Test Acc: 0.7787\n",
      "Seed: 42, Epoch: 042, Loss: 0.3102, Val Acc: 0.7840, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 043, Loss: 0.3187, Val Acc: 0.7840, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 044, Loss: 0.3111, Val Acc: 0.7973, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 045, Loss: 0.3026, Val Acc: 0.7987, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 046, Loss: 0.2972, Val Acc: 0.8000, Test Acc: 0.8027\n",
      "Seed: 42, Epoch: 047, Loss: 0.2910, Val Acc: 0.7800, Test Acc: 0.8093\n",
      "Seed: 42, Epoch: 048, Loss: 0.2898, Val Acc: 0.7987, Test Acc: 0.7973\n",
      "Seed: 42, Epoch: 049, Loss: 0.2854, Val Acc: 0.7813, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 050, Loss: 0.2790, Val Acc: 0.8160, Test Acc: 0.7920\n",
      "Seed: 42, Epoch: 051, Loss: 0.2792, Val Acc: 0.7933, Test Acc: 0.7813\n",
      "Seed: 42, Epoch: 052, Loss: 0.2773, Val Acc: 0.7747, Test Acc: 0.8080\n",
      "Seed: 42, Epoch: 053, Loss: 0.2700, Val Acc: 0.8000, Test Acc: 0.8093\n",
      "Seed: 42, Epoch: 054, Loss: 0.2650, Val Acc: 0.8147, Test Acc: 0.8027\n",
      "Seed: 42, Epoch: 055, Loss: 0.2613, Val Acc: 0.8040, Test Acc: 0.7907\n",
      "Seed: 42, Epoch: 056, Loss: 0.2584, Val Acc: 0.7827, Test Acc: 0.8107\n",
      "Seed: 42, Epoch: 057, Loss: 0.2562, Val Acc: 0.7973, Test Acc: 0.8027\n",
      "Seed: 42, Epoch: 058, Loss: 0.2495, Val Acc: 0.7933, Test Acc: 0.8107\n",
      "Seed: 42, Epoch: 059, Loss: 0.2502, Val Acc: 0.8027, Test Acc: 0.8093\n",
      "Seed: 42, Epoch: 060, Loss: 0.2436, Val Acc: 0.8053, Test Acc: 0.8040\n",
      "Seed: 42, Epoch: 061, Loss: 0.2582, Val Acc: 0.7973, Test Acc: 0.7907\n",
      "Seed: 42, Epoch: 062, Loss: 0.2390, Val Acc: 0.7813, Test Acc: 0.8053\n",
      "Seed: 42, Epoch: 063, Loss: 0.2385, Val Acc: 0.8027, Test Acc: 0.8107\n",
      "Seed: 42, Epoch: 064, Loss: 0.2348, Val Acc: 0.7973, Test Acc: 0.8107\n",
      "Seed: 42, Epoch: 065, Loss: 0.2287, Val Acc: 0.7947, Test Acc: 0.8080\n",
      "Seed: 42, Epoch: 066, Loss: 0.2380, Val Acc: 0.7933, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 067, Loss: 0.2393, Val Acc: 0.7853, Test Acc: 0.8040\n",
      "Seed: 42, Epoch: 068, Loss: 0.2262, Val Acc: 0.8053, Test Acc: 0.8053\n",
      "Seed: 42, Epoch: 069, Loss: 0.2219, Val Acc: 0.8040, Test Acc: 0.7987\n",
      "Seed: 42, Epoch: 070, Loss: 0.2267, Val Acc: 0.7987, Test Acc: 0.8147\n",
      "Seed: 42, Epoch: 071, Loss: 0.2171, Val Acc: 0.8000, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 072, Loss: 0.2186, Val Acc: 0.7987, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 073, Loss: 0.2132, Val Acc: 0.8067, Test Acc: 0.8053\n",
      "Seed: 42, Epoch: 074, Loss: 0.2070, Val Acc: 0.7960, Test Acc: 0.8093\n",
      "Seed: 42, Epoch: 075, Loss: 0.2076, Val Acc: 0.8000, Test Acc: 0.8027\n",
      "Seed: 42, Epoch: 076, Loss: 0.2131, Val Acc: 0.7920, Test Acc: 0.8213\n",
      "Seed: 42, Epoch: 077, Loss: 0.2073, Val Acc: 0.7947, Test Acc: 0.8080\n",
      "Seed: 42, Epoch: 078, Loss: 0.1999, Val Acc: 0.8013, Test Acc: 0.8053\n",
      "Seed: 42, Epoch: 079, Loss: 0.1964, Val Acc: 0.8053, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 080, Loss: 0.1991, Val Acc: 0.8040, Test Acc: 0.8093\n",
      "Seed: 42, Epoch: 081, Loss: 0.2012, Val Acc: 0.7947, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 082, Loss: 0.1979, Val Acc: 0.7907, Test Acc: 0.8147\n",
      "Seed: 42, Epoch: 083, Loss: 0.2123, Val Acc: 0.7867, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 084, Loss: 0.1998, Val Acc: 0.7907, Test Acc: 0.8120\n",
      "Seed: 42, Epoch: 085, Loss: 0.1925, Val Acc: 0.7973, Test Acc: 0.8027\n",
      "Seed: 42, Epoch: 086, Loss: 0.1901, Val Acc: 0.8027, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 087, Loss: 0.1840, Val Acc: 0.8053, Test Acc: 0.7987\n",
      "Seed: 42, Epoch: 088, Loss: 0.1773, Val Acc: 0.8040, Test Acc: 0.7960\n",
      "Seed: 42, Epoch: 089, Loss: 0.1777, Val Acc: 0.8013, Test Acc: 0.7987\n",
      "Seed: 42, Epoch: 090, Loss: 0.1809, Val Acc: 0.8013, Test Acc: 0.8120\n",
      "Seed: 42, Epoch: 091, Loss: 0.1820, Val Acc: 0.7947, Test Acc: 0.7987\n",
      "Seed: 42, Epoch: 092, Loss: 0.1729, Val Acc: 0.8027, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 093, Loss: 0.1704, Val Acc: 0.7987, Test Acc: 0.7973\n",
      "Seed: 42, Epoch: 094, Loss: 0.1708, Val Acc: 0.8040, Test Acc: 0.7947\n",
      "Seed: 42, Epoch: 095, Loss: 0.1668, Val Acc: 0.7960, Test Acc: 0.7947\n",
      "Seed: 42, Epoch: 096, Loss: 0.1667, Val Acc: 0.8013, Test Acc: 0.7960\n",
      "Seed: 42, Epoch: 097, Loss: 0.1645, Val Acc: 0.7907, Test Acc: 0.7960\n",
      "Seed: 42, Epoch: 098, Loss: 0.1713, Val Acc: 0.8013, Test Acc: 0.7947\n",
      "Seed: 42, Epoch: 099, Loss: 0.1790, Val Acc: 0.8000, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 100, Loss: 0.1647, Val Acc: 0.8040, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 101, Loss: 0.1548, Val Acc: 0.8000, Test Acc: 0.7907\n",
      "Seed: 42, Epoch: 102, Loss: 0.1513, Val Acc: 0.7973, Test Acc: 0.8027\n",
      "Seed: 42, Epoch: 103, Loss: 0.1559, Val Acc: 0.7973, Test Acc: 0.7973\n",
      "Seed: 42, Epoch: 104, Loss: 0.1534, Val Acc: 0.8040, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 105, Loss: 0.1483, Val Acc: 0.7973, Test Acc: 0.7920\n",
      "Seed: 42, Epoch: 106, Loss: 0.1471, Val Acc: 0.7947, Test Acc: 0.7960\n",
      "Seed: 42, Epoch: 107, Loss: 0.1673, Val Acc: 0.7627, Test Acc: 0.8013\n",
      "Seed: 42, Epoch: 108, Loss: 0.1871, Val Acc: 0.7667, Test Acc: 0.7960\n",
      "Seed: 42, Epoch: 109, Loss: 0.1584, Val Acc: 0.7973, Test Acc: 0.7920\n",
      "Seed: 42, Epoch: 110, Loss: 0.1476, Val Acc: 0.7947, Test Acc: 0.8013\n",
      "Seed: 42, Epoch: 111, Loss: 0.1441, Val Acc: 0.7973, Test Acc: 0.7907\n",
      "Seed: 42, Epoch: 112, Loss: 0.1399, Val Acc: 0.7987, Test Acc: 0.7893\n",
      "Seed: 42, Epoch: 113, Loss: 0.1412, Val Acc: 0.7973, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 114, Loss: 0.1391, Val Acc: 0.7973, Test Acc: 0.7840\n",
      "Seed: 42, Epoch: 115, Loss: 0.1395, Val Acc: 0.7947, Test Acc: 0.8040\n",
      "Seed: 42, Epoch: 116, Loss: 0.1386, Val Acc: 0.7987, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 117, Loss: 0.1370, Val Acc: 0.8053, Test Acc: 0.7987\n",
      "Seed: 42, Epoch: 118, Loss: 0.1369, Val Acc: 0.7960, Test Acc: 0.7947\n",
      "Seed: 42, Epoch: 119, Loss: 0.1337, Val Acc: 0.7973, Test Acc: 0.7907\n",
      "Seed: 42, Epoch: 120, Loss: 0.1331, Val Acc: 0.7960, Test Acc: 0.7920\n",
      "Seed: 42, Epoch: 121, Loss: 0.1283, Val Acc: 0.7960, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 122, Loss: 0.1270, Val Acc: 0.7733, Test Acc: 0.7920\n",
      "Seed: 42, Epoch: 123, Loss: 0.1378, Val Acc: 0.7813, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 124, Loss: 0.1456, Val Acc: 0.7800, Test Acc: 0.7947\n",
      "Seed: 42, Epoch: 125, Loss: 0.1488, Val Acc: 0.7653, Test Acc: 0.7973\n",
      "Seed: 42, Epoch: 126, Loss: 0.1596, Val Acc: 0.7773, Test Acc: 0.7987\n",
      "Seed: 42, Epoch: 127, Loss: 0.1391, Val Acc: 0.7813, Test Acc: 0.8053\n",
      "Seed: 42, Epoch: 128, Loss: 0.1375, Val Acc: 0.7800, Test Acc: 0.7920\n",
      "Seed: 42, Epoch: 129, Loss: 0.1315, Val Acc: 0.7920, Test Acc: 0.7893\n",
      "Seed: 42, Epoch: 130, Loss: 0.1260, Val Acc: 0.7973, Test Acc: 0.7920\n",
      "Seed: 42, Epoch: 131, Loss: 0.1224, Val Acc: 0.7733, Test Acc: 0.8027\n",
      "Seed: 42, Epoch: 132, Loss: 0.1361, Val Acc: 0.7853, Test Acc: 0.7920\n",
      "Seed: 42, Epoch: 133, Loss: 0.1304, Val Acc: 0.7947, Test Acc: 0.8027\n",
      "Seed: 42, Epoch: 134, Loss: 0.1264, Val Acc: 0.8027, Test Acc: 0.7840\n",
      "Seed: 42, Epoch: 135, Loss: 0.1199, Val Acc: 0.8000, Test Acc: 0.7987\n",
      "Seed: 42, Epoch: 136, Loss: 0.1193, Val Acc: 0.7880, Test Acc: 0.7960\n",
      "Seed: 42, Epoch: 137, Loss: 0.1142, Val Acc: 0.7987, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 138, Loss: 0.1141, Val Acc: 0.7933, Test Acc: 0.7840\n",
      "Seed: 42, Epoch: 139, Loss: 0.1114, Val Acc: 0.7893, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 140, Loss: 0.1082, Val Acc: 0.7973, Test Acc: 0.7827\n",
      "Seed: 42, Epoch: 141, Loss: 0.1100, Val Acc: 0.7853, Test Acc: 0.8027\n",
      "Seed: 42, Epoch: 142, Loss: 0.1082, Val Acc: 0.7920, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 143, Loss: 0.1064, Val Acc: 0.8000, Test Acc: 0.7947\n",
      "Seed: 42, Epoch: 144, Loss: 0.1078, Val Acc: 0.7947, Test Acc: 0.7960\n",
      "Seed: 42, Epoch: 145, Loss: 0.1096, Val Acc: 0.7893, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 146, Loss: 0.1069, Val Acc: 0.7973, Test Acc: 0.8013\n",
      "Seed: 42, Epoch: 147, Loss: 0.1031, Val Acc: 0.7920, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 148, Loss: 0.1008, Val Acc: 0.7947, Test Acc: 0.7920\n",
      "Seed: 42, Epoch: 149, Loss: 0.0992, Val Acc: 0.8000, Test Acc: 0.7987\n",
      "Seed: 42, Epoch: 150, Loss: 0.1034, Val Acc: 0.8000, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 151, Loss: 0.1009, Val Acc: 0.7933, Test Acc: 0.7960\n",
      "Seed: 42, Epoch: 152, Loss: 0.1168, Val Acc: 0.7933, Test Acc: 0.7853\n",
      "Seed: 42, Epoch: 153, Loss: 0.1399, Val Acc: 0.7640, Test Acc: 0.7840\n",
      "Seed: 42, Epoch: 154, Loss: 0.1428, Val Acc: 0.8080, Test Acc: 0.8027\n",
      "Seed: 42, Epoch: 155, Loss: 0.1256, Val Acc: 0.7893, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 156, Loss: 0.1100, Val Acc: 0.7827, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 157, Loss: 0.1006, Val Acc: 0.7933, Test Acc: 0.7987\n",
      "Seed: 42, Epoch: 158, Loss: 0.0979, Val Acc: 0.7827, Test Acc: 0.8013\n",
      "Seed: 42, Epoch: 159, Loss: 0.0984, Val Acc: 0.7853, Test Acc: 0.7987\n",
      "Seed: 42, Epoch: 160, Loss: 0.0940, Val Acc: 0.8000, Test Acc: 0.7960\n",
      "Seed: 42, Epoch: 161, Loss: 0.0927, Val Acc: 0.7960, Test Acc: 0.7960\n",
      "Seed: 42, Epoch: 162, Loss: 0.0914, Val Acc: 0.8000, Test Acc: 0.7973\n",
      "Seed: 42, Epoch: 163, Loss: 0.0920, Val Acc: 0.7947, Test Acc: 0.8027\n",
      "Seed: 42, Epoch: 164, Loss: 0.0931, Val Acc: 0.7920, Test Acc: 0.8013\n",
      "Seed: 42, Epoch: 165, Loss: 0.0925, Val Acc: 0.7880, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 166, Loss: 0.0932, Val Acc: 0.7813, Test Acc: 0.8027\n",
      "Seed: 42, Epoch: 167, Loss: 0.0923, Val Acc: 0.8027, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 168, Loss: 0.0915, Val Acc: 0.7973, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 169, Loss: 0.0862, Val Acc: 0.7973, Test Acc: 0.7987\n",
      "Seed: 42, Epoch: 170, Loss: 0.0870, Val Acc: 0.8013, Test Acc: 0.7920\n",
      "Seed: 42, Epoch: 171, Loss: 0.0838, Val Acc: 0.7880, Test Acc: 0.7893\n",
      "Seed: 42, Epoch: 172, Loss: 0.0867, Val Acc: 0.7853, Test Acc: 0.7920\n",
      "Seed: 42, Epoch: 173, Loss: 0.0868, Val Acc: 0.7867, Test Acc: 0.7907\n",
      "Seed: 42, Epoch: 174, Loss: 0.0999, Val Acc: 0.7933, Test Acc: 0.7893\n",
      "Seed: 42, Epoch: 175, Loss: 0.1334, Val Acc: 0.7747, Test Acc: 0.7987\n",
      "Seed: 42, Epoch: 176, Loss: 0.1467, Val Acc: 0.7707, Test Acc: 0.7827\n",
      "Seed: 42, Epoch: 177, Loss: 0.1935, Val Acc: 0.7867, Test Acc: 0.7853\n",
      "Seed: 42, Epoch: 178, Loss: 0.1414, Val Acc: 0.7867, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 179, Loss: 0.1212, Val Acc: 0.7667, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 180, Loss: 0.1052, Val Acc: 0.7867, Test Acc: 0.8173\n",
      "Seed: 42, Epoch: 181, Loss: 0.0941, Val Acc: 0.7987, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 182, Loss: 0.0851, Val Acc: 0.7973, Test Acc: 0.7973\n",
      "Seed: 42, Epoch: 183, Loss: 0.0850, Val Acc: 0.7907, Test Acc: 0.7947\n",
      "Seed: 42, Epoch: 184, Loss: 0.0880, Val Acc: 0.7853, Test Acc: 0.7987\n",
      "Seed: 42, Epoch: 185, Loss: 0.0875, Val Acc: 0.8000, Test Acc: 0.7960\n",
      "Seed: 42, Epoch: 186, Loss: 0.0808, Val Acc: 0.7907, Test Acc: 0.7907\n",
      "Seed: 42, Epoch: 187, Loss: 0.0795, Val Acc: 0.7947, Test Acc: 0.7960\n",
      "Seed: 42, Epoch: 188, Loss: 0.0813, Val Acc: 0.7960, Test Acc: 0.7840\n",
      "Seed: 42, Epoch: 189, Loss: 0.0802, Val Acc: 0.7973, Test Acc: 0.7893\n",
      "Seed: 42, Epoch: 190, Loss: 0.0800, Val Acc: 0.7893, Test Acc: 0.7947\n",
      "Seed: 42, Epoch: 191, Loss: 0.0784, Val Acc: 0.7880, Test Acc: 0.7853\n",
      "Seed: 42, Epoch: 192, Loss: 0.0762, Val Acc: 0.7947, Test Acc: 0.7907\n",
      "Seed: 42, Epoch: 193, Loss: 0.0749, Val Acc: 0.7907, Test Acc: 0.7947\n",
      "Seed: 42, Epoch: 194, Loss: 0.0765, Val Acc: 0.7893, Test Acc: 0.7960\n",
      "Seed: 42, Epoch: 195, Loss: 0.0761, Val Acc: 0.7893, Test Acc: 0.7920\n",
      "Seed: 42, Epoch: 196, Loss: 0.0743, Val Acc: 0.7973, Test Acc: 0.7907\n",
      "Seed: 42, Epoch: 197, Loss: 0.0747, Val Acc: 0.7933, Test Acc: 0.7893\n",
      "Seed: 42, Epoch: 198, Loss: 0.0733, Val Acc: 0.7947, Test Acc: 0.7920\n",
      "Seed: 42, Epoch: 199, Loss: 0.0734, Val Acc: 0.7853, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 200, Loss: 0.0746, Val Acc: 0.7907, Test Acc: 0.7920\n",
      "Early stopping at epoch 200 for seed 42\n",
      "Seed: 43, Epoch: 001, Loss: 1.1269, Val Acc: 0.2267, Test Acc: 0.2440\n",
      "Seed: 43, Epoch: 002, Loss: 1.0528, Val Acc: 0.5053, Test Acc: 0.5160\n",
      "Seed: 43, Epoch: 003, Loss: 0.9298, Val Acc: 0.6547, Test Acc: 0.6387\n",
      "Seed: 43, Epoch: 004, Loss: 0.7577, Val Acc: 0.6920, Test Acc: 0.6827\n",
      "Seed: 43, Epoch: 005, Loss: 0.6234, Val Acc: 0.7053, Test Acc: 0.7227\n",
      "Seed: 43, Epoch: 006, Loss: 0.5906, Val Acc: 0.7147, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 007, Loss: 0.5666, Val Acc: 0.7187, Test Acc: 0.7213\n",
      "Seed: 43, Epoch: 008, Loss: 0.5474, Val Acc: 0.7307, Test Acc: 0.7373\n",
      "Seed: 43, Epoch: 009, Loss: 0.5292, Val Acc: 0.7507, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 010, Loss: 0.5135, Val Acc: 0.7613, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 011, Loss: 0.4984, Val Acc: 0.7680, Test Acc: 0.7547\n",
      "Seed: 43, Epoch: 012, Loss: 0.4849, Val Acc: 0.7760, Test Acc: 0.7680\n",
      "Seed: 43, Epoch: 013, Loss: 0.4716, Val Acc: 0.7787, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 014, Loss: 0.4587, Val Acc: 0.7907, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 015, Loss: 0.4520, Val Acc: 0.7813, Test Acc: 0.7627\n",
      "Seed: 43, Epoch: 016, Loss: 0.4450, Val Acc: 0.7867, Test Acc: 0.7760\n",
      "Seed: 43, Epoch: 017, Loss: 0.4353, Val Acc: 0.7893, Test Acc: 0.7760\n",
      "Seed: 43, Epoch: 018, Loss: 0.4282, Val Acc: 0.7907, Test Acc: 0.7720\n",
      "Seed: 43, Epoch: 019, Loss: 0.4265, Val Acc: 0.7920, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 020, Loss: 0.4232, Val Acc: 0.7880, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 021, Loss: 0.4177, Val Acc: 0.7907, Test Acc: 0.7693\n",
      "Seed: 43, Epoch: 022, Loss: 0.4093, Val Acc: 0.7920, Test Acc: 0.7813\n",
      "Seed: 43, Epoch: 023, Loss: 0.4047, Val Acc: 0.7973, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 024, Loss: 0.4154, Val Acc: 0.7880, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 025, Loss: 0.4035, Val Acc: 0.8013, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 026, Loss: 0.3954, Val Acc: 0.7987, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 027, Loss: 0.3843, Val Acc: 0.8013, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 028, Loss: 0.3879, Val Acc: 0.8013, Test Acc: 0.7787\n",
      "Seed: 43, Epoch: 029, Loss: 0.3824, Val Acc: 0.8027, Test Acc: 0.7827\n",
      "Seed: 43, Epoch: 030, Loss: 0.3794, Val Acc: 0.8053, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 031, Loss: 0.3701, Val Acc: 0.7973, Test Acc: 0.7840\n",
      "Seed: 43, Epoch: 032, Loss: 0.3612, Val Acc: 0.8040, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 033, Loss: 0.3577, Val Acc: 0.8067, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 034, Loss: 0.3539, Val Acc: 0.8067, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 035, Loss: 0.3427, Val Acc: 0.8067, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 036, Loss: 0.3353, Val Acc: 0.8120, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 037, Loss: 0.3364, Val Acc: 0.8147, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 038, Loss: 0.3291, Val Acc: 0.8067, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 039, Loss: 0.3283, Val Acc: 0.8187, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 040, Loss: 0.3155, Val Acc: 0.8133, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 041, Loss: 0.3138, Val Acc: 0.8040, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 042, Loss: 0.3100, Val Acc: 0.8080, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 043, Loss: 0.3021, Val Acc: 0.8107, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 044, Loss: 0.3019, Val Acc: 0.8147, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 045, Loss: 0.2955, Val Acc: 0.8173, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 046, Loss: 0.2901, Val Acc: 0.8227, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 047, Loss: 0.2834, Val Acc: 0.8133, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 048, Loss: 0.2815, Val Acc: 0.8200, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 049, Loss: 0.2769, Val Acc: 0.8147, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 050, Loss: 0.2689, Val Acc: 0.8160, Test Acc: 0.8107\n",
      "Seed: 43, Epoch: 051, Loss: 0.2703, Val Acc: 0.8133, Test Acc: 0.8093\n",
      "Seed: 43, Epoch: 052, Loss: 0.2657, Val Acc: 0.8160, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 053, Loss: 0.2728, Val Acc: 0.8213, Test Acc: 0.8093\n",
      "Seed: 43, Epoch: 054, Loss: 0.2728, Val Acc: 0.8120, Test Acc: 0.8107\n",
      "Seed: 43, Epoch: 055, Loss: 0.2694, Val Acc: 0.8213, Test Acc: 0.8160\n",
      "Seed: 43, Epoch: 056, Loss: 0.2568, Val Acc: 0.8187, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 057, Loss: 0.2570, Val Acc: 0.8187, Test Acc: 0.8187\n",
      "Seed: 43, Epoch: 058, Loss: 0.2438, Val Acc: 0.8227, Test Acc: 0.8120\n",
      "Seed: 43, Epoch: 059, Loss: 0.2448, Val Acc: 0.8187, Test Acc: 0.8213\n",
      "Seed: 43, Epoch: 060, Loss: 0.2358, Val Acc: 0.8227, Test Acc: 0.8173\n",
      "Seed: 43, Epoch: 061, Loss: 0.2349, Val Acc: 0.8200, Test Acc: 0.8240\n",
      "Seed: 43, Epoch: 062, Loss: 0.2357, Val Acc: 0.8187, Test Acc: 0.8187\n",
      "Seed: 43, Epoch: 063, Loss: 0.2385, Val Acc: 0.8213, Test Acc: 0.8133\n",
      "Seed: 43, Epoch: 064, Loss: 0.2275, Val Acc: 0.8200, Test Acc: 0.8133\n",
      "Seed: 43, Epoch: 065, Loss: 0.2364, Val Acc: 0.8213, Test Acc: 0.8160\n",
      "Seed: 43, Epoch: 066, Loss: 0.2171, Val Acc: 0.8307, Test Acc: 0.8187\n",
      "Seed: 43, Epoch: 067, Loss: 0.2152, Val Acc: 0.8200, Test Acc: 0.8227\n",
      "Seed: 43, Epoch: 068, Loss: 0.2116, Val Acc: 0.8333, Test Acc: 0.8173\n",
      "Seed: 43, Epoch: 069, Loss: 0.2090, Val Acc: 0.8147, Test Acc: 0.8173\n",
      "Seed: 43, Epoch: 070, Loss: 0.2126, Val Acc: 0.8253, Test Acc: 0.8267\n",
      "Seed: 43, Epoch: 071, Loss: 0.2131, Val Acc: 0.8267, Test Acc: 0.8280\n",
      "Seed: 43, Epoch: 072, Loss: 0.2145, Val Acc: 0.8227, Test Acc: 0.8107\n",
      "Seed: 43, Epoch: 073, Loss: 0.2195, Val Acc: 0.8267, Test Acc: 0.8120\n",
      "Seed: 43, Epoch: 074, Loss: 0.2045, Val Acc: 0.8240, Test Acc: 0.8173\n",
      "Seed: 43, Epoch: 075, Loss: 0.2072, Val Acc: 0.8053, Test Acc: 0.8213\n",
      "Seed: 43, Epoch: 076, Loss: 0.2014, Val Acc: 0.8240, Test Acc: 0.8147\n",
      "Seed: 43, Epoch: 077, Loss: 0.1895, Val Acc: 0.8080, Test Acc: 0.8173\n",
      "Seed: 43, Epoch: 078, Loss: 0.1903, Val Acc: 0.8187, Test Acc: 0.8240\n",
      "Seed: 43, Epoch: 079, Loss: 0.1874, Val Acc: 0.8147, Test Acc: 0.8187\n",
      "Seed: 43, Epoch: 080, Loss: 0.1922, Val Acc: 0.8013, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 081, Loss: 0.1863, Val Acc: 0.8053, Test Acc: 0.8147\n",
      "Seed: 43, Epoch: 082, Loss: 0.1828, Val Acc: 0.8213, Test Acc: 0.8267\n",
      "Seed: 43, Epoch: 083, Loss: 0.1806, Val Acc: 0.8093, Test Acc: 0.8240\n",
      "Seed: 43, Epoch: 084, Loss: 0.1801, Val Acc: 0.8213, Test Acc: 0.8213\n",
      "Seed: 43, Epoch: 085, Loss: 0.1845, Val Acc: 0.8200, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 086, Loss: 0.1868, Val Acc: 0.8173, Test Acc: 0.8133\n",
      "Seed: 43, Epoch: 087, Loss: 0.1673, Val Acc: 0.8120, Test Acc: 0.8160\n",
      "Seed: 43, Epoch: 088, Loss: 0.1671, Val Acc: 0.7947, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 089, Loss: 0.1645, Val Acc: 0.8120, Test Acc: 0.8160\n",
      "Seed: 43, Epoch: 090, Loss: 0.1603, Val Acc: 0.8040, Test Acc: 0.8093\n",
      "Seed: 43, Epoch: 091, Loss: 0.1578, Val Acc: 0.8093, Test Acc: 0.8147\n",
      "Seed: 43, Epoch: 092, Loss: 0.1533, Val Acc: 0.8027, Test Acc: 0.8107\n",
      "Seed: 43, Epoch: 093, Loss: 0.1525, Val Acc: 0.8067, Test Acc: 0.8093\n",
      "Seed: 43, Epoch: 094, Loss: 0.1510, Val Acc: 0.8187, Test Acc: 0.8267\n",
      "Seed: 43, Epoch: 095, Loss: 0.1576, Val Acc: 0.8027, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 096, Loss: 0.1506, Val Acc: 0.8147, Test Acc: 0.8173\n",
      "Seed: 43, Epoch: 097, Loss: 0.1531, Val Acc: 0.8040, Test Acc: 0.8133\n",
      "Seed: 43, Epoch: 098, Loss: 0.1649, Val Acc: 0.8067, Test Acc: 0.8133\n",
      "Seed: 43, Epoch: 099, Loss: 0.1543, Val Acc: 0.8107, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 100, Loss: 0.1497, Val Acc: 0.7973, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 101, Loss: 0.1552, Val Acc: 0.7853, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 102, Loss: 0.1801, Val Acc: 0.7867, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 103, Loss: 0.1864, Val Acc: 0.7947, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 104, Loss: 0.1585, Val Acc: 0.8107, Test Acc: 0.8133\n",
      "Seed: 43, Epoch: 105, Loss: 0.1565, Val Acc: 0.8000, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 106, Loss: 0.1566, Val Acc: 0.7960, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 107, Loss: 0.1373, Val Acc: 0.8067, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 108, Loss: 0.1357, Val Acc: 0.7987, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 109, Loss: 0.1304, Val Acc: 0.8093, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 110, Loss: 0.1293, Val Acc: 0.7933, Test Acc: 0.8107\n",
      "Seed: 43, Epoch: 111, Loss: 0.1289, Val Acc: 0.8027, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 112, Loss: 0.1259, Val Acc: 0.8053, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 113, Loss: 0.1362, Val Acc: 0.8013, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 114, Loss: 0.1293, Val Acc: 0.8027, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 115, Loss: 0.1244, Val Acc: 0.8053, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 116, Loss: 0.1245, Val Acc: 0.8080, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 117, Loss: 0.1357, Val Acc: 0.8027, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 118, Loss: 0.1283, Val Acc: 0.8027, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 119, Loss: 0.1238, Val Acc: 0.8080, Test Acc: 0.8133\n",
      "Seed: 43, Epoch: 120, Loss: 0.1293, Val Acc: 0.7960, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 121, Loss: 0.1238, Val Acc: 0.8040, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 122, Loss: 0.1169, Val Acc: 0.8067, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 123, Loss: 0.1150, Val Acc: 0.7933, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 124, Loss: 0.1102, Val Acc: 0.8013, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 125, Loss: 0.1122, Val Acc: 0.8040, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 126, Loss: 0.1113, Val Acc: 0.8000, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 127, Loss: 0.1105, Val Acc: 0.7933, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 128, Loss: 0.1142, Val Acc: 0.7933, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 129, Loss: 0.1120, Val Acc: 0.8040, Test Acc: 0.8120\n",
      "Seed: 43, Epoch: 130, Loss: 0.1104, Val Acc: 0.8013, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 131, Loss: 0.1147, Val Acc: 0.8000, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 132, Loss: 0.1245, Val Acc: 0.7973, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 133, Loss: 0.1443, Val Acc: 0.7947, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 134, Loss: 0.1153, Val Acc: 0.7933, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 135, Loss: 0.1086, Val Acc: 0.8027, Test Acc: 0.8160\n",
      "Seed: 43, Epoch: 136, Loss: 0.1078, Val Acc: 0.8000, Test Acc: 0.8147\n",
      "Seed: 43, Epoch: 137, Loss: 0.1084, Val Acc: 0.8040, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 138, Loss: 0.1078, Val Acc: 0.8027, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 139, Loss: 0.1159, Val Acc: 0.8027, Test Acc: 0.8093\n",
      "Seed: 43, Epoch: 140, Loss: 0.1062, Val Acc: 0.8080, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 141, Loss: 0.1116, Val Acc: 0.8067, Test Acc: 0.8147\n",
      "Seed: 43, Epoch: 142, Loss: 0.1317, Val Acc: 0.8040, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 143, Loss: 0.1062, Val Acc: 0.8053, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 144, Loss: 0.1010, Val Acc: 0.7960, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 145, Loss: 0.0990, Val Acc: 0.7933, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 146, Loss: 0.0977, Val Acc: 0.7973, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 147, Loss: 0.0993, Val Acc: 0.7947, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 148, Loss: 0.0960, Val Acc: 0.8053, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 149, Loss: 0.0926, Val Acc: 0.7973, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 150, Loss: 0.0951, Val Acc: 0.7987, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 151, Loss: 0.0945, Val Acc: 0.8013, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 152, Loss: 0.0904, Val Acc: 0.8067, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 153, Loss: 0.0914, Val Acc: 0.7933, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 154, Loss: 0.1023, Val Acc: 0.7947, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 155, Loss: 0.1092, Val Acc: 0.8027, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 156, Loss: 0.0962, Val Acc: 0.7973, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 157, Loss: 0.0914, Val Acc: 0.8067, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 158, Loss: 0.0889, Val Acc: 0.8013, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 159, Loss: 0.0898, Val Acc: 0.7973, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 160, Loss: 0.0931, Val Acc: 0.7813, Test Acc: 0.7827\n",
      "Seed: 43, Epoch: 161, Loss: 0.0943, Val Acc: 0.7960, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 162, Loss: 0.0917, Val Acc: 0.8000, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 163, Loss: 0.0863, Val Acc: 0.8040, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 164, Loss: 0.0828, Val Acc: 0.8040, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 165, Loss: 0.0870, Val Acc: 0.8067, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 166, Loss: 0.0825, Val Acc: 0.8013, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 167, Loss: 0.0796, Val Acc: 0.8000, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 168, Loss: 0.0839, Val Acc: 0.8027, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 169, Loss: 0.0839, Val Acc: 0.8013, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 170, Loss: 0.0864, Val Acc: 0.8040, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 171, Loss: 0.0821, Val Acc: 0.7987, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 172, Loss: 0.0808, Val Acc: 0.8013, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 173, Loss: 0.0795, Val Acc: 0.7973, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 174, Loss: 0.0803, Val Acc: 0.7947, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 175, Loss: 0.0813, Val Acc: 0.8027, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 176, Loss: 0.0812, Val Acc: 0.7893, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 177, Loss: 0.0809, Val Acc: 0.8013, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 178, Loss: 0.0765, Val Acc: 0.7987, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 179, Loss: 0.0783, Val Acc: 0.8000, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 180, Loss: 0.0830, Val Acc: 0.7973, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 181, Loss: 0.0834, Val Acc: 0.7960, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 182, Loss: 0.0788, Val Acc: 0.7960, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 183, Loss: 0.0775, Val Acc: 0.7880, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 184, Loss: 0.0785, Val Acc: 0.7907, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 185, Loss: 0.0804, Val Acc: 0.8040, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 186, Loss: 0.0878, Val Acc: 0.8013, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 187, Loss: 0.0935, Val Acc: 0.8000, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 188, Loss: 0.0962, Val Acc: 0.7960, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 189, Loss: 0.1011, Val Acc: 0.7933, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 190, Loss: 0.1033, Val Acc: 0.7853, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 191, Loss: 0.1134, Val Acc: 0.7800, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 192, Loss: 0.1435, Val Acc: 0.7467, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 193, Loss: 0.1870, Val Acc: 0.7933, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 194, Loss: 0.1134, Val Acc: 0.7813, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 195, Loss: 0.1867, Val Acc: 0.8027, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 196, Loss: 0.1369, Val Acc: 0.7920, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 197, Loss: 0.1084, Val Acc: 0.8133, Test Acc: 0.8133\n",
      "Seed: 43, Epoch: 198, Loss: 0.0950, Val Acc: 0.7960, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 199, Loss: 0.0837, Val Acc: 0.8053, Test Acc: 0.8093\n",
      "Seed: 43, Epoch: 200, Loss: 0.0788, Val Acc: 0.7947, Test Acc: 0.8053\n",
      "Seed: 44, Epoch: 001, Loss: 1.0813, Val Acc: 0.5920, Test Acc: 0.6093\n",
      "Seed: 44, Epoch: 002, Loss: 1.0452, Val Acc: 0.5480, Test Acc: 0.5680\n",
      "Seed: 44, Epoch: 003, Loss: 0.9345, Val Acc: 0.6280, Test Acc: 0.6440\n",
      "Seed: 44, Epoch: 004, Loss: 0.7682, Val Acc: 0.6773, Test Acc: 0.6800\n",
      "Seed: 44, Epoch: 005, Loss: 0.6519, Val Acc: 0.7133, Test Acc: 0.7120\n",
      "Seed: 44, Epoch: 006, Loss: 0.5987, Val Acc: 0.7160, Test Acc: 0.7173\n",
      "Seed: 44, Epoch: 007, Loss: 0.5658, Val Acc: 0.7280, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 008, Loss: 0.5411, Val Acc: 0.7293, Test Acc: 0.7147\n",
      "Seed: 44, Epoch: 009, Loss: 0.5234, Val Acc: 0.7280, Test Acc: 0.7173\n",
      "Seed: 44, Epoch: 010, Loss: 0.4998, Val Acc: 0.7227, Test Acc: 0.7147\n",
      "Seed: 44, Epoch: 011, Loss: 0.4844, Val Acc: 0.7307, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 012, Loss: 0.4747, Val Acc: 0.7413, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 013, Loss: 0.4592, Val Acc: 0.7480, Test Acc: 0.7493\n",
      "Seed: 44, Epoch: 014, Loss: 0.4514, Val Acc: 0.7480, Test Acc: 0.7480\n",
      "Seed: 44, Epoch: 015, Loss: 0.4457, Val Acc: 0.7573, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 016, Loss: 0.4395, Val Acc: 0.7613, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 017, Loss: 0.4368, Val Acc: 0.7600, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 018, Loss: 0.4314, Val Acc: 0.7507, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 019, Loss: 0.4261, Val Acc: 0.7573, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 020, Loss: 0.4261, Val Acc: 0.7587, Test Acc: 0.7760\n",
      "Seed: 44, Epoch: 021, Loss: 0.4127, Val Acc: 0.7587, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 022, Loss: 0.4164, Val Acc: 0.7547, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 023, Loss: 0.4114, Val Acc: 0.7600, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 024, Loss: 0.4017, Val Acc: 0.7600, Test Acc: 0.7787\n",
      "Seed: 44, Epoch: 025, Loss: 0.4000, Val Acc: 0.7507, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 026, Loss: 0.3980, Val Acc: 0.7560, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 027, Loss: 0.3998, Val Acc: 0.7600, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 028, Loss: 0.3849, Val Acc: 0.7600, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 029, Loss: 0.3792, Val Acc: 0.7507, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 030, Loss: 0.3740, Val Acc: 0.7587, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 031, Loss: 0.3909, Val Acc: 0.7627, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 032, Loss: 0.3757, Val Acc: 0.7627, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 033, Loss: 0.3625, Val Acc: 0.7707, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 034, Loss: 0.3622, Val Acc: 0.7733, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 035, Loss: 0.3633, Val Acc: 0.7720, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 036, Loss: 0.3494, Val Acc: 0.7800, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 037, Loss: 0.3478, Val Acc: 0.7733, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 038, Loss: 0.3411, Val Acc: 0.7747, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 039, Loss: 0.3341, Val Acc: 0.7733, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 040, Loss: 0.3338, Val Acc: 0.7747, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 041, Loss: 0.3318, Val Acc: 0.7773, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 042, Loss: 0.3281, Val Acc: 0.7813, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 043, Loss: 0.3273, Val Acc: 0.7813, Test Acc: 0.7960\n",
      "Seed: 44, Epoch: 044, Loss: 0.3127, Val Acc: 0.7853, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 045, Loss: 0.3085, Val Acc: 0.7840, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 046, Loss: 0.3066, Val Acc: 0.7867, Test Acc: 0.8080\n",
      "Seed: 44, Epoch: 047, Loss: 0.2996, Val Acc: 0.7840, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 048, Loss: 0.2975, Val Acc: 0.7920, Test Acc: 0.8040\n",
      "Seed: 44, Epoch: 049, Loss: 0.3020, Val Acc: 0.7813, Test Acc: 0.8093\n",
      "Seed: 44, Epoch: 050, Loss: 0.2982, Val Acc: 0.7813, Test Acc: 0.7987\n",
      "Seed: 44, Epoch: 051, Loss: 0.2933, Val Acc: 0.7907, Test Acc: 0.8093\n",
      "Seed: 44, Epoch: 052, Loss: 0.2854, Val Acc: 0.7960, Test Acc: 0.8160\n",
      "Seed: 44, Epoch: 053, Loss: 0.2815, Val Acc: 0.7853, Test Acc: 0.8067\n",
      "Seed: 44, Epoch: 054, Loss: 0.2889, Val Acc: 0.7867, Test Acc: 0.7947\n",
      "Seed: 44, Epoch: 055, Loss: 0.2768, Val Acc: 0.7947, Test Acc: 0.8107\n",
      "Seed: 44, Epoch: 056, Loss: 0.2845, Val Acc: 0.7933, Test Acc: 0.8053\n",
      "Seed: 44, Epoch: 057, Loss: 0.2694, Val Acc: 0.7867, Test Acc: 0.8027\n",
      "Seed: 44, Epoch: 058, Loss: 0.2706, Val Acc: 0.8040, Test Acc: 0.8227\n",
      "Seed: 44, Epoch: 059, Loss: 0.2552, Val Acc: 0.7960, Test Acc: 0.8253\n",
      "Seed: 44, Epoch: 060, Loss: 0.2555, Val Acc: 0.7920, Test Acc: 0.8080\n",
      "Seed: 44, Epoch: 061, Loss: 0.2530, Val Acc: 0.7880, Test Acc: 0.8093\n",
      "Seed: 44, Epoch: 062, Loss: 0.2588, Val Acc: 0.7747, Test Acc: 0.7933\n",
      "Seed: 44, Epoch: 063, Loss: 0.2580, Val Acc: 0.8133, Test Acc: 0.8093\n",
      "Seed: 44, Epoch: 064, Loss: 0.2417, Val Acc: 0.7920, Test Acc: 0.8240\n",
      "Seed: 44, Epoch: 065, Loss: 0.2403, Val Acc: 0.7907, Test Acc: 0.8080\n",
      "Seed: 44, Epoch: 066, Loss: 0.2356, Val Acc: 0.7907, Test Acc: 0.8147\n",
      "Seed: 44, Epoch: 067, Loss: 0.2317, Val Acc: 0.8013, Test Acc: 0.8160\n",
      "Seed: 44, Epoch: 068, Loss: 0.2292, Val Acc: 0.7933, Test Acc: 0.8160\n",
      "Seed: 44, Epoch: 069, Loss: 0.2264, Val Acc: 0.7933, Test Acc: 0.8027\n",
      "Seed: 44, Epoch: 070, Loss: 0.2261, Val Acc: 0.7987, Test Acc: 0.8080\n",
      "Seed: 44, Epoch: 071, Loss: 0.2236, Val Acc: 0.7920, Test Acc: 0.8107\n",
      "Seed: 44, Epoch: 072, Loss: 0.2198, Val Acc: 0.7933, Test Acc: 0.8147\n",
      "Seed: 44, Epoch: 073, Loss: 0.2185, Val Acc: 0.7880, Test Acc: 0.8040\n",
      "Seed: 44, Epoch: 074, Loss: 0.2152, Val Acc: 0.7947, Test Acc: 0.8120\n",
      "Seed: 44, Epoch: 075, Loss: 0.2110, Val Acc: 0.7907, Test Acc: 0.8107\n",
      "Seed: 44, Epoch: 076, Loss: 0.2108, Val Acc: 0.7853, Test Acc: 0.8040\n",
      "Seed: 44, Epoch: 077, Loss: 0.2216, Val Acc: 0.7880, Test Acc: 0.7960\n",
      "Seed: 44, Epoch: 078, Loss: 0.2142, Val Acc: 0.7880, Test Acc: 0.7947\n",
      "Seed: 44, Epoch: 079, Loss: 0.2143, Val Acc: 0.8000, Test Acc: 0.8093\n",
      "Seed: 44, Epoch: 080, Loss: 0.2036, Val Acc: 0.7853, Test Acc: 0.7933\n",
      "Seed: 44, Epoch: 081, Loss: 0.1977, Val Acc: 0.7947, Test Acc: 0.7960\n",
      "Seed: 44, Epoch: 082, Loss: 0.1970, Val Acc: 0.7813, Test Acc: 0.8053\n",
      "Seed: 44, Epoch: 083, Loss: 0.1989, Val Acc: 0.7867, Test Acc: 0.8040\n",
      "Seed: 44, Epoch: 084, Loss: 0.1995, Val Acc: 0.7947, Test Acc: 0.8040\n",
      "Seed: 44, Epoch: 085, Loss: 0.2035, Val Acc: 0.7827, Test Acc: 0.8000\n",
      "Seed: 44, Epoch: 086, Loss: 0.1982, Val Acc: 0.7880, Test Acc: 0.8133\n",
      "Seed: 44, Epoch: 087, Loss: 0.1840, Val Acc: 0.7867, Test Acc: 0.7987\n",
      "Seed: 44, Epoch: 088, Loss: 0.1932, Val Acc: 0.7920, Test Acc: 0.8093\n",
      "Seed: 44, Epoch: 089, Loss: 0.1860, Val Acc: 0.7827, Test Acc: 0.7973\n",
      "Seed: 44, Epoch: 090, Loss: 0.1845, Val Acc: 0.7920, Test Acc: 0.8040\n",
      "Seed: 44, Epoch: 091, Loss: 0.2051, Val Acc: 0.7787, Test Acc: 0.7960\n",
      "Seed: 44, Epoch: 092, Loss: 0.2303, Val Acc: 0.7960, Test Acc: 0.7960\n",
      "Seed: 44, Epoch: 093, Loss: 0.1923, Val Acc: 0.7880, Test Acc: 0.7973\n",
      "Seed: 44, Epoch: 094, Loss: 0.1812, Val Acc: 0.7893, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 095, Loss: 0.1736, Val Acc: 0.7907, Test Acc: 0.8120\n",
      "Seed: 44, Epoch: 096, Loss: 0.1705, Val Acc: 0.7880, Test Acc: 0.8027\n",
      "Seed: 44, Epoch: 097, Loss: 0.1681, Val Acc: 0.7867, Test Acc: 0.7920\n",
      "Seed: 44, Epoch: 098, Loss: 0.1637, Val Acc: 0.7973, Test Acc: 0.8027\n",
      "Seed: 44, Epoch: 099, Loss: 0.1674, Val Acc: 0.7840, Test Acc: 0.8080\n",
      "Seed: 44, Epoch: 100, Loss: 0.1659, Val Acc: 0.7827, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 101, Loss: 0.1660, Val Acc: 0.7893, Test Acc: 0.8027\n",
      "Seed: 44, Epoch: 102, Loss: 0.1586, Val Acc: 0.7893, Test Acc: 0.8013\n",
      "Seed: 44, Epoch: 103, Loss: 0.1606, Val Acc: 0.7867, Test Acc: 0.8000\n",
      "Seed: 44, Epoch: 104, Loss: 0.1580, Val Acc: 0.7947, Test Acc: 0.7947\n",
      "Seed: 44, Epoch: 105, Loss: 0.1647, Val Acc: 0.7853, Test Acc: 0.7987\n",
      "Seed: 44, Epoch: 106, Loss: 0.1572, Val Acc: 0.7867, Test Acc: 0.8013\n",
      "Seed: 44, Epoch: 107, Loss: 0.1525, Val Acc: 0.7907, Test Acc: 0.8067\n",
      "Seed: 44, Epoch: 108, Loss: 0.1529, Val Acc: 0.7867, Test Acc: 0.7973\n",
      "Seed: 44, Epoch: 109, Loss: 0.1553, Val Acc: 0.7853, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 110, Loss: 0.1536, Val Acc: 0.7907, Test Acc: 0.7947\n",
      "Seed: 44, Epoch: 111, Loss: 0.1556, Val Acc: 0.7813, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 112, Loss: 0.1639, Val Acc: 0.7853, Test Acc: 0.7987\n",
      "Seed: 44, Epoch: 113, Loss: 0.1615, Val Acc: 0.7907, Test Acc: 0.7933\n",
      "Seed: 44, Epoch: 114, Loss: 0.1438, Val Acc: 0.7813, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 115, Loss: 0.1453, Val Acc: 0.7773, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 116, Loss: 0.1580, Val Acc: 0.7920, Test Acc: 0.7987\n",
      "Seed: 44, Epoch: 117, Loss: 0.1526, Val Acc: 0.7867, Test Acc: 0.7960\n",
      "Seed: 44, Epoch: 118, Loss: 0.1454, Val Acc: 0.7947, Test Acc: 0.7920\n",
      "Seed: 44, Epoch: 119, Loss: 0.1421, Val Acc: 0.7907, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 120, Loss: 0.1465, Val Acc: 0.7880, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 121, Loss: 0.1418, Val Acc: 0.7880, Test Acc: 0.8000\n",
      "Seed: 44, Epoch: 122, Loss: 0.1393, Val Acc: 0.7907, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 123, Loss: 0.1342, Val Acc: 0.7880, Test Acc: 0.7960\n",
      "Seed: 44, Epoch: 124, Loss: 0.1358, Val Acc: 0.7867, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 125, Loss: 0.1296, Val Acc: 0.7840, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 126, Loss: 0.1264, Val Acc: 0.7880, Test Acc: 0.7933\n",
      "Seed: 44, Epoch: 127, Loss: 0.1257, Val Acc: 0.7880, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 128, Loss: 0.1253, Val Acc: 0.7880, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 129, Loss: 0.1225, Val Acc: 0.7893, Test Acc: 0.7973\n",
      "Seed: 44, Epoch: 130, Loss: 0.1249, Val Acc: 0.7893, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 131, Loss: 0.1250, Val Acc: 0.7920, Test Acc: 0.7920\n",
      "Seed: 44, Epoch: 132, Loss: 0.1262, Val Acc: 0.7960, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 133, Loss: 0.1238, Val Acc: 0.7880, Test Acc: 0.7973\n",
      "Seed: 44, Epoch: 134, Loss: 0.1210, Val Acc: 0.7933, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 135, Loss: 0.1183, Val Acc: 0.8000, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 136, Loss: 0.1171, Val Acc: 0.7867, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 137, Loss: 0.1180, Val Acc: 0.7893, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 138, Loss: 0.1235, Val Acc: 0.7880, Test Acc: 0.7933\n",
      "Seed: 44, Epoch: 139, Loss: 0.1385, Val Acc: 0.7787, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 140, Loss: 0.1351, Val Acc: 0.7800, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 141, Loss: 0.1246, Val Acc: 0.7893, Test Acc: 0.7947\n",
      "Seed: 44, Epoch: 142, Loss: 0.1187, Val Acc: 0.7867, Test Acc: 0.7947\n",
      "Seed: 44, Epoch: 143, Loss: 0.1136, Val Acc: 0.7947, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 144, Loss: 0.1139, Val Acc: 0.7827, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 145, Loss: 0.1182, Val Acc: 0.7880, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 146, Loss: 0.1129, Val Acc: 0.7907, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 147, Loss: 0.1101, Val Acc: 0.7907, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 148, Loss: 0.1115, Val Acc: 0.7920, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 149, Loss: 0.1115, Val Acc: 0.7827, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 150, Loss: 0.1089, Val Acc: 0.7867, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 151, Loss: 0.1104, Val Acc: 0.7960, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 152, Loss: 0.1045, Val Acc: 0.7920, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 153, Loss: 0.1015, Val Acc: 0.7960, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 154, Loss: 0.1018, Val Acc: 0.7853, Test Acc: 0.7920\n",
      "Seed: 44, Epoch: 155, Loss: 0.1027, Val Acc: 0.7947, Test Acc: 0.7920\n",
      "Seed: 44, Epoch: 156, Loss: 0.0983, Val Acc: 0.7960, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 157, Loss: 0.0987, Val Acc: 0.7880, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 158, Loss: 0.1010, Val Acc: 0.7867, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 159, Loss: 0.0986, Val Acc: 0.7813, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 160, Loss: 0.1051, Val Acc: 0.7933, Test Acc: 0.7933\n",
      "Seed: 44, Epoch: 161, Loss: 0.1032, Val Acc: 0.7840, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 162, Loss: 0.1058, Val Acc: 0.7880, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 163, Loss: 0.1776, Val Acc: 0.7707, Test Acc: 0.7760\n",
      "Seed: 44, Epoch: 164, Loss: 0.2131, Val Acc: 0.7693, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 165, Loss: 0.1458, Val Acc: 0.7893, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 166, Loss: 0.1191, Val Acc: 0.7880, Test Acc: 0.7973\n",
      "Seed: 44, Epoch: 167, Loss: 0.1078, Val Acc: 0.7880, Test Acc: 0.7947\n",
      "Seed: 44, Epoch: 168, Loss: 0.1000, Val Acc: 0.7867, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 169, Loss: 0.0961, Val Acc: 0.7853, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 170, Loss: 0.0935, Val Acc: 0.7907, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 171, Loss: 0.0931, Val Acc: 0.7893, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 172, Loss: 0.0907, Val Acc: 0.7893, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 173, Loss: 0.0904, Val Acc: 0.7880, Test Acc: 0.7947\n",
      "Seed: 44, Epoch: 174, Loss: 0.0931, Val Acc: 0.7907, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 175, Loss: 0.0983, Val Acc: 0.7947, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 176, Loss: 0.0921, Val Acc: 0.7827, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 177, Loss: 0.0868, Val Acc: 0.7893, Test Acc: 0.7960\n",
      "Seed: 44, Epoch: 178, Loss: 0.0875, Val Acc: 0.7960, Test Acc: 0.7920\n",
      "Seed: 44, Epoch: 179, Loss: 0.0853, Val Acc: 0.7933, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 180, Loss: 0.0858, Val Acc: 0.7840, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 181, Loss: 0.0842, Val Acc: 0.7880, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 182, Loss: 0.0979, Val Acc: 0.7813, Test Acc: 0.7960\n",
      "Seed: 44, Epoch: 183, Loss: 0.1018, Val Acc: 0.7787, Test Acc: 0.7920\n",
      "Seed: 44, Epoch: 184, Loss: 0.1036, Val Acc: 0.7880, Test Acc: 0.7973\n",
      "Seed: 44, Epoch: 185, Loss: 0.1025, Val Acc: 0.7867, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 186, Loss: 0.1017, Val Acc: 0.7800, Test Acc: 0.7947\n",
      "Seed: 44, Epoch: 187, Loss: 0.0971, Val Acc: 0.7853, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 188, Loss: 0.0955, Val Acc: 0.7800, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 189, Loss: 0.0973, Val Acc: 0.7907, Test Acc: 0.8000\n",
      "Seed: 44, Epoch: 190, Loss: 0.0847, Val Acc: 0.7920, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 191, Loss: 0.0877, Val Acc: 0.7880, Test Acc: 0.7947\n",
      "Seed: 44, Epoch: 192, Loss: 0.0853, Val Acc: 0.7933, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 193, Loss: 0.0801, Val Acc: 0.7840, Test Acc: 0.7920\n",
      "Seed: 44, Epoch: 194, Loss: 0.0795, Val Acc: 0.7960, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 195, Loss: 0.0765, Val Acc: 0.7893, Test Acc: 0.7920\n",
      "Seed: 44, Epoch: 196, Loss: 0.0768, Val Acc: 0.7867, Test Acc: 0.7920\n",
      "Seed: 44, Epoch: 197, Loss: 0.0750, Val Acc: 0.7987, Test Acc: 0.7920\n",
      "Seed: 44, Epoch: 198, Loss: 0.0743, Val Acc: 0.7867, Test Acc: 0.7920\n",
      "Seed: 44, Epoch: 199, Loss: 0.0727, Val Acc: 0.7880, Test Acc: 0.7920\n",
      "Seed: 44, Epoch: 200, Loss: 0.0727, Val Acc: 0.7880, Test Acc: 0.7880\n",
      "Average Time: 1784.65 seconds\n",
      "Var Time: 6.56 seconds\n",
      "Average Memory: 60514.00 MB\n",
      "Average Best Val Acc: 0.8209\n",
      "Std Best Test Acc: 0.0106\n",
      "Average Test Acc: 0.8062\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_nodes = 500\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"COLLAB\",\n",
    "    transform=T.Compose([T.OneHotDegree(491), T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "dataset = dataset_dense\n",
    "dataset = dataset.shuffle()\n",
    "N = 150\n",
    "mp_layers = 1\n",
    "mp_channels = 64\n",
    "mp_activation = \"relu\"\n",
    "delta_coeff = 2.0\n",
    "\n",
    "mlp_hidden_layers = 2\n",
    "mlp_hidden_channels = 64\n",
    "mlp_activation = \"relu\"\n",
    "totvar_coeff = 0.5\n",
    "balance_coeff = 0.5\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "learning_rate = 5e-4\n",
    "l2_reg_val = 0\n",
    "patience = 10\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        if self.lin is not None:\n",
    "            x = self.lin(x).relu()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_AsymCheegerCut(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset.num_classes)\n",
    "\n",
    "        self.pool1 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "        self.pool2 = AsymCheegerCutPool(int(N//2),\n",
    "                           mlp_channels=[mp_channels] +\n",
    "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
    "                           mlp_activation=mlp_activation,\n",
    "                           totvar_coeff=totvar_coeff,\n",
    "                           balance_coeff=balance_coeff,\n",
    "                           return_selection=False,\n",
    "                           return_pooled_graph=True)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool1(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, tv1, bal1 = self.pool2(x, adj, mask=None)\n",
    "        #x = pool_output1.x_pool\n",
    "        #adj = pool_output1.adj_pool\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_AsymCheegerCut().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "    model = Net_AsymCheegerCut().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QM7 (2 64, 1 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existed dataset loaded: datasets/processed/qm7.pt\n",
      "\n",
      "Current dataset: qm7, include 6832 molecules and 1 regression tasks\n",
      "\n",
      "Splitting, finish 1/1  \n",
      "Epoch: 1/500MAE=1545.6508 MAE=1532.2898 MAE=1511.2916 MAE=1476.9377 MAE=1453.9104 MAE=1414.8418 MAE=1332.9738 MAE=1354.1702 MAE=1256.8965 Epoch: 10/500MAE=1249.6379 MAE=1143.9844 MAE=1042.0984 MAE=1040.6293 MAE=981.3605 MAE=859.9890 MAE=789.3861 MAE=598.2144 MAE=522.1515 MAE=376.8714 Epoch: 20/500MAE=496.9565 MAE=437.2871 MAE=353.8682 MAE=301.8752 MAE=78.5323 MAE=328.9137 MAE=144.1179 MAE=136.7178 MAE=143.6091 MAE=232.3712 Epoch: 30/500MAE=242.3170 MAE=104.6889 MAE=104.4016 MAE=161.7224 MAE=244.0971 MAE=183.4391 MAE=221.0983 MAE=194.1880 MAE=204.7583 MAE=185.3420 Epoch: 40/500MAE=197.0789 MAE=205.3470 MAE=198.0338 MAE=195.7416 MAE=201.6071 MAE=205.5452 MAE=204.5414 MAE=203.5570 MAE=198.0005 MAE=204.2218 Epoch: 50/500MAE=206.4478 MAE=202.4700 MAE=207.8313 MAE=203.9200 MAE=203.3765 MAE=204.7877 MAE=204.4341 MAE=204.5223 MAE=203.4426 MAE=203.9673 Epoch: 60/500MAE=204.1517 MAE=204.4212 MAE=203.8665 MAE=204.1880 MAE=204.3253 MAE=204.4065 MAE=204.3965 MAE=204.3077 MAE=204.1091 MAE=204.5222 Epoch: 70/500MAE=204.4202 MAE=204.2256 MAE=204.1876 MAE=204.3457 MAE=204.1807 MAE=204.3167 MAE=204.2137 MAE=203.9975 MAE=204.3104 MAE=204.3465 Epoch: 80/500MAE=204.4288 MAE=204.0944 MAE=204.1705 MAE=204.3177 MAE=204.4801 MAE=204.2304 MAE=204.3120 MAE=203.9656 MAE=203.9892 MAE=203.8747 Epoch: 90/500MAE=203.9952 MAE=204.1501 MAE=204.1460 MAE=204.0705 MAE=204.1354 MAE=204.2203 MAE=203.9588 MAE=204.1588 MAE=204.2138 MAE=204.2115 Epoch: 100/500MAE=204.3291 MAE=204.2742 MAE=204.2527 MAE=204.1985 MAE=204.0037 MAE=204.2351 MAE=203.9944 MAE=203.9760 MAE=204.0212 MAE=204.2413 Epoch: 110/500MAE=204.3233 MAE=204.0623 MAE=203.9722 MAE=204.1884 MAE=204.2579 MAE=204.1581 MAE=204.2601 MAE=204.1778 MAE=204.0974 MAE=203.8992 Epoch: 120/500MAE=203.9739 MAE=204.0060 MAE=204.5522 MAE=203.9714 MAE=203.8024 MAE=203.9793 MAE=204.0228 MAE=204.0344 MAE=204.0275 MAE=203.7600 Epoch: 130/500MAE=204.1339 MAE=203.9707 MAE=204.1144 MAE=204.0283 MAE=204.0395 MAE=204.1167 MAE=203.9881 MAE=204.0901 MAE=204.0641 MAE=204.0156 Epoch: 140/500MAE=204.0601 MAE=204.3345 MAE=204.0152 MAE=204.2018 MAE=203.8796 MAE=203.7963 MAE=203.9556 MAE=204.0003 MAE=204.0834 MAE=203.7024 Epoch: 150/500MAE=203.8826 MAE=203.7937 MAE=203.9221 MAE=203.9719 MAE=203.8647 MAE=203.8640 MAE=203.6750 MAE=203.9652 MAE=203.6302 MAE=203.8236 Epoch: 160/500MAE=203.5451 MAE=203.7966 MAE=203.9017 MAE=203.7298 MAE=203.8666 MAE=203.8621 MAE=203.7433 MAE=203.9796 MAE=203.7397 MAE=203.7269 Epoch: 170/500MAE=203.5286 MAE=203.6630 MAE=203.6179 MAE=203.7215 MAE=203.7896 MAE=76.7319 \n",
      "********************1's fold 1's run over********************\n",
      "MAE: 76.732 +/- 0.000\n",
      "\n",
      "Epoch: 1/500MAE=1545.0117 MAE=1514.9900 MAE=1490.5854 MAE=1483.2740 MAE=1458.6013 MAE=1438.6926 MAE=1398.5752 MAE=1351.8823 MAE=1302.4928 Epoch: 10/500MAE=1231.9172 MAE=1167.0338 MAE=1063.5515 MAE=997.1294 MAE=874.5740 MAE=869.7272 MAE=864.4507 MAE=687.0923 MAE=764.7701 MAE=307.2811 Epoch: 20/500MAE=650.5646 MAE=375.6712 MAE=589.1554 MAE=425.6545 MAE=160.1342 MAE=191.0085 MAE=95.4940 MAE=65.6497 MAE=144.0096 MAE=73.7061 Epoch: 30/500MAE=156.1822 MAE=142.3238 MAE=84.1690 MAE=102.0958 MAE=95.0483 MAE=53.6219 MAE=88.4175 MAE=65.8365 MAE=59.9744 MAE=71.8189 Epoch: 40/500MAE=75.8119 MAE=73.9749 MAE=73.7087 MAE=52.1732 MAE=63.6056 MAE=71.9197 MAE=81.4391 MAE=76.8375 MAE=62.3487 MAE=64.4538 Epoch: 50/500MAE=55.1893 MAE=74.4824 MAE=63.0405 MAE=63.6021 MAE=69.6972 MAE=67.2379 MAE=65.6228 MAE=66.0958 MAE=65.8288 MAE=68.3806 Epoch: 60/500MAE=67.8889 MAE=68.6167 MAE=69.3938 MAE=67.8457 MAE=67.1103 MAE=67.6072 MAE=68.3294 MAE=67.8956 MAE=68.0466 MAE=68.0693 Epoch: 70/500MAE=67.8425 MAE=67.9872 MAE=67.9234 MAE=67.6133 MAE=67.8335 MAE=67.7678 MAE=67.9656 MAE=67.7412 MAE=67.8320 MAE=67.6918 Epoch: 80/500MAE=67.9556 MAE=67.9090 MAE=67.8101 MAE=68.1764 MAE=67.7310 MAE=67.6247 MAE=67.8636 MAE=67.8070 MAE=67.9556 MAE=67.7049 Epoch: 90/500MAE=67.7745 MAE=67.8952 MAE=67.8729 MAE=67.9767 MAE=67.9198 MAE=68.1260 MAE=68.0731 MAE=68.0332 MAE=68.0898 MAE=67.9888 Epoch: 100/500MAE=67.9487 MAE=67.8549 MAE=68.0825 MAE=68.1345 MAE=68.1295 MAE=68.0967 MAE=68.0412 MAE=68.0713 MAE=68.0502 MAE=67.9342 Epoch: 110/500MAE=68.0487 MAE=67.9805 MAE=68.0711 MAE=68.0591 MAE=68.1289 MAE=68.0844 MAE=68.0478 MAE=68.2150 MAE=68.2686 MAE=68.3631 Epoch: 120/500MAE=68.2329 MAE=68.0625 MAE=68.0365 MAE=67.9796 MAE=68.1404 MAE=68.1124 MAE=68.2896 MAE=68.2031 MAE=68.1223 MAE=68.2284 Epoch: 130/500MAE=68.3546 MAE=68.2801 MAE=68.2098 MAE=68.2419 MAE=68.2171 MAE=68.1910 MAE=68.2028 MAE=68.3237 MAE=68.3986 MAE=68.3342 Epoch: 140/500MAE=68.2419 MAE=68.4026 MAE=68.2973 MAE=68.2590 MAE=68.4547 MAE=68.4452 MAE=68.1389 MAE=68.4153 MAE=68.5055 MAE=68.3726 Epoch: 150/500MAE=68.1912 MAE=68.4489 MAE=68.3380 MAE=68.3337 MAE=68.3118 MAE=68.3658 MAE=68.3239 MAE=68.1593 MAE=68.3722 MAE=68.3860 Epoch: 160/500MAE=68.2440 MAE=68.3468 MAE=68.3960 MAE=68.3280 MAE=68.2837 MAE=68.2195 MAE=68.4139 MAE=68.4648 MAE=68.3303 MAE=68.3283 Epoch: 170/500MAE=68.3030 MAE=68.4201 MAE=68.4448 MAE=68.4532 MAE=68.6073 MAE=68.4146 MAE=68.3570 MAE=68.5069 MAE=68.3501 MAE=68.3899 Epoch: 180/500MAE=68.3282 MAE=68.2420 MAE=68.4055 MAE=68.4249 MAE=68.2565 MAE=68.3139 MAE=68.1896 MAE=68.1793 MAE=68.3380 MAE=68.1397 Epoch: 190/500MAE=68.3495 MAE=68.2940 MAE=68.4636 MAE=68.3331 MAE=52.2089 \n",
      "********************1's fold 2's run over********************\n",
      "MAE: 64.470 +/- 12.262\n",
      "\n",
      "Epoch: 1/500MAE=1544.9478 MAE=1517.9012 MAE=1498.5747 MAE=1432.1943 MAE=1408.5710 MAE=1400.0361 MAE=1313.7629 MAE=1358.8950 MAE=1272.9913 Epoch: 10/500MAE=1246.4436 MAE=1141.3199 MAE=1130.1331 MAE=958.0520 MAE=890.9610 MAE=816.5079 MAE=737.8314 MAE=605.0349 MAE=732.1354 MAE=433.5457 Epoch: 20/500MAE=465.7396 MAE=247.3194 MAE=318.6554 MAE=247.1524 MAE=232.8176 MAE=89.8245 MAE=334.6315 MAE=238.9688 MAE=163.5303 MAE=276.6973 Epoch: 30/500MAE=140.3617 MAE=244.1251 MAE=87.9646 MAE=74.1539 MAE=237.5999 MAE=262.5101 MAE=57.5558 MAE=221.1885 MAE=548.0499 MAE=821.1152 Epoch: 40/500MAE=126.5617 MAE=218.0073 MAE=197.1384 MAE=182.0560 MAE=144.8333 MAE=178.0782 MAE=228.1686 MAE=215.5887 MAE=138.7127 MAE=210.0324 Epoch: 50/500MAE=219.7756 MAE=210.7063 MAE=209.3707 MAE=211.7646 MAE=208.5166 MAE=199.7110 MAE=207.5736 MAE=195.3777 MAE=206.0600 MAE=209.0645 Epoch: 60/500MAE=207.3983 MAE=198.2555 MAE=196.9685 MAE=203.3154 MAE=204.6530 MAE=201.3563 MAE=203.8203 MAE=200.3472 MAE=201.4699 MAE=200.5579 Epoch: 70/500MAE=199.7082 MAE=199.2856 MAE=201.5970 MAE=200.4219 MAE=198.4259 MAE=198.8630 MAE=199.4316 MAE=198.4513 MAE=199.2395 MAE=199.7316 Epoch: 80/500MAE=198.5750 MAE=200.2955 MAE=199.1516 MAE=198.7868 MAE=199.1967 MAE=199.5617 MAE=199.6759 MAE=198.4283 MAE=199.2997 MAE=198.5903 Epoch: 90/500MAE=198.6506 MAE=197.5539 MAE=199.6599 MAE=199.8457 MAE=198.6595 MAE=199.5639 MAE=200.0350 MAE=200.1066 MAE=199.8481 MAE=199.7659 Epoch: 100/500MAE=200.1106 MAE=199.1895 MAE=199.3603 MAE=201.4778 MAE=199.9187 MAE=199.8684 MAE=199.5909 MAE=198.3513 MAE=201.0985 MAE=199.1273 Epoch: 110/500MAE=200.1994 MAE=199.9673 MAE=199.6837 MAE=200.8701 MAE=199.7134 MAE=199.8697 MAE=199.6186 MAE=199.8787 MAE=199.4898 MAE=197.9932 Epoch: 120/500MAE=200.1404 MAE=200.1339 MAE=199.3992 MAE=199.4181 MAE=199.7217 MAE=199.1081 MAE=199.6667 MAE=198.9675 MAE=199.5331 MAE=200.0738 Epoch: 130/500MAE=200.3532 MAE=199.5688 MAE=201.6118 MAE=199.6111 MAE=199.5947 MAE=199.3906 MAE=200.8273 MAE=199.4432 MAE=199.1574 MAE=201.4802 Epoch: 140/500MAE=200.5556 MAE=200.5626 MAE=200.2991 MAE=200.4831 MAE=200.7168 MAE=200.2979 MAE=200.1794 MAE=200.1641 MAE=199.0339 MAE=200.4511 Epoch: 150/500MAE=199.1597 MAE=199.9491 MAE=200.6284 MAE=200.6277 MAE=199.7177 MAE=199.6327 MAE=200.2654 MAE=199.1838 MAE=198.0664 MAE=199.7869 Epoch: 160/500MAE=199.3476 MAE=199.3560 MAE=200.3348 MAE=199.7154 MAE=198.9178 MAE=199.7444 MAE=200.0609 MAE=199.7035 MAE=199.6942 MAE=200.3700 Epoch: 170/500MAE=199.4233 MAE=201.0872 MAE=199.4441 MAE=199.9257 MAE=199.1667 MAE=200.5085 MAE=200.0524 MAE=200.2903 MAE=200.1395 MAE=199.8681 Epoch: 180/500MAE=198.7641 MAE=201.2622 MAE=199.6399 MAE=199.9673 MAE=199.8625 MAE=199.3593 MAE=200.1092 MAE=69.2245 \n",
      "********************1's fold 3's run over********************\n",
      "MAE: 66.055 +/- 10.259\n",
      "\n",
      "Epoch: 1/500MAE=1546.4419 MAE=1523.1635 MAE=1491.6219 MAE=1486.7815 MAE=1469.4587 MAE=1439.9995 MAE=1383.4094 MAE=1320.0193 MAE=1264.9653 Epoch: 10/500MAE=1291.6685 MAE=1192.9243 MAE=1146.1316 MAE=1131.8293 MAE=925.0527 MAE=928.0225 MAE=896.7327 MAE=611.2388 MAE=408.2723 MAE=479.6607 Epoch: 20/500MAE=464.2455 MAE=383.6838 MAE=262.3616 MAE=413.4310 MAE=98.0443 MAE=99.8413 MAE=331.0992 MAE=147.0003 MAE=233.2529 MAE=62.1891 Epoch: 30/500MAE=62.7399 MAE=171.6182 MAE=57.6669 MAE=61.5202 MAE=95.9577 MAE=166.7666 MAE=238.0632 MAE=93.7195 MAE=89.8363 MAE=58.1923 Epoch: 40/500MAE=67.7626 MAE=152.2997 MAE=108.5289 MAE=116.7207 MAE=132.5485 MAE=107.9714 MAE=88.4652 MAE=112.2069 MAE=127.6058 MAE=96.6732 Epoch: 50/500MAE=96.3469 MAE=113.1458 MAE=111.7686 MAE=100.3799 MAE=95.3924 MAE=99.0867 MAE=95.8651 MAE=103.2840 MAE=97.7481 MAE=99.0087 Epoch: 60/500MAE=101.5430 MAE=99.7060 MAE=98.6136 MAE=96.5851 MAE=99.3403 MAE=99.6960 MAE=99.2450 MAE=98.9594 MAE=99.5128 MAE=98.5221 Epoch: 70/500MAE=98.3877 MAE=99.2093 MAE=98.7689 MAE=99.1056 MAE=98.5657 MAE=99.0820 MAE=98.8376 MAE=99.0812 MAE=98.9907 MAE=98.8605 Epoch: 80/500MAE=98.5724 MAE=98.7066 MAE=99.0683 MAE=98.5635 MAE=98.8722 MAE=98.8608 MAE=98.7521 MAE=98.1115 MAE=98.8638 MAE=98.4035 Epoch: 90/500MAE=98.6763 MAE=98.3678 MAE=98.4623 MAE=98.5816 MAE=98.6649 MAE=98.6162 MAE=98.1638 MAE=98.6642 MAE=98.7240 MAE=98.5514 Epoch: 100/500MAE=98.2114 MAE=98.8263 MAE=98.2443 MAE=98.7691 MAE=98.3761 MAE=98.4435 MAE=98.5609 MAE=98.3100 MAE=98.6003 MAE=98.2315 Epoch: 110/500MAE=98.3315 MAE=98.4850 MAE=98.1961 MAE=98.4542 MAE=98.5141 MAE=98.4400 MAE=98.5262 MAE=98.4496 MAE=98.1474 MAE=98.2581 Epoch: 120/500MAE=97.8975 MAE=98.4626 MAE=98.0879 MAE=97.8339 MAE=98.2767 MAE=98.0824 MAE=98.4166 MAE=98.8910 MAE=98.7332 MAE=98.8233 Epoch: 130/500MAE=98.4579 MAE=98.1639 MAE=98.2015 MAE=98.4074 MAE=98.5185 MAE=98.1801 MAE=97.8411 MAE=98.5983 MAE=98.2153 MAE=98.2459 Epoch: 140/500MAE=97.9184 MAE=97.8128 MAE=98.4290 MAE=98.0779 MAE=98.1248 MAE=97.8654 MAE=98.0377 MAE=98.3669 MAE=98.0521 MAE=98.0557 Epoch: 150/500MAE=98.0626 MAE=97.8363 MAE=97.7711 MAE=98.1480 MAE=97.8282 MAE=97.9511 MAE=97.9929 MAE=97.5862 MAE=98.0166 MAE=98.0406 Epoch: 160/500MAE=97.4664 MAE=97.7970 MAE=97.2633 MAE=97.8546 MAE=98.0472 MAE=97.4589 MAE=97.9551 MAE=97.7004 MAE=97.8463 MAE=97.9909 Epoch: 170/500MAE=97.8226 MAE=98.4561 MAE=97.6690 MAE=97.8637 MAE=97.6073 MAE=97.4139 MAE=97.6047 MAE=97.3012 MAE=97.6711 MAE=97.2617 Epoch: 180/500MAE=97.7706 MAE=97.9073 MAE=97.5322 MAE=60.0914 \n",
      "********************1's fold 4's run over********************\n",
      "MAE: 64.564 +/- 9.252\n",
      "\n",
      "Epoch: 1/500MAE=1544.7024 MAE=1523.1826 MAE=1507.2268 MAE=1481.2776 MAE=1463.9127 MAE=1358.7659 MAE=1415.7786 MAE=1346.8945 MAE=1314.0310 Epoch: 10/500MAE=1240.0994 MAE=1122.8167 MAE=1111.3628 MAE=1084.2639 MAE=962.2665 MAE=729.8590 MAE=699.6479 MAE=759.5527 MAE=605.3685 MAE=247.5117 Epoch: 20/500MAE=261.0612 MAE=297.1452 MAE=149.3487 MAE=151.7213 MAE=83.5092 MAE=93.0127 MAE=106.6654 MAE=75.7473 MAE=151.6989 MAE=154.2531 Epoch: 30/500MAE=126.2526 MAE=77.1921 MAE=121.6013 MAE=116.9946 MAE=62.1751 MAE=73.9457 MAE=189.4113 MAE=178.9105 MAE=248.9536 MAE=108.8997 Epoch: 40/500MAE=122.5872 MAE=195.4944 MAE=140.8032 MAE=111.3694 MAE=140.3014 MAE=97.9180 MAE=105.0458 MAE=144.2873 MAE=149.0667 MAE=177.1129 Epoch: 50/500MAE=157.8306 MAE=183.5001 MAE=153.6225 MAE=152.7896 MAE=154.6872 MAE=178.8082 MAE=182.2445 MAE=172.1255 MAE=172.3879 MAE=179.6461 Epoch: 60/500MAE=173.9854 MAE=179.2936 MAE=180.7845 MAE=175.5462 MAE=179.9737 MAE=179.7023 MAE=177.3412 MAE=178.7456 MAE=180.4247 MAE=179.0533 Epoch: 70/500MAE=179.0986 MAE=180.3694 MAE=180.4189 MAE=179.6712 MAE=179.5147 MAE=180.4812 MAE=179.4811 MAE=179.9319 MAE=179.8296 MAE=179.5387 Epoch: 80/500MAE=179.5256 MAE=179.5604 MAE=179.8040 MAE=179.6431 MAE=180.4806 MAE=179.7311 MAE=179.2217 MAE=179.4984 MAE=179.9078 MAE=180.3654 Epoch: 90/500MAE=179.5941 MAE=179.5415 MAE=179.6719 MAE=179.9719 MAE=179.8643 MAE=180.2367 MAE=179.6877 MAE=180.0642 MAE=180.0392 MAE=179.8431 Epoch: 100/500MAE=179.3905 MAE=180.2383 MAE=180.6221 MAE=180.0596 MAE=180.2366 MAE=179.1644 MAE=179.9337 MAE=179.6468 MAE=180.1854 MAE=180.0478 Epoch: 110/500MAE=180.1000 MAE=180.2891 MAE=180.3434 MAE=180.3877 MAE=180.5459 MAE=180.5593 MAE=180.0597 MAE=180.6688 MAE=180.5594 MAE=179.9361 Epoch: 120/500MAE=180.6351 MAE=181.0899 MAE=180.3611 MAE=180.4861 MAE=180.9545 MAE=180.8970 MAE=180.7057 MAE=180.3714 MAE=179.9454 MAE=180.3863 Epoch: 130/500MAE=180.1139 MAE=180.2860 MAE=180.5388 MAE=180.1742 MAE=180.0199 MAE=180.7631 MAE=180.5469 MAE=180.4482 MAE=180.1926 MAE=180.5553 Epoch: 140/500MAE=181.1521 MAE=180.0653 MAE=180.3389 MAE=180.7188 MAE=180.1983 MAE=179.2839 MAE=179.9236 MAE=180.1785 MAE=180.2191 MAE=180.0148 Epoch: 150/500MAE=179.8730 MAE=180.3569 MAE=179.9478 MAE=180.8360 MAE=180.5516 MAE=180.7803 MAE=180.2616 MAE=180.5570 MAE=179.9810 MAE=180.1881 Epoch: 160/500MAE=179.5980 MAE=180.4238 MAE=179.7736 MAE=180.5650 MAE=181.0079 MAE=180.9104 MAE=180.2990 MAE=180.6885 MAE=180.4766 MAE=180.4601 Epoch: 170/500MAE=180.2847 MAE=180.7220 MAE=180.7203 MAE=180.1301 MAE=181.4433 MAE=180.6919 MAE=180.7688 MAE=180.6980 MAE=180.6235 MAE=180.0105 Epoch: 180/500MAE=180.3313 MAE=179.7131 MAE=180.3420 MAE=180.6786 MAE=179.9427 MAE=66.2843 \n",
      "********************1's fold 5's run over********************\n",
      "MAE: 64.908 +/- 8.304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python /data/XXX/Pooling/Graph_Pooling_Benchmark/Regression/run_regression.py --dataset=qm7 --cuda_num 0 --run_times=5 --patience=150 --epochs=500 --pooling='AsymCheegerCut'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CG-ODE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
