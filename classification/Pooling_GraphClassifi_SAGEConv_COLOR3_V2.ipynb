{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N5YYcpp84KiL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "import torch\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import ToUndirected, AddSelfLoops\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "import os\n",
        "import torch\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.utils import degree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IxodCbqpMr4N"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import random\n",
        "random.seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from sklearn.model_selection import KFold\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "import psutil\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, TopKPooling\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "\n",
        "\n",
        "data_path = \"/data/zeyu/Pooling\"  # Adjust path as needed\n",
        "max_nodes = 150\n",
        "\n",
        "dataset_sparse = TUDataset(root=data_path, name='COLORS-3', use_node_attr=True, transform=T.Constant(), pre_filter=lambda data: data.num_nodes <= max_nodes)\n",
        "dataset_sparse = dataset_sparse.shuffle()\n",
        "\n",
        "dataset_size = len(dataset_sparse)\n",
        "train_size = int(dataset_size * 0.7)\n",
        "val_size = int(dataset_size * 0.15)\n",
        "test_size = dataset_size - train_size - val_size\n",
        "\n",
        "train_dataset = dataset_sparse[:train_size]\n",
        "val_dataset = dataset_sparse[train_size:train_size+val_size]\n",
        "test_dataset = dataset_sparse[train_size+val_size:]\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=True)\n",
        "valid_loader = DataLoader(val_dataset, batch_size=2048, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUGRHf1_NhfO"
      },
      "source": [
        "## TopKPooling with HierarchicalGCN (2019)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oms55mqCB93_",
        "outputId": "751962cb-23e1-4bb5-ba9d-7f200180016c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 001, Loss: 2.4046, Val Acc: 0.0601, Test Acc: 0.0722\n",
            "Seed: 42, Epoch: 002, Loss: 2.4034, Val Acc: 0.0601, Test Acc: 0.0722\n",
            "Seed: 42, Epoch: 003, Loss: 2.4023, Val Acc: 0.0601, Test Acc: 0.0722\n",
            "Seed: 42, Epoch: 004, Loss: 2.4013, Val Acc: 0.0601, Test Acc: 0.0722\n",
            "Seed: 42, Epoch: 005, Loss: 2.4002, Val Acc: 0.0601, Test Acc: 0.0722\n",
            "Seed: 42, Epoch: 006, Loss: 2.3990, Val Acc: 0.0610, Test Acc: 0.0688\n",
            "Seed: 42, Epoch: 007, Loss: 2.3975, Val Acc: 0.0627, Test Acc: 0.0714\n",
            "Seed: 42, Epoch: 008, Loss: 2.3961, Val Acc: 0.0653, Test Acc: 0.0844\n",
            "Seed: 42, Epoch: 009, Loss: 2.3943, Val Acc: 0.0740, Test Acc: 0.0923\n",
            "Seed: 42, Epoch: 010, Loss: 2.3921, Val Acc: 0.0819, Test Acc: 0.0870\n",
            "Seed: 42, Epoch: 011, Loss: 2.3892, Val Acc: 0.0871, Test Acc: 0.0888\n",
            "Seed: 42, Epoch: 012, Loss: 2.3852, Val Acc: 0.1098, Test Acc: 0.1114\n",
            "Seed: 42, Epoch: 013, Loss: 2.3800, Val Acc: 0.1446, Test Acc: 0.1558\n",
            "Seed: 42, Epoch: 014, Loss: 2.3736, Val Acc: 0.1603, Test Acc: 0.1749\n",
            "Seed: 42, Epoch: 015, Loss: 2.3649, Val Acc: 0.1812, Test Acc: 0.1880\n",
            "Seed: 42, Epoch: 016, Loss: 2.3545, Val Acc: 0.1786, Test Acc: 0.1828\n",
            "Seed: 42, Epoch: 017, Loss: 2.3395, Val Acc: 0.1925, Test Acc: 0.1984\n",
            "Seed: 42, Epoch: 018, Loss: 2.3205, Val Acc: 0.1934, Test Acc: 0.2132\n",
            "Seed: 42, Epoch: 019, Loss: 2.3014, Val Acc: 0.1916, Test Acc: 0.2063\n",
            "Seed: 42, Epoch: 020, Loss: 2.2823, Val Acc: 0.1916, Test Acc: 0.2106\n",
            "Seed: 42, Epoch: 021, Loss: 2.2631, Val Acc: 0.1934, Test Acc: 0.2089\n",
            "Seed: 42, Epoch: 022, Loss: 2.2442, Val Acc: 0.2038, Test Acc: 0.2010\n",
            "Seed: 42, Epoch: 023, Loss: 2.2268, Val Acc: 0.1855, Test Acc: 0.1723\n",
            "Seed: 42, Epoch: 024, Loss: 2.2054, Val Acc: 0.1803, Test Acc: 0.1715\n",
            "Seed: 42, Epoch: 025, Loss: 2.1907, Val Acc: 0.1472, Test Acc: 0.1662\n",
            "Seed: 42, Epoch: 026, Loss: 2.1772, Val Acc: 0.1768, Test Acc: 0.1828\n",
            "Seed: 42, Epoch: 027, Loss: 2.1607, Val Acc: 0.1638, Test Acc: 0.1845\n",
            "Seed: 42, Epoch: 028, Loss: 2.1443, Val Acc: 0.1629, Test Acc: 0.1862\n",
            "Seed: 42, Epoch: 029, Loss: 2.1331, Val Acc: 0.1699, Test Acc: 0.1941\n",
            "Seed: 42, Epoch: 030, Loss: 2.1264, Val Acc: 0.1786, Test Acc: 0.2019\n",
            "Seed: 42, Epoch: 031, Loss: 2.1193, Val Acc: 0.1690, Test Acc: 0.2228\n",
            "Seed: 42, Epoch: 032, Loss: 2.1110, Val Acc: 0.1873, Test Acc: 0.2124\n",
            "Seed: 42, Epoch: 033, Loss: 2.1043, Val Acc: 0.1733, Test Acc: 0.2202\n",
            "Seed: 42, Epoch: 034, Loss: 2.0997, Val Acc: 0.1707, Test Acc: 0.2037\n",
            "Seed: 42, Epoch: 035, Loss: 2.0978, Val Acc: 0.1838, Test Acc: 0.2010\n",
            "Seed: 42, Epoch: 036, Loss: 2.0931, Val Acc: 0.1794, Test Acc: 0.2211\n",
            "Seed: 42, Epoch: 037, Loss: 2.0847, Val Acc: 0.1725, Test Acc: 0.2071\n",
            "Seed: 42, Epoch: 038, Loss: 2.0791, Val Acc: 0.1768, Test Acc: 0.2150\n",
            "Seed: 42, Epoch: 039, Loss: 2.0766, Val Acc: 0.1742, Test Acc: 0.2150\n",
            "Seed: 42, Epoch: 040, Loss: 2.0666, Val Acc: 0.1908, Test Acc: 0.2124\n",
            "Seed: 42, Epoch: 041, Loss: 2.0599, Val Acc: 0.1908, Test Acc: 0.2158\n",
            "Seed: 42, Epoch: 042, Loss: 2.0573, Val Acc: 0.1882, Test Acc: 0.2158\n",
            "Seed: 42, Epoch: 043, Loss: 2.0519, Val Acc: 0.1934, Test Acc: 0.2176\n",
            "Seed: 42, Epoch: 044, Loss: 2.0494, Val Acc: 0.1847, Test Acc: 0.2106\n",
            "Seed: 42, Epoch: 045, Loss: 2.0438, Val Acc: 0.1899, Test Acc: 0.2176\n",
            "Seed: 42, Epoch: 046, Loss: 2.0400, Val Acc: 0.1847, Test Acc: 0.2237\n",
            "Seed: 42, Epoch: 047, Loss: 2.0357, Val Acc: 0.2047, Test Acc: 0.2211\n",
            "Seed: 42, Epoch: 048, Loss: 2.0334, Val Acc: 0.1960, Test Acc: 0.2202\n",
            "Seed: 42, Epoch: 049, Loss: 2.0288, Val Acc: 0.1943, Test Acc: 0.2228\n",
            "Seed: 42, Epoch: 050, Loss: 2.0249, Val Acc: 0.1986, Test Acc: 0.2289\n",
            "Seed: 42, Epoch: 051, Loss: 2.0229, Val Acc: 0.1838, Test Acc: 0.2185\n",
            "Seed: 42, Epoch: 052, Loss: 2.0250, Val Acc: 0.1995, Test Acc: 0.2185\n",
            "Seed: 42, Epoch: 053, Loss: 2.0255, Val Acc: 0.1873, Test Acc: 0.2158\n",
            "Seed: 42, Epoch: 054, Loss: 2.0245, Val Acc: 0.1821, Test Acc: 0.2089\n",
            "Seed: 42, Epoch: 055, Loss: 2.0298, Val Acc: 0.1873, Test Acc: 0.2089\n",
            "Seed: 42, Epoch: 056, Loss: 2.0309, Val Acc: 0.1855, Test Acc: 0.2150\n",
            "Seed: 42, Epoch: 057, Loss: 2.0286, Val Acc: 0.1951, Test Acc: 0.2019\n",
            "Seed: 42, Epoch: 058, Loss: 2.0284, Val Acc: 0.1969, Test Acc: 0.2141\n",
            "Seed: 42, Epoch: 059, Loss: 2.0211, Val Acc: 0.1890, Test Acc: 0.2132\n",
            "Seed: 42, Epoch: 060, Loss: 2.0168, Val Acc: 0.1838, Test Acc: 0.2071\n",
            "Seed: 42, Epoch: 061, Loss: 2.0123, Val Acc: 0.1908, Test Acc: 0.2089\n",
            "Seed: 42, Epoch: 062, Loss: 2.0068, Val Acc: 0.1916, Test Acc: 0.2089\n",
            "Seed: 42, Epoch: 063, Loss: 2.0058, Val Acc: 0.1838, Test Acc: 0.1993\n",
            "Seed: 42, Epoch: 064, Loss: 2.0010, Val Acc: 0.1760, Test Acc: 0.2115\n",
            "Seed: 42, Epoch: 065, Loss: 1.9976, Val Acc: 0.1794, Test Acc: 0.2132\n",
            "Seed: 42, Epoch: 066, Loss: 1.9929, Val Acc: 0.1812, Test Acc: 0.2010\n",
            "Seed: 42, Epoch: 067, Loss: 1.9924, Val Acc: 0.1916, Test Acc: 0.2158\n",
            "Seed: 42, Epoch: 068, Loss: 1.9893, Val Acc: 0.1908, Test Acc: 0.2080\n",
            "Seed: 42, Epoch: 069, Loss: 1.9862, Val Acc: 0.1864, Test Acc: 0.2228\n",
            "Seed: 42, Epoch: 070, Loss: 1.9841, Val Acc: 0.1908, Test Acc: 0.2167\n",
            "Seed: 42, Epoch: 071, Loss: 1.9801, Val Acc: 0.1882, Test Acc: 0.2106\n",
            "Seed: 42, Epoch: 072, Loss: 1.9770, Val Acc: 0.1908, Test Acc: 0.2176\n",
            "Seed: 42, Epoch: 073, Loss: 1.9721, Val Acc: 0.1890, Test Acc: 0.2132\n",
            "Seed: 42, Epoch: 074, Loss: 1.9656, Val Acc: 0.2030, Test Acc: 0.2263\n",
            "Seed: 42, Epoch: 075, Loss: 1.9657, Val Acc: 0.2012, Test Acc: 0.2219\n",
            "Seed: 42, Epoch: 076, Loss: 1.9674, Val Acc: 0.2030, Test Acc: 0.2019\n",
            "Seed: 42, Epoch: 077, Loss: 1.9654, Val Acc: 0.2021, Test Acc: 0.2263\n",
            "Seed: 42, Epoch: 078, Loss: 1.9617, Val Acc: 0.2012, Test Acc: 0.2237\n",
            "Seed: 42, Epoch: 079, Loss: 1.9688, Val Acc: 0.2056, Test Acc: 0.2185\n",
            "Seed: 42, Epoch: 080, Loss: 1.9643, Val Acc: 0.2099, Test Acc: 0.2158\n",
            "Seed: 42, Epoch: 081, Loss: 1.9615, Val Acc: 0.2064, Test Acc: 0.2193\n",
            "Seed: 42, Epoch: 082, Loss: 1.9550, Val Acc: 0.2125, Test Acc: 0.2167\n",
            "Seed: 42, Epoch: 083, Loss: 1.9543, Val Acc: 0.2134, Test Acc: 0.2228\n",
            "Seed: 42, Epoch: 084, Loss: 1.9536, Val Acc: 0.2160, Test Acc: 0.2280\n",
            "Seed: 42, Epoch: 085, Loss: 1.9514, Val Acc: 0.2047, Test Acc: 0.2289\n",
            "Seed: 42, Epoch: 086, Loss: 1.9443, Val Acc: 0.2056, Test Acc: 0.2185\n",
            "Seed: 42, Epoch: 087, Loss: 1.9487, Val Acc: 0.2178, Test Acc: 0.2245\n",
            "Seed: 42, Epoch: 088, Loss: 1.9453, Val Acc: 0.2169, Test Acc: 0.2263\n",
            "Seed: 42, Epoch: 089, Loss: 1.9468, Val Acc: 0.2134, Test Acc: 0.2298\n",
            "Seed: 42, Epoch: 090, Loss: 1.9408, Val Acc: 0.2134, Test Acc: 0.2367\n",
            "Seed: 42, Epoch: 091, Loss: 1.9404, Val Acc: 0.2125, Test Acc: 0.2376\n",
            "Seed: 42, Epoch: 092, Loss: 1.9405, Val Acc: 0.2056, Test Acc: 0.2272\n",
            "Seed: 42, Epoch: 093, Loss: 1.9367, Val Acc: 0.2143, Test Acc: 0.2280\n",
            "Seed: 42, Epoch: 094, Loss: 1.9351, Val Acc: 0.2117, Test Acc: 0.2289\n",
            "Seed: 42, Epoch: 095, Loss: 1.9312, Val Acc: 0.2160, Test Acc: 0.2254\n",
            "Seed: 42, Epoch: 096, Loss: 1.9315, Val Acc: 0.2021, Test Acc: 0.2332\n",
            "Seed: 42, Epoch: 097, Loss: 1.9237, Val Acc: 0.2143, Test Acc: 0.2219\n",
            "Seed: 42, Epoch: 098, Loss: 1.9237, Val Acc: 0.2195, Test Acc: 0.2359\n",
            "Seed: 42, Epoch: 099, Loss: 1.9227, Val Acc: 0.2195, Test Acc: 0.2306\n",
            "Seed: 42, Epoch: 100, Loss: 1.9216, Val Acc: 0.2204, Test Acc: 0.2237\n",
            "Seed: 42, Epoch: 101, Loss: 1.9198, Val Acc: 0.2247, Test Acc: 0.2254\n",
            "Seed: 42, Epoch: 102, Loss: 1.9154, Val Acc: 0.2291, Test Acc: 0.2245\n",
            "Seed: 42, Epoch: 103, Loss: 1.9161, Val Acc: 0.2230, Test Acc: 0.2350\n",
            "Seed: 42, Epoch: 104, Loss: 1.9233, Val Acc: 0.2204, Test Acc: 0.2306\n",
            "Seed: 42, Epoch: 105, Loss: 1.9336, Val Acc: 0.2186, Test Acc: 0.2237\n",
            "Seed: 42, Epoch: 106, Loss: 1.9312, Val Acc: 0.2178, Test Acc: 0.2350\n",
            "Seed: 42, Epoch: 107, Loss: 1.9302, Val Acc: 0.2274, Test Acc: 0.2332\n",
            "Seed: 42, Epoch: 108, Loss: 1.9319, Val Acc: 0.2343, Test Acc: 0.2332\n",
            "Seed: 42, Epoch: 109, Loss: 1.9233, Val Acc: 0.2256, Test Acc: 0.2298\n",
            "Seed: 42, Epoch: 110, Loss: 1.9331, Val Acc: 0.2256, Test Acc: 0.2263\n",
            "Seed: 42, Epoch: 111, Loss: 1.9309, Val Acc: 0.2195, Test Acc: 0.2341\n",
            "Seed: 42, Epoch: 112, Loss: 1.9336, Val Acc: 0.2195, Test Acc: 0.2341\n",
            "Seed: 42, Epoch: 113, Loss: 1.9268, Val Acc: 0.2195, Test Acc: 0.2176\n",
            "Seed: 42, Epoch: 114, Loss: 1.9463, Val Acc: 0.2230, Test Acc: 0.2141\n",
            "Seed: 42, Epoch: 115, Loss: 1.9273, Val Acc: 0.2213, Test Acc: 0.2115\n",
            "Seed: 42, Epoch: 116, Loss: 1.9293, Val Acc: 0.2274, Test Acc: 0.2185\n",
            "Seed: 42, Epoch: 117, Loss: 1.9275, Val Acc: 0.2300, Test Acc: 0.2158\n",
            "Seed: 42, Epoch: 118, Loss: 1.9231, Val Acc: 0.2308, Test Acc: 0.2332\n",
            "Seed: 42, Epoch: 119, Loss: 1.9178, Val Acc: 0.2378, Test Acc: 0.2289\n",
            "Seed: 42, Epoch: 120, Loss: 1.9105, Val Acc: 0.2352, Test Acc: 0.2385\n",
            "Seed: 42, Epoch: 121, Loss: 1.9033, Val Acc: 0.2369, Test Acc: 0.2489\n",
            "Seed: 42, Epoch: 122, Loss: 1.9001, Val Acc: 0.2291, Test Acc: 0.2411\n",
            "Seed: 42, Epoch: 123, Loss: 1.9038, Val Acc: 0.2361, Test Acc: 0.2498\n",
            "Seed: 42, Epoch: 124, Loss: 1.9035, Val Acc: 0.2456, Test Acc: 0.2602\n",
            "Seed: 42, Epoch: 125, Loss: 1.9021, Val Acc: 0.2509, Test Acc: 0.2620\n",
            "Seed: 42, Epoch: 126, Loss: 1.8893, Val Acc: 0.2483, Test Acc: 0.2646\n",
            "Seed: 42, Epoch: 127, Loss: 1.8988, Val Acc: 0.2535, Test Acc: 0.2663\n",
            "Seed: 42, Epoch: 128, Loss: 1.8814, Val Acc: 0.2517, Test Acc: 0.2681\n",
            "Seed: 42, Epoch: 129, Loss: 1.8862, Val Acc: 0.2404, Test Acc: 0.2480\n",
            "Seed: 42, Epoch: 130, Loss: 1.8886, Val Acc: 0.2517, Test Acc: 0.2585\n",
            "Seed: 42, Epoch: 131, Loss: 1.8903, Val Acc: 0.2483, Test Acc: 0.2541\n",
            "Seed: 42, Epoch: 132, Loss: 1.8918, Val Acc: 0.2456, Test Acc: 0.2437\n",
            "Seed: 42, Epoch: 133, Loss: 1.8924, Val Acc: 0.2474, Test Acc: 0.2594\n",
            "Seed: 42, Epoch: 134, Loss: 1.8847, Val Acc: 0.2439, Test Acc: 0.2698\n",
            "Seed: 42, Epoch: 135, Loss: 1.8743, Val Acc: 0.2587, Test Acc: 0.2637\n",
            "Seed: 42, Epoch: 136, Loss: 1.8745, Val Acc: 0.2631, Test Acc: 0.2715\n",
            "Seed: 42, Epoch: 137, Loss: 1.8630, Val Acc: 0.2700, Test Acc: 0.2750\n",
            "Seed: 42, Epoch: 138, Loss: 1.8536, Val Acc: 0.2718, Test Acc: 0.2759\n",
            "Seed: 42, Epoch: 139, Loss: 1.8536, Val Acc: 0.2631, Test Acc: 0.2881\n",
            "Seed: 42, Epoch: 140, Loss: 1.8477, Val Acc: 0.2657, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 141, Loss: 1.8465, Val Acc: 0.2674, Test Acc: 0.2863\n",
            "Seed: 42, Epoch: 142, Loss: 1.8461, Val Acc: 0.2761, Test Acc: 0.2698\n",
            "Seed: 42, Epoch: 143, Loss: 1.8438, Val Acc: 0.2726, Test Acc: 0.2829\n",
            "Seed: 42, Epoch: 144, Loss: 1.8508, Val Acc: 0.2744, Test Acc: 0.2942\n",
            "Seed: 42, Epoch: 145, Loss: 1.8451, Val Acc: 0.2779, Test Acc: 0.2829\n",
            "Seed: 42, Epoch: 146, Loss: 1.8360, Val Acc: 0.2735, Test Acc: 0.2855\n",
            "Seed: 42, Epoch: 147, Loss: 1.8368, Val Acc: 0.2744, Test Acc: 0.2750\n",
            "Seed: 42, Epoch: 148, Loss: 1.8432, Val Acc: 0.2831, Test Acc: 0.2811\n",
            "Seed: 42, Epoch: 149, Loss: 1.8352, Val Acc: 0.2692, Test Acc: 0.2724\n",
            "Seed: 42, Epoch: 150, Loss: 1.8341, Val Acc: 0.2779, Test Acc: 0.2750\n",
            "Seed: 42, Epoch: 151, Loss: 1.8295, Val Acc: 0.2692, Test Acc: 0.2768\n",
            "Seed: 42, Epoch: 152, Loss: 1.8285, Val Acc: 0.2683, Test Acc: 0.2759\n",
            "Seed: 42, Epoch: 153, Loss: 1.8246, Val Acc: 0.2770, Test Acc: 0.2829\n",
            "Seed: 42, Epoch: 154, Loss: 1.8242, Val Acc: 0.2840, Test Acc: 0.2820\n",
            "Seed: 42, Epoch: 155, Loss: 1.8214, Val Acc: 0.2892, Test Acc: 0.2785\n",
            "Seed: 42, Epoch: 156, Loss: 1.8181, Val Acc: 0.2883, Test Acc: 0.2881\n",
            "Seed: 42, Epoch: 157, Loss: 1.8126, Val Acc: 0.2787, Test Acc: 0.2968\n",
            "Seed: 42, Epoch: 158, Loss: 1.8107, Val Acc: 0.2840, Test Acc: 0.3011\n",
            "Seed: 42, Epoch: 159, Loss: 1.8085, Val Acc: 0.2875, Test Acc: 0.2881\n",
            "Seed: 42, Epoch: 160, Loss: 1.8064, Val Acc: 0.2953, Test Acc: 0.2872\n",
            "Seed: 42, Epoch: 161, Loss: 1.8034, Val Acc: 0.2814, Test Acc: 0.2794\n",
            "Seed: 42, Epoch: 162, Loss: 1.7992, Val Acc: 0.2857, Test Acc: 0.2855\n",
            "Seed: 42, Epoch: 163, Loss: 1.7997, Val Acc: 0.2683, Test Acc: 0.2898\n",
            "Seed: 42, Epoch: 164, Loss: 1.7966, Val Acc: 0.2735, Test Acc: 0.2863\n",
            "Seed: 42, Epoch: 165, Loss: 1.7932, Val Acc: 0.2831, Test Acc: 0.3029\n",
            "Seed: 42, Epoch: 166, Loss: 1.7922, Val Acc: 0.2735, Test Acc: 0.2872\n",
            "Seed: 42, Epoch: 167, Loss: 1.7883, Val Acc: 0.2761, Test Acc: 0.2985\n",
            "Seed: 42, Epoch: 168, Loss: 1.7878, Val Acc: 0.2927, Test Acc: 0.3098\n",
            "Seed: 42, Epoch: 169, Loss: 1.7855, Val Acc: 0.2805, Test Acc: 0.3011\n",
            "Seed: 42, Epoch: 170, Loss: 1.7798, Val Acc: 0.2840, Test Acc: 0.3046\n",
            "Seed: 42, Epoch: 171, Loss: 1.7802, Val Acc: 0.2857, Test Acc: 0.3090\n",
            "Seed: 42, Epoch: 172, Loss: 1.7706, Val Acc: 0.2918, Test Acc: 0.3029\n",
            "Seed: 42, Epoch: 173, Loss: 1.7669, Val Acc: 0.2866, Test Acc: 0.3098\n",
            "Seed: 42, Epoch: 174, Loss: 1.7650, Val Acc: 0.2997, Test Acc: 0.3081\n",
            "Seed: 42, Epoch: 175, Loss: 1.7673, Val Acc: 0.2953, Test Acc: 0.3020\n",
            "Seed: 42, Epoch: 176, Loss: 1.7646, Val Acc: 0.3031, Test Acc: 0.3107\n",
            "Seed: 42, Epoch: 177, Loss: 1.7617, Val Acc: 0.3153, Test Acc: 0.3168\n",
            "Seed: 42, Epoch: 178, Loss: 1.7631, Val Acc: 0.3127, Test Acc: 0.3020\n",
            "Seed: 42, Epoch: 179, Loss: 1.7595, Val Acc: 0.3023, Test Acc: 0.3133\n",
            "Seed: 42, Epoch: 180, Loss: 1.7590, Val Acc: 0.3084, Test Acc: 0.3133\n",
            "Seed: 42, Epoch: 181, Loss: 1.7582, Val Acc: 0.3014, Test Acc: 0.3107\n",
            "Seed: 42, Epoch: 182, Loss: 1.7657, Val Acc: 0.3049, Test Acc: 0.3081\n",
            "Seed: 42, Epoch: 183, Loss: 1.7585, Val Acc: 0.2875, Test Acc: 0.3124\n",
            "Seed: 42, Epoch: 184, Loss: 1.7692, Val Acc: 0.2892, Test Acc: 0.3003\n",
            "Seed: 42, Epoch: 185, Loss: 1.7702, Val Acc: 0.2944, Test Acc: 0.3142\n",
            "Seed: 42, Epoch: 186, Loss: 1.7611, Val Acc: 0.2857, Test Acc: 0.3064\n",
            "Seed: 42, Epoch: 187, Loss: 1.7593, Val Acc: 0.3066, Test Acc: 0.3107\n",
            "Seed: 42, Epoch: 188, Loss: 1.7519, Val Acc: 0.3049, Test Acc: 0.3090\n",
            "Seed: 42, Epoch: 189, Loss: 1.7464, Val Acc: 0.2875, Test Acc: 0.2968\n",
            "Seed: 42, Epoch: 190, Loss: 1.7471, Val Acc: 0.2979, Test Acc: 0.3133\n",
            "Seed: 42, Epoch: 191, Loss: 1.7441, Val Acc: 0.3057, Test Acc: 0.3133\n",
            "Seed: 42, Epoch: 192, Loss: 1.7415, Val Acc: 0.2918, Test Acc: 0.3064\n",
            "Seed: 42, Epoch: 193, Loss: 1.7464, Val Acc: 0.3049, Test Acc: 0.3072\n",
            "Seed: 42, Epoch: 194, Loss: 1.7521, Val Acc: 0.2970, Test Acc: 0.3037\n",
            "Seed: 42, Epoch: 195, Loss: 1.7427, Val Acc: 0.2901, Test Acc: 0.2968\n",
            "Seed: 42, Epoch: 196, Loss: 1.7465, Val Acc: 0.2944, Test Acc: 0.3090\n",
            "Seed: 42, Epoch: 197, Loss: 1.7411, Val Acc: 0.3005, Test Acc: 0.3081\n",
            "Seed: 42, Epoch: 198, Loss: 1.7433, Val Acc: 0.2779, Test Acc: 0.2916\n",
            "Seed: 42, Epoch: 199, Loss: 1.7552, Val Acc: 0.2997, Test Acc: 0.2968\n",
            "Seed: 42, Epoch: 200, Loss: 1.7526, Val Acc: 0.3057, Test Acc: 0.3098\n",
            "Seed: 43, Epoch: 001, Loss: 2.4111, Val Acc: 0.0967, Test Acc: 0.0879\n",
            "Seed: 43, Epoch: 002, Loss: 2.4096, Val Acc: 0.0949, Test Acc: 0.0870\n",
            "Seed: 43, Epoch: 003, Loss: 2.4081, Val Acc: 0.0967, Test Acc: 0.0844\n",
            "Seed: 43, Epoch: 004, Loss: 2.4069, Val Acc: 0.1037, Test Acc: 0.0862\n",
            "Seed: 43, Epoch: 005, Loss: 2.4056, Val Acc: 0.1019, Test Acc: 0.0853\n",
            "Seed: 43, Epoch: 006, Loss: 2.4044, Val Acc: 0.1010, Test Acc: 0.0844\n",
            "Seed: 43, Epoch: 007, Loss: 2.4031, Val Acc: 0.1010, Test Acc: 0.0844\n",
            "Seed: 43, Epoch: 008, Loss: 2.4016, Val Acc: 0.1010, Test Acc: 0.0844\n",
            "Seed: 43, Epoch: 009, Loss: 2.3996, Val Acc: 0.1010, Test Acc: 0.0844\n",
            "Seed: 43, Epoch: 010, Loss: 2.3972, Val Acc: 0.1010, Test Acc: 0.0844\n",
            "Seed: 43, Epoch: 011, Loss: 2.3938, Val Acc: 0.1150, Test Acc: 0.1044\n",
            "Seed: 43, Epoch: 012, Loss: 2.3893, Val Acc: 0.1437, Test Acc: 0.1401\n",
            "Seed: 43, Epoch: 013, Loss: 2.3835, Val Acc: 0.1646, Test Acc: 0.1619\n",
            "Seed: 43, Epoch: 014, Loss: 2.3752, Val Acc: 0.1925, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 015, Loss: 2.3642, Val Acc: 0.1890, Test Acc: 0.1862\n",
            "Seed: 43, Epoch: 016, Loss: 2.3512, Val Acc: 0.1951, Test Acc: 0.2019\n",
            "Seed: 43, Epoch: 017, Loss: 2.3348, Val Acc: 0.1838, Test Acc: 0.1923\n",
            "Seed: 43, Epoch: 018, Loss: 2.3196, Val Acc: 0.1899, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 019, Loss: 2.3019, Val Acc: 0.1890, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 020, Loss: 2.2881, Val Acc: 0.1908, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 021, Loss: 2.2722, Val Acc: 0.1890, Test Acc: 0.1906\n",
            "Seed: 43, Epoch: 022, Loss: 2.2585, Val Acc: 0.1890, Test Acc: 0.1958\n",
            "Seed: 43, Epoch: 023, Loss: 2.2462, Val Acc: 0.1751, Test Acc: 0.2037\n",
            "Seed: 43, Epoch: 024, Loss: 2.2378, Val Acc: 0.1794, Test Acc: 0.1984\n",
            "Seed: 43, Epoch: 025, Loss: 2.2287, Val Acc: 0.1847, Test Acc: 0.2045\n",
            "Seed: 43, Epoch: 026, Loss: 2.2185, Val Acc: 0.1908, Test Acc: 0.2185\n",
            "Seed: 43, Epoch: 027, Loss: 2.2092, Val Acc: 0.1916, Test Acc: 0.2228\n",
            "Seed: 43, Epoch: 028, Loss: 2.1998, Val Acc: 0.1864, Test Acc: 0.2245\n",
            "Seed: 43, Epoch: 029, Loss: 2.1914, Val Acc: 0.1908, Test Acc: 0.2289\n",
            "Seed: 43, Epoch: 030, Loss: 2.1811, Val Acc: 0.1873, Test Acc: 0.2202\n",
            "Seed: 43, Epoch: 031, Loss: 2.1719, Val Acc: 0.1925, Test Acc: 0.2272\n",
            "Seed: 43, Epoch: 032, Loss: 2.1633, Val Acc: 0.1908, Test Acc: 0.2245\n",
            "Seed: 43, Epoch: 033, Loss: 2.1552, Val Acc: 0.2012, Test Acc: 0.2367\n",
            "Seed: 43, Epoch: 034, Loss: 2.1467, Val Acc: 0.2030, Test Acc: 0.2202\n",
            "Seed: 43, Epoch: 035, Loss: 2.1386, Val Acc: 0.2073, Test Acc: 0.2289\n",
            "Seed: 43, Epoch: 036, Loss: 2.1303, Val Acc: 0.2134, Test Acc: 0.2350\n",
            "Seed: 43, Epoch: 037, Loss: 2.1228, Val Acc: 0.2134, Test Acc: 0.2359\n",
            "Seed: 43, Epoch: 038, Loss: 2.1145, Val Acc: 0.2091, Test Acc: 0.2507\n",
            "Seed: 43, Epoch: 039, Loss: 2.1084, Val Acc: 0.2247, Test Acc: 0.2498\n",
            "Seed: 43, Epoch: 040, Loss: 2.1012, Val Acc: 0.2143, Test Acc: 0.2437\n",
            "Seed: 43, Epoch: 041, Loss: 2.0930, Val Acc: 0.2274, Test Acc: 0.2498\n",
            "Seed: 43, Epoch: 042, Loss: 2.0866, Val Acc: 0.2300, Test Acc: 0.2637\n",
            "Seed: 43, Epoch: 043, Loss: 2.0785, Val Acc: 0.2213, Test Acc: 0.2602\n",
            "Seed: 43, Epoch: 044, Loss: 2.0723, Val Acc: 0.2186, Test Acc: 0.2620\n",
            "Seed: 43, Epoch: 045, Loss: 2.0667, Val Acc: 0.2395, Test Acc: 0.2594\n",
            "Seed: 43, Epoch: 046, Loss: 2.0613, Val Acc: 0.2413, Test Acc: 0.2637\n",
            "Seed: 43, Epoch: 047, Loss: 2.0568, Val Acc: 0.2239, Test Acc: 0.2698\n",
            "Seed: 43, Epoch: 048, Loss: 2.0452, Val Acc: 0.2422, Test Acc: 0.2733\n",
            "Seed: 43, Epoch: 049, Loss: 2.0378, Val Acc: 0.2317, Test Acc: 0.2663\n",
            "Seed: 43, Epoch: 050, Loss: 2.0308, Val Acc: 0.2369, Test Acc: 0.2663\n",
            "Seed: 43, Epoch: 051, Loss: 2.0239, Val Acc: 0.2509, Test Acc: 0.2776\n",
            "Seed: 43, Epoch: 052, Loss: 2.0194, Val Acc: 0.2387, Test Acc: 0.2715\n",
            "Seed: 43, Epoch: 053, Loss: 2.0119, Val Acc: 0.2378, Test Acc: 0.2707\n",
            "Seed: 43, Epoch: 054, Loss: 2.0063, Val Acc: 0.2422, Test Acc: 0.2742\n",
            "Seed: 43, Epoch: 055, Loss: 2.0010, Val Acc: 0.2456, Test Acc: 0.2776\n",
            "Seed: 43, Epoch: 056, Loss: 1.9962, Val Acc: 0.2666, Test Acc: 0.2672\n",
            "Seed: 43, Epoch: 057, Loss: 1.9916, Val Acc: 0.2404, Test Acc: 0.2663\n",
            "Seed: 43, Epoch: 058, Loss: 1.9929, Val Acc: 0.2718, Test Acc: 0.2794\n",
            "Seed: 43, Epoch: 059, Loss: 1.9779, Val Acc: 0.2570, Test Acc: 0.2950\n",
            "Seed: 43, Epoch: 060, Loss: 1.9736, Val Acc: 0.2761, Test Acc: 0.2733\n",
            "Seed: 43, Epoch: 061, Loss: 1.9675, Val Acc: 0.2483, Test Acc: 0.2855\n",
            "Seed: 43, Epoch: 062, Loss: 1.9619, Val Acc: 0.2805, Test Acc: 0.2855\n",
            "Seed: 43, Epoch: 063, Loss: 1.9568, Val Acc: 0.2726, Test Acc: 0.2985\n",
            "Seed: 43, Epoch: 064, Loss: 1.9501, Val Acc: 0.2805, Test Acc: 0.2802\n",
            "Seed: 43, Epoch: 065, Loss: 1.9459, Val Acc: 0.2744, Test Acc: 0.2829\n",
            "Seed: 43, Epoch: 066, Loss: 1.9400, Val Acc: 0.2700, Test Acc: 0.2863\n",
            "Seed: 43, Epoch: 067, Loss: 1.9337, Val Acc: 0.2709, Test Acc: 0.2872\n",
            "Seed: 43, Epoch: 068, Loss: 1.9285, Val Acc: 0.2761, Test Acc: 0.2785\n",
            "Seed: 43, Epoch: 069, Loss: 1.9241, Val Acc: 0.2787, Test Acc: 0.2811\n",
            "Seed: 43, Epoch: 070, Loss: 1.9202, Val Acc: 0.2787, Test Acc: 0.2924\n",
            "Seed: 43, Epoch: 071, Loss: 1.9155, Val Acc: 0.2735, Test Acc: 0.2785\n",
            "Seed: 43, Epoch: 072, Loss: 1.9130, Val Acc: 0.2700, Test Acc: 0.2977\n",
            "Seed: 43, Epoch: 073, Loss: 1.9063, Val Acc: 0.2822, Test Acc: 0.2829\n",
            "Seed: 43, Epoch: 074, Loss: 1.9022, Val Acc: 0.2761, Test Acc: 0.2898\n",
            "Seed: 43, Epoch: 075, Loss: 1.8969, Val Acc: 0.2918, Test Acc: 0.2829\n",
            "Seed: 43, Epoch: 076, Loss: 1.8911, Val Acc: 0.2779, Test Acc: 0.3003\n",
            "Seed: 43, Epoch: 077, Loss: 1.8870, Val Acc: 0.2831, Test Acc: 0.2881\n",
            "Seed: 43, Epoch: 078, Loss: 1.8823, Val Acc: 0.2840, Test Acc: 0.2863\n",
            "Seed: 43, Epoch: 079, Loss: 1.8782, Val Acc: 0.2944, Test Acc: 0.2855\n",
            "Seed: 43, Epoch: 080, Loss: 1.8735, Val Acc: 0.2779, Test Acc: 0.2942\n",
            "Seed: 43, Epoch: 081, Loss: 1.8705, Val Acc: 0.2936, Test Acc: 0.2959\n",
            "Seed: 43, Epoch: 082, Loss: 1.8664, Val Acc: 0.2927, Test Acc: 0.2916\n",
            "Seed: 43, Epoch: 083, Loss: 1.8617, Val Acc: 0.2944, Test Acc: 0.2994\n",
            "Seed: 43, Epoch: 084, Loss: 1.8580, Val Acc: 0.2866, Test Acc: 0.2811\n",
            "Seed: 43, Epoch: 085, Loss: 1.8556, Val Acc: 0.2883, Test Acc: 0.2942\n",
            "Seed: 43, Epoch: 086, Loss: 1.8504, Val Acc: 0.2805, Test Acc: 0.2820\n",
            "Seed: 43, Epoch: 087, Loss: 1.8448, Val Acc: 0.2927, Test Acc: 0.2959\n",
            "Seed: 43, Epoch: 088, Loss: 1.8406, Val Acc: 0.3023, Test Acc: 0.2959\n",
            "Seed: 43, Epoch: 089, Loss: 1.8380, Val Acc: 0.2892, Test Acc: 0.3046\n",
            "Seed: 43, Epoch: 090, Loss: 1.8340, Val Acc: 0.2927, Test Acc: 0.2863\n",
            "Seed: 43, Epoch: 091, Loss: 1.8309, Val Acc: 0.2883, Test Acc: 0.3046\n",
            "Seed: 43, Epoch: 092, Loss: 1.8274, Val Acc: 0.3092, Test Acc: 0.2959\n",
            "Seed: 43, Epoch: 093, Loss: 1.8218, Val Acc: 0.2988, Test Acc: 0.2933\n",
            "Seed: 43, Epoch: 094, Loss: 1.8177, Val Acc: 0.2918, Test Acc: 0.3037\n",
            "Seed: 43, Epoch: 095, Loss: 1.8195, Val Acc: 0.2918, Test Acc: 0.2994\n",
            "Seed: 43, Epoch: 096, Loss: 1.8169, Val Acc: 0.2970, Test Acc: 0.3011\n",
            "Seed: 43, Epoch: 097, Loss: 1.8118, Val Acc: 0.3014, Test Acc: 0.3037\n",
            "Seed: 43, Epoch: 098, Loss: 1.8074, Val Acc: 0.3023, Test Acc: 0.3107\n",
            "Seed: 43, Epoch: 099, Loss: 1.8048, Val Acc: 0.3171, Test Acc: 0.3046\n",
            "Seed: 43, Epoch: 100, Loss: 1.8011, Val Acc: 0.2796, Test Acc: 0.2802\n",
            "Seed: 43, Epoch: 101, Loss: 1.8006, Val Acc: 0.3101, Test Acc: 0.3168\n",
            "Seed: 43, Epoch: 102, Loss: 1.7971, Val Acc: 0.3005, Test Acc: 0.2942\n",
            "Seed: 43, Epoch: 103, Loss: 1.7922, Val Acc: 0.3023, Test Acc: 0.3081\n",
            "Seed: 43, Epoch: 104, Loss: 1.7866, Val Acc: 0.3005, Test Acc: 0.3055\n",
            "Seed: 43, Epoch: 105, Loss: 1.7816, Val Acc: 0.3057, Test Acc: 0.3159\n",
            "Seed: 43, Epoch: 106, Loss: 1.7793, Val Acc: 0.3110, Test Acc: 0.3124\n",
            "Seed: 43, Epoch: 107, Loss: 1.7752, Val Acc: 0.3118, Test Acc: 0.3037\n",
            "Seed: 43, Epoch: 108, Loss: 1.7723, Val Acc: 0.3188, Test Acc: 0.3029\n",
            "Seed: 43, Epoch: 109, Loss: 1.7682, Val Acc: 0.3057, Test Acc: 0.3011\n",
            "Seed: 43, Epoch: 110, Loss: 1.7666, Val Acc: 0.3171, Test Acc: 0.3133\n",
            "Seed: 43, Epoch: 111, Loss: 1.7627, Val Acc: 0.3110, Test Acc: 0.3072\n",
            "Seed: 43, Epoch: 112, Loss: 1.7601, Val Acc: 0.3206, Test Acc: 0.3238\n",
            "Seed: 43, Epoch: 113, Loss: 1.7571, Val Acc: 0.3145, Test Acc: 0.2994\n",
            "Seed: 43, Epoch: 114, Loss: 1.7533, Val Acc: 0.3075, Test Acc: 0.3177\n",
            "Seed: 43, Epoch: 115, Loss: 1.7508, Val Acc: 0.3145, Test Acc: 0.3037\n",
            "Seed: 43, Epoch: 116, Loss: 1.7539, Val Acc: 0.3171, Test Acc: 0.3220\n",
            "Seed: 43, Epoch: 117, Loss: 1.7470, Val Acc: 0.3127, Test Acc: 0.3064\n",
            "Seed: 43, Epoch: 118, Loss: 1.7464, Val Acc: 0.3057, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 119, Loss: 1.7423, Val Acc: 0.3162, Test Acc: 0.3151\n",
            "Seed: 43, Epoch: 120, Loss: 1.7366, Val Acc: 0.3049, Test Acc: 0.3090\n",
            "Seed: 43, Epoch: 121, Loss: 1.7360, Val Acc: 0.3023, Test Acc: 0.3299\n",
            "Seed: 43, Epoch: 122, Loss: 1.7346, Val Acc: 0.3206, Test Acc: 0.3220\n",
            "Seed: 43, Epoch: 123, Loss: 1.7306, Val Acc: 0.3197, Test Acc: 0.3238\n",
            "Seed: 43, Epoch: 124, Loss: 1.7294, Val Acc: 0.3110, Test Acc: 0.3081\n",
            "Seed: 43, Epoch: 125, Loss: 1.7292, Val Acc: 0.3206, Test Acc: 0.3107\n",
            "Seed: 43, Epoch: 126, Loss: 1.7264, Val Acc: 0.3171, Test Acc: 0.3272\n",
            "Seed: 43, Epoch: 127, Loss: 1.7238, Val Acc: 0.3049, Test Acc: 0.3081\n",
            "Seed: 43, Epoch: 128, Loss: 1.7230, Val Acc: 0.3162, Test Acc: 0.3351\n",
            "Seed: 43, Epoch: 129, Loss: 1.7183, Val Acc: 0.3101, Test Acc: 0.3211\n",
            "Seed: 43, Epoch: 130, Loss: 1.7171, Val Acc: 0.3171, Test Acc: 0.3116\n",
            "Seed: 43, Epoch: 131, Loss: 1.7133, Val Acc: 0.3145, Test Acc: 0.3159\n",
            "Seed: 43, Epoch: 132, Loss: 1.7110, Val Acc: 0.3145, Test Acc: 0.3229\n",
            "Seed: 43, Epoch: 133, Loss: 1.7097, Val Acc: 0.3136, Test Acc: 0.3142\n",
            "Seed: 43, Epoch: 134, Loss: 1.7098, Val Acc: 0.3110, Test Acc: 0.3264\n",
            "Seed: 43, Epoch: 135, Loss: 1.7038, Val Acc: 0.3214, Test Acc: 0.3168\n",
            "Seed: 43, Epoch: 136, Loss: 1.7047, Val Acc: 0.3162, Test Acc: 0.3098\n",
            "Seed: 43, Epoch: 137, Loss: 1.7022, Val Acc: 0.3101, Test Acc: 0.3194\n",
            "Seed: 43, Epoch: 138, Loss: 1.7055, Val Acc: 0.3301, Test Acc: 0.3072\n",
            "Seed: 43, Epoch: 139, Loss: 1.7063, Val Acc: 0.3267, Test Acc: 0.3229\n",
            "Seed: 43, Epoch: 140, Loss: 1.7101, Val Acc: 0.3293, Test Acc: 0.3090\n",
            "Seed: 43, Epoch: 141, Loss: 1.7062, Val Acc: 0.3223, Test Acc: 0.3159\n",
            "Seed: 43, Epoch: 142, Loss: 1.7141, Val Acc: 0.3188, Test Acc: 0.3107\n",
            "Seed: 43, Epoch: 143, Loss: 1.7116, Val Acc: 0.3232, Test Acc: 0.3220\n",
            "Seed: 43, Epoch: 144, Loss: 1.7102, Val Acc: 0.3171, Test Acc: 0.3220\n",
            "Seed: 43, Epoch: 145, Loss: 1.7121, Val Acc: 0.3240, Test Acc: 0.3090\n",
            "Seed: 43, Epoch: 146, Loss: 1.7125, Val Acc: 0.3110, Test Acc: 0.3124\n",
            "Seed: 43, Epoch: 147, Loss: 1.7104, Val Acc: 0.3162, Test Acc: 0.3177\n",
            "Seed: 43, Epoch: 148, Loss: 1.7025, Val Acc: 0.3267, Test Acc: 0.3168\n",
            "Seed: 43, Epoch: 149, Loss: 1.7023, Val Acc: 0.3179, Test Acc: 0.3055\n",
            "Seed: 43, Epoch: 150, Loss: 1.7027, Val Acc: 0.3293, Test Acc: 0.3220\n",
            "Seed: 43, Epoch: 151, Loss: 1.6935, Val Acc: 0.3284, Test Acc: 0.3299\n",
            "Seed: 43, Epoch: 152, Loss: 1.6901, Val Acc: 0.3197, Test Acc: 0.2898\n",
            "Seed: 43, Epoch: 153, Loss: 1.6914, Val Acc: 0.3232, Test Acc: 0.3281\n",
            "Seed: 43, Epoch: 154, Loss: 1.6845, Val Acc: 0.3301, Test Acc: 0.3003\n",
            "Seed: 43, Epoch: 155, Loss: 1.6856, Val Acc: 0.3441, Test Acc: 0.3159\n",
            "Seed: 43, Epoch: 156, Loss: 1.6837, Val Acc: 0.3336, Test Acc: 0.3003\n",
            "Seed: 43, Epoch: 157, Loss: 1.6795, Val Acc: 0.3319, Test Acc: 0.3272\n",
            "Seed: 43, Epoch: 158, Loss: 1.6790, Val Acc: 0.3328, Test Acc: 0.3011\n",
            "Seed: 43, Epoch: 159, Loss: 1.6742, Val Acc: 0.3362, Test Acc: 0.3238\n",
            "Seed: 43, Epoch: 160, Loss: 1.6734, Val Acc: 0.3354, Test Acc: 0.3055\n",
            "Seed: 43, Epoch: 161, Loss: 1.6730, Val Acc: 0.3232, Test Acc: 0.3177\n",
            "Seed: 43, Epoch: 162, Loss: 1.6687, Val Acc: 0.3362, Test Acc: 0.3055\n",
            "Seed: 43, Epoch: 163, Loss: 1.6757, Val Acc: 0.3362, Test Acc: 0.3011\n",
            "Seed: 43, Epoch: 164, Loss: 1.6674, Val Acc: 0.3484, Test Acc: 0.3116\n",
            "Seed: 43, Epoch: 165, Loss: 1.6670, Val Acc: 0.3389, Test Acc: 0.3020\n",
            "Seed: 43, Epoch: 166, Loss: 1.6645, Val Acc: 0.3345, Test Acc: 0.3229\n",
            "Seed: 43, Epoch: 167, Loss: 1.6610, Val Acc: 0.3362, Test Acc: 0.3107\n",
            "Seed: 43, Epoch: 168, Loss: 1.6587, Val Acc: 0.3328, Test Acc: 0.3220\n",
            "Seed: 43, Epoch: 169, Loss: 1.6590, Val Acc: 0.3371, Test Acc: 0.3116\n",
            "Seed: 43, Epoch: 170, Loss: 1.6549, Val Acc: 0.3319, Test Acc: 0.3168\n",
            "Seed: 43, Epoch: 171, Loss: 1.6584, Val Acc: 0.3328, Test Acc: 0.3090\n",
            "Seed: 43, Epoch: 172, Loss: 1.6564, Val Acc: 0.3275, Test Acc: 0.3220\n",
            "Seed: 43, Epoch: 173, Loss: 1.6541, Val Acc: 0.3397, Test Acc: 0.3064\n",
            "Seed: 43, Epoch: 174, Loss: 1.6515, Val Acc: 0.3423, Test Acc: 0.3203\n",
            "Seed: 43, Epoch: 175, Loss: 1.6479, Val Acc: 0.3397, Test Acc: 0.3177\n",
            "Seed: 43, Epoch: 176, Loss: 1.6464, Val Acc: 0.3354, Test Acc: 0.3159\n",
            "Seed: 43, Epoch: 177, Loss: 1.6441, Val Acc: 0.3423, Test Acc: 0.3133\n",
            "Seed: 43, Epoch: 178, Loss: 1.6432, Val Acc: 0.3354, Test Acc: 0.3238\n",
            "Seed: 43, Epoch: 179, Loss: 1.6441, Val Acc: 0.3371, Test Acc: 0.3220\n",
            "Seed: 43, Epoch: 180, Loss: 1.6411, Val Acc: 0.3328, Test Acc: 0.3203\n",
            "Seed: 43, Epoch: 181, Loss: 1.6415, Val Acc: 0.3406, Test Acc: 0.3142\n",
            "Seed: 43, Epoch: 182, Loss: 1.6365, Val Acc: 0.3423, Test Acc: 0.3133\n",
            "Seed: 43, Epoch: 183, Loss: 1.6406, Val Acc: 0.3449, Test Acc: 0.3229\n",
            "Seed: 43, Epoch: 184, Loss: 1.6354, Val Acc: 0.3545, Test Acc: 0.3264\n",
            "Seed: 43, Epoch: 185, Loss: 1.6337, Val Acc: 0.3432, Test Acc: 0.3177\n",
            "Seed: 43, Epoch: 186, Loss: 1.6334, Val Acc: 0.3449, Test Acc: 0.3264\n",
            "Seed: 43, Epoch: 187, Loss: 1.6309, Val Acc: 0.3389, Test Acc: 0.3203\n",
            "Seed: 43, Epoch: 188, Loss: 1.6296, Val Acc: 0.3510, Test Acc: 0.3142\n",
            "Seed: 43, Epoch: 189, Loss: 1.6275, Val Acc: 0.3493, Test Acc: 0.3168\n",
            "Seed: 43, Epoch: 190, Loss: 1.6255, Val Acc: 0.3545, Test Acc: 0.3142\n",
            "Seed: 43, Epoch: 191, Loss: 1.6241, Val Acc: 0.3354, Test Acc: 0.3185\n",
            "Seed: 43, Epoch: 192, Loss: 1.6244, Val Acc: 0.3441, Test Acc: 0.3159\n",
            "Seed: 43, Epoch: 193, Loss: 1.6269, Val Acc: 0.3528, Test Acc: 0.3229\n",
            "Seed: 43, Epoch: 194, Loss: 1.6256, Val Acc: 0.3476, Test Acc: 0.3116\n",
            "Seed: 43, Epoch: 195, Loss: 1.6337, Val Acc: 0.3545, Test Acc: 0.3246\n",
            "Seed: 43, Epoch: 196, Loss: 1.6247, Val Acc: 0.3510, Test Acc: 0.3229\n",
            "Seed: 43, Epoch: 197, Loss: 1.6168, Val Acc: 0.3571, Test Acc: 0.3290\n",
            "Seed: 43, Epoch: 198, Loss: 1.6158, Val Acc: 0.3615, Test Acc: 0.3255\n",
            "Seed: 43, Epoch: 199, Loss: 1.6154, Val Acc: 0.3467, Test Acc: 0.3211\n",
            "Seed: 43, Epoch: 200, Loss: 1.6177, Val Acc: 0.3432, Test Acc: 0.3220\n",
            "Seed: 44, Epoch: 001, Loss: 2.4028, Val Acc: 0.1002, Test Acc: 0.0975\n",
            "Seed: 44, Epoch: 002, Loss: 2.4015, Val Acc: 0.1002, Test Acc: 0.0975\n",
            "Seed: 44, Epoch: 003, Loss: 2.4002, Val Acc: 0.1002, Test Acc: 0.0975\n",
            "Seed: 44, Epoch: 004, Loss: 2.3986, Val Acc: 0.1002, Test Acc: 0.0975\n",
            "Seed: 44, Epoch: 005, Loss: 2.3968, Val Acc: 0.1002, Test Acc: 0.0975\n",
            "Seed: 44, Epoch: 006, Loss: 2.3943, Val Acc: 0.1002, Test Acc: 0.0975\n",
            "Seed: 44, Epoch: 007, Loss: 2.3909, Val Acc: 0.1002, Test Acc: 0.0975\n",
            "Seed: 44, Epoch: 008, Loss: 2.3870, Val Acc: 0.1002, Test Acc: 0.0975\n",
            "Seed: 44, Epoch: 009, Loss: 2.3830, Val Acc: 0.1002, Test Acc: 0.0975\n",
            "Seed: 44, Epoch: 010, Loss: 2.3780, Val Acc: 0.1002, Test Acc: 0.0975\n",
            "Seed: 44, Epoch: 011, Loss: 2.3708, Val Acc: 0.1002, Test Acc: 0.0975\n",
            "Seed: 44, Epoch: 012, Loss: 2.3616, Val Acc: 0.1002, Test Acc: 0.0975\n",
            "Seed: 44, Epoch: 013, Loss: 2.3490, Val Acc: 0.1176, Test Acc: 0.1149\n",
            "Seed: 44, Epoch: 014, Loss: 2.3321, Val Acc: 0.1463, Test Acc: 0.1540\n",
            "Seed: 44, Epoch: 015, Loss: 2.3099, Val Acc: 0.1481, Test Acc: 0.1610\n",
            "Seed: 44, Epoch: 016, Loss: 2.2829, Val Acc: 0.1646, Test Acc: 0.1836\n",
            "Seed: 44, Epoch: 017, Loss: 2.2553, Val Acc: 0.1551, Test Acc: 0.1775\n",
            "Seed: 44, Epoch: 018, Loss: 2.2278, Val Acc: 0.1551, Test Acc: 0.1715\n",
            "Seed: 44, Epoch: 019, Loss: 2.2020, Val Acc: 0.1463, Test Acc: 0.1628\n",
            "Seed: 44, Epoch: 020, Loss: 2.1742, Val Acc: 0.1742, Test Acc: 0.1836\n",
            "Seed: 44, Epoch: 021, Loss: 2.1583, Val Acc: 0.1855, Test Acc: 0.1897\n",
            "Seed: 44, Epoch: 022, Loss: 2.1462, Val Acc: 0.1890, Test Acc: 0.1775\n",
            "Seed: 44, Epoch: 023, Loss: 2.1291, Val Acc: 0.1873, Test Acc: 0.1749\n",
            "Seed: 44, Epoch: 024, Loss: 2.1220, Val Acc: 0.1855, Test Acc: 0.1732\n",
            "Seed: 44, Epoch: 025, Loss: 2.1082, Val Acc: 0.1786, Test Acc: 0.1932\n",
            "Seed: 44, Epoch: 026, Loss: 2.0950, Val Acc: 0.1873, Test Acc: 0.1941\n",
            "Seed: 44, Epoch: 027, Loss: 2.0882, Val Acc: 0.1969, Test Acc: 0.2002\n",
            "Seed: 44, Epoch: 028, Loss: 2.0768, Val Acc: 0.1812, Test Acc: 0.1897\n",
            "Seed: 44, Epoch: 029, Loss: 2.0641, Val Acc: 0.1943, Test Acc: 0.2010\n",
            "Seed: 44, Epoch: 030, Loss: 2.0555, Val Acc: 0.2047, Test Acc: 0.2167\n",
            "Seed: 44, Epoch: 031, Loss: 2.0452, Val Acc: 0.2012, Test Acc: 0.2315\n",
            "Seed: 44, Epoch: 032, Loss: 2.0375, Val Acc: 0.1934, Test Acc: 0.2237\n",
            "Seed: 44, Epoch: 033, Loss: 2.0288, Val Acc: 0.1829, Test Acc: 0.2019\n",
            "Seed: 44, Epoch: 034, Loss: 2.0255, Val Acc: 0.2143, Test Acc: 0.2324\n",
            "Seed: 44, Epoch: 035, Loss: 2.0153, Val Acc: 0.2186, Test Acc: 0.2359\n",
            "Seed: 44, Epoch: 036, Loss: 2.0120, Val Acc: 0.2056, Test Acc: 0.2350\n",
            "Seed: 44, Epoch: 037, Loss: 1.9973, Val Acc: 0.1855, Test Acc: 0.2193\n",
            "Seed: 44, Epoch: 038, Loss: 1.9952, Val Acc: 0.2195, Test Acc: 0.2550\n",
            "Seed: 44, Epoch: 039, Loss: 1.9851, Val Acc: 0.2247, Test Acc: 0.2498\n",
            "Seed: 44, Epoch: 040, Loss: 1.9772, Val Acc: 0.1995, Test Acc: 0.2393\n",
            "Seed: 44, Epoch: 041, Loss: 1.9715, Val Acc: 0.2239, Test Acc: 0.2567\n",
            "Seed: 44, Epoch: 042, Loss: 1.9562, Val Acc: 0.2317, Test Acc: 0.2585\n",
            "Seed: 44, Epoch: 043, Loss: 1.9481, Val Acc: 0.2204, Test Acc: 0.2646\n",
            "Seed: 44, Epoch: 044, Loss: 1.9402, Val Acc: 0.2230, Test Acc: 0.2698\n",
            "Seed: 44, Epoch: 045, Loss: 1.9327, Val Acc: 0.2195, Test Acc: 0.2559\n",
            "Seed: 44, Epoch: 046, Loss: 1.9310, Val Acc: 0.2291, Test Acc: 0.2567\n",
            "Seed: 44, Epoch: 047, Loss: 1.9172, Val Acc: 0.2334, Test Acc: 0.2663\n",
            "Seed: 44, Epoch: 048, Loss: 1.9072, Val Acc: 0.2483, Test Acc: 0.2707\n",
            "Seed: 44, Epoch: 049, Loss: 1.9054, Val Acc: 0.2631, Test Acc: 0.2724\n",
            "Seed: 44, Epoch: 050, Loss: 1.9262, Val Acc: 0.2718, Test Acc: 0.2672\n",
            "Seed: 44, Epoch: 051, Loss: 1.9085, Val Acc: 0.2361, Test Acc: 0.2637\n",
            "Seed: 44, Epoch: 052, Loss: 1.8960, Val Acc: 0.2430, Test Acc: 0.2829\n",
            "Seed: 44, Epoch: 053, Loss: 1.8831, Val Acc: 0.2622, Test Acc: 0.2794\n",
            "Seed: 44, Epoch: 054, Loss: 1.8821, Val Acc: 0.2526, Test Acc: 0.2863\n",
            "Seed: 44, Epoch: 055, Loss: 1.8673, Val Acc: 0.2666, Test Acc: 0.2802\n",
            "Seed: 44, Epoch: 056, Loss: 1.8597, Val Acc: 0.2770, Test Acc: 0.2933\n",
            "Seed: 44, Epoch: 057, Loss: 1.8540, Val Acc: 0.2666, Test Acc: 0.2977\n",
            "Seed: 44, Epoch: 058, Loss: 1.8464, Val Acc: 0.2683, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 059, Loss: 1.8371, Val Acc: 0.2805, Test Acc: 0.3037\n",
            "Seed: 44, Epoch: 060, Loss: 1.8354, Val Acc: 0.2770, Test Acc: 0.3003\n",
            "Seed: 44, Epoch: 061, Loss: 1.8227, Val Acc: 0.2814, Test Acc: 0.2994\n",
            "Seed: 44, Epoch: 062, Loss: 1.8158, Val Acc: 0.2979, Test Acc: 0.3159\n",
            "Seed: 44, Epoch: 063, Loss: 1.8137, Val Acc: 0.2744, Test Acc: 0.3055\n",
            "Seed: 44, Epoch: 064, Loss: 1.8084, Val Acc: 0.2822, Test Acc: 0.3029\n",
            "Seed: 44, Epoch: 065, Loss: 1.7986, Val Acc: 0.3040, Test Acc: 0.3220\n",
            "Seed: 44, Epoch: 066, Loss: 1.8218, Val Acc: 0.3214, Test Acc: 0.3185\n",
            "Seed: 44, Epoch: 067, Loss: 1.8021, Val Acc: 0.2805, Test Acc: 0.2985\n",
            "Seed: 44, Epoch: 068, Loss: 1.7997, Val Acc: 0.3005, Test Acc: 0.3116\n",
            "Seed: 44, Epoch: 069, Loss: 1.7994, Val Acc: 0.2927, Test Acc: 0.3003\n",
            "Seed: 44, Epoch: 070, Loss: 1.7909, Val Acc: 0.3162, Test Acc: 0.3116\n",
            "Seed: 44, Epoch: 071, Loss: 1.7787, Val Acc: 0.3223, Test Acc: 0.3264\n",
            "Seed: 44, Epoch: 072, Loss: 1.7816, Val Acc: 0.2787, Test Acc: 0.2924\n",
            "Seed: 44, Epoch: 073, Loss: 1.7791, Val Acc: 0.3328, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 074, Loss: 1.7691, Val Acc: 0.2979, Test Acc: 0.3011\n",
            "Seed: 44, Epoch: 075, Loss: 1.7659, Val Acc: 0.3267, Test Acc: 0.3299\n",
            "Seed: 44, Epoch: 076, Loss: 1.7555, Val Acc: 0.3206, Test Acc: 0.3377\n",
            "Seed: 44, Epoch: 077, Loss: 1.7507, Val Acc: 0.3084, Test Acc: 0.3281\n",
            "Seed: 44, Epoch: 078, Loss: 1.7390, Val Acc: 0.3397, Test Acc: 0.3473\n",
            "Seed: 44, Epoch: 079, Loss: 1.7373, Val Acc: 0.3162, Test Acc: 0.3394\n",
            "Seed: 44, Epoch: 080, Loss: 1.7321, Val Acc: 0.3249, Test Acc: 0.3420\n",
            "Seed: 44, Epoch: 081, Loss: 1.7219, Val Acc: 0.3275, Test Acc: 0.3342\n",
            "Seed: 44, Epoch: 082, Loss: 1.7183, Val Acc: 0.3371, Test Acc: 0.3560\n",
            "Seed: 44, Epoch: 083, Loss: 1.7128, Val Acc: 0.3188, Test Acc: 0.3342\n",
            "Seed: 44, Epoch: 084, Loss: 1.7104, Val Acc: 0.3510, Test Acc: 0.3525\n",
            "Seed: 44, Epoch: 085, Loss: 1.7043, Val Acc: 0.3502, Test Acc: 0.3534\n",
            "Seed: 44, Epoch: 086, Loss: 1.7005, Val Acc: 0.3519, Test Acc: 0.3473\n",
            "Seed: 44, Epoch: 087, Loss: 1.6965, Val Acc: 0.3589, Test Acc: 0.3499\n",
            "Seed: 44, Epoch: 088, Loss: 1.6918, Val Acc: 0.3441, Test Acc: 0.3446\n",
            "Seed: 44, Epoch: 089, Loss: 1.6872, Val Acc: 0.3484, Test Acc: 0.3499\n",
            "Seed: 44, Epoch: 090, Loss: 1.6834, Val Acc: 0.3493, Test Acc: 0.3525\n",
            "Seed: 44, Epoch: 091, Loss: 1.6784, Val Acc: 0.3493, Test Acc: 0.3542\n",
            "Seed: 44, Epoch: 092, Loss: 1.6744, Val Acc: 0.3545, Test Acc: 0.3638\n",
            "Seed: 44, Epoch: 093, Loss: 1.6710, Val Acc: 0.3580, Test Acc: 0.3594\n",
            "Seed: 44, Epoch: 094, Loss: 1.6670, Val Acc: 0.3537, Test Acc: 0.3612\n",
            "Seed: 44, Epoch: 095, Loss: 1.6632, Val Acc: 0.3458, Test Acc: 0.3586\n",
            "Seed: 44, Epoch: 096, Loss: 1.6661, Val Acc: 0.3615, Test Acc: 0.3768\n",
            "Seed: 44, Epoch: 097, Loss: 1.6559, Val Acc: 0.3615, Test Acc: 0.3699\n",
            "Seed: 44, Epoch: 098, Loss: 1.6556, Val Acc: 0.3563, Test Acc: 0.3734\n",
            "Seed: 44, Epoch: 099, Loss: 1.6528, Val Acc: 0.3484, Test Acc: 0.3716\n",
            "Seed: 44, Epoch: 100, Loss: 1.6476, Val Acc: 0.3624, Test Acc: 0.3690\n",
            "Seed: 44, Epoch: 101, Loss: 1.6436, Val Acc: 0.3632, Test Acc: 0.3751\n",
            "Seed: 44, Epoch: 102, Loss: 1.6338, Val Acc: 0.3554, Test Acc: 0.3742\n",
            "Seed: 44, Epoch: 103, Loss: 1.6366, Val Acc: 0.3728, Test Acc: 0.3803\n",
            "Seed: 44, Epoch: 104, Loss: 1.6312, Val Acc: 0.3824, Test Acc: 0.3908\n",
            "Seed: 44, Epoch: 105, Loss: 1.6211, Val Acc: 0.3667, Test Acc: 0.3882\n",
            "Seed: 44, Epoch: 106, Loss: 1.6223, Val Acc: 0.3789, Test Acc: 0.3838\n",
            "Seed: 44, Epoch: 107, Loss: 1.6187, Val Acc: 0.3841, Test Acc: 0.3951\n",
            "Seed: 44, Epoch: 108, Loss: 1.6109, Val Acc: 0.3667, Test Acc: 0.3977\n",
            "Seed: 44, Epoch: 109, Loss: 1.6067, Val Acc: 0.3815, Test Acc: 0.3943\n",
            "Seed: 44, Epoch: 110, Loss: 1.6022, Val Acc: 0.3894, Test Acc: 0.3925\n",
            "Seed: 44, Epoch: 111, Loss: 1.5971, Val Acc: 0.3641, Test Acc: 0.3777\n",
            "Seed: 44, Epoch: 112, Loss: 1.5952, Val Acc: 0.3876, Test Acc: 0.3908\n",
            "Seed: 44, Epoch: 113, Loss: 1.5890, Val Acc: 0.3815, Test Acc: 0.3977\n",
            "Seed: 44, Epoch: 114, Loss: 1.5891, Val Acc: 0.3754, Test Acc: 0.4003\n",
            "Seed: 44, Epoch: 115, Loss: 1.5912, Val Acc: 0.4024, Test Acc: 0.3890\n",
            "Seed: 44, Epoch: 116, Loss: 1.5808, Val Acc: 0.3754, Test Acc: 0.3847\n",
            "Seed: 44, Epoch: 117, Loss: 1.5757, Val Acc: 0.3746, Test Acc: 0.3873\n",
            "Seed: 44, Epoch: 118, Loss: 1.5721, Val Acc: 0.3789, Test Acc: 0.3960\n",
            "Seed: 44, Epoch: 119, Loss: 1.5687, Val Acc: 0.3946, Test Acc: 0.4099\n",
            "Seed: 44, Epoch: 120, Loss: 1.5647, Val Acc: 0.3911, Test Acc: 0.4021\n",
            "Seed: 44, Epoch: 121, Loss: 1.5611, Val Acc: 0.3885, Test Acc: 0.4064\n",
            "Seed: 44, Epoch: 122, Loss: 1.5602, Val Acc: 0.3972, Test Acc: 0.4038\n",
            "Seed: 44, Epoch: 123, Loss: 1.5551, Val Acc: 0.3868, Test Acc: 0.4091\n",
            "Seed: 44, Epoch: 124, Loss: 1.5504, Val Acc: 0.3833, Test Acc: 0.3960\n",
            "Seed: 44, Epoch: 125, Loss: 1.5504, Val Acc: 0.3902, Test Acc: 0.4151\n",
            "Seed: 44, Epoch: 126, Loss: 1.5440, Val Acc: 0.4024, Test Acc: 0.4151\n",
            "Seed: 44, Epoch: 127, Loss: 1.5420, Val Acc: 0.3946, Test Acc: 0.3908\n",
            "Seed: 44, Epoch: 128, Loss: 1.5416, Val Acc: 0.3929, Test Acc: 0.3995\n",
            "Seed: 44, Epoch: 129, Loss: 1.5365, Val Acc: 0.3929, Test Acc: 0.4082\n",
            "Seed: 44, Epoch: 130, Loss: 1.5305, Val Acc: 0.3963, Test Acc: 0.4151\n",
            "Seed: 44, Epoch: 131, Loss: 1.5278, Val Acc: 0.4059, Test Acc: 0.4064\n",
            "Seed: 44, Epoch: 132, Loss: 1.5246, Val Acc: 0.4042, Test Acc: 0.4099\n",
            "Seed: 44, Epoch: 133, Loss: 1.5228, Val Acc: 0.4077, Test Acc: 0.4099\n",
            "Seed: 44, Epoch: 134, Loss: 1.5201, Val Acc: 0.4033, Test Acc: 0.4143\n",
            "Seed: 44, Epoch: 135, Loss: 1.5177, Val Acc: 0.4059, Test Acc: 0.4238\n",
            "Seed: 44, Epoch: 136, Loss: 1.5174, Val Acc: 0.3981, Test Acc: 0.4160\n",
            "Seed: 44, Epoch: 137, Loss: 1.5152, Val Acc: 0.3780, Test Acc: 0.4125\n",
            "Seed: 44, Epoch: 138, Loss: 1.5205, Val Acc: 0.4077, Test Acc: 0.4030\n",
            "Seed: 44, Epoch: 139, Loss: 1.5078, Val Acc: 0.4059, Test Acc: 0.4151\n",
            "Seed: 44, Epoch: 140, Loss: 1.5040, Val Acc: 0.4085, Test Acc: 0.4265\n",
            "Seed: 44, Epoch: 141, Loss: 1.5025, Val Acc: 0.4129, Test Acc: 0.4238\n",
            "Seed: 44, Epoch: 142, Loss: 1.4993, Val Acc: 0.4103, Test Acc: 0.4238\n",
            "Seed: 44, Epoch: 143, Loss: 1.4962, Val Acc: 0.4042, Test Acc: 0.4169\n",
            "Seed: 44, Epoch: 144, Loss: 1.4951, Val Acc: 0.4155, Test Acc: 0.4465\n",
            "Seed: 44, Epoch: 145, Loss: 1.4896, Val Acc: 0.4077, Test Acc: 0.4256\n",
            "Seed: 44, Epoch: 146, Loss: 1.4877, Val Acc: 0.3981, Test Acc: 0.4082\n",
            "Seed: 44, Epoch: 147, Loss: 1.4853, Val Acc: 0.3955, Test Acc: 0.4178\n",
            "Seed: 44, Epoch: 148, Loss: 1.4843, Val Acc: 0.4077, Test Acc: 0.4413\n",
            "Seed: 44, Epoch: 149, Loss: 1.4815, Val Acc: 0.4164, Test Acc: 0.4430\n",
            "Seed: 44, Epoch: 150, Loss: 1.4786, Val Acc: 0.4042, Test Acc: 0.4169\n",
            "Seed: 44, Epoch: 151, Loss: 1.4777, Val Acc: 0.4042, Test Acc: 0.4195\n",
            "Seed: 44, Epoch: 152, Loss: 1.4742, Val Acc: 0.4051, Test Acc: 0.4238\n",
            "Seed: 44, Epoch: 153, Loss: 1.4744, Val Acc: 0.4068, Test Acc: 0.4291\n",
            "Seed: 44, Epoch: 154, Loss: 1.4698, Val Acc: 0.4068, Test Acc: 0.4204\n",
            "Seed: 44, Epoch: 155, Loss: 1.4706, Val Acc: 0.4129, Test Acc: 0.4230\n",
            "Seed: 44, Epoch: 156, Loss: 1.4635, Val Acc: 0.4216, Test Acc: 0.4308\n",
            "Seed: 44, Epoch: 157, Loss: 1.4607, Val Acc: 0.4103, Test Acc: 0.4151\n",
            "Seed: 44, Epoch: 158, Loss: 1.4596, Val Acc: 0.4164, Test Acc: 0.4317\n",
            "Seed: 44, Epoch: 159, Loss: 1.4562, Val Acc: 0.4242, Test Acc: 0.4404\n",
            "Seed: 44, Epoch: 160, Loss: 1.4552, Val Acc: 0.4111, Test Acc: 0.4204\n",
            "Seed: 44, Epoch: 161, Loss: 1.4556, Val Acc: 0.4172, Test Acc: 0.4195\n",
            "Seed: 44, Epoch: 162, Loss: 1.4573, Val Acc: 0.4181, Test Acc: 0.4273\n",
            "Seed: 44, Epoch: 163, Loss: 1.4509, Val Acc: 0.4199, Test Acc: 0.4238\n",
            "Seed: 44, Epoch: 164, Loss: 1.4495, Val Acc: 0.4242, Test Acc: 0.4343\n",
            "Seed: 44, Epoch: 165, Loss: 1.4475, Val Acc: 0.4129, Test Acc: 0.4317\n",
            "Seed: 44, Epoch: 166, Loss: 1.4485, Val Acc: 0.4155, Test Acc: 0.4447\n",
            "Seed: 44, Epoch: 167, Loss: 1.4431, Val Acc: 0.4268, Test Acc: 0.4299\n",
            "Seed: 44, Epoch: 168, Loss: 1.4367, Val Acc: 0.4146, Test Acc: 0.4386\n",
            "Seed: 44, Epoch: 169, Loss: 1.4370, Val Acc: 0.4286, Test Acc: 0.4378\n",
            "Seed: 44, Epoch: 170, Loss: 1.4284, Val Acc: 0.4329, Test Acc: 0.4343\n",
            "Seed: 44, Epoch: 171, Loss: 1.4268, Val Acc: 0.4303, Test Acc: 0.4430\n",
            "Seed: 44, Epoch: 172, Loss: 1.4254, Val Acc: 0.4347, Test Acc: 0.4465\n",
            "Seed: 44, Epoch: 173, Loss: 1.4231, Val Acc: 0.4260, Test Acc: 0.4456\n",
            "Seed: 44, Epoch: 174, Loss: 1.4199, Val Acc: 0.4207, Test Acc: 0.4386\n",
            "Seed: 44, Epoch: 175, Loss: 1.4171, Val Acc: 0.4233, Test Acc: 0.4265\n",
            "Seed: 44, Epoch: 176, Loss: 1.4183, Val Acc: 0.4416, Test Acc: 0.4482\n",
            "Seed: 44, Epoch: 177, Loss: 1.4146, Val Acc: 0.4286, Test Acc: 0.4456\n",
            "Seed: 44, Epoch: 178, Loss: 1.4153, Val Acc: 0.4364, Test Acc: 0.4386\n",
            "Seed: 44, Epoch: 179, Loss: 1.4116, Val Acc: 0.4251, Test Acc: 0.4386\n",
            "Seed: 44, Epoch: 180, Loss: 1.4081, Val Acc: 0.4321, Test Acc: 0.4587\n",
            "Seed: 44, Epoch: 181, Loss: 1.4096, Val Acc: 0.4312, Test Acc: 0.4456\n",
            "Seed: 44, Epoch: 182, Loss: 1.4086, Val Acc: 0.4329, Test Acc: 0.4482\n",
            "Seed: 44, Epoch: 183, Loss: 1.4086, Val Acc: 0.4321, Test Acc: 0.4491\n",
            "Seed: 44, Epoch: 184, Loss: 1.4064, Val Acc: 0.4364, Test Acc: 0.4413\n",
            "Seed: 44, Epoch: 185, Loss: 1.4035, Val Acc: 0.4242, Test Acc: 0.4473\n",
            "Seed: 44, Epoch: 186, Loss: 1.4025, Val Acc: 0.4190, Test Acc: 0.4430\n",
            "Seed: 44, Epoch: 187, Loss: 1.4006, Val Acc: 0.4408, Test Acc: 0.4456\n",
            "Seed: 44, Epoch: 188, Loss: 1.3984, Val Acc: 0.4321, Test Acc: 0.4447\n",
            "Seed: 44, Epoch: 189, Loss: 1.3941, Val Acc: 0.4312, Test Acc: 0.4517\n",
            "Seed: 44, Epoch: 190, Loss: 1.3933, Val Acc: 0.4321, Test Acc: 0.4526\n",
            "Seed: 44, Epoch: 191, Loss: 1.3895, Val Acc: 0.4460, Test Acc: 0.4560\n",
            "Seed: 44, Epoch: 192, Loss: 1.3871, Val Acc: 0.4329, Test Acc: 0.4621\n",
            "Seed: 44, Epoch: 193, Loss: 1.3845, Val Acc: 0.4321, Test Acc: 0.4421\n",
            "Seed: 44, Epoch: 194, Loss: 1.3859, Val Acc: 0.4251, Test Acc: 0.4395\n",
            "Seed: 44, Epoch: 195, Loss: 1.3832, Val Acc: 0.4364, Test Acc: 0.4378\n",
            "Seed: 44, Epoch: 196, Loss: 1.3848, Val Acc: 0.4425, Test Acc: 0.4587\n",
            "Seed: 44, Epoch: 197, Loss: 1.3825, Val Acc: 0.4408, Test Acc: 0.4386\n",
            "Seed: 44, Epoch: 198, Loss: 1.3880, Val Acc: 0.4321, Test Acc: 0.4595\n",
            "Seed: 44, Epoch: 199, Loss: 1.3832, Val Acc: 0.4347, Test Acc: 0.4473\n",
            "Seed: 44, Epoch: 200, Loss: 1.3828, Val Acc: 0.4416, Test Acc: 0.4517\n",
            "Seed: 45, Epoch: 001, Loss: 2.3990, Val Acc: 0.1054, Test Acc: 0.1114\n",
            "Seed: 45, Epoch: 002, Loss: 2.3982, Val Acc: 0.1054, Test Acc: 0.1114\n",
            "Seed: 45, Epoch: 003, Loss: 2.3973, Val Acc: 0.1054, Test Acc: 0.1114\n",
            "Seed: 45, Epoch: 004, Loss: 2.3962, Val Acc: 0.1054, Test Acc: 0.1114\n",
            "Seed: 45, Epoch: 005, Loss: 2.3948, Val Acc: 0.1054, Test Acc: 0.1114\n",
            "Seed: 45, Epoch: 006, Loss: 2.3928, Val Acc: 0.1054, Test Acc: 0.1114\n",
            "Seed: 45, Epoch: 007, Loss: 2.3898, Val Acc: 0.1054, Test Acc: 0.1114\n",
            "Seed: 45, Epoch: 008, Loss: 2.3853, Val Acc: 0.1098, Test Acc: 0.1166\n",
            "Seed: 45, Epoch: 009, Loss: 2.3787, Val Acc: 0.1115, Test Acc: 0.1123\n",
            "Seed: 45, Epoch: 010, Loss: 2.3687, Val Acc: 0.1150, Test Acc: 0.1253\n",
            "Seed: 45, Epoch: 011, Loss: 2.3560, Val Acc: 0.1420, Test Acc: 0.1401\n",
            "Seed: 45, Epoch: 012, Loss: 2.3403, Val Acc: 0.1516, Test Acc: 0.1619\n",
            "Seed: 45, Epoch: 013, Loss: 2.3253, Val Acc: 0.1916, Test Acc: 0.1915\n",
            "Seed: 45, Epoch: 014, Loss: 2.3117, Val Acc: 0.1977, Test Acc: 0.1958\n",
            "Seed: 45, Epoch: 015, Loss: 2.2934, Val Acc: 0.1899, Test Acc: 0.1836\n",
            "Seed: 45, Epoch: 016, Loss: 2.2755, Val Acc: 0.1786, Test Acc: 0.1662\n",
            "Seed: 45, Epoch: 017, Loss: 2.2560, Val Acc: 0.1699, Test Acc: 0.1671\n",
            "Seed: 45, Epoch: 018, Loss: 2.2407, Val Acc: 0.1855, Test Acc: 0.1662\n",
            "Seed: 45, Epoch: 019, Loss: 2.2326, Val Acc: 0.2021, Test Acc: 0.1958\n",
            "Seed: 45, Epoch: 020, Loss: 2.2331, Val Acc: 0.1847, Test Acc: 0.1706\n",
            "Seed: 45, Epoch: 021, Loss: 2.2306, Val Acc: 0.1699, Test Acc: 0.1523\n",
            "Seed: 45, Epoch: 022, Loss: 2.2220, Val Acc: 0.2047, Test Acc: 0.1784\n",
            "Seed: 45, Epoch: 023, Loss: 2.2116, Val Acc: 0.1690, Test Acc: 0.1610\n",
            "Seed: 45, Epoch: 024, Loss: 2.2117, Val Acc: 0.1638, Test Acc: 0.1775\n",
            "Seed: 45, Epoch: 025, Loss: 2.2053, Val Acc: 0.1490, Test Acc: 0.1654\n",
            "Seed: 45, Epoch: 026, Loss: 2.1996, Val Acc: 0.1542, Test Acc: 0.1497\n",
            "Seed: 45, Epoch: 027, Loss: 2.1907, Val Acc: 0.1490, Test Acc: 0.1549\n",
            "Seed: 45, Epoch: 028, Loss: 2.1863, Val Acc: 0.1585, Test Acc: 0.1610\n",
            "Seed: 45, Epoch: 029, Loss: 2.1829, Val Acc: 0.1585, Test Acc: 0.1558\n",
            "Seed: 45, Epoch: 030, Loss: 2.1759, Val Acc: 0.1542, Test Acc: 0.1636\n",
            "Seed: 45, Epoch: 031, Loss: 2.1697, Val Acc: 0.1733, Test Acc: 0.1680\n",
            "Seed: 45, Epoch: 032, Loss: 2.1659, Val Acc: 0.1768, Test Acc: 0.1767\n",
            "Seed: 45, Epoch: 033, Loss: 2.1569, Val Acc: 0.1716, Test Acc: 0.1793\n",
            "Seed: 45, Epoch: 034, Loss: 2.1519, Val Acc: 0.1577, Test Acc: 0.1567\n",
            "Seed: 45, Epoch: 035, Loss: 2.1540, Val Acc: 0.1829, Test Acc: 0.1784\n",
            "Seed: 45, Epoch: 036, Loss: 2.1534, Val Acc: 0.1742, Test Acc: 0.1862\n",
            "Seed: 45, Epoch: 037, Loss: 2.1381, Val Acc: 0.1655, Test Acc: 0.1662\n",
            "Seed: 45, Epoch: 038, Loss: 2.1367, Val Acc: 0.1786, Test Acc: 0.1793\n",
            "Seed: 45, Epoch: 039, Loss: 2.1289, Val Acc: 0.1916, Test Acc: 0.1967\n",
            "Seed: 45, Epoch: 040, Loss: 2.1299, Val Acc: 0.1646, Test Acc: 0.1662\n",
            "Seed: 45, Epoch: 041, Loss: 2.1279, Val Acc: 0.1821, Test Acc: 0.1749\n",
            "Seed: 45, Epoch: 042, Loss: 2.1146, Val Acc: 0.1986, Test Acc: 0.2132\n",
            "Seed: 45, Epoch: 043, Loss: 2.1107, Val Acc: 0.1690, Test Acc: 0.1732\n",
            "Seed: 45, Epoch: 044, Loss: 2.1152, Val Acc: 0.1908, Test Acc: 0.2002\n",
            "Seed: 45, Epoch: 045, Loss: 2.1142, Val Acc: 0.2012, Test Acc: 0.2193\n",
            "Seed: 45, Epoch: 046, Loss: 2.1074, Val Acc: 0.1821, Test Acc: 0.1749\n",
            "Seed: 45, Epoch: 047, Loss: 2.0991, Val Acc: 0.2143, Test Acc: 0.2237\n",
            "Seed: 45, Epoch: 048, Loss: 2.0960, Val Acc: 0.2099, Test Acc: 0.2097\n",
            "Seed: 45, Epoch: 049, Loss: 2.0886, Val Acc: 0.1943, Test Acc: 0.1932\n",
            "Seed: 45, Epoch: 050, Loss: 2.0845, Val Acc: 0.2056, Test Acc: 0.2167\n",
            "Seed: 45, Epoch: 051, Loss: 2.0818, Val Acc: 0.1960, Test Acc: 0.1958\n",
            "Seed: 45, Epoch: 052, Loss: 2.0784, Val Acc: 0.2099, Test Acc: 0.2219\n",
            "Seed: 45, Epoch: 053, Loss: 2.0766, Val Acc: 0.2178, Test Acc: 0.2185\n",
            "Seed: 45, Epoch: 054, Loss: 2.0698, Val Acc: 0.2030, Test Acc: 0.2037\n",
            "Seed: 45, Epoch: 055, Loss: 2.0635, Val Acc: 0.2178, Test Acc: 0.2167\n",
            "Seed: 45, Epoch: 056, Loss: 2.0602, Val Acc: 0.2160, Test Acc: 0.2150\n",
            "Seed: 45, Epoch: 057, Loss: 2.0567, Val Acc: 0.2056, Test Acc: 0.2219\n",
            "Seed: 45, Epoch: 058, Loss: 2.0512, Val Acc: 0.2064, Test Acc: 0.2193\n",
            "Seed: 45, Epoch: 059, Loss: 2.0471, Val Acc: 0.2108, Test Acc: 0.2315\n",
            "Seed: 45, Epoch: 060, Loss: 2.0477, Val Acc: 0.2117, Test Acc: 0.2237\n",
            "Seed: 45, Epoch: 061, Loss: 2.0433, Val Acc: 0.2099, Test Acc: 0.2124\n",
            "Seed: 45, Epoch: 062, Loss: 2.0396, Val Acc: 0.2247, Test Acc: 0.2254\n",
            "Seed: 45, Epoch: 063, Loss: 2.0350, Val Acc: 0.2439, Test Acc: 0.2254\n",
            "Seed: 45, Epoch: 064, Loss: 2.0276, Val Acc: 0.2361, Test Acc: 0.2298\n",
            "Seed: 45, Epoch: 065, Loss: 2.0227, Val Acc: 0.2308, Test Acc: 0.2393\n",
            "Seed: 45, Epoch: 066, Loss: 2.0225, Val Acc: 0.2291, Test Acc: 0.2306\n",
            "Seed: 45, Epoch: 067, Loss: 2.0142, Val Acc: 0.2265, Test Acc: 0.2341\n",
            "Seed: 45, Epoch: 068, Loss: 2.0125, Val Acc: 0.2282, Test Acc: 0.2402\n",
            "Seed: 45, Epoch: 069, Loss: 2.0081, Val Acc: 0.2256, Test Acc: 0.2376\n",
            "Seed: 45, Epoch: 070, Loss: 2.0001, Val Acc: 0.2247, Test Acc: 0.2324\n",
            "Seed: 45, Epoch: 071, Loss: 1.9949, Val Acc: 0.2160, Test Acc: 0.2341\n",
            "Seed: 45, Epoch: 072, Loss: 1.9978, Val Acc: 0.2291, Test Acc: 0.2393\n",
            "Seed: 45, Epoch: 073, Loss: 1.9887, Val Acc: 0.2552, Test Acc: 0.2419\n",
            "Seed: 45, Epoch: 074, Loss: 1.9843, Val Acc: 0.2395, Test Acc: 0.2480\n",
            "Seed: 45, Epoch: 075, Loss: 1.9775, Val Acc: 0.2343, Test Acc: 0.2480\n",
            "Seed: 45, Epoch: 076, Loss: 1.9742, Val Acc: 0.2387, Test Acc: 0.2515\n",
            "Seed: 45, Epoch: 077, Loss: 1.9648, Val Acc: 0.2509, Test Acc: 0.2611\n",
            "Seed: 45, Epoch: 078, Loss: 1.9552, Val Acc: 0.2387, Test Acc: 0.2628\n",
            "Seed: 45, Epoch: 079, Loss: 1.9580, Val Acc: 0.2474, Test Acc: 0.2576\n",
            "Seed: 45, Epoch: 080, Loss: 1.9478, Val Acc: 0.2500, Test Acc: 0.2559\n",
            "Seed: 45, Epoch: 081, Loss: 1.9399, Val Acc: 0.2500, Test Acc: 0.2498\n",
            "Seed: 45, Epoch: 082, Loss: 1.9342, Val Acc: 0.2517, Test Acc: 0.2567\n",
            "Seed: 45, Epoch: 083, Loss: 1.9296, Val Acc: 0.2544, Test Acc: 0.2672\n",
            "Seed: 45, Epoch: 084, Loss: 1.9257, Val Acc: 0.2587, Test Acc: 0.2611\n",
            "Seed: 45, Epoch: 085, Loss: 1.9199, Val Acc: 0.2613, Test Acc: 0.2681\n",
            "Seed: 45, Epoch: 086, Loss: 1.9140, Val Acc: 0.2700, Test Acc: 0.2672\n",
            "Seed: 45, Epoch: 087, Loss: 1.9116, Val Acc: 0.2491, Test Acc: 0.2663\n",
            "Seed: 45, Epoch: 088, Loss: 1.9076, Val Acc: 0.2491, Test Acc: 0.2715\n",
            "Seed: 45, Epoch: 089, Loss: 1.9026, Val Acc: 0.2709, Test Acc: 0.2881\n",
            "Seed: 45, Epoch: 090, Loss: 1.8974, Val Acc: 0.2535, Test Acc: 0.2689\n",
            "Seed: 45, Epoch: 091, Loss: 1.8963, Val Acc: 0.2735, Test Acc: 0.2855\n",
            "Seed: 45, Epoch: 092, Loss: 1.8906, Val Acc: 0.2944, Test Acc: 0.2811\n",
            "Seed: 45, Epoch: 093, Loss: 1.8842, Val Acc: 0.2648, Test Acc: 0.2776\n",
            "Seed: 45, Epoch: 094, Loss: 1.8791, Val Acc: 0.2866, Test Acc: 0.2916\n",
            "Seed: 45, Epoch: 095, Loss: 1.8733, Val Acc: 0.2962, Test Acc: 0.2881\n",
            "Seed: 45, Epoch: 096, Loss: 1.8679, Val Acc: 0.2761, Test Acc: 0.3081\n",
            "Seed: 45, Epoch: 097, Loss: 1.8634, Val Acc: 0.2918, Test Acc: 0.2907\n",
            "Seed: 45, Epoch: 098, Loss: 1.8589, Val Acc: 0.2927, Test Acc: 0.2933\n",
            "Seed: 45, Epoch: 099, Loss: 1.8540, Val Acc: 0.2892, Test Acc: 0.2959\n",
            "Seed: 45, Epoch: 100, Loss: 1.8483, Val Acc: 0.2988, Test Acc: 0.2942\n",
            "Seed: 45, Epoch: 101, Loss: 1.8459, Val Acc: 0.2848, Test Acc: 0.2942\n",
            "Seed: 45, Epoch: 102, Loss: 1.8409, Val Acc: 0.3014, Test Acc: 0.2907\n",
            "Seed: 45, Epoch: 103, Loss: 1.8370, Val Acc: 0.2927, Test Acc: 0.2942\n",
            "Seed: 45, Epoch: 104, Loss: 1.8384, Val Acc: 0.3014, Test Acc: 0.2898\n",
            "Seed: 45, Epoch: 105, Loss: 1.8319, Val Acc: 0.2875, Test Acc: 0.2898\n",
            "Seed: 45, Epoch: 106, Loss: 1.8253, Val Acc: 0.2997, Test Acc: 0.2898\n",
            "Seed: 45, Epoch: 107, Loss: 1.8234, Val Acc: 0.3031, Test Acc: 0.2907\n",
            "Seed: 45, Epoch: 108, Loss: 1.8184, Val Acc: 0.2970, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 109, Loss: 1.8167, Val Acc: 0.3101, Test Acc: 0.2968\n",
            "Seed: 45, Epoch: 110, Loss: 1.8139, Val Acc: 0.2866, Test Acc: 0.2977\n",
            "Seed: 45, Epoch: 111, Loss: 1.8123, Val Acc: 0.3057, Test Acc: 0.2985\n",
            "Seed: 45, Epoch: 112, Loss: 1.8056, Val Acc: 0.2875, Test Acc: 0.2907\n",
            "Seed: 45, Epoch: 113, Loss: 1.7996, Val Acc: 0.3092, Test Acc: 0.2968\n",
            "Seed: 45, Epoch: 114, Loss: 1.7981, Val Acc: 0.2979, Test Acc: 0.3011\n",
            "Seed: 45, Epoch: 115, Loss: 1.7941, Val Acc: 0.3171, Test Acc: 0.2968\n",
            "Seed: 45, Epoch: 116, Loss: 1.7896, Val Acc: 0.2988, Test Acc: 0.2924\n",
            "Seed: 45, Epoch: 117, Loss: 1.7861, Val Acc: 0.3171, Test Acc: 0.2907\n",
            "Seed: 45, Epoch: 118, Loss: 1.7817, Val Acc: 0.3005, Test Acc: 0.2907\n",
            "Seed: 45, Epoch: 119, Loss: 1.7765, Val Acc: 0.3127, Test Acc: 0.2968\n",
            "Seed: 45, Epoch: 120, Loss: 1.7757, Val Acc: 0.2953, Test Acc: 0.2950\n",
            "Seed: 45, Epoch: 121, Loss: 1.7710, Val Acc: 0.3223, Test Acc: 0.3011\n",
            "Seed: 45, Epoch: 122, Loss: 1.7689, Val Acc: 0.3153, Test Acc: 0.3098\n",
            "Seed: 45, Epoch: 123, Loss: 1.7654, Val Acc: 0.3014, Test Acc: 0.2985\n",
            "Seed: 45, Epoch: 124, Loss: 1.7635, Val Acc: 0.3171, Test Acc: 0.3081\n",
            "Seed: 45, Epoch: 125, Loss: 1.7602, Val Acc: 0.3040, Test Acc: 0.3064\n",
            "Seed: 45, Epoch: 126, Loss: 1.7581, Val Acc: 0.3458, Test Acc: 0.3185\n",
            "Seed: 45, Epoch: 127, Loss: 1.7562, Val Acc: 0.3153, Test Acc: 0.3081\n",
            "Seed: 45, Epoch: 128, Loss: 1.7511, Val Acc: 0.3092, Test Acc: 0.3011\n",
            "Seed: 45, Epoch: 129, Loss: 1.7488, Val Acc: 0.3066, Test Acc: 0.3046\n",
            "Seed: 45, Epoch: 130, Loss: 1.7455, Val Acc: 0.3084, Test Acc: 0.3151\n",
            "Seed: 45, Epoch: 131, Loss: 1.7478, Val Acc: 0.3136, Test Acc: 0.3151\n",
            "Seed: 45, Epoch: 132, Loss: 1.7441, Val Acc: 0.3110, Test Acc: 0.3064\n",
            "Seed: 45, Epoch: 133, Loss: 1.7429, Val Acc: 0.3162, Test Acc: 0.3029\n",
            "Seed: 45, Epoch: 134, Loss: 1.7378, Val Acc: 0.3118, Test Acc: 0.3116\n",
            "Seed: 45, Epoch: 135, Loss: 1.7359, Val Acc: 0.3171, Test Acc: 0.3107\n",
            "Seed: 45, Epoch: 136, Loss: 1.7306, Val Acc: 0.3258, Test Acc: 0.3081\n",
            "Seed: 45, Epoch: 137, Loss: 1.7276, Val Acc: 0.3118, Test Acc: 0.3046\n",
            "Seed: 45, Epoch: 138, Loss: 1.7249, Val Acc: 0.3145, Test Acc: 0.3072\n",
            "Seed: 45, Epoch: 139, Loss: 1.7242, Val Acc: 0.3197, Test Acc: 0.3081\n",
            "Seed: 45, Epoch: 140, Loss: 1.7234, Val Acc: 0.3110, Test Acc: 0.3081\n",
            "Seed: 45, Epoch: 141, Loss: 1.7205, Val Acc: 0.3145, Test Acc: 0.3072\n",
            "Seed: 45, Epoch: 142, Loss: 1.7179, Val Acc: 0.3162, Test Acc: 0.3159\n",
            "Seed: 45, Epoch: 143, Loss: 1.7151, Val Acc: 0.3188, Test Acc: 0.3168\n",
            "Seed: 45, Epoch: 144, Loss: 1.7128, Val Acc: 0.3171, Test Acc: 0.3229\n",
            "Seed: 45, Epoch: 145, Loss: 1.7082, Val Acc: 0.3171, Test Acc: 0.3151\n",
            "Seed: 45, Epoch: 146, Loss: 1.7071, Val Acc: 0.3075, Test Acc: 0.3203\n",
            "Seed: 45, Epoch: 147, Loss: 1.7067, Val Acc: 0.3214, Test Acc: 0.3194\n",
            "Seed: 45, Epoch: 148, Loss: 1.7054, Val Acc: 0.3267, Test Acc: 0.3159\n",
            "Seed: 45, Epoch: 149, Loss: 1.7048, Val Acc: 0.3249, Test Acc: 0.3211\n",
            "Seed: 45, Epoch: 150, Loss: 1.7007, Val Acc: 0.3127, Test Acc: 0.3203\n",
            "Seed: 45, Epoch: 151, Loss: 1.7031, Val Acc: 0.3328, Test Acc: 0.3151\n",
            "Seed: 45, Epoch: 152, Loss: 1.7063, Val Acc: 0.2997, Test Acc: 0.3046\n",
            "Seed: 45, Epoch: 153, Loss: 1.7011, Val Acc: 0.3232, Test Acc: 0.3081\n",
            "Seed: 45, Epoch: 154, Loss: 1.6988, Val Acc: 0.3171, Test Acc: 0.3081\n",
            "Seed: 45, Epoch: 155, Loss: 1.6942, Val Acc: 0.3319, Test Acc: 0.3264\n",
            "Seed: 45, Epoch: 156, Loss: 1.6897, Val Acc: 0.3284, Test Acc: 0.3124\n",
            "Seed: 45, Epoch: 157, Loss: 1.6879, Val Acc: 0.3179, Test Acc: 0.3159\n",
            "Seed: 45, Epoch: 158, Loss: 1.6901, Val Acc: 0.3423, Test Acc: 0.3290\n",
            "Seed: 45, Epoch: 159, Loss: 1.6867, Val Acc: 0.3171, Test Acc: 0.3168\n",
            "Seed: 45, Epoch: 160, Loss: 1.6838, Val Acc: 0.3328, Test Acc: 0.3238\n",
            "Seed: 45, Epoch: 161, Loss: 1.6760, Val Acc: 0.3179, Test Acc: 0.3133\n",
            "Seed: 45, Epoch: 162, Loss: 1.6755, Val Acc: 0.3528, Test Acc: 0.3299\n",
            "Seed: 45, Epoch: 163, Loss: 1.6717, Val Acc: 0.3153, Test Acc: 0.3229\n",
            "Seed: 45, Epoch: 164, Loss: 1.6698, Val Acc: 0.3328, Test Acc: 0.3194\n",
            "Seed: 45, Epoch: 165, Loss: 1.6686, Val Acc: 0.3275, Test Acc: 0.3124\n",
            "Seed: 45, Epoch: 166, Loss: 1.6654, Val Acc: 0.3301, Test Acc: 0.3351\n",
            "Seed: 45, Epoch: 167, Loss: 1.6627, Val Acc: 0.3267, Test Acc: 0.3342\n",
            "Seed: 45, Epoch: 168, Loss: 1.6573, Val Acc: 0.3301, Test Acc: 0.3159\n",
            "Seed: 45, Epoch: 169, Loss: 1.6554, Val Acc: 0.3232, Test Acc: 0.3133\n",
            "Seed: 45, Epoch: 170, Loss: 1.6517, Val Acc: 0.3275, Test Acc: 0.3142\n",
            "Seed: 45, Epoch: 171, Loss: 1.6536, Val Acc: 0.3223, Test Acc: 0.3229\n",
            "Seed: 45, Epoch: 172, Loss: 1.6515, Val Acc: 0.3328, Test Acc: 0.3420\n",
            "Seed: 45, Epoch: 173, Loss: 1.6484, Val Acc: 0.3267, Test Acc: 0.3272\n",
            "Seed: 45, Epoch: 174, Loss: 1.6452, Val Acc: 0.3240, Test Acc: 0.3203\n",
            "Seed: 45, Epoch: 175, Loss: 1.6440, Val Acc: 0.3284, Test Acc: 0.3238\n",
            "Seed: 45, Epoch: 176, Loss: 1.6438, Val Acc: 0.3267, Test Acc: 0.3351\n",
            "Seed: 45, Epoch: 177, Loss: 1.6459, Val Acc: 0.3301, Test Acc: 0.3272\n",
            "Seed: 45, Epoch: 178, Loss: 1.6453, Val Acc: 0.3162, Test Acc: 0.3194\n",
            "Seed: 45, Epoch: 179, Loss: 1.6431, Val Acc: 0.3319, Test Acc: 0.3325\n",
            "Seed: 45, Epoch: 180, Loss: 1.6506, Val Acc: 0.3293, Test Acc: 0.3159\n",
            "Seed: 45, Epoch: 181, Loss: 1.6507, Val Acc: 0.3249, Test Acc: 0.3290\n",
            "Seed: 45, Epoch: 182, Loss: 1.6484, Val Acc: 0.3301, Test Acc: 0.3429\n",
            "Seed: 45, Epoch: 183, Loss: 1.6462, Val Acc: 0.3197, Test Acc: 0.3229\n",
            "Seed: 45, Epoch: 184, Loss: 1.6432, Val Acc: 0.3354, Test Acc: 0.3438\n",
            "Seed: 45, Epoch: 185, Loss: 1.6409, Val Acc: 0.3240, Test Acc: 0.3394\n",
            "Seed: 45, Epoch: 186, Loss: 1.6468, Val Acc: 0.3214, Test Acc: 0.3229\n",
            "Seed: 45, Epoch: 187, Loss: 1.6595, Val Acc: 0.3354, Test Acc: 0.3255\n",
            "Seed: 45, Epoch: 188, Loss: 1.6463, Val Acc: 0.3441, Test Acc: 0.3325\n",
            "Seed: 45, Epoch: 189, Loss: 1.6470, Val Acc: 0.3214, Test Acc: 0.3072\n",
            "Seed: 45, Epoch: 190, Loss: 1.6504, Val Acc: 0.3467, Test Acc: 0.3299\n",
            "Seed: 45, Epoch: 191, Loss: 1.6541, Val Acc: 0.3362, Test Acc: 0.3246\n",
            "Seed: 45, Epoch: 192, Loss: 1.6512, Val Acc: 0.3319, Test Acc: 0.3151\n",
            "Seed: 45, Epoch: 193, Loss: 1.6483, Val Acc: 0.3336, Test Acc: 0.3299\n",
            "Seed: 45, Epoch: 194, Loss: 1.6470, Val Acc: 0.3371, Test Acc: 0.3211\n",
            "Seed: 45, Epoch: 195, Loss: 1.6418, Val Acc: 0.3380, Test Acc: 0.3307\n",
            "Seed: 45, Epoch: 196, Loss: 1.6401, Val Acc: 0.3493, Test Acc: 0.3342\n",
            "Seed: 45, Epoch: 197, Loss: 1.6410, Val Acc: 0.3502, Test Acc: 0.3211\n",
            "Seed: 45, Epoch: 198, Loss: 1.6415, Val Acc: 0.3232, Test Acc: 0.3159\n",
            "Seed: 45, Epoch: 199, Loss: 1.6395, Val Acc: 0.3458, Test Acc: 0.3368\n",
            "Seed: 45, Epoch: 200, Loss: 1.6387, Val Acc: 0.3476, Test Acc: 0.3151\n",
            "Seed: 46, Epoch: 001, Loss: 2.3997, Val Acc: 0.0601, Test Acc: 0.0722\n",
            "Seed: 46, Epoch: 002, Loss: 2.3988, Val Acc: 0.0601, Test Acc: 0.0722\n",
            "Seed: 46, Epoch: 003, Loss: 2.3979, Val Acc: 0.0601, Test Acc: 0.0722\n",
            "Seed: 46, Epoch: 004, Loss: 2.3969, Val Acc: 0.0549, Test Acc: 0.0748\n",
            "Seed: 46, Epoch: 005, Loss: 2.3960, Val Acc: 0.0662, Test Acc: 0.0923\n",
            "Seed: 46, Epoch: 006, Loss: 2.3948, Val Acc: 0.0854, Test Acc: 0.0983\n",
            "Seed: 46, Epoch: 007, Loss: 2.3935, Val Acc: 0.0967, Test Acc: 0.1001\n",
            "Seed: 46, Epoch: 008, Loss: 2.3916, Val Acc: 0.0949, Test Acc: 0.0940\n",
            "Seed: 46, Epoch: 009, Loss: 2.3895, Val Acc: 0.0941, Test Acc: 0.0923\n",
            "Seed: 46, Epoch: 010, Loss: 2.3857, Val Acc: 0.1063, Test Acc: 0.1070\n",
            "Seed: 46, Epoch: 011, Loss: 2.3807, Val Acc: 0.1019, Test Acc: 0.1123\n",
            "Seed: 46, Epoch: 012, Loss: 2.3736, Val Acc: 0.1115, Test Acc: 0.1332\n",
            "Seed: 46, Epoch: 013, Loss: 2.3646, Val Acc: 0.1411, Test Acc: 0.1436\n",
            "Seed: 46, Epoch: 014, Loss: 2.3540, Val Acc: 0.1368, Test Acc: 0.1471\n",
            "Seed: 46, Epoch: 015, Loss: 2.3414, Val Acc: 0.1228, Test Acc: 0.1410\n",
            "Seed: 46, Epoch: 016, Loss: 2.3270, Val Acc: 0.1376, Test Acc: 0.1453\n",
            "Seed: 46, Epoch: 017, Loss: 2.3102, Val Acc: 0.1263, Test Acc: 0.1471\n",
            "Seed: 46, Epoch: 018, Loss: 2.2885, Val Acc: 0.1280, Test Acc: 0.1410\n",
            "Seed: 46, Epoch: 019, Loss: 2.2714, Val Acc: 0.1228, Test Acc: 0.1349\n",
            "Seed: 46, Epoch: 020, Loss: 2.2533, Val Acc: 0.1307, Test Acc: 0.1462\n",
            "Seed: 46, Epoch: 021, Loss: 2.2326, Val Acc: 0.1437, Test Acc: 0.1532\n",
            "Seed: 46, Epoch: 022, Loss: 2.2249, Val Acc: 0.1385, Test Acc: 0.1497\n",
            "Seed: 46, Epoch: 023, Loss: 2.2434, Val Acc: 0.1254, Test Acc: 0.1323\n",
            "Seed: 46, Epoch: 024, Loss: 2.2671, Val Acc: 0.0967, Test Acc: 0.1158\n",
            "Seed: 46, Epoch: 025, Loss: 2.2830, Val Acc: 0.1402, Test Acc: 0.1340\n",
            "Seed: 46, Epoch: 026, Loss: 2.2684, Val Acc: 0.1220, Test Acc: 0.1393\n",
            "Seed: 46, Epoch: 027, Loss: 2.2430, Val Acc: 0.1524, Test Acc: 0.1471\n",
            "Seed: 46, Epoch: 028, Loss: 2.2285, Val Acc: 0.1498, Test Acc: 0.1584\n",
            "Seed: 46, Epoch: 029, Loss: 2.2109, Val Acc: 0.1341, Test Acc: 0.1384\n",
            "Seed: 46, Epoch: 030, Loss: 2.2102, Val Acc: 0.1490, Test Acc: 0.1506\n",
            "Seed: 46, Epoch: 031, Loss: 2.2013, Val Acc: 0.1490, Test Acc: 0.1540\n",
            "Seed: 46, Epoch: 032, Loss: 2.1962, Val Acc: 0.1446, Test Acc: 0.1462\n",
            "Seed: 46, Epoch: 033, Loss: 2.1880, Val Acc: 0.1507, Test Acc: 0.1497\n",
            "Seed: 46, Epoch: 034, Loss: 2.1800, Val Acc: 0.1551, Test Acc: 0.1567\n",
            "Seed: 46, Epoch: 035, Loss: 2.1758, Val Acc: 0.1585, Test Acc: 0.1619\n",
            "Seed: 46, Epoch: 036, Loss: 2.1679, Val Acc: 0.1507, Test Acc: 0.1584\n",
            "Seed: 46, Epoch: 037, Loss: 2.1615, Val Acc: 0.1620, Test Acc: 0.1619\n",
            "Seed: 46, Epoch: 038, Loss: 2.1537, Val Acc: 0.1603, Test Acc: 0.1575\n",
            "Seed: 46, Epoch: 039, Loss: 2.1470, Val Acc: 0.1585, Test Acc: 0.1584\n",
            "Seed: 46, Epoch: 040, Loss: 2.1395, Val Acc: 0.1629, Test Acc: 0.1662\n",
            "Seed: 46, Epoch: 041, Loss: 2.1313, Val Acc: 0.1646, Test Acc: 0.1628\n",
            "Seed: 46, Epoch: 042, Loss: 2.1213, Val Acc: 0.1751, Test Acc: 0.1741\n",
            "Seed: 46, Epoch: 043, Loss: 2.1099, Val Acc: 0.1725, Test Acc: 0.1749\n",
            "Seed: 46, Epoch: 044, Loss: 2.1011, Val Acc: 0.1794, Test Acc: 0.1845\n",
            "Seed: 46, Epoch: 045, Loss: 2.0909, Val Acc: 0.1760, Test Acc: 0.1732\n",
            "Seed: 46, Epoch: 046, Loss: 2.0835, Val Acc: 0.1742, Test Acc: 0.1819\n",
            "Seed: 46, Epoch: 047, Loss: 2.0768, Val Acc: 0.1725, Test Acc: 0.1871\n",
            "Seed: 46, Epoch: 048, Loss: 2.0699, Val Acc: 0.1864, Test Acc: 0.1749\n",
            "Seed: 46, Epoch: 049, Loss: 2.0651, Val Acc: 0.1829, Test Acc: 0.1610\n",
            "Seed: 46, Epoch: 050, Loss: 2.0741, Val Acc: 0.1786, Test Acc: 0.1836\n",
            "Seed: 46, Epoch: 051, Loss: 2.0788, Val Acc: 0.1699, Test Acc: 0.1775\n",
            "Seed: 46, Epoch: 052, Loss: 2.0797, Val Acc: 0.1725, Test Acc: 0.1967\n",
            "Seed: 46, Epoch: 053, Loss: 2.0662, Val Acc: 0.1777, Test Acc: 0.1880\n",
            "Seed: 46, Epoch: 054, Loss: 2.0589, Val Acc: 0.1873, Test Acc: 0.2002\n",
            "Seed: 46, Epoch: 055, Loss: 2.0498, Val Acc: 0.1925, Test Acc: 0.2019\n",
            "Seed: 46, Epoch: 056, Loss: 2.0440, Val Acc: 0.1838, Test Acc: 0.2037\n",
            "Seed: 46, Epoch: 057, Loss: 2.0417, Val Acc: 0.1908, Test Acc: 0.2106\n",
            "Seed: 46, Epoch: 058, Loss: 2.0355, Val Acc: 0.2056, Test Acc: 0.2106\n",
            "Seed: 46, Epoch: 059, Loss: 2.0273, Val Acc: 0.1916, Test Acc: 0.2211\n",
            "Seed: 46, Epoch: 060, Loss: 2.0206, Val Acc: 0.2056, Test Acc: 0.2132\n",
            "Seed: 46, Epoch: 061, Loss: 2.0166, Val Acc: 0.1890, Test Acc: 0.2097\n",
            "Seed: 46, Epoch: 062, Loss: 2.0073, Val Acc: 0.2030, Test Acc: 0.2167\n",
            "Seed: 46, Epoch: 063, Loss: 2.0024, Val Acc: 0.2003, Test Acc: 0.2185\n",
            "Seed: 46, Epoch: 064, Loss: 1.9998, Val Acc: 0.2082, Test Acc: 0.2045\n",
            "Seed: 46, Epoch: 065, Loss: 1.9927, Val Acc: 0.2047, Test Acc: 0.2115\n",
            "Seed: 46, Epoch: 066, Loss: 1.9872, Val Acc: 0.2152, Test Acc: 0.2141\n",
            "Seed: 46, Epoch: 067, Loss: 1.9825, Val Acc: 0.2195, Test Acc: 0.2193\n",
            "Seed: 46, Epoch: 068, Loss: 1.9747, Val Acc: 0.2195, Test Acc: 0.2089\n",
            "Seed: 46, Epoch: 069, Loss: 1.9696, Val Acc: 0.2221, Test Acc: 0.2124\n",
            "Seed: 46, Epoch: 070, Loss: 1.9626, Val Acc: 0.2352, Test Acc: 0.2150\n",
            "Seed: 46, Epoch: 071, Loss: 1.9577, Val Acc: 0.2308, Test Acc: 0.2185\n",
            "Seed: 46, Epoch: 072, Loss: 1.9531, Val Acc: 0.2274, Test Acc: 0.2211\n",
            "Seed: 46, Epoch: 073, Loss: 1.9474, Val Acc: 0.2361, Test Acc: 0.2237\n",
            "Seed: 46, Epoch: 074, Loss: 1.9419, Val Acc: 0.2378, Test Acc: 0.2237\n",
            "Seed: 46, Epoch: 075, Loss: 1.9383, Val Acc: 0.2422, Test Acc: 0.2324\n",
            "Seed: 46, Epoch: 076, Loss: 1.9321, Val Acc: 0.2413, Test Acc: 0.2306\n",
            "Seed: 46, Epoch: 077, Loss: 1.9285, Val Acc: 0.2352, Test Acc: 0.2245\n",
            "Seed: 46, Epoch: 078, Loss: 1.9221, Val Acc: 0.2378, Test Acc: 0.2376\n",
            "Seed: 46, Epoch: 079, Loss: 1.9217, Val Acc: 0.2404, Test Acc: 0.2298\n",
            "Seed: 46, Epoch: 080, Loss: 1.9182, Val Acc: 0.2334, Test Acc: 0.2272\n",
            "Seed: 46, Epoch: 081, Loss: 1.9177, Val Acc: 0.2570, Test Acc: 0.2419\n",
            "Seed: 46, Epoch: 082, Loss: 1.9043, Val Acc: 0.2622, Test Acc: 0.2454\n",
            "Seed: 46, Epoch: 083, Loss: 1.9024, Val Acc: 0.2378, Test Acc: 0.2324\n",
            "Seed: 46, Epoch: 084, Loss: 1.8977, Val Acc: 0.2605, Test Acc: 0.2411\n",
            "Seed: 46, Epoch: 085, Loss: 1.9032, Val Acc: 0.2700, Test Acc: 0.2594\n",
            "Seed: 46, Epoch: 086, Loss: 1.8882, Val Acc: 0.2657, Test Acc: 0.2628\n",
            "Seed: 46, Epoch: 087, Loss: 1.8813, Val Acc: 0.2657, Test Acc: 0.2559\n",
            "Seed: 46, Epoch: 088, Loss: 1.8721, Val Acc: 0.2866, Test Acc: 0.2681\n",
            "Seed: 46, Epoch: 089, Loss: 1.8658, Val Acc: 0.2805, Test Acc: 0.2698\n",
            "Seed: 46, Epoch: 090, Loss: 1.8583, Val Acc: 0.2814, Test Acc: 0.2646\n",
            "Seed: 46, Epoch: 091, Loss: 1.8557, Val Acc: 0.2744, Test Acc: 0.2646\n",
            "Seed: 46, Epoch: 092, Loss: 1.8522, Val Acc: 0.2848, Test Acc: 0.2829\n",
            "Seed: 46, Epoch: 093, Loss: 1.8466, Val Acc: 0.2953, Test Acc: 0.2820\n",
            "Seed: 46, Epoch: 094, Loss: 1.8429, Val Acc: 0.2936, Test Acc: 0.2785\n",
            "Seed: 46, Epoch: 095, Loss: 1.8368, Val Acc: 0.2796, Test Acc: 0.2733\n",
            "Seed: 46, Epoch: 096, Loss: 1.8341, Val Acc: 0.2909, Test Acc: 0.2881\n",
            "Seed: 46, Epoch: 097, Loss: 1.8298, Val Acc: 0.2857, Test Acc: 0.2829\n",
            "Seed: 46, Epoch: 098, Loss: 1.8223, Val Acc: 0.2901, Test Acc: 0.2811\n",
            "Seed: 46, Epoch: 099, Loss: 1.8193, Val Acc: 0.3031, Test Acc: 0.2942\n",
            "Seed: 46, Epoch: 100, Loss: 1.8148, Val Acc: 0.3049, Test Acc: 0.2933\n",
            "Seed: 46, Epoch: 101, Loss: 1.8083, Val Acc: 0.3118, Test Acc: 0.2977\n",
            "Seed: 46, Epoch: 102, Loss: 1.8053, Val Acc: 0.3092, Test Acc: 0.3072\n",
            "Seed: 46, Epoch: 103, Loss: 1.8001, Val Acc: 0.3075, Test Acc: 0.2863\n",
            "Seed: 46, Epoch: 104, Loss: 1.7937, Val Acc: 0.3014, Test Acc: 0.2950\n",
            "Seed: 46, Epoch: 105, Loss: 1.7910, Val Acc: 0.3136, Test Acc: 0.2985\n",
            "Seed: 46, Epoch: 106, Loss: 1.7894, Val Acc: 0.3249, Test Acc: 0.3011\n",
            "Seed: 46, Epoch: 107, Loss: 1.7854, Val Acc: 0.3127, Test Acc: 0.2898\n",
            "Seed: 46, Epoch: 108, Loss: 1.7881, Val Acc: 0.3110, Test Acc: 0.3020\n",
            "Seed: 46, Epoch: 109, Loss: 1.7800, Val Acc: 0.3075, Test Acc: 0.2968\n",
            "Seed: 46, Epoch: 110, Loss: 1.7745, Val Acc: 0.3223, Test Acc: 0.3072\n",
            "Seed: 46, Epoch: 111, Loss: 1.7714, Val Acc: 0.3371, Test Acc: 0.3090\n",
            "Seed: 46, Epoch: 112, Loss: 1.7664, Val Acc: 0.3258, Test Acc: 0.3055\n",
            "Seed: 46, Epoch: 113, Loss: 1.7651, Val Acc: 0.3345, Test Acc: 0.3142\n",
            "Seed: 46, Epoch: 114, Loss: 1.7611, Val Acc: 0.3310, Test Acc: 0.3055\n",
            "Seed: 46, Epoch: 115, Loss: 1.7591, Val Acc: 0.3397, Test Acc: 0.3055\n",
            "Seed: 46, Epoch: 116, Loss: 1.7595, Val Acc: 0.3223, Test Acc: 0.3020\n",
            "Seed: 46, Epoch: 117, Loss: 1.7553, Val Acc: 0.3336, Test Acc: 0.3090\n",
            "Seed: 46, Epoch: 118, Loss: 1.7494, Val Acc: 0.3223, Test Acc: 0.3055\n",
            "Seed: 46, Epoch: 119, Loss: 1.7448, Val Acc: 0.3258, Test Acc: 0.3029\n",
            "Seed: 46, Epoch: 120, Loss: 1.7427, Val Acc: 0.3336, Test Acc: 0.3211\n",
            "Seed: 46, Epoch: 121, Loss: 1.7390, Val Acc: 0.3415, Test Acc: 0.3142\n",
            "Seed: 46, Epoch: 122, Loss: 1.7367, Val Acc: 0.3423, Test Acc: 0.3151\n",
            "Seed: 46, Epoch: 123, Loss: 1.7347, Val Acc: 0.3240, Test Acc: 0.3168\n",
            "Seed: 46, Epoch: 124, Loss: 1.7327, Val Acc: 0.3284, Test Acc: 0.3159\n",
            "Seed: 46, Epoch: 125, Loss: 1.7290, Val Acc: 0.3293, Test Acc: 0.3107\n",
            "Seed: 46, Epoch: 126, Loss: 1.7265, Val Acc: 0.3371, Test Acc: 0.3064\n",
            "Seed: 46, Epoch: 127, Loss: 1.7265, Val Acc: 0.3380, Test Acc: 0.3011\n",
            "Seed: 46, Epoch: 128, Loss: 1.7240, Val Acc: 0.3371, Test Acc: 0.3037\n",
            "Seed: 46, Epoch: 129, Loss: 1.7215, Val Acc: 0.3336, Test Acc: 0.3029\n",
            "Seed: 46, Epoch: 130, Loss: 1.7208, Val Acc: 0.3293, Test Acc: 0.3072\n",
            "Seed: 46, Epoch: 131, Loss: 1.7201, Val Acc: 0.3249, Test Acc: 0.3116\n",
            "Seed: 46, Epoch: 132, Loss: 1.7154, Val Acc: 0.3301, Test Acc: 0.3020\n",
            "Seed: 46, Epoch: 133, Loss: 1.7189, Val Acc: 0.3232, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 134, Loss: 1.7308, Val Acc: 0.3362, Test Acc: 0.3055\n",
            "Seed: 46, Epoch: 135, Loss: 1.7211, Val Acc: 0.3362, Test Acc: 0.3046\n",
            "Seed: 46, Epoch: 136, Loss: 1.7180, Val Acc: 0.3301, Test Acc: 0.2985\n",
            "Seed: 46, Epoch: 137, Loss: 1.7109, Val Acc: 0.3258, Test Acc: 0.3124\n",
            "Seed: 46, Epoch: 138, Loss: 1.7048, Val Acc: 0.3328, Test Acc: 0.3168\n",
            "Seed: 46, Epoch: 139, Loss: 1.7047, Val Acc: 0.3380, Test Acc: 0.2994\n",
            "Seed: 46, Epoch: 140, Loss: 1.7000, Val Acc: 0.3406, Test Acc: 0.3081\n",
            "Seed: 46, Epoch: 141, Loss: 1.7135, Val Acc: 0.3301, Test Acc: 0.3055\n",
            "Seed: 46, Epoch: 142, Loss: 1.7072, Val Acc: 0.3258, Test Acc: 0.3185\n",
            "Seed: 46, Epoch: 143, Loss: 1.7098, Val Acc: 0.3389, Test Acc: 0.3098\n",
            "Seed: 46, Epoch: 144, Loss: 1.7117, Val Acc: 0.3528, Test Acc: 0.3081\n",
            "Seed: 46, Epoch: 145, Loss: 1.7126, Val Acc: 0.3441, Test Acc: 0.3142\n",
            "Seed: 46, Epoch: 146, Loss: 1.7081, Val Acc: 0.3389, Test Acc: 0.3072\n",
            "Seed: 46, Epoch: 147, Loss: 1.7141, Val Acc: 0.3476, Test Acc: 0.3151\n",
            "Seed: 46, Epoch: 148, Loss: 1.7107, Val Acc: 0.3371, Test Acc: 0.3064\n",
            "Seed: 46, Epoch: 149, Loss: 1.7068, Val Acc: 0.3354, Test Acc: 0.3029\n",
            "Seed: 46, Epoch: 150, Loss: 1.7058, Val Acc: 0.3415, Test Acc: 0.3142\n",
            "Seed: 46, Epoch: 151, Loss: 1.6994, Val Acc: 0.3441, Test Acc: 0.3116\n",
            "Seed: 46, Epoch: 152, Loss: 1.6960, Val Acc: 0.3449, Test Acc: 0.3185\n",
            "Seed: 46, Epoch: 153, Loss: 1.6976, Val Acc: 0.3432, Test Acc: 0.3133\n",
            "Seed: 46, Epoch: 154, Loss: 1.6944, Val Acc: 0.3458, Test Acc: 0.3037\n",
            "Seed: 46, Epoch: 155, Loss: 1.6944, Val Acc: 0.3345, Test Acc: 0.3064\n",
            "Seed: 46, Epoch: 156, Loss: 1.6931, Val Acc: 0.3397, Test Acc: 0.3116\n",
            "Seed: 46, Epoch: 157, Loss: 1.7033, Val Acc: 0.3380, Test Acc: 0.3020\n",
            "Seed: 46, Epoch: 158, Loss: 1.7189, Val Acc: 0.3415, Test Acc: 0.3003\n",
            "Seed: 46, Epoch: 159, Loss: 1.7120, Val Acc: 0.3484, Test Acc: 0.3072\n",
            "Seed: 46, Epoch: 160, Loss: 1.7191, Val Acc: 0.3214, Test Acc: 0.3116\n",
            "Seed: 46, Epoch: 161, Loss: 1.7156, Val Acc: 0.3319, Test Acc: 0.2837\n",
            "Seed: 46, Epoch: 162, Loss: 1.7136, Val Acc: 0.3206, Test Acc: 0.3055\n",
            "Seed: 46, Epoch: 163, Loss: 1.7090, Val Acc: 0.3179, Test Acc: 0.3072\n",
            "Seed: 46, Epoch: 164, Loss: 1.7060, Val Acc: 0.3336, Test Acc: 0.3124\n",
            "Seed: 46, Epoch: 165, Loss: 1.7064, Val Acc: 0.3301, Test Acc: 0.3220\n",
            "Seed: 46, Epoch: 166, Loss: 1.7030, Val Acc: 0.3415, Test Acc: 0.3124\n",
            "Seed: 46, Epoch: 167, Loss: 1.6978, Val Acc: 0.3406, Test Acc: 0.3159\n",
            "Seed: 46, Epoch: 168, Loss: 1.6927, Val Acc: 0.3380, Test Acc: 0.3151\n",
            "Seed: 46, Epoch: 169, Loss: 1.6893, Val Acc: 0.3484, Test Acc: 0.3151\n",
            "Seed: 46, Epoch: 170, Loss: 1.6878, Val Acc: 0.3258, Test Acc: 0.3116\n",
            "Seed: 46, Epoch: 171, Loss: 1.6894, Val Acc: 0.3397, Test Acc: 0.3124\n",
            "Seed: 46, Epoch: 172, Loss: 1.6873, Val Acc: 0.3441, Test Acc: 0.3151\n",
            "Seed: 46, Epoch: 173, Loss: 1.6858, Val Acc: 0.3371, Test Acc: 0.3098\n",
            "Seed: 46, Epoch: 174, Loss: 1.6857, Val Acc: 0.3458, Test Acc: 0.3124\n",
            "Seed: 46, Epoch: 175, Loss: 1.6845, Val Acc: 0.3415, Test Acc: 0.3194\n",
            "Seed: 46, Epoch: 176, Loss: 1.6793, Val Acc: 0.3449, Test Acc: 0.3133\n",
            "Seed: 46, Epoch: 177, Loss: 1.6769, Val Acc: 0.3362, Test Acc: 0.3133\n",
            "Seed: 46, Epoch: 178, Loss: 1.6743, Val Acc: 0.3432, Test Acc: 0.3020\n",
            "Seed: 46, Epoch: 179, Loss: 1.6740, Val Acc: 0.3423, Test Acc: 0.3055\n",
            "Seed: 46, Epoch: 180, Loss: 1.6731, Val Acc: 0.3406, Test Acc: 0.3064\n",
            "Seed: 46, Epoch: 181, Loss: 1.6708, Val Acc: 0.3493, Test Acc: 0.3124\n",
            "Seed: 46, Epoch: 182, Loss: 1.6758, Val Acc: 0.3502, Test Acc: 0.3133\n",
            "Seed: 46, Epoch: 183, Loss: 1.6741, Val Acc: 0.3423, Test Acc: 0.3090\n",
            "Seed: 46, Epoch: 184, Loss: 1.6742, Val Acc: 0.3563, Test Acc: 0.3159\n",
            "Seed: 46, Epoch: 185, Loss: 1.6722, Val Acc: 0.3345, Test Acc: 0.3203\n",
            "Seed: 46, Epoch: 186, Loss: 1.6759, Val Acc: 0.3449, Test Acc: 0.3151\n",
            "Seed: 46, Epoch: 187, Loss: 1.6715, Val Acc: 0.3380, Test Acc: 0.3177\n",
            "Seed: 46, Epoch: 188, Loss: 1.6691, Val Acc: 0.3319, Test Acc: 0.3151\n",
            "Seed: 46, Epoch: 189, Loss: 1.6735, Val Acc: 0.3389, Test Acc: 0.3107\n",
            "Seed: 46, Epoch: 190, Loss: 1.6693, Val Acc: 0.3336, Test Acc: 0.3203\n",
            "Seed: 46, Epoch: 191, Loss: 1.6670, Val Acc: 0.3380, Test Acc: 0.3159\n",
            "Seed: 46, Epoch: 192, Loss: 1.6660, Val Acc: 0.3345, Test Acc: 0.3185\n",
            "Seed: 46, Epoch: 193, Loss: 1.6658, Val Acc: 0.3293, Test Acc: 0.3133\n",
            "Seed: 46, Epoch: 194, Loss: 1.6660, Val Acc: 0.3354, Test Acc: 0.3203\n",
            "Seed: 46, Epoch: 195, Loss: 1.6694, Val Acc: 0.3467, Test Acc: 0.3316\n",
            "Seed: 46, Epoch: 196, Loss: 1.6645, Val Acc: 0.3354, Test Acc: 0.3194\n",
            "Seed: 46, Epoch: 197, Loss: 1.6604, Val Acc: 0.3362, Test Acc: 0.3003\n",
            "Seed: 46, Epoch: 198, Loss: 1.6605, Val Acc: 0.3354, Test Acc: 0.3116\n",
            "Seed: 46, Epoch: 199, Loss: 1.6599, Val Acc: 0.3362, Test Acc: 0.3133\n",
            "Seed: 46, Epoch: 200, Loss: 1.6579, Val Acc: 0.3519, Test Acc: 0.3177\n",
            "Average Time: 189.99 seconds\n",
            "Var Time: 4.02 seconds\n",
            "Average Memory: 3656.00 MB\n",
            "Average Best Val Acc: 0.3664\n",
            "Std Best Test Acc: 0.0539\n",
            "Average Test Acc: 0.3488\n",
            "Test Acc: [0.3167972149695387, 0.32550043516100957, 0.4560487380330722, 0.329852045256745, 0.31592689295039167]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, TopKPooling\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "import time\n",
        "class HierarchicalGCN_TOPK(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes):\n",
        "        super(HierarchicalGCN_TOPK, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.pool1 = TopKPooling(hidden_channels, ratio=0.5)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.pool2 = TopKPooling(hidden_channels, ratio=0.5)\n",
        "        self.conv3 = SAGEConv(hidden_channels, out_channels)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.lin1 = torch.nn.Linear(out_channels, 32)\n",
        "        self.lin2 = torch.nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        # First GCN and pooling layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn1(x)\n",
        "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, batch=batch)\n",
        "\n",
        "        # Second GCN and pooling layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn2(x)\n",
        "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, batch=batch)\n",
        "\n",
        "        # Third GCN layer\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn3(x)\n",
        "\n",
        "        # Mean pooling over the nodes\n",
        "        x, mask = to_dense_batch(x, batch)\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.lin1(x).relu()\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "num_classes = dataset_sparse.num_classes\n",
        "in_channels = dataset_sparse.num_features\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HierarchicalGCN_TOPK(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        data.y = data.y.to(torch.long)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == data.y).sum().item()\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seeds = [42, 43, 44, 45, 46]\n",
        "times = []\n",
        "memories = []\n",
        "best_val_accs = []\n",
        "best_test_accs = []\n",
        "\n",
        "early_stop_patience = 150\n",
        "tolerance = 0.0001\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    model = HierarchicalGCN_TOPK(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        val_acc = test(valid_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        if val_acc > best_val_acc + tolerance:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "        if epochs_no_improve >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
        "\n",
        "    times.append(total_time)\n",
        "    memories.append(memory_allocated)\n",
        "    best_val_accs.append(best_val_acc)\n",
        "    best_test_accs.append(best_test_acc)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
        "print(f'Var Time: {np.var(times):.2f} seconds')\n",
        "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
        "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
        "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
        "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')\n",
        "print(f'Test Acc: {best_test_accs}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFlxXyYaKWIB"
      },
      "source": [
        "## SAGPooling with HierarchicalGCN (2019)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "flOqRJT4KdJO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 001, Loss: 2.4024, Val Acc: 0.1054, Test Acc: 0.1114\n",
            "Seed: 42, Epoch: 002, Loss: 2.4013, Val Acc: 0.1054, Test Acc: 0.1114\n",
            "Seed: 42, Epoch: 003, Loss: 2.4002, Val Acc: 0.1054, Test Acc: 0.1114\n",
            "Seed: 42, Epoch: 004, Loss: 2.3987, Val Acc: 0.1054, Test Acc: 0.1114\n",
            "Seed: 42, Epoch: 005, Loss: 2.3966, Val Acc: 0.1054, Test Acc: 0.1114\n",
            "Seed: 42, Epoch: 006, Loss: 2.3934, Val Acc: 0.1054, Test Acc: 0.1114\n",
            "Seed: 42, Epoch: 007, Loss: 2.3888, Val Acc: 0.1071, Test Acc: 0.1123\n",
            "Seed: 42, Epoch: 008, Loss: 2.3829, Val Acc: 0.1263, Test Acc: 0.1271\n",
            "Seed: 42, Epoch: 009, Loss: 2.3748, Val Acc: 0.1437, Test Acc: 0.1523\n",
            "Seed: 42, Epoch: 010, Loss: 2.3639, Val Acc: 0.1524, Test Acc: 0.1427\n",
            "Seed: 42, Epoch: 011, Loss: 2.3489, Val Acc: 0.1551, Test Acc: 0.1480\n",
            "Seed: 42, Epoch: 012, Loss: 2.3312, Val Acc: 0.1655, Test Acc: 0.1723\n",
            "Seed: 42, Epoch: 013, Loss: 2.3104, Val Acc: 0.1733, Test Acc: 0.1793\n",
            "Seed: 42, Epoch: 014, Loss: 2.2847, Val Acc: 0.1882, Test Acc: 0.2037\n",
            "Seed: 42, Epoch: 015, Loss: 2.2555, Val Acc: 0.2003, Test Acc: 0.2097\n",
            "Seed: 42, Epoch: 016, Loss: 2.2248, Val Acc: 0.2282, Test Acc: 0.2106\n",
            "Seed: 42, Epoch: 017, Loss: 2.1914, Val Acc: 0.2117, Test Acc: 0.2245\n",
            "Seed: 42, Epoch: 018, Loss: 2.1604, Val Acc: 0.2073, Test Acc: 0.2237\n",
            "Seed: 42, Epoch: 019, Loss: 2.1337, Val Acc: 0.2082, Test Acc: 0.2193\n",
            "Seed: 42, Epoch: 020, Loss: 2.1124, Val Acc: 0.2465, Test Acc: 0.2428\n",
            "Seed: 42, Epoch: 021, Loss: 2.0938, Val Acc: 0.2282, Test Acc: 0.2376\n",
            "Seed: 42, Epoch: 022, Loss: 2.0790, Val Acc: 0.2465, Test Acc: 0.2402\n",
            "Seed: 42, Epoch: 023, Loss: 2.0571, Val Acc: 0.2125, Test Acc: 0.2324\n",
            "Seed: 42, Epoch: 024, Loss: 2.0433, Val Acc: 0.2143, Test Acc: 0.2359\n",
            "Seed: 42, Epoch: 025, Loss: 2.0317, Val Acc: 0.2160, Test Acc: 0.2332\n",
            "Seed: 42, Epoch: 026, Loss: 2.0200, Val Acc: 0.2247, Test Acc: 0.2376\n",
            "Seed: 42, Epoch: 027, Loss: 2.0084, Val Acc: 0.2456, Test Acc: 0.2428\n",
            "Seed: 42, Epoch: 028, Loss: 1.9980, Val Acc: 0.2221, Test Acc: 0.2480\n",
            "Seed: 42, Epoch: 029, Loss: 1.9872, Val Acc: 0.2247, Test Acc: 0.2428\n",
            "Seed: 42, Epoch: 030, Loss: 1.9788, Val Acc: 0.2265, Test Acc: 0.2446\n",
            "Seed: 42, Epoch: 031, Loss: 1.9713, Val Acc: 0.2300, Test Acc: 0.2411\n",
            "Seed: 42, Epoch: 032, Loss: 1.9627, Val Acc: 0.2291, Test Acc: 0.2350\n",
            "Seed: 42, Epoch: 033, Loss: 1.9564, Val Acc: 0.2265, Test Acc: 0.2498\n",
            "Seed: 42, Epoch: 034, Loss: 1.9517, Val Acc: 0.2274, Test Acc: 0.2498\n",
            "Seed: 42, Epoch: 035, Loss: 1.9462, Val Acc: 0.2274, Test Acc: 0.2472\n",
            "Seed: 42, Epoch: 036, Loss: 1.9445, Val Acc: 0.2256, Test Acc: 0.2446\n",
            "Seed: 42, Epoch: 037, Loss: 1.9388, Val Acc: 0.2265, Test Acc: 0.2411\n",
            "Seed: 42, Epoch: 038, Loss: 1.9339, Val Acc: 0.2247, Test Acc: 0.2489\n",
            "Seed: 42, Epoch: 039, Loss: 1.9310, Val Acc: 0.2282, Test Acc: 0.2332\n",
            "Seed: 42, Epoch: 040, Loss: 1.9274, Val Acc: 0.2317, Test Acc: 0.2454\n",
            "Seed: 42, Epoch: 041, Loss: 1.9207, Val Acc: 0.2343, Test Acc: 0.2428\n",
            "Seed: 42, Epoch: 042, Loss: 1.9173, Val Acc: 0.2378, Test Acc: 0.2515\n",
            "Seed: 42, Epoch: 043, Loss: 1.9116, Val Acc: 0.2448, Test Acc: 0.2585\n",
            "Seed: 42, Epoch: 044, Loss: 1.9095, Val Acc: 0.2378, Test Acc: 0.2463\n",
            "Seed: 42, Epoch: 045, Loss: 1.9075, Val Acc: 0.2413, Test Acc: 0.2428\n",
            "Seed: 42, Epoch: 046, Loss: 1.9040, Val Acc: 0.2369, Test Acc: 0.2498\n",
            "Seed: 42, Epoch: 047, Loss: 1.9016, Val Acc: 0.2387, Test Acc: 0.2489\n",
            "Seed: 42, Epoch: 048, Loss: 1.8988, Val Acc: 0.2387, Test Acc: 0.2646\n",
            "Seed: 42, Epoch: 049, Loss: 1.8983, Val Acc: 0.2369, Test Acc: 0.2567\n",
            "Seed: 42, Epoch: 050, Loss: 1.8945, Val Acc: 0.2474, Test Acc: 0.2515\n",
            "Seed: 42, Epoch: 051, Loss: 1.8935, Val Acc: 0.2456, Test Acc: 0.2594\n",
            "Seed: 42, Epoch: 052, Loss: 1.8917, Val Acc: 0.2387, Test Acc: 0.2698\n",
            "Seed: 42, Epoch: 053, Loss: 1.8935, Val Acc: 0.2517, Test Acc: 0.2620\n",
            "Seed: 42, Epoch: 054, Loss: 1.8873, Val Acc: 0.2369, Test Acc: 0.2559\n",
            "Seed: 42, Epoch: 055, Loss: 1.8843, Val Acc: 0.2483, Test Acc: 0.2637\n",
            "Seed: 42, Epoch: 056, Loss: 1.8802, Val Acc: 0.2439, Test Acc: 0.2637\n",
            "Seed: 42, Epoch: 057, Loss: 1.8766, Val Acc: 0.2465, Test Acc: 0.2646\n",
            "Seed: 42, Epoch: 058, Loss: 1.8767, Val Acc: 0.2483, Test Acc: 0.2654\n",
            "Seed: 42, Epoch: 059, Loss: 1.8705, Val Acc: 0.2439, Test Acc: 0.2707\n",
            "Seed: 42, Epoch: 060, Loss: 1.8722, Val Acc: 0.2587, Test Acc: 0.2681\n",
            "Seed: 42, Epoch: 061, Loss: 1.8684, Val Acc: 0.2491, Test Acc: 0.2602\n",
            "Seed: 42, Epoch: 062, Loss: 1.8668, Val Acc: 0.2570, Test Acc: 0.2654\n",
            "Seed: 42, Epoch: 063, Loss: 1.8616, Val Acc: 0.2500, Test Acc: 0.2681\n",
            "Seed: 42, Epoch: 064, Loss: 1.8614, Val Acc: 0.2605, Test Acc: 0.2794\n",
            "Seed: 42, Epoch: 065, Loss: 1.8614, Val Acc: 0.2578, Test Acc: 0.2707\n",
            "Seed: 42, Epoch: 066, Loss: 1.8605, Val Acc: 0.2605, Test Acc: 0.2733\n",
            "Seed: 42, Epoch: 067, Loss: 1.8557, Val Acc: 0.2535, Test Acc: 0.2750\n",
            "Seed: 42, Epoch: 068, Loss: 1.8495, Val Acc: 0.2596, Test Acc: 0.2742\n",
            "Seed: 42, Epoch: 069, Loss: 1.8473, Val Acc: 0.2622, Test Acc: 0.2742\n",
            "Seed: 42, Epoch: 070, Loss: 1.8447, Val Acc: 0.2700, Test Acc: 0.2942\n",
            "Seed: 42, Epoch: 071, Loss: 1.8417, Val Acc: 0.2674, Test Acc: 0.2907\n",
            "Seed: 42, Epoch: 072, Loss: 1.8404, Val Acc: 0.2692, Test Acc: 0.2855\n",
            "Seed: 42, Epoch: 073, Loss: 1.8362, Val Acc: 0.2631, Test Acc: 0.2950\n",
            "Seed: 42, Epoch: 074, Loss: 1.8330, Val Acc: 0.2753, Test Acc: 0.2872\n",
            "Seed: 42, Epoch: 075, Loss: 1.8294, Val Acc: 0.2761, Test Acc: 0.2820\n",
            "Seed: 42, Epoch: 076, Loss: 1.8263, Val Acc: 0.2857, Test Acc: 0.2898\n",
            "Seed: 42, Epoch: 077, Loss: 1.8209, Val Acc: 0.2944, Test Acc: 0.3107\n",
            "Seed: 42, Epoch: 078, Loss: 1.8185, Val Acc: 0.2901, Test Acc: 0.2950\n",
            "Seed: 42, Epoch: 079, Loss: 1.8145, Val Acc: 0.2936, Test Acc: 0.2985\n",
            "Seed: 42, Epoch: 080, Loss: 1.8123, Val Acc: 0.2909, Test Acc: 0.3064\n",
            "Seed: 42, Epoch: 081, Loss: 1.8096, Val Acc: 0.2892, Test Acc: 0.2959\n",
            "Seed: 42, Epoch: 082, Loss: 1.8067, Val Acc: 0.2883, Test Acc: 0.3090\n",
            "Seed: 42, Epoch: 083, Loss: 1.8035, Val Acc: 0.2918, Test Acc: 0.3159\n",
            "Seed: 42, Epoch: 084, Loss: 1.8010, Val Acc: 0.2944, Test Acc: 0.3159\n",
            "Seed: 42, Epoch: 085, Loss: 1.7991, Val Acc: 0.2822, Test Acc: 0.3037\n",
            "Seed: 42, Epoch: 086, Loss: 1.7994, Val Acc: 0.3110, Test Acc: 0.3133\n",
            "Seed: 42, Epoch: 087, Loss: 1.7958, Val Acc: 0.2761, Test Acc: 0.3037\n",
            "Seed: 42, Epoch: 088, Loss: 1.7977, Val Acc: 0.3118, Test Acc: 0.3290\n",
            "Seed: 42, Epoch: 089, Loss: 1.7910, Val Acc: 0.2962, Test Acc: 0.3064\n",
            "Seed: 42, Epoch: 090, Loss: 1.7876, Val Acc: 0.2875, Test Acc: 0.3072\n",
            "Seed: 42, Epoch: 091, Loss: 1.7845, Val Acc: 0.3110, Test Acc: 0.3185\n",
            "Seed: 42, Epoch: 092, Loss: 1.7838, Val Acc: 0.2953, Test Acc: 0.3098\n",
            "Seed: 42, Epoch: 093, Loss: 1.7786, Val Acc: 0.3092, Test Acc: 0.3090\n",
            "Seed: 42, Epoch: 094, Loss: 1.7764, Val Acc: 0.2979, Test Acc: 0.3090\n",
            "Seed: 42, Epoch: 095, Loss: 1.7745, Val Acc: 0.3206, Test Acc: 0.3316\n",
            "Seed: 42, Epoch: 096, Loss: 1.7735, Val Acc: 0.2979, Test Acc: 0.3055\n",
            "Seed: 42, Epoch: 097, Loss: 1.7685, Val Acc: 0.2927, Test Acc: 0.3072\n",
            "Seed: 42, Epoch: 098, Loss: 1.7687, Val Acc: 0.3136, Test Acc: 0.3211\n",
            "Seed: 42, Epoch: 099, Loss: 1.7689, Val Acc: 0.3066, Test Acc: 0.3159\n",
            "Seed: 42, Epoch: 100, Loss: 1.7656, Val Acc: 0.3084, Test Acc: 0.3107\n",
            "Seed: 42, Epoch: 101, Loss: 1.7657, Val Acc: 0.3014, Test Acc: 0.3133\n",
            "Seed: 42, Epoch: 102, Loss: 1.7616, Val Acc: 0.3057, Test Acc: 0.3185\n",
            "Seed: 42, Epoch: 103, Loss: 1.7583, Val Acc: 0.3084, Test Acc: 0.3159\n",
            "Seed: 42, Epoch: 104, Loss: 1.7586, Val Acc: 0.3145, Test Acc: 0.3246\n",
            "Seed: 42, Epoch: 105, Loss: 1.7599, Val Acc: 0.3171, Test Acc: 0.3151\n",
            "Seed: 42, Epoch: 106, Loss: 1.7584, Val Acc: 0.3232, Test Acc: 0.3220\n",
            "Seed: 42, Epoch: 107, Loss: 1.7552, Val Acc: 0.3145, Test Acc: 0.3351\n",
            "Seed: 42, Epoch: 108, Loss: 1.7511, Val Acc: 0.3118, Test Acc: 0.3194\n",
            "Seed: 42, Epoch: 109, Loss: 1.7504, Val Acc: 0.2927, Test Acc: 0.3255\n",
            "Seed: 42, Epoch: 110, Loss: 1.7496, Val Acc: 0.3066, Test Acc: 0.3290\n",
            "Seed: 42, Epoch: 111, Loss: 1.7379, Val Acc: 0.3145, Test Acc: 0.3151\n",
            "Seed: 42, Epoch: 112, Loss: 1.7325, Val Acc: 0.3136, Test Acc: 0.3220\n",
            "Seed: 42, Epoch: 113, Loss: 1.7271, Val Acc: 0.3145, Test Acc: 0.3342\n",
            "Seed: 42, Epoch: 114, Loss: 1.7265, Val Acc: 0.3014, Test Acc: 0.3211\n",
            "Seed: 42, Epoch: 115, Loss: 1.7218, Val Acc: 0.3206, Test Acc: 0.3299\n",
            "Seed: 42, Epoch: 116, Loss: 1.7226, Val Acc: 0.3066, Test Acc: 0.3220\n",
            "Seed: 42, Epoch: 117, Loss: 1.7147, Val Acc: 0.3441, Test Acc: 0.3420\n",
            "Seed: 42, Epoch: 118, Loss: 1.7077, Val Acc: 0.3319, Test Acc: 0.3420\n",
            "Seed: 42, Epoch: 119, Loss: 1.7007, Val Acc: 0.3510, Test Acc: 0.3412\n",
            "Seed: 42, Epoch: 120, Loss: 1.6946, Val Acc: 0.3807, Test Acc: 0.3516\n",
            "Seed: 42, Epoch: 121, Loss: 1.6935, Val Acc: 0.3693, Test Acc: 0.3560\n",
            "Seed: 42, Epoch: 122, Loss: 1.6902, Val Acc: 0.3493, Test Acc: 0.3603\n",
            "Seed: 42, Epoch: 123, Loss: 1.6819, Val Acc: 0.3563, Test Acc: 0.3629\n",
            "Seed: 42, Epoch: 124, Loss: 1.6738, Val Acc: 0.3615, Test Acc: 0.3603\n",
            "Seed: 42, Epoch: 125, Loss: 1.6702, Val Acc: 0.3632, Test Acc: 0.3708\n",
            "Seed: 42, Epoch: 126, Loss: 1.6649, Val Acc: 0.3728, Test Acc: 0.3734\n",
            "Seed: 42, Epoch: 127, Loss: 1.6624, Val Acc: 0.3563, Test Acc: 0.3742\n",
            "Seed: 42, Epoch: 128, Loss: 1.6612, Val Acc: 0.3667, Test Acc: 0.3760\n",
            "Seed: 42, Epoch: 129, Loss: 1.6605, Val Acc: 0.3667, Test Acc: 0.3803\n",
            "Seed: 42, Epoch: 130, Loss: 1.6574, Val Acc: 0.3720, Test Acc: 0.3803\n",
            "Seed: 42, Epoch: 131, Loss: 1.6598, Val Acc: 0.3737, Test Acc: 0.3856\n",
            "Seed: 42, Epoch: 132, Loss: 1.6613, Val Acc: 0.3737, Test Acc: 0.3873\n",
            "Seed: 42, Epoch: 133, Loss: 1.6587, Val Acc: 0.3641, Test Acc: 0.3882\n",
            "Seed: 42, Epoch: 134, Loss: 1.6574, Val Acc: 0.3632, Test Acc: 0.3873\n",
            "Seed: 42, Epoch: 135, Loss: 1.6570, Val Acc: 0.3632, Test Acc: 0.3908\n",
            "Seed: 42, Epoch: 136, Loss: 1.6569, Val Acc: 0.3624, Test Acc: 0.3768\n",
            "Seed: 42, Epoch: 137, Loss: 1.6581, Val Acc: 0.3632, Test Acc: 0.3821\n",
            "Seed: 42, Epoch: 138, Loss: 1.6553, Val Acc: 0.3720, Test Acc: 0.3655\n",
            "Seed: 42, Epoch: 139, Loss: 1.6536, Val Acc: 0.3624, Test Acc: 0.3838\n",
            "Seed: 42, Epoch: 140, Loss: 1.6534, Val Acc: 0.3720, Test Acc: 0.3699\n",
            "Seed: 42, Epoch: 141, Loss: 1.6504, Val Acc: 0.3737, Test Acc: 0.3768\n",
            "Seed: 42, Epoch: 142, Loss: 1.6463, Val Acc: 0.3807, Test Acc: 0.3768\n",
            "Seed: 42, Epoch: 143, Loss: 1.6476, Val Acc: 0.3772, Test Acc: 0.3664\n",
            "Seed: 42, Epoch: 144, Loss: 1.6484, Val Acc: 0.3720, Test Acc: 0.3795\n",
            "Seed: 42, Epoch: 145, Loss: 1.6425, Val Acc: 0.3876, Test Acc: 0.3777\n",
            "Seed: 42, Epoch: 146, Loss: 1.6407, Val Acc: 0.3894, Test Acc: 0.3943\n",
            "Seed: 42, Epoch: 147, Loss: 1.6404, Val Acc: 0.3885, Test Acc: 0.3821\n",
            "Seed: 42, Epoch: 148, Loss: 1.6372, Val Acc: 0.3780, Test Acc: 0.3821\n",
            "Seed: 42, Epoch: 149, Loss: 1.6346, Val Acc: 0.3780, Test Acc: 0.3873\n",
            "Seed: 42, Epoch: 150, Loss: 1.6357, Val Acc: 0.3807, Test Acc: 0.3829\n",
            "Seed: 42, Epoch: 151, Loss: 1.6330, Val Acc: 0.3850, Test Acc: 0.3803\n",
            "Seed: 42, Epoch: 152, Loss: 1.6310, Val Acc: 0.3859, Test Acc: 0.3699\n",
            "Seed: 42, Epoch: 153, Loss: 1.6284, Val Acc: 0.3920, Test Acc: 0.3795\n",
            "Seed: 42, Epoch: 154, Loss: 1.6260, Val Acc: 0.3920, Test Acc: 0.3908\n",
            "Seed: 42, Epoch: 155, Loss: 1.6202, Val Acc: 0.3850, Test Acc: 0.3890\n",
            "Seed: 42, Epoch: 156, Loss: 1.6223, Val Acc: 0.3807, Test Acc: 0.3916\n",
            "Seed: 42, Epoch: 157, Loss: 1.6235, Val Acc: 0.3841, Test Acc: 0.3760\n",
            "Seed: 42, Epoch: 158, Loss: 1.6287, Val Acc: 0.3737, Test Acc: 0.3708\n",
            "Seed: 42, Epoch: 159, Loss: 1.6294, Val Acc: 0.4016, Test Acc: 0.3943\n",
            "Seed: 42, Epoch: 160, Loss: 1.6169, Val Acc: 0.3920, Test Acc: 0.3838\n",
            "Seed: 42, Epoch: 161, Loss: 1.6150, Val Acc: 0.3841, Test Acc: 0.3890\n",
            "Seed: 42, Epoch: 162, Loss: 1.6089, Val Acc: 0.3841, Test Acc: 0.3864\n",
            "Seed: 42, Epoch: 163, Loss: 1.6087, Val Acc: 0.4024, Test Acc: 0.3882\n",
            "Seed: 42, Epoch: 164, Loss: 1.6051, Val Acc: 0.3946, Test Acc: 0.3838\n",
            "Seed: 42, Epoch: 165, Loss: 1.6011, Val Acc: 0.3929, Test Acc: 0.3908\n",
            "Seed: 42, Epoch: 166, Loss: 1.5982, Val Acc: 0.3963, Test Acc: 0.3969\n",
            "Seed: 42, Epoch: 167, Loss: 1.5965, Val Acc: 0.3937, Test Acc: 0.3995\n",
            "Seed: 42, Epoch: 168, Loss: 1.5927, Val Acc: 0.4016, Test Acc: 0.3951\n",
            "Seed: 42, Epoch: 169, Loss: 1.5888, Val Acc: 0.3972, Test Acc: 0.3960\n",
            "Seed: 42, Epoch: 170, Loss: 1.5885, Val Acc: 0.3955, Test Acc: 0.3916\n",
            "Seed: 42, Epoch: 171, Loss: 1.5873, Val Acc: 0.3946, Test Acc: 0.4003\n",
            "Seed: 42, Epoch: 172, Loss: 1.5817, Val Acc: 0.3981, Test Acc: 0.4073\n",
            "Seed: 42, Epoch: 173, Loss: 1.5817, Val Acc: 0.3929, Test Acc: 0.4003\n",
            "Seed: 42, Epoch: 174, Loss: 1.5845, Val Acc: 0.3876, Test Acc: 0.3943\n",
            "Seed: 42, Epoch: 175, Loss: 1.5831, Val Acc: 0.4068, Test Acc: 0.3969\n",
            "Seed: 42, Epoch: 176, Loss: 1.5793, Val Acc: 0.4042, Test Acc: 0.3882\n",
            "Seed: 42, Epoch: 177, Loss: 1.5821, Val Acc: 0.4007, Test Acc: 0.3960\n",
            "Seed: 42, Epoch: 178, Loss: 1.5786, Val Acc: 0.4155, Test Acc: 0.3925\n",
            "Seed: 42, Epoch: 179, Loss: 1.5762, Val Acc: 0.3798, Test Acc: 0.3925\n",
            "Seed: 42, Epoch: 180, Loss: 1.5802, Val Acc: 0.4111, Test Acc: 0.3847\n",
            "Seed: 42, Epoch: 181, Loss: 1.5768, Val Acc: 0.4103, Test Acc: 0.3890\n",
            "Seed: 42, Epoch: 182, Loss: 1.5746, Val Acc: 0.3998, Test Acc: 0.3925\n",
            "Seed: 42, Epoch: 183, Loss: 1.5702, Val Acc: 0.3902, Test Acc: 0.3995\n",
            "Seed: 42, Epoch: 184, Loss: 1.5654, Val Acc: 0.4155, Test Acc: 0.3960\n",
            "Seed: 42, Epoch: 185, Loss: 1.5709, Val Acc: 0.3920, Test Acc: 0.3873\n",
            "Seed: 42, Epoch: 186, Loss: 1.5844, Val Acc: 0.4138, Test Acc: 0.3873\n",
            "Seed: 42, Epoch: 187, Loss: 1.5727, Val Acc: 0.3850, Test Acc: 0.3943\n",
            "Seed: 42, Epoch: 188, Loss: 1.5816, Val Acc: 0.4111, Test Acc: 0.3977\n",
            "Seed: 42, Epoch: 189, Loss: 1.5731, Val Acc: 0.4146, Test Acc: 0.3934\n",
            "Seed: 42, Epoch: 190, Loss: 1.5683, Val Acc: 0.4033, Test Acc: 0.3925\n",
            "Seed: 42, Epoch: 191, Loss: 1.5655, Val Acc: 0.4120, Test Acc: 0.3969\n",
            "Seed: 42, Epoch: 192, Loss: 1.5620, Val Acc: 0.4068, Test Acc: 0.3925\n",
            "Seed: 42, Epoch: 193, Loss: 1.5576, Val Acc: 0.4077, Test Acc: 0.3943\n",
            "Seed: 42, Epoch: 194, Loss: 1.5529, Val Acc: 0.4260, Test Acc: 0.4003\n",
            "Seed: 42, Epoch: 195, Loss: 1.5495, Val Acc: 0.4138, Test Acc: 0.3977\n",
            "Seed: 42, Epoch: 196, Loss: 1.5488, Val Acc: 0.4146, Test Acc: 0.3977\n",
            "Seed: 42, Epoch: 197, Loss: 1.5454, Val Acc: 0.4164, Test Acc: 0.3916\n",
            "Seed: 42, Epoch: 198, Loss: 1.5423, Val Acc: 0.4172, Test Acc: 0.4012\n",
            "Seed: 42, Epoch: 199, Loss: 1.5398, Val Acc: 0.4216, Test Acc: 0.4160\n",
            "Seed: 42, Epoch: 200, Loss: 1.5408, Val Acc: 0.4216, Test Acc: 0.4073\n",
            "Seed: 43, Epoch: 001, Loss: 2.4002, Val Acc: 0.0889, Test Acc: 0.0879\n",
            "Seed: 43, Epoch: 002, Loss: 2.3995, Val Acc: 0.0889, Test Acc: 0.0879\n",
            "Seed: 43, Epoch: 003, Loss: 2.3987, Val Acc: 0.0889, Test Acc: 0.0879\n",
            "Seed: 43, Epoch: 004, Loss: 2.3979, Val Acc: 0.0889, Test Acc: 0.0896\n",
            "Seed: 43, Epoch: 005, Loss: 2.3969, Val Acc: 0.0906, Test Acc: 0.0870\n",
            "Seed: 43, Epoch: 006, Loss: 2.3958, Val Acc: 0.0915, Test Acc: 0.0853\n",
            "Seed: 43, Epoch: 007, Loss: 2.3943, Val Acc: 0.0993, Test Acc: 0.0949\n",
            "Seed: 43, Epoch: 008, Loss: 2.3920, Val Acc: 0.1124, Test Acc: 0.1053\n",
            "Seed: 43, Epoch: 009, Loss: 2.3885, Val Acc: 0.1324, Test Acc: 0.1218\n",
            "Seed: 43, Epoch: 010, Loss: 2.3832, Val Acc: 0.1455, Test Acc: 0.1375\n",
            "Seed: 43, Epoch: 011, Loss: 2.3760, Val Acc: 0.1516, Test Acc: 0.1436\n",
            "Seed: 43, Epoch: 012, Loss: 2.3672, Val Acc: 0.1594, Test Acc: 0.1506\n",
            "Seed: 43, Epoch: 013, Loss: 2.3562, Val Acc: 0.1951, Test Acc: 0.1984\n",
            "Seed: 43, Epoch: 014, Loss: 2.3422, Val Acc: 0.1908, Test Acc: 0.1950\n",
            "Seed: 43, Epoch: 015, Loss: 2.3269, Val Acc: 0.1716, Test Acc: 0.1784\n",
            "Seed: 43, Epoch: 016, Loss: 2.3039, Val Acc: 0.1472, Test Acc: 0.1636\n",
            "Seed: 43, Epoch: 017, Loss: 2.2778, Val Acc: 0.1446, Test Acc: 0.1593\n",
            "Seed: 43, Epoch: 018, Loss: 2.2455, Val Acc: 0.1481, Test Acc: 0.1671\n",
            "Seed: 43, Epoch: 019, Loss: 2.2102, Val Acc: 0.1577, Test Acc: 0.1828\n",
            "Seed: 43, Epoch: 020, Loss: 2.1837, Val Acc: 0.1551, Test Acc: 0.1784\n",
            "Seed: 43, Epoch: 021, Loss: 2.1603, Val Acc: 0.1455, Test Acc: 0.1619\n",
            "Seed: 43, Epoch: 022, Loss: 2.1471, Val Acc: 0.1333, Test Acc: 0.1480\n",
            "Seed: 43, Epoch: 023, Loss: 2.1269, Val Acc: 0.1629, Test Acc: 0.1775\n",
            "Seed: 43, Epoch: 024, Loss: 2.1089, Val Acc: 0.1751, Test Acc: 0.1862\n",
            "Seed: 43, Epoch: 025, Loss: 2.0930, Val Acc: 0.1847, Test Acc: 0.2037\n",
            "Seed: 43, Epoch: 026, Loss: 2.0774, Val Acc: 0.2021, Test Acc: 0.2010\n",
            "Seed: 43, Epoch: 027, Loss: 2.0663, Val Acc: 0.2030, Test Acc: 0.1984\n",
            "Seed: 43, Epoch: 028, Loss: 2.0534, Val Acc: 0.2056, Test Acc: 0.1950\n",
            "Seed: 43, Epoch: 029, Loss: 2.0468, Val Acc: 0.1760, Test Acc: 0.1880\n",
            "Seed: 43, Epoch: 030, Loss: 2.0409, Val Acc: 0.1873, Test Acc: 0.1923\n",
            "Seed: 43, Epoch: 031, Loss: 2.0359, Val Acc: 0.1733, Test Acc: 0.1793\n",
            "Seed: 43, Epoch: 032, Loss: 2.0262, Val Acc: 0.1847, Test Acc: 0.1897\n",
            "Seed: 43, Epoch: 033, Loss: 2.0159, Val Acc: 0.1864, Test Acc: 0.1950\n",
            "Seed: 43, Epoch: 034, Loss: 2.0027, Val Acc: 0.1951, Test Acc: 0.1958\n",
            "Seed: 43, Epoch: 035, Loss: 1.9967, Val Acc: 0.2073, Test Acc: 0.2124\n",
            "Seed: 43, Epoch: 036, Loss: 1.9889, Val Acc: 0.1934, Test Acc: 0.1880\n",
            "Seed: 43, Epoch: 037, Loss: 1.9853, Val Acc: 0.2265, Test Acc: 0.2141\n",
            "Seed: 43, Epoch: 038, Loss: 1.9766, Val Acc: 0.2282, Test Acc: 0.2176\n",
            "Seed: 43, Epoch: 039, Loss: 1.9666, Val Acc: 0.2265, Test Acc: 0.2132\n",
            "Seed: 43, Epoch: 040, Loss: 1.9564, Val Acc: 0.2378, Test Acc: 0.2376\n",
            "Seed: 43, Epoch: 041, Loss: 1.9475, Val Acc: 0.2369, Test Acc: 0.2245\n",
            "Seed: 43, Epoch: 042, Loss: 1.9407, Val Acc: 0.2265, Test Acc: 0.2489\n",
            "Seed: 43, Epoch: 043, Loss: 1.9346, Val Acc: 0.2517, Test Acc: 0.2559\n",
            "Seed: 43, Epoch: 044, Loss: 1.9255, Val Acc: 0.2552, Test Acc: 0.2541\n",
            "Seed: 43, Epoch: 045, Loss: 1.9178, Val Acc: 0.2561, Test Acc: 0.2567\n",
            "Seed: 43, Epoch: 046, Loss: 1.9123, Val Acc: 0.2605, Test Acc: 0.2698\n",
            "Seed: 43, Epoch: 047, Loss: 1.9064, Val Acc: 0.2657, Test Acc: 0.2681\n",
            "Seed: 43, Epoch: 048, Loss: 1.9010, Val Acc: 0.2561, Test Acc: 0.2654\n",
            "Seed: 43, Epoch: 049, Loss: 1.8931, Val Acc: 0.2552, Test Acc: 0.2628\n",
            "Seed: 43, Epoch: 050, Loss: 1.8865, Val Acc: 0.2517, Test Acc: 0.2620\n",
            "Seed: 43, Epoch: 051, Loss: 1.8814, Val Acc: 0.2526, Test Acc: 0.2715\n",
            "Seed: 43, Epoch: 052, Loss: 1.8754, Val Acc: 0.2578, Test Acc: 0.2672\n",
            "Seed: 43, Epoch: 053, Loss: 1.8713, Val Acc: 0.2657, Test Acc: 0.2733\n",
            "Seed: 43, Epoch: 054, Loss: 1.8658, Val Acc: 0.2639, Test Acc: 0.2768\n",
            "Seed: 43, Epoch: 055, Loss: 1.8600, Val Acc: 0.2753, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 056, Loss: 1.8576, Val Acc: 0.2631, Test Acc: 0.2837\n",
            "Seed: 43, Epoch: 057, Loss: 1.8509, Val Acc: 0.2883, Test Acc: 0.2846\n",
            "Seed: 43, Epoch: 058, Loss: 1.8456, Val Acc: 0.2779, Test Acc: 0.2933\n",
            "Seed: 43, Epoch: 059, Loss: 1.8402, Val Acc: 0.2848, Test Acc: 0.3098\n",
            "Seed: 43, Epoch: 060, Loss: 1.8352, Val Acc: 0.2901, Test Acc: 0.3055\n",
            "Seed: 43, Epoch: 061, Loss: 1.8276, Val Acc: 0.2918, Test Acc: 0.3151\n",
            "Seed: 43, Epoch: 062, Loss: 1.8221, Val Acc: 0.2840, Test Acc: 0.2985\n",
            "Seed: 43, Epoch: 063, Loss: 1.8167, Val Acc: 0.2918, Test Acc: 0.3029\n",
            "Seed: 43, Epoch: 064, Loss: 1.8125, Val Acc: 0.2970, Test Acc: 0.3064\n",
            "Seed: 43, Epoch: 065, Loss: 1.8074, Val Acc: 0.3040, Test Acc: 0.3185\n",
            "Seed: 43, Epoch: 066, Loss: 1.8019, Val Acc: 0.3075, Test Acc: 0.3142\n",
            "Seed: 43, Epoch: 067, Loss: 1.7975, Val Acc: 0.3075, Test Acc: 0.3194\n",
            "Seed: 43, Epoch: 068, Loss: 1.7938, Val Acc: 0.3066, Test Acc: 0.3255\n",
            "Seed: 43, Epoch: 069, Loss: 1.7919, Val Acc: 0.3127, Test Acc: 0.3151\n",
            "Seed: 43, Epoch: 070, Loss: 1.7842, Val Acc: 0.3092, Test Acc: 0.3325\n",
            "Seed: 43, Epoch: 071, Loss: 1.7786, Val Acc: 0.3040, Test Acc: 0.3203\n",
            "Seed: 43, Epoch: 072, Loss: 1.7751, Val Acc: 0.3110, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 073, Loss: 1.7685, Val Acc: 0.3162, Test Acc: 0.3246\n",
            "Seed: 43, Epoch: 074, Loss: 1.7641, Val Acc: 0.3162, Test Acc: 0.3351\n",
            "Seed: 43, Epoch: 075, Loss: 1.7605, Val Acc: 0.3127, Test Acc: 0.3359\n",
            "Seed: 43, Epoch: 076, Loss: 1.7579, Val Acc: 0.3258, Test Acc: 0.3351\n",
            "Seed: 43, Epoch: 077, Loss: 1.7502, Val Acc: 0.3179, Test Acc: 0.3403\n",
            "Seed: 43, Epoch: 078, Loss: 1.7419, Val Acc: 0.3275, Test Acc: 0.3507\n",
            "Seed: 43, Epoch: 079, Loss: 1.7401, Val Acc: 0.3171, Test Acc: 0.3560\n",
            "Seed: 43, Epoch: 080, Loss: 1.7371, Val Acc: 0.3328, Test Acc: 0.3507\n",
            "Seed: 43, Epoch: 081, Loss: 1.7339, Val Acc: 0.3389, Test Acc: 0.3655\n",
            "Seed: 43, Epoch: 082, Loss: 1.7275, Val Acc: 0.3310, Test Acc: 0.3612\n",
            "Seed: 43, Epoch: 083, Loss: 1.7230, Val Acc: 0.3389, Test Acc: 0.3551\n",
            "Seed: 43, Epoch: 084, Loss: 1.7206, Val Acc: 0.3484, Test Acc: 0.3629\n",
            "Seed: 43, Epoch: 085, Loss: 1.7156, Val Acc: 0.3493, Test Acc: 0.3647\n",
            "Seed: 43, Epoch: 086, Loss: 1.7109, Val Acc: 0.3545, Test Acc: 0.3821\n",
            "Seed: 43, Epoch: 087, Loss: 1.7061, Val Acc: 0.3545, Test Acc: 0.3890\n",
            "Seed: 43, Epoch: 088, Loss: 1.7008, Val Acc: 0.3650, Test Acc: 0.3812\n",
            "Seed: 43, Epoch: 089, Loss: 1.6923, Val Acc: 0.3624, Test Acc: 0.3708\n",
            "Seed: 43, Epoch: 090, Loss: 1.6904, Val Acc: 0.3780, Test Acc: 0.3777\n",
            "Seed: 43, Epoch: 091, Loss: 1.6872, Val Acc: 0.3685, Test Acc: 0.3890\n",
            "Seed: 43, Epoch: 092, Loss: 1.6787, Val Acc: 0.3685, Test Acc: 0.3751\n",
            "Seed: 43, Epoch: 093, Loss: 1.6755, Val Acc: 0.3711, Test Acc: 0.3838\n",
            "Seed: 43, Epoch: 094, Loss: 1.6704, Val Acc: 0.3902, Test Acc: 0.3916\n",
            "Seed: 43, Epoch: 095, Loss: 1.6660, Val Acc: 0.3720, Test Acc: 0.3786\n",
            "Seed: 43, Epoch: 096, Loss: 1.6636, Val Acc: 0.3754, Test Acc: 0.3908\n",
            "Seed: 43, Epoch: 097, Loss: 1.6560, Val Acc: 0.3990, Test Acc: 0.4003\n",
            "Seed: 43, Epoch: 098, Loss: 1.6529, Val Acc: 0.3894, Test Acc: 0.3760\n",
            "Seed: 43, Epoch: 099, Loss: 1.6556, Val Acc: 0.4042, Test Acc: 0.3986\n",
            "Seed: 43, Epoch: 100, Loss: 1.6475, Val Acc: 0.3990, Test Acc: 0.4056\n",
            "Seed: 43, Epoch: 101, Loss: 1.6427, Val Acc: 0.4033, Test Acc: 0.4108\n",
            "Seed: 43, Epoch: 102, Loss: 1.6377, Val Acc: 0.4007, Test Acc: 0.4030\n",
            "Seed: 43, Epoch: 103, Loss: 1.6371, Val Acc: 0.4024, Test Acc: 0.4038\n",
            "Seed: 43, Epoch: 104, Loss: 1.6301, Val Acc: 0.4138, Test Acc: 0.4169\n",
            "Seed: 43, Epoch: 105, Loss: 1.6286, Val Acc: 0.4051, Test Acc: 0.4073\n",
            "Seed: 43, Epoch: 106, Loss: 1.6227, Val Acc: 0.4129, Test Acc: 0.3977\n",
            "Seed: 43, Epoch: 107, Loss: 1.6192, Val Acc: 0.3946, Test Acc: 0.4021\n",
            "Seed: 43, Epoch: 108, Loss: 1.6139, Val Acc: 0.4181, Test Acc: 0.4047\n",
            "Seed: 43, Epoch: 109, Loss: 1.6114, Val Acc: 0.3885, Test Acc: 0.3864\n",
            "Seed: 43, Epoch: 110, Loss: 1.6446, Val Acc: 0.4016, Test Acc: 0.3890\n",
            "Seed: 43, Epoch: 111, Loss: 1.6473, Val Acc: 0.4225, Test Acc: 0.4134\n",
            "Seed: 43, Epoch: 112, Loss: 1.6402, Val Acc: 0.4216, Test Acc: 0.3943\n",
            "Seed: 43, Epoch: 113, Loss: 1.6244, Val Acc: 0.4181, Test Acc: 0.4021\n",
            "Seed: 43, Epoch: 114, Loss: 1.6140, Val Acc: 0.4312, Test Acc: 0.4265\n",
            "Seed: 43, Epoch: 115, Loss: 1.6180, Val Acc: 0.4233, Test Acc: 0.3995\n",
            "Seed: 43, Epoch: 116, Loss: 1.6138, Val Acc: 0.4111, Test Acc: 0.4012\n",
            "Seed: 43, Epoch: 117, Loss: 1.6053, Val Acc: 0.4294, Test Acc: 0.4230\n",
            "Seed: 43, Epoch: 118, Loss: 1.5990, Val Acc: 0.4373, Test Acc: 0.4230\n",
            "Seed: 43, Epoch: 119, Loss: 1.5919, Val Acc: 0.4434, Test Acc: 0.4282\n",
            "Seed: 43, Epoch: 120, Loss: 1.5912, Val Acc: 0.4390, Test Acc: 0.4369\n",
            "Seed: 43, Epoch: 121, Loss: 1.5861, Val Acc: 0.4503, Test Acc: 0.4395\n",
            "Seed: 43, Epoch: 122, Loss: 1.5819, Val Acc: 0.4434, Test Acc: 0.4308\n",
            "Seed: 43, Epoch: 123, Loss: 1.5804, Val Acc: 0.4408, Test Acc: 0.4299\n",
            "Seed: 43, Epoch: 124, Loss: 1.5794, Val Acc: 0.4373, Test Acc: 0.4343\n",
            "Seed: 43, Epoch: 125, Loss: 1.5753, Val Acc: 0.4408, Test Acc: 0.4334\n",
            "Seed: 43, Epoch: 126, Loss: 1.5701, Val Acc: 0.4512, Test Acc: 0.4386\n",
            "Seed: 43, Epoch: 127, Loss: 1.5654, Val Acc: 0.4538, Test Acc: 0.4413\n",
            "Seed: 43, Epoch: 128, Loss: 1.5614, Val Acc: 0.4486, Test Acc: 0.4421\n",
            "Seed: 43, Epoch: 129, Loss: 1.5606, Val Acc: 0.4521, Test Acc: 0.4369\n",
            "Seed: 43, Epoch: 130, Loss: 1.5753, Val Acc: 0.4373, Test Acc: 0.4421\n",
            "Seed: 43, Epoch: 131, Loss: 1.5576, Val Acc: 0.4425, Test Acc: 0.4352\n",
            "Seed: 43, Epoch: 132, Loss: 1.5550, Val Acc: 0.4425, Test Acc: 0.4247\n",
            "Seed: 43, Epoch: 133, Loss: 1.5502, Val Acc: 0.4564, Test Acc: 0.4386\n",
            "Seed: 43, Epoch: 134, Loss: 1.5482, Val Acc: 0.4512, Test Acc: 0.4386\n",
            "Seed: 43, Epoch: 135, Loss: 1.5428, Val Acc: 0.4556, Test Acc: 0.4543\n",
            "Seed: 43, Epoch: 136, Loss: 1.5425, Val Acc: 0.4521, Test Acc: 0.4421\n",
            "Seed: 43, Epoch: 137, Loss: 1.5366, Val Acc: 0.4591, Test Acc: 0.4500\n",
            "Seed: 43, Epoch: 138, Loss: 1.5319, Val Acc: 0.4599, Test Acc: 0.4473\n",
            "Seed: 43, Epoch: 139, Loss: 1.5313, Val Acc: 0.4634, Test Acc: 0.4508\n",
            "Seed: 43, Epoch: 140, Loss: 1.5250, Val Acc: 0.4608, Test Acc: 0.4430\n",
            "Seed: 43, Epoch: 141, Loss: 1.5251, Val Acc: 0.4686, Test Acc: 0.4439\n",
            "Seed: 43, Epoch: 142, Loss: 1.5220, Val Acc: 0.4678, Test Acc: 0.4430\n",
            "Seed: 43, Epoch: 143, Loss: 1.5208, Val Acc: 0.4669, Test Acc: 0.4543\n",
            "Seed: 43, Epoch: 144, Loss: 1.5167, Val Acc: 0.4599, Test Acc: 0.4447\n",
            "Seed: 43, Epoch: 145, Loss: 1.5094, Val Acc: 0.4564, Test Acc: 0.4465\n",
            "Seed: 43, Epoch: 146, Loss: 1.5098, Val Acc: 0.4538, Test Acc: 0.4543\n",
            "Seed: 43, Epoch: 147, Loss: 1.5103, Val Acc: 0.4721, Test Acc: 0.4526\n",
            "Seed: 43, Epoch: 148, Loss: 1.5082, Val Acc: 0.4669, Test Acc: 0.4465\n",
            "Seed: 43, Epoch: 149, Loss: 1.5020, Val Acc: 0.4591, Test Acc: 0.4526\n",
            "Seed: 43, Epoch: 150, Loss: 1.5009, Val Acc: 0.4556, Test Acc: 0.4491\n",
            "Seed: 43, Epoch: 151, Loss: 1.4964, Val Acc: 0.4643, Test Acc: 0.4613\n",
            "Seed: 43, Epoch: 152, Loss: 1.4968, Val Acc: 0.4713, Test Acc: 0.4491\n",
            "Seed: 43, Epoch: 153, Loss: 1.4946, Val Acc: 0.4730, Test Acc: 0.4430\n",
            "Seed: 43, Epoch: 154, Loss: 1.4936, Val Acc: 0.4530, Test Acc: 0.4360\n",
            "Seed: 43, Epoch: 155, Loss: 1.4969, Val Acc: 0.4704, Test Acc: 0.4317\n",
            "Seed: 43, Epoch: 156, Loss: 1.4997, Val Acc: 0.4643, Test Acc: 0.4491\n",
            "Seed: 43, Epoch: 157, Loss: 1.4878, Val Acc: 0.4869, Test Acc: 0.4560\n",
            "Seed: 43, Epoch: 158, Loss: 1.4924, Val Acc: 0.4686, Test Acc: 0.4491\n",
            "Seed: 43, Epoch: 159, Loss: 1.4838, Val Acc: 0.4739, Test Acc: 0.4543\n",
            "Seed: 43, Epoch: 160, Loss: 1.4800, Val Acc: 0.4660, Test Acc: 0.4621\n",
            "Seed: 43, Epoch: 161, Loss: 1.4743, Val Acc: 0.4774, Test Acc: 0.4613\n",
            "Seed: 43, Epoch: 162, Loss: 1.4752, Val Acc: 0.4669, Test Acc: 0.4517\n",
            "Seed: 43, Epoch: 163, Loss: 1.4722, Val Acc: 0.4782, Test Acc: 0.4578\n",
            "Seed: 43, Epoch: 164, Loss: 1.4690, Val Acc: 0.4713, Test Acc: 0.4491\n",
            "Seed: 43, Epoch: 165, Loss: 1.4687, Val Acc: 0.4747, Test Acc: 0.4465\n",
            "Seed: 43, Epoch: 166, Loss: 1.4754, Val Acc: 0.4547, Test Acc: 0.4578\n",
            "Seed: 43, Epoch: 167, Loss: 1.4639, Val Acc: 0.4887, Test Acc: 0.4517\n",
            "Seed: 43, Epoch: 168, Loss: 1.4696, Val Acc: 0.4608, Test Acc: 0.4473\n",
            "Seed: 43, Epoch: 169, Loss: 1.4649, Val Acc: 0.4747, Test Acc: 0.4500\n",
            "Seed: 43, Epoch: 170, Loss: 1.4732, Val Acc: 0.4686, Test Acc: 0.4552\n",
            "Seed: 43, Epoch: 171, Loss: 1.4670, Val Acc: 0.4695, Test Acc: 0.4508\n",
            "Seed: 43, Epoch: 172, Loss: 1.4779, Val Acc: 0.4512, Test Acc: 0.4500\n",
            "Seed: 43, Epoch: 173, Loss: 1.4657, Val Acc: 0.4660, Test Acc: 0.4465\n",
            "Seed: 43, Epoch: 174, Loss: 1.4577, Val Acc: 0.4730, Test Acc: 0.4552\n",
            "Seed: 43, Epoch: 175, Loss: 1.4598, Val Acc: 0.4686, Test Acc: 0.4648\n",
            "Seed: 43, Epoch: 176, Loss: 1.4565, Val Acc: 0.4739, Test Acc: 0.4743\n",
            "Seed: 43, Epoch: 177, Loss: 1.4525, Val Acc: 0.4704, Test Acc: 0.4534\n",
            "Seed: 43, Epoch: 178, Loss: 1.4437, Val Acc: 0.4782, Test Acc: 0.4543\n",
            "Seed: 43, Epoch: 179, Loss: 1.4415, Val Acc: 0.4843, Test Acc: 0.4639\n",
            "Seed: 43, Epoch: 180, Loss: 1.4407, Val Acc: 0.4765, Test Acc: 0.4769\n",
            "Seed: 43, Epoch: 181, Loss: 1.4419, Val Acc: 0.4800, Test Acc: 0.4595\n",
            "Seed: 43, Epoch: 182, Loss: 1.4462, Val Acc: 0.4739, Test Acc: 0.4648\n",
            "Seed: 43, Epoch: 183, Loss: 1.4351, Val Acc: 0.4756, Test Acc: 0.4595\n",
            "Seed: 43, Epoch: 184, Loss: 1.4332, Val Acc: 0.4713, Test Acc: 0.4526\n",
            "Seed: 43, Epoch: 185, Loss: 1.4315, Val Acc: 0.4826, Test Acc: 0.4752\n",
            "Seed: 43, Epoch: 186, Loss: 1.4292, Val Acc: 0.4756, Test Acc: 0.4691\n",
            "Seed: 43, Epoch: 187, Loss: 1.4295, Val Acc: 0.4721, Test Acc: 0.4708\n",
            "Seed: 43, Epoch: 188, Loss: 1.4259, Val Acc: 0.4678, Test Acc: 0.4743\n",
            "Seed: 43, Epoch: 189, Loss: 1.4238, Val Acc: 0.4808, Test Acc: 0.4648\n",
            "Seed: 43, Epoch: 190, Loss: 1.4216, Val Acc: 0.4713, Test Acc: 0.4621\n",
            "Seed: 43, Epoch: 191, Loss: 1.4243, Val Acc: 0.4730, Test Acc: 0.4674\n",
            "Seed: 43, Epoch: 192, Loss: 1.4173, Val Acc: 0.4713, Test Acc: 0.4761\n",
            "Seed: 43, Epoch: 193, Loss: 1.4154, Val Acc: 0.4800, Test Acc: 0.4726\n",
            "Seed: 43, Epoch: 194, Loss: 1.4139, Val Acc: 0.4739, Test Acc: 0.4708\n",
            "Seed: 43, Epoch: 195, Loss: 1.4144, Val Acc: 0.4756, Test Acc: 0.4900\n",
            "Seed: 43, Epoch: 196, Loss: 1.4090, Val Acc: 0.4730, Test Acc: 0.4769\n",
            "Seed: 43, Epoch: 197, Loss: 1.4103, Val Acc: 0.4721, Test Acc: 0.4813\n",
            "Seed: 43, Epoch: 198, Loss: 1.4054, Val Acc: 0.4765, Test Acc: 0.4717\n",
            "Seed: 43, Epoch: 199, Loss: 1.4053, Val Acc: 0.4713, Test Acc: 0.4708\n",
            "Seed: 43, Epoch: 200, Loss: 1.4029, Val Acc: 0.4660, Test Acc: 0.4795\n",
            "Seed: 44, Epoch: 001, Loss: 2.4027, Val Acc: 0.1124, Test Acc: 0.1062\n",
            "Seed: 44, Epoch: 002, Loss: 2.4019, Val Acc: 0.1124, Test Acc: 0.1062\n",
            "Seed: 44, Epoch: 003, Loss: 2.4013, Val Acc: 0.1124, Test Acc: 0.1062\n",
            "Seed: 44, Epoch: 004, Loss: 2.4006, Val Acc: 0.1124, Test Acc: 0.1062\n",
            "Seed: 44, Epoch: 005, Loss: 2.3999, Val Acc: 0.1124, Test Acc: 0.1062\n",
            "Seed: 44, Epoch: 006, Loss: 2.3992, Val Acc: 0.1124, Test Acc: 0.1062\n",
            "Seed: 44, Epoch: 007, Loss: 2.3982, Val Acc: 0.1124, Test Acc: 0.1062\n",
            "Seed: 44, Epoch: 008, Loss: 2.3971, Val Acc: 0.1124, Test Acc: 0.1062\n",
            "Seed: 44, Epoch: 009, Loss: 2.3958, Val Acc: 0.1167, Test Acc: 0.1053\n",
            "Seed: 44, Epoch: 010, Loss: 2.3939, Val Acc: 0.1141, Test Acc: 0.1097\n",
            "Seed: 44, Epoch: 011, Loss: 2.3913, Val Acc: 0.1159, Test Acc: 0.1062\n",
            "Seed: 44, Epoch: 012, Loss: 2.3871, Val Acc: 0.1185, Test Acc: 0.1079\n",
            "Seed: 44, Epoch: 013, Loss: 2.3807, Val Acc: 0.1542, Test Acc: 0.1610\n",
            "Seed: 44, Epoch: 014, Loss: 2.3719, Val Acc: 0.1638, Test Acc: 0.1584\n",
            "Seed: 44, Epoch: 015, Loss: 2.3602, Val Acc: 0.1402, Test Acc: 0.1497\n",
            "Seed: 44, Epoch: 016, Loss: 2.3425, Val Acc: 0.1437, Test Acc: 0.1480\n",
            "Seed: 44, Epoch: 017, Loss: 2.3210, Val Acc: 0.1498, Test Acc: 0.1523\n",
            "Seed: 44, Epoch: 018, Loss: 2.2957, Val Acc: 0.1716, Test Acc: 0.1767\n",
            "Seed: 44, Epoch: 019, Loss: 2.2699, Val Acc: 0.1646, Test Acc: 0.1749\n",
            "Seed: 44, Epoch: 020, Loss: 2.2473, Val Acc: 0.1655, Test Acc: 0.1706\n",
            "Seed: 44, Epoch: 021, Loss: 2.2231, Val Acc: 0.1594, Test Acc: 0.1688\n",
            "Seed: 44, Epoch: 022, Loss: 2.2024, Val Acc: 0.1699, Test Acc: 0.1871\n",
            "Seed: 44, Epoch: 023, Loss: 2.1874, Val Acc: 0.1620, Test Acc: 0.1845\n",
            "Seed: 44, Epoch: 024, Loss: 2.1777, Val Acc: 0.1655, Test Acc: 0.1915\n",
            "Seed: 44, Epoch: 025, Loss: 2.1668, Val Acc: 0.1821, Test Acc: 0.2089\n",
            "Seed: 44, Epoch: 026, Loss: 2.1582, Val Acc: 0.1760, Test Acc: 0.2115\n",
            "Seed: 44, Epoch: 027, Loss: 2.1487, Val Acc: 0.1899, Test Acc: 0.2185\n",
            "Seed: 44, Epoch: 028, Loss: 2.1403, Val Acc: 0.1873, Test Acc: 0.2115\n",
            "Seed: 44, Epoch: 029, Loss: 2.1306, Val Acc: 0.1690, Test Acc: 0.2019\n",
            "Seed: 44, Epoch: 030, Loss: 2.1203, Val Acc: 0.1943, Test Acc: 0.2150\n",
            "Seed: 44, Epoch: 031, Loss: 2.1099, Val Acc: 0.1681, Test Acc: 0.2106\n",
            "Seed: 44, Epoch: 032, Loss: 2.0981, Val Acc: 0.1916, Test Acc: 0.2124\n",
            "Seed: 44, Epoch: 033, Loss: 2.0898, Val Acc: 0.2003, Test Acc: 0.2141\n",
            "Seed: 44, Epoch: 034, Loss: 2.0785, Val Acc: 0.2012, Test Acc: 0.2272\n",
            "Seed: 44, Epoch: 035, Loss: 2.0652, Val Acc: 0.2291, Test Acc: 0.2428\n",
            "Seed: 44, Epoch: 036, Loss: 2.0541, Val Acc: 0.2178, Test Acc: 0.2350\n",
            "Seed: 44, Epoch: 037, Loss: 2.0436, Val Acc: 0.2256, Test Acc: 0.2385\n",
            "Seed: 44, Epoch: 038, Loss: 2.0314, Val Acc: 0.2291, Test Acc: 0.2446\n",
            "Seed: 44, Epoch: 039, Loss: 2.0215, Val Acc: 0.2361, Test Acc: 0.2541\n",
            "Seed: 44, Epoch: 040, Loss: 2.0105, Val Acc: 0.2230, Test Acc: 0.2480\n",
            "Seed: 44, Epoch: 041, Loss: 1.9945, Val Acc: 0.2334, Test Acc: 0.2585\n",
            "Seed: 44, Epoch: 042, Loss: 1.9779, Val Acc: 0.2517, Test Acc: 0.2768\n",
            "Seed: 44, Epoch: 043, Loss: 1.9659, Val Acc: 0.2430, Test Acc: 0.2628\n",
            "Seed: 44, Epoch: 044, Loss: 1.9519, Val Acc: 0.2674, Test Acc: 0.2907\n",
            "Seed: 44, Epoch: 045, Loss: 1.9359, Val Acc: 0.2500, Test Acc: 0.2698\n",
            "Seed: 44, Epoch: 046, Loss: 1.9232, Val Acc: 0.2744, Test Acc: 0.3072\n",
            "Seed: 44, Epoch: 047, Loss: 1.9103, Val Acc: 0.2753, Test Acc: 0.2802\n",
            "Seed: 44, Epoch: 048, Loss: 1.8974, Val Acc: 0.2683, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 049, Loss: 1.8872, Val Acc: 0.2622, Test Acc: 0.2637\n",
            "Seed: 44, Epoch: 050, Loss: 1.8780, Val Acc: 0.2726, Test Acc: 0.2637\n",
            "Seed: 44, Epoch: 051, Loss: 1.8688, Val Acc: 0.2779, Test Acc: 0.2872\n",
            "Seed: 44, Epoch: 052, Loss: 1.8612, Val Acc: 0.2761, Test Acc: 0.2759\n",
            "Seed: 44, Epoch: 053, Loss: 1.8569, Val Acc: 0.3057, Test Acc: 0.2994\n",
            "Seed: 44, Epoch: 054, Loss: 1.8507, Val Acc: 0.2787, Test Acc: 0.2985\n",
            "Seed: 44, Epoch: 055, Loss: 1.8496, Val Acc: 0.3110, Test Acc: 0.3003\n",
            "Seed: 44, Epoch: 056, Loss: 1.8363, Val Acc: 0.3162, Test Acc: 0.3220\n",
            "Seed: 44, Epoch: 057, Loss: 1.8284, Val Acc: 0.3258, Test Acc: 0.3064\n",
            "Seed: 44, Epoch: 058, Loss: 1.8237, Val Acc: 0.3206, Test Acc: 0.3281\n",
            "Seed: 44, Epoch: 059, Loss: 1.8203, Val Acc: 0.3023, Test Acc: 0.3151\n",
            "Seed: 44, Epoch: 060, Loss: 1.8129, Val Acc: 0.3057, Test Acc: 0.3116\n",
            "Seed: 44, Epoch: 061, Loss: 1.8061, Val Acc: 0.3354, Test Acc: 0.3525\n",
            "Seed: 44, Epoch: 062, Loss: 1.8023, Val Acc: 0.3406, Test Acc: 0.3203\n",
            "Seed: 44, Epoch: 063, Loss: 1.7945, Val Acc: 0.3389, Test Acc: 0.3420\n",
            "Seed: 44, Epoch: 064, Loss: 1.7925, Val Acc: 0.3293, Test Acc: 0.3246\n",
            "Seed: 44, Epoch: 065, Loss: 1.7833, Val Acc: 0.3484, Test Acc: 0.3420\n",
            "Seed: 44, Epoch: 066, Loss: 1.7817, Val Acc: 0.3345, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 067, Loss: 1.7744, Val Acc: 0.3467, Test Acc: 0.3412\n",
            "Seed: 44, Epoch: 068, Loss: 1.7666, Val Acc: 0.3632, Test Acc: 0.3594\n",
            "Seed: 44, Epoch: 069, Loss: 1.7646, Val Acc: 0.3659, Test Acc: 0.3446\n",
            "Seed: 44, Epoch: 070, Loss: 1.7586, Val Acc: 0.3615, Test Acc: 0.3534\n",
            "Seed: 44, Epoch: 071, Loss: 1.7537, Val Acc: 0.3728, Test Acc: 0.3577\n",
            "Seed: 44, Epoch: 072, Loss: 1.7478, Val Acc: 0.3598, Test Acc: 0.3568\n",
            "Seed: 44, Epoch: 073, Loss: 1.7478, Val Acc: 0.3702, Test Acc: 0.3638\n",
            "Seed: 44, Epoch: 074, Loss: 1.7411, Val Acc: 0.3754, Test Acc: 0.3664\n",
            "Seed: 44, Epoch: 075, Loss: 1.7395, Val Acc: 0.3780, Test Acc: 0.3699\n",
            "Seed: 44, Epoch: 076, Loss: 1.7297, Val Acc: 0.3850, Test Acc: 0.3751\n",
            "Seed: 44, Epoch: 077, Loss: 1.7281, Val Acc: 0.3667, Test Acc: 0.3716\n",
            "Seed: 44, Epoch: 078, Loss: 1.7247, Val Acc: 0.3920, Test Acc: 0.3760\n",
            "Seed: 44, Epoch: 079, Loss: 1.7198, Val Acc: 0.3772, Test Acc: 0.3603\n",
            "Seed: 44, Epoch: 080, Loss: 1.7127, Val Acc: 0.3841, Test Acc: 0.3829\n",
            "Seed: 44, Epoch: 081, Loss: 1.7086, Val Acc: 0.3728, Test Acc: 0.3795\n",
            "Seed: 44, Epoch: 082, Loss: 1.7053, Val Acc: 0.3929, Test Acc: 0.3803\n",
            "Seed: 44, Epoch: 083, Loss: 1.7003, Val Acc: 0.3728, Test Acc: 0.3594\n",
            "Seed: 44, Epoch: 084, Loss: 1.6983, Val Acc: 0.4007, Test Acc: 0.3838\n",
            "Seed: 44, Epoch: 085, Loss: 1.6922, Val Acc: 0.3946, Test Acc: 0.3786\n",
            "Seed: 44, Epoch: 086, Loss: 1.6903, Val Acc: 0.3902, Test Acc: 0.3725\n",
            "Seed: 44, Epoch: 087, Loss: 1.6835, Val Acc: 0.3911, Test Acc: 0.3786\n",
            "Seed: 44, Epoch: 088, Loss: 1.6869, Val Acc: 0.3833, Test Acc: 0.3916\n",
            "Seed: 44, Epoch: 089, Loss: 1.6811, Val Acc: 0.3937, Test Acc: 0.3838\n",
            "Seed: 44, Epoch: 090, Loss: 1.6820, Val Acc: 0.3902, Test Acc: 0.3786\n",
            "Seed: 44, Epoch: 091, Loss: 1.6741, Val Acc: 0.3998, Test Acc: 0.3934\n",
            "Seed: 44, Epoch: 092, Loss: 1.6693, Val Acc: 0.4129, Test Acc: 0.4021\n",
            "Seed: 44, Epoch: 093, Loss: 1.6648, Val Acc: 0.4068, Test Acc: 0.4047\n",
            "Seed: 44, Epoch: 094, Loss: 1.6602, Val Acc: 0.3963, Test Acc: 0.3925\n",
            "Seed: 44, Epoch: 095, Loss: 1.6564, Val Acc: 0.4129, Test Acc: 0.4064\n",
            "Seed: 44, Epoch: 096, Loss: 1.6577, Val Acc: 0.3981, Test Acc: 0.4003\n",
            "Seed: 44, Epoch: 097, Loss: 1.6493, Val Acc: 0.4059, Test Acc: 0.3977\n",
            "Seed: 44, Epoch: 098, Loss: 1.6459, Val Acc: 0.4007, Test Acc: 0.4047\n",
            "Seed: 44, Epoch: 099, Loss: 1.6430, Val Acc: 0.4146, Test Acc: 0.4003\n",
            "Seed: 44, Epoch: 100, Loss: 1.6421, Val Acc: 0.4085, Test Acc: 0.4082\n",
            "Seed: 44, Epoch: 101, Loss: 1.6309, Val Acc: 0.4059, Test Acc: 0.4082\n",
            "Seed: 44, Epoch: 102, Loss: 1.6318, Val Acc: 0.4111, Test Acc: 0.4021\n",
            "Seed: 44, Epoch: 103, Loss: 1.6262, Val Acc: 0.4111, Test Acc: 0.4073\n",
            "Seed: 44, Epoch: 104, Loss: 1.6261, Val Acc: 0.4172, Test Acc: 0.4073\n",
            "Seed: 44, Epoch: 105, Loss: 1.6216, Val Acc: 0.4077, Test Acc: 0.4151\n",
            "Seed: 44, Epoch: 106, Loss: 1.6170, Val Acc: 0.4251, Test Acc: 0.4030\n",
            "Seed: 44, Epoch: 107, Loss: 1.6143, Val Acc: 0.4268, Test Acc: 0.4151\n",
            "Seed: 44, Epoch: 108, Loss: 1.6102, Val Acc: 0.4199, Test Acc: 0.4099\n",
            "Seed: 44, Epoch: 109, Loss: 1.6064, Val Acc: 0.4164, Test Acc: 0.4178\n",
            "Seed: 44, Epoch: 110, Loss: 1.6044, Val Acc: 0.4033, Test Acc: 0.4125\n",
            "Seed: 44, Epoch: 111, Loss: 1.6023, Val Acc: 0.4190, Test Acc: 0.4082\n",
            "Seed: 44, Epoch: 112, Loss: 1.5987, Val Acc: 0.4207, Test Acc: 0.4204\n",
            "Seed: 44, Epoch: 113, Loss: 1.5954, Val Acc: 0.4181, Test Acc: 0.4334\n",
            "Seed: 44, Epoch: 114, Loss: 1.5936, Val Acc: 0.4294, Test Acc: 0.4117\n",
            "Seed: 44, Epoch: 115, Loss: 1.5913, Val Acc: 0.4190, Test Acc: 0.4204\n",
            "Seed: 44, Epoch: 116, Loss: 1.5906, Val Acc: 0.4277, Test Acc: 0.4291\n",
            "Seed: 44, Epoch: 117, Loss: 1.5836, Val Acc: 0.4216, Test Acc: 0.4221\n",
            "Seed: 44, Epoch: 118, Loss: 1.5846, Val Acc: 0.4390, Test Acc: 0.4247\n",
            "Seed: 44, Epoch: 119, Loss: 1.5813, Val Acc: 0.4425, Test Acc: 0.4238\n",
            "Seed: 44, Epoch: 120, Loss: 1.5791, Val Acc: 0.4251, Test Acc: 0.4099\n",
            "Seed: 44, Epoch: 121, Loss: 1.5747, Val Acc: 0.4347, Test Acc: 0.4256\n",
            "Seed: 44, Epoch: 122, Loss: 1.5707, Val Acc: 0.4321, Test Acc: 0.4378\n",
            "Seed: 44, Epoch: 123, Loss: 1.5676, Val Acc: 0.4321, Test Acc: 0.4256\n",
            "Seed: 44, Epoch: 124, Loss: 1.5643, Val Acc: 0.4321, Test Acc: 0.4256\n",
            "Seed: 44, Epoch: 125, Loss: 1.5606, Val Acc: 0.4364, Test Acc: 0.4247\n",
            "Seed: 44, Epoch: 126, Loss: 1.5582, Val Acc: 0.4303, Test Acc: 0.4299\n",
            "Seed: 44, Epoch: 127, Loss: 1.5552, Val Acc: 0.4216, Test Acc: 0.4273\n",
            "Seed: 44, Epoch: 128, Loss: 1.5517, Val Acc: 0.4260, Test Acc: 0.4395\n",
            "Seed: 44, Epoch: 129, Loss: 1.5499, Val Acc: 0.4321, Test Acc: 0.4326\n",
            "Seed: 44, Epoch: 130, Loss: 1.5478, Val Acc: 0.4225, Test Acc: 0.4256\n",
            "Seed: 44, Epoch: 131, Loss: 1.5444, Val Acc: 0.4373, Test Acc: 0.4482\n",
            "Seed: 44, Epoch: 132, Loss: 1.5421, Val Acc: 0.4303, Test Acc: 0.4291\n",
            "Seed: 44, Epoch: 133, Loss: 1.5425, Val Acc: 0.4225, Test Acc: 0.4265\n",
            "Seed: 44, Epoch: 134, Loss: 1.5333, Val Acc: 0.4207, Test Acc: 0.4178\n",
            "Seed: 44, Epoch: 135, Loss: 1.5407, Val Acc: 0.4312, Test Acc: 0.4395\n",
            "Seed: 44, Epoch: 136, Loss: 1.5348, Val Acc: 0.4425, Test Acc: 0.4212\n",
            "Seed: 44, Epoch: 137, Loss: 1.5416, Val Acc: 0.4129, Test Acc: 0.4143\n",
            "Seed: 44, Epoch: 138, Loss: 1.5283, Val Acc: 0.4347, Test Acc: 0.4439\n",
            "Seed: 44, Epoch: 139, Loss: 1.5363, Val Acc: 0.4382, Test Acc: 0.4352\n",
            "Seed: 44, Epoch: 140, Loss: 1.5239, Val Acc: 0.3955, Test Acc: 0.4291\n",
            "Seed: 44, Epoch: 141, Loss: 1.5278, Val Acc: 0.4251, Test Acc: 0.4560\n",
            "Seed: 44, Epoch: 142, Loss: 1.5178, Val Acc: 0.4172, Test Acc: 0.4299\n",
            "Seed: 44, Epoch: 143, Loss: 1.5192, Val Acc: 0.4129, Test Acc: 0.4230\n",
            "Seed: 44, Epoch: 144, Loss: 1.5183, Val Acc: 0.4512, Test Acc: 0.4473\n",
            "Seed: 44, Epoch: 145, Loss: 1.5090, Val Acc: 0.4399, Test Acc: 0.4447\n",
            "Seed: 44, Epoch: 146, Loss: 1.5120, Val Acc: 0.4425, Test Acc: 0.4560\n",
            "Seed: 44, Epoch: 147, Loss: 1.5048, Val Acc: 0.4382, Test Acc: 0.4447\n",
            "Seed: 44, Epoch: 148, Loss: 1.5057, Val Acc: 0.4277, Test Acc: 0.4369\n",
            "Seed: 44, Epoch: 149, Loss: 1.5018, Val Acc: 0.4408, Test Acc: 0.4447\n",
            "Seed: 44, Epoch: 150, Loss: 1.5001, Val Acc: 0.4364, Test Acc: 0.4421\n",
            "Seed: 44, Epoch: 151, Loss: 1.4958, Val Acc: 0.4355, Test Acc: 0.4473\n",
            "Seed: 44, Epoch: 152, Loss: 1.4915, Val Acc: 0.4382, Test Acc: 0.4360\n",
            "Seed: 44, Epoch: 153, Loss: 1.4882, Val Acc: 0.4408, Test Acc: 0.4482\n",
            "Seed: 44, Epoch: 154, Loss: 1.4874, Val Acc: 0.4399, Test Acc: 0.4482\n",
            "Seed: 44, Epoch: 155, Loss: 1.4848, Val Acc: 0.4399, Test Acc: 0.4508\n",
            "Seed: 44, Epoch: 156, Loss: 1.4813, Val Acc: 0.4321, Test Acc: 0.4430\n",
            "Seed: 44, Epoch: 157, Loss: 1.4827, Val Acc: 0.4512, Test Acc: 0.4421\n",
            "Seed: 44, Epoch: 158, Loss: 1.4776, Val Acc: 0.4477, Test Acc: 0.4473\n",
            "Seed: 44, Epoch: 159, Loss: 1.4758, Val Acc: 0.4399, Test Acc: 0.4560\n",
            "Seed: 44, Epoch: 160, Loss: 1.4738, Val Acc: 0.4608, Test Acc: 0.4482\n",
            "Seed: 44, Epoch: 161, Loss: 1.4708, Val Acc: 0.4382, Test Acc: 0.4534\n",
            "Seed: 44, Epoch: 162, Loss: 1.4682, Val Acc: 0.4460, Test Acc: 0.4665\n",
            "Seed: 44, Epoch: 163, Loss: 1.4646, Val Acc: 0.4451, Test Acc: 0.4560\n",
            "Seed: 44, Epoch: 164, Loss: 1.4630, Val Acc: 0.4547, Test Acc: 0.4665\n",
            "Seed: 44, Epoch: 165, Loss: 1.4589, Val Acc: 0.4495, Test Acc: 0.4587\n",
            "Seed: 44, Epoch: 166, Loss: 1.4608, Val Acc: 0.4512, Test Acc: 0.4534\n",
            "Seed: 44, Epoch: 167, Loss: 1.4579, Val Acc: 0.4373, Test Acc: 0.4569\n",
            "Seed: 44, Epoch: 168, Loss: 1.4612, Val Acc: 0.4477, Test Acc: 0.4708\n",
            "Seed: 44, Epoch: 169, Loss: 1.4559, Val Acc: 0.4408, Test Acc: 0.4587\n",
            "Seed: 44, Epoch: 170, Loss: 1.4528, Val Acc: 0.4556, Test Acc: 0.4595\n",
            "Seed: 44, Epoch: 171, Loss: 1.4521, Val Acc: 0.4443, Test Acc: 0.4526\n",
            "Seed: 44, Epoch: 172, Loss: 1.4486, Val Acc: 0.4521, Test Acc: 0.4621\n",
            "Seed: 44, Epoch: 173, Loss: 1.4463, Val Acc: 0.4443, Test Acc: 0.4630\n",
            "Seed: 44, Epoch: 174, Loss: 1.4473, Val Acc: 0.4564, Test Acc: 0.4630\n",
            "Seed: 44, Epoch: 175, Loss: 1.4393, Val Acc: 0.4573, Test Acc: 0.4560\n",
            "Seed: 44, Epoch: 176, Loss: 1.4418, Val Acc: 0.4573, Test Acc: 0.4656\n",
            "Seed: 44, Epoch: 177, Loss: 1.4371, Val Acc: 0.4608, Test Acc: 0.4700\n",
            "Seed: 44, Epoch: 178, Loss: 1.4349, Val Acc: 0.4503, Test Acc: 0.4517\n",
            "Seed: 44, Epoch: 179, Loss: 1.4360, Val Acc: 0.4704, Test Acc: 0.4578\n",
            "Seed: 44, Epoch: 180, Loss: 1.4326, Val Acc: 0.4530, Test Acc: 0.4595\n",
            "Seed: 44, Epoch: 181, Loss: 1.4295, Val Acc: 0.4617, Test Acc: 0.4648\n",
            "Seed: 44, Epoch: 182, Loss: 1.4292, Val Acc: 0.4608, Test Acc: 0.4595\n",
            "Seed: 44, Epoch: 183, Loss: 1.4277, Val Acc: 0.4477, Test Acc: 0.4543\n",
            "Seed: 44, Epoch: 184, Loss: 1.4237, Val Acc: 0.4625, Test Acc: 0.4769\n",
            "Seed: 44, Epoch: 185, Loss: 1.4261, Val Acc: 0.4591, Test Acc: 0.4787\n",
            "Seed: 44, Epoch: 186, Loss: 1.4219, Val Acc: 0.4495, Test Acc: 0.4691\n",
            "Seed: 44, Epoch: 187, Loss: 1.4187, Val Acc: 0.4564, Test Acc: 0.4743\n",
            "Seed: 44, Epoch: 188, Loss: 1.4189, Val Acc: 0.4617, Test Acc: 0.4665\n",
            "Seed: 44, Epoch: 189, Loss: 1.4167, Val Acc: 0.4652, Test Acc: 0.4630\n",
            "Seed: 44, Epoch: 190, Loss: 1.4123, Val Acc: 0.4556, Test Acc: 0.4674\n",
            "Seed: 44, Epoch: 191, Loss: 1.4147, Val Acc: 0.4669, Test Acc: 0.4865\n",
            "Seed: 44, Epoch: 192, Loss: 1.4084, Val Acc: 0.4721, Test Acc: 0.4787\n",
            "Seed: 44, Epoch: 193, Loss: 1.4131, Val Acc: 0.4564, Test Acc: 0.4665\n",
            "Seed: 44, Epoch: 194, Loss: 1.4070, Val Acc: 0.4643, Test Acc: 0.4743\n",
            "Seed: 44, Epoch: 195, Loss: 1.4043, Val Acc: 0.4608, Test Acc: 0.4665\n",
            "Seed: 44, Epoch: 196, Loss: 1.4036, Val Acc: 0.4512, Test Acc: 0.4578\n",
            "Seed: 44, Epoch: 197, Loss: 1.4050, Val Acc: 0.4599, Test Acc: 0.4665\n",
            "Seed: 44, Epoch: 198, Loss: 1.3995, Val Acc: 0.4573, Test Acc: 0.4761\n",
            "Seed: 44, Epoch: 199, Loss: 1.3981, Val Acc: 0.4591, Test Acc: 0.4761\n",
            "Seed: 44, Epoch: 200, Loss: 1.3963, Val Acc: 0.4591, Test Acc: 0.4761\n",
            "Seed: 45, Epoch: 001, Loss: 2.4008, Val Acc: 0.0949, Test Acc: 0.0766\n",
            "Seed: 45, Epoch: 002, Loss: 2.3994, Val Acc: 0.0949, Test Acc: 0.0766\n",
            "Seed: 45, Epoch: 003, Loss: 2.3980, Val Acc: 0.0949, Test Acc: 0.0766\n",
            "Seed: 45, Epoch: 004, Loss: 2.3966, Val Acc: 0.0949, Test Acc: 0.0766\n",
            "Seed: 45, Epoch: 005, Loss: 2.3951, Val Acc: 0.0941, Test Acc: 0.0757\n",
            "Seed: 45, Epoch: 006, Loss: 2.3931, Val Acc: 0.0897, Test Acc: 0.0792\n",
            "Seed: 45, Epoch: 007, Loss: 2.3905, Val Acc: 0.1063, Test Acc: 0.1036\n",
            "Seed: 45, Epoch: 008, Loss: 2.3869, Val Acc: 0.1150, Test Acc: 0.1062\n",
            "Seed: 45, Epoch: 009, Loss: 2.3825, Val Acc: 0.1533, Test Acc: 0.1471\n",
            "Seed: 45, Epoch: 010, Loss: 2.3766, Val Acc: 0.1733, Test Acc: 0.1732\n",
            "Seed: 45, Epoch: 011, Loss: 2.3688, Val Acc: 0.1733, Test Acc: 0.1732\n",
            "Seed: 45, Epoch: 012, Loss: 2.3582, Val Acc: 0.1751, Test Acc: 0.1732\n",
            "Seed: 45, Epoch: 013, Loss: 2.3431, Val Acc: 0.1908, Test Acc: 0.1767\n",
            "Seed: 45, Epoch: 014, Loss: 2.3228, Val Acc: 0.2134, Test Acc: 0.1880\n",
            "Seed: 45, Epoch: 015, Loss: 2.2977, Val Acc: 0.2134, Test Acc: 0.1984\n",
            "Seed: 45, Epoch: 016, Loss: 2.2684, Val Acc: 0.2352, Test Acc: 0.2254\n",
            "Seed: 45, Epoch: 017, Loss: 2.2399, Val Acc: 0.2395, Test Acc: 0.2472\n",
            "Seed: 45, Epoch: 018, Loss: 2.2145, Val Acc: 0.2152, Test Acc: 0.2167\n",
            "Seed: 45, Epoch: 019, Loss: 2.1949, Val Acc: 0.1969, Test Acc: 0.2071\n",
            "Seed: 45, Epoch: 020, Loss: 2.1754, Val Acc: 0.1882, Test Acc: 0.2002\n",
            "Seed: 45, Epoch: 021, Loss: 2.1546, Val Acc: 0.2030, Test Acc: 0.2037\n",
            "Seed: 45, Epoch: 022, Loss: 2.1361, Val Acc: 0.2125, Test Acc: 0.2071\n",
            "Seed: 45, Epoch: 023, Loss: 2.1173, Val Acc: 0.2073, Test Acc: 0.2150\n",
            "Seed: 45, Epoch: 024, Loss: 2.1055, Val Acc: 0.2108, Test Acc: 0.2263\n",
            "Seed: 45, Epoch: 025, Loss: 2.0904, Val Acc: 0.2108, Test Acc: 0.2219\n",
            "Seed: 45, Epoch: 026, Loss: 2.0774, Val Acc: 0.2186, Test Acc: 0.2185\n",
            "Seed: 45, Epoch: 027, Loss: 2.0644, Val Acc: 0.2195, Test Acc: 0.2254\n",
            "Seed: 45, Epoch: 028, Loss: 2.0533, Val Acc: 0.2195, Test Acc: 0.2254\n",
            "Seed: 45, Epoch: 029, Loss: 2.0448, Val Acc: 0.2213, Test Acc: 0.2280\n",
            "Seed: 45, Epoch: 030, Loss: 2.0358, Val Acc: 0.2317, Test Acc: 0.2298\n",
            "Seed: 45, Epoch: 031, Loss: 2.0261, Val Acc: 0.2282, Test Acc: 0.2298\n",
            "Seed: 45, Epoch: 032, Loss: 2.0195, Val Acc: 0.2378, Test Acc: 0.2315\n",
            "Seed: 45, Epoch: 033, Loss: 2.0142, Val Acc: 0.2317, Test Acc: 0.2515\n",
            "Seed: 45, Epoch: 034, Loss: 2.0055, Val Acc: 0.2247, Test Acc: 0.2463\n",
            "Seed: 45, Epoch: 035, Loss: 1.9983, Val Acc: 0.2456, Test Acc: 0.2472\n",
            "Seed: 45, Epoch: 036, Loss: 1.9913, Val Acc: 0.2465, Test Acc: 0.2507\n",
            "Seed: 45, Epoch: 037, Loss: 1.9848, Val Acc: 0.2404, Test Acc: 0.2585\n",
            "Seed: 45, Epoch: 038, Loss: 1.9738, Val Acc: 0.2430, Test Acc: 0.2672\n",
            "Seed: 45, Epoch: 039, Loss: 1.9695, Val Acc: 0.2605, Test Acc: 0.2585\n",
            "Seed: 45, Epoch: 040, Loss: 1.9613, Val Acc: 0.2535, Test Acc: 0.2567\n",
            "Seed: 45, Epoch: 041, Loss: 1.9540, Val Acc: 0.2639, Test Acc: 0.2724\n",
            "Seed: 45, Epoch: 042, Loss: 1.9496, Val Acc: 0.2631, Test Acc: 0.2750\n",
            "Seed: 45, Epoch: 043, Loss: 1.9433, Val Acc: 0.2700, Test Acc: 0.2698\n",
            "Seed: 45, Epoch: 044, Loss: 1.9365, Val Acc: 0.2700, Test Acc: 0.2776\n",
            "Seed: 45, Epoch: 045, Loss: 1.9350, Val Acc: 0.2639, Test Acc: 0.2750\n",
            "Seed: 45, Epoch: 046, Loss: 1.9305, Val Acc: 0.2622, Test Acc: 0.2733\n",
            "Seed: 45, Epoch: 047, Loss: 1.9318, Val Acc: 0.2692, Test Acc: 0.2855\n",
            "Seed: 45, Epoch: 048, Loss: 1.9193, Val Acc: 0.2779, Test Acc: 0.2872\n",
            "Seed: 45, Epoch: 049, Loss: 1.9112, Val Acc: 0.2718, Test Acc: 0.2829\n",
            "Seed: 45, Epoch: 050, Loss: 1.9039, Val Acc: 0.2718, Test Acc: 0.2820\n",
            "Seed: 45, Epoch: 051, Loss: 1.8997, Val Acc: 0.2770, Test Acc: 0.2907\n",
            "Seed: 45, Epoch: 052, Loss: 1.9003, Val Acc: 0.2857, Test Acc: 0.2916\n",
            "Seed: 45, Epoch: 053, Loss: 1.8922, Val Acc: 0.2875, Test Acc: 0.2950\n",
            "Seed: 45, Epoch: 054, Loss: 1.8871, Val Acc: 0.2918, Test Acc: 0.3029\n",
            "Seed: 45, Epoch: 055, Loss: 1.8828, Val Acc: 0.2770, Test Acc: 0.2985\n",
            "Seed: 45, Epoch: 056, Loss: 1.8777, Val Acc: 0.2848, Test Acc: 0.3029\n",
            "Seed: 45, Epoch: 057, Loss: 1.8767, Val Acc: 0.2857, Test Acc: 0.3046\n",
            "Seed: 45, Epoch: 058, Loss: 1.8720, Val Acc: 0.2988, Test Acc: 0.2950\n",
            "Seed: 45, Epoch: 059, Loss: 1.8678, Val Acc: 0.2970, Test Acc: 0.2994\n",
            "Seed: 45, Epoch: 060, Loss: 1.8646, Val Acc: 0.3057, Test Acc: 0.3037\n",
            "Seed: 45, Epoch: 061, Loss: 1.8559, Val Acc: 0.3005, Test Acc: 0.3133\n",
            "Seed: 45, Epoch: 062, Loss: 1.8508, Val Acc: 0.3005, Test Acc: 0.3055\n",
            "Seed: 45, Epoch: 063, Loss: 1.8455, Val Acc: 0.3092, Test Acc: 0.2872\n",
            "Seed: 45, Epoch: 064, Loss: 1.8436, Val Acc: 0.3057, Test Acc: 0.3029\n",
            "Seed: 45, Epoch: 065, Loss: 1.8396, Val Acc: 0.3223, Test Acc: 0.3159\n",
            "Seed: 45, Epoch: 066, Loss: 1.8353, Val Acc: 0.3267, Test Acc: 0.3177\n",
            "Seed: 45, Epoch: 067, Loss: 1.8350, Val Acc: 0.3197, Test Acc: 0.3238\n",
            "Seed: 45, Epoch: 068, Loss: 1.8368, Val Acc: 0.3145, Test Acc: 0.3168\n",
            "Seed: 45, Epoch: 069, Loss: 1.8395, Val Acc: 0.3145, Test Acc: 0.3255\n",
            "Seed: 45, Epoch: 070, Loss: 1.8321, Val Acc: 0.3136, Test Acc: 0.3342\n",
            "Seed: 45, Epoch: 071, Loss: 1.8264, Val Acc: 0.3223, Test Acc: 0.3264\n",
            "Seed: 45, Epoch: 072, Loss: 1.8202, Val Acc: 0.3162, Test Acc: 0.3151\n",
            "Seed: 45, Epoch: 073, Loss: 1.8262, Val Acc: 0.3214, Test Acc: 0.3264\n",
            "Seed: 45, Epoch: 074, Loss: 1.8100, Val Acc: 0.3258, Test Acc: 0.3299\n",
            "Seed: 45, Epoch: 075, Loss: 1.8087, Val Acc: 0.3240, Test Acc: 0.3377\n",
            "Seed: 45, Epoch: 076, Loss: 1.8048, Val Acc: 0.3240, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 077, Loss: 1.7968, Val Acc: 0.3301, Test Acc: 0.3290\n",
            "Seed: 45, Epoch: 078, Loss: 1.7886, Val Acc: 0.3336, Test Acc: 0.3272\n",
            "Seed: 45, Epoch: 079, Loss: 1.7840, Val Acc: 0.3441, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 080, Loss: 1.7733, Val Acc: 0.3354, Test Acc: 0.3377\n",
            "Seed: 45, Epoch: 081, Loss: 1.7681, Val Acc: 0.3336, Test Acc: 0.3577\n",
            "Seed: 45, Epoch: 082, Loss: 1.7599, Val Acc: 0.3528, Test Acc: 0.3429\n",
            "Seed: 45, Epoch: 083, Loss: 1.7511, Val Acc: 0.3502, Test Acc: 0.3420\n",
            "Seed: 45, Epoch: 084, Loss: 1.7484, Val Acc: 0.3423, Test Acc: 0.3377\n",
            "Seed: 45, Epoch: 085, Loss: 1.7505, Val Acc: 0.3467, Test Acc: 0.3603\n",
            "Seed: 45, Epoch: 086, Loss: 1.7386, Val Acc: 0.3476, Test Acc: 0.3473\n",
            "Seed: 45, Epoch: 087, Loss: 1.7330, Val Acc: 0.3528, Test Acc: 0.3473\n",
            "Seed: 45, Epoch: 088, Loss: 1.7293, Val Acc: 0.3537, Test Acc: 0.3621\n",
            "Seed: 45, Epoch: 089, Loss: 1.7265, Val Acc: 0.3467, Test Acc: 0.3490\n",
            "Seed: 45, Epoch: 090, Loss: 1.7265, Val Acc: 0.3458, Test Acc: 0.3516\n",
            "Seed: 45, Epoch: 091, Loss: 1.7181, Val Acc: 0.3389, Test Acc: 0.3429\n",
            "Seed: 45, Epoch: 092, Loss: 1.7132, Val Acc: 0.3484, Test Acc: 0.3507\n",
            "Seed: 45, Epoch: 093, Loss: 1.7134, Val Acc: 0.3432, Test Acc: 0.3446\n",
            "Seed: 45, Epoch: 094, Loss: 1.7033, Val Acc: 0.3449, Test Acc: 0.3542\n",
            "Seed: 45, Epoch: 095, Loss: 1.6985, Val Acc: 0.3502, Test Acc: 0.3368\n",
            "Seed: 45, Epoch: 096, Loss: 1.6925, Val Acc: 0.3615, Test Acc: 0.3516\n",
            "Seed: 45, Epoch: 097, Loss: 1.6928, Val Acc: 0.3380, Test Acc: 0.3386\n",
            "Seed: 45, Epoch: 098, Loss: 1.6908, Val Acc: 0.3423, Test Acc: 0.3577\n",
            "Seed: 45, Epoch: 099, Loss: 1.6931, Val Acc: 0.3510, Test Acc: 0.3420\n",
            "Seed: 45, Epoch: 100, Loss: 1.6792, Val Acc: 0.3476, Test Acc: 0.3534\n",
            "Seed: 45, Epoch: 101, Loss: 1.6823, Val Acc: 0.3545, Test Acc: 0.3629\n",
            "Seed: 45, Epoch: 102, Loss: 1.6734, Val Acc: 0.3510, Test Acc: 0.3499\n",
            "Seed: 45, Epoch: 103, Loss: 1.6680, Val Acc: 0.3519, Test Acc: 0.3751\n",
            "Seed: 45, Epoch: 104, Loss: 1.6650, Val Acc: 0.3519, Test Acc: 0.3655\n",
            "Seed: 45, Epoch: 105, Loss: 1.6624, Val Acc: 0.3598, Test Acc: 0.3681\n",
            "Seed: 45, Epoch: 106, Loss: 1.6587, Val Acc: 0.3554, Test Acc: 0.3690\n",
            "Seed: 45, Epoch: 107, Loss: 1.6594, Val Acc: 0.3537, Test Acc: 0.3760\n",
            "Seed: 45, Epoch: 108, Loss: 1.6601, Val Acc: 0.3598, Test Acc: 0.3655\n",
            "Seed: 45, Epoch: 109, Loss: 1.6481, Val Acc: 0.3615, Test Acc: 0.3612\n",
            "Seed: 45, Epoch: 110, Loss: 1.6417, Val Acc: 0.3676, Test Acc: 0.3725\n",
            "Seed: 45, Epoch: 111, Loss: 1.6378, Val Acc: 0.3685, Test Acc: 0.3812\n",
            "Seed: 45, Epoch: 112, Loss: 1.6348, Val Acc: 0.3711, Test Acc: 0.3647\n",
            "Seed: 45, Epoch: 113, Loss: 1.6301, Val Acc: 0.3746, Test Acc: 0.3655\n",
            "Seed: 45, Epoch: 114, Loss: 1.6275, Val Acc: 0.3554, Test Acc: 0.3734\n",
            "Seed: 45, Epoch: 115, Loss: 1.6227, Val Acc: 0.3789, Test Acc: 0.3838\n",
            "Seed: 45, Epoch: 116, Loss: 1.6172, Val Acc: 0.3728, Test Acc: 0.3690\n",
            "Seed: 45, Epoch: 117, Loss: 1.6139, Val Acc: 0.3624, Test Acc: 0.3829\n",
            "Seed: 45, Epoch: 118, Loss: 1.6145, Val Acc: 0.3728, Test Acc: 0.3899\n",
            "Seed: 45, Epoch: 119, Loss: 1.6121, Val Acc: 0.3702, Test Acc: 0.3829\n",
            "Seed: 45, Epoch: 120, Loss: 1.6075, Val Acc: 0.3754, Test Acc: 0.3873\n",
            "Seed: 45, Epoch: 121, Loss: 1.6057, Val Acc: 0.3624, Test Acc: 0.3890\n",
            "Seed: 45, Epoch: 122, Loss: 1.6027, Val Acc: 0.3737, Test Acc: 0.3899\n",
            "Seed: 45, Epoch: 123, Loss: 1.5958, Val Acc: 0.3545, Test Acc: 0.3890\n",
            "Seed: 45, Epoch: 124, Loss: 1.5903, Val Acc: 0.3659, Test Acc: 0.3856\n",
            "Seed: 45, Epoch: 125, Loss: 1.5872, Val Acc: 0.3807, Test Acc: 0.3934\n",
            "Seed: 45, Epoch: 126, Loss: 1.5853, Val Acc: 0.3720, Test Acc: 0.3977\n",
            "Seed: 45, Epoch: 127, Loss: 1.5798, Val Acc: 0.3720, Test Acc: 0.4012\n",
            "Seed: 45, Epoch: 128, Loss: 1.5801, Val Acc: 0.3650, Test Acc: 0.3856\n",
            "Seed: 45, Epoch: 129, Loss: 1.5778, Val Acc: 0.3798, Test Acc: 0.4003\n",
            "Seed: 45, Epoch: 130, Loss: 1.5700, Val Acc: 0.3659, Test Acc: 0.3977\n",
            "Seed: 45, Epoch: 131, Loss: 1.5651, Val Acc: 0.3615, Test Acc: 0.3916\n",
            "Seed: 45, Epoch: 132, Loss: 1.5640, Val Acc: 0.3702, Test Acc: 0.3995\n",
            "Seed: 45, Epoch: 133, Loss: 1.5624, Val Acc: 0.3850, Test Acc: 0.4091\n",
            "Seed: 45, Epoch: 134, Loss: 1.5590, Val Acc: 0.3798, Test Acc: 0.4117\n",
            "Seed: 45, Epoch: 135, Loss: 1.5528, Val Acc: 0.3815, Test Acc: 0.4212\n",
            "Seed: 45, Epoch: 136, Loss: 1.5517, Val Acc: 0.3789, Test Acc: 0.4186\n",
            "Seed: 45, Epoch: 137, Loss: 1.5485, Val Acc: 0.3815, Test Acc: 0.4143\n",
            "Seed: 45, Epoch: 138, Loss: 1.5430, Val Acc: 0.3876, Test Acc: 0.4143\n",
            "Seed: 45, Epoch: 139, Loss: 1.5428, Val Acc: 0.3929, Test Acc: 0.4021\n",
            "Seed: 45, Epoch: 140, Loss: 1.5386, Val Acc: 0.3902, Test Acc: 0.4082\n",
            "Seed: 45, Epoch: 141, Loss: 1.5382, Val Acc: 0.3876, Test Acc: 0.4073\n",
            "Seed: 45, Epoch: 142, Loss: 1.5349, Val Acc: 0.4016, Test Acc: 0.4204\n",
            "Seed: 45, Epoch: 143, Loss: 1.5324, Val Acc: 0.3772, Test Acc: 0.4169\n",
            "Seed: 45, Epoch: 144, Loss: 1.5309, Val Acc: 0.3963, Test Acc: 0.4212\n",
            "Seed: 45, Epoch: 145, Loss: 1.5272, Val Acc: 0.4155, Test Acc: 0.4178\n",
            "Seed: 45, Epoch: 146, Loss: 1.5232, Val Acc: 0.3789, Test Acc: 0.3986\n",
            "Seed: 45, Epoch: 147, Loss: 1.5235, Val Acc: 0.3981, Test Acc: 0.4221\n",
            "Seed: 45, Epoch: 148, Loss: 1.5198, Val Acc: 0.4016, Test Acc: 0.4204\n",
            "Seed: 45, Epoch: 149, Loss: 1.5159, Val Acc: 0.4024, Test Acc: 0.4169\n",
            "Seed: 45, Epoch: 150, Loss: 1.5123, Val Acc: 0.4077, Test Acc: 0.4247\n",
            "Seed: 45, Epoch: 151, Loss: 1.5071, Val Acc: 0.4051, Test Acc: 0.4247\n",
            "Seed: 45, Epoch: 152, Loss: 1.5055, Val Acc: 0.4111, Test Acc: 0.4186\n",
            "Seed: 45, Epoch: 153, Loss: 1.5038, Val Acc: 0.4103, Test Acc: 0.4326\n",
            "Seed: 45, Epoch: 154, Loss: 1.5027, Val Acc: 0.3963, Test Acc: 0.4125\n",
            "Seed: 45, Epoch: 155, Loss: 1.4991, Val Acc: 0.4172, Test Acc: 0.4265\n",
            "Seed: 45, Epoch: 156, Loss: 1.4955, Val Acc: 0.4111, Test Acc: 0.4195\n",
            "Seed: 45, Epoch: 157, Loss: 1.4922, Val Acc: 0.4199, Test Acc: 0.4291\n",
            "Seed: 45, Epoch: 158, Loss: 1.4904, Val Acc: 0.4155, Test Acc: 0.4299\n",
            "Seed: 45, Epoch: 159, Loss: 1.4895, Val Acc: 0.4111, Test Acc: 0.4360\n",
            "Seed: 45, Epoch: 160, Loss: 1.4883, Val Acc: 0.4094, Test Acc: 0.4082\n",
            "Seed: 45, Epoch: 161, Loss: 1.4819, Val Acc: 0.4303, Test Acc: 0.4395\n",
            "Seed: 45, Epoch: 162, Loss: 1.4807, Val Acc: 0.4007, Test Acc: 0.4291\n",
            "Seed: 45, Epoch: 163, Loss: 1.4789, Val Acc: 0.4251, Test Acc: 0.4343\n",
            "Seed: 45, Epoch: 164, Loss: 1.4756, Val Acc: 0.4172, Test Acc: 0.4247\n",
            "Seed: 45, Epoch: 165, Loss: 1.4719, Val Acc: 0.4260, Test Acc: 0.4343\n",
            "Seed: 45, Epoch: 166, Loss: 1.4719, Val Acc: 0.4216, Test Acc: 0.4352\n",
            "Seed: 45, Epoch: 167, Loss: 1.4690, Val Acc: 0.4207, Test Acc: 0.4308\n",
            "Seed: 45, Epoch: 168, Loss: 1.4649, Val Acc: 0.4347, Test Acc: 0.4491\n",
            "Seed: 45, Epoch: 169, Loss: 1.4650, Val Acc: 0.4207, Test Acc: 0.4299\n",
            "Seed: 45, Epoch: 170, Loss: 1.4628, Val Acc: 0.4382, Test Acc: 0.4447\n",
            "Seed: 45, Epoch: 171, Loss: 1.4582, Val Acc: 0.4068, Test Acc: 0.4230\n",
            "Seed: 45, Epoch: 172, Loss: 1.4614, Val Acc: 0.4347, Test Acc: 0.4491\n",
            "Seed: 45, Epoch: 173, Loss: 1.4550, Val Acc: 0.4347, Test Acc: 0.4421\n",
            "Seed: 45, Epoch: 174, Loss: 1.4532, Val Acc: 0.4469, Test Acc: 0.4404\n",
            "Seed: 45, Epoch: 175, Loss: 1.4496, Val Acc: 0.4242, Test Acc: 0.4421\n",
            "Seed: 45, Epoch: 176, Loss: 1.4499, Val Acc: 0.4146, Test Acc: 0.4299\n",
            "Seed: 45, Epoch: 177, Loss: 1.4505, Val Acc: 0.4216, Test Acc: 0.4430\n",
            "Seed: 45, Epoch: 178, Loss: 1.4453, Val Acc: 0.4242, Test Acc: 0.4439\n",
            "Seed: 45, Epoch: 179, Loss: 1.4450, Val Acc: 0.4077, Test Acc: 0.4386\n",
            "Seed: 45, Epoch: 180, Loss: 1.4415, Val Acc: 0.4390, Test Acc: 0.4552\n",
            "Seed: 45, Epoch: 181, Loss: 1.4420, Val Acc: 0.4338, Test Acc: 0.4500\n",
            "Seed: 45, Epoch: 182, Loss: 1.4381, Val Acc: 0.4225, Test Acc: 0.4560\n",
            "Seed: 45, Epoch: 183, Loss: 1.4348, Val Acc: 0.4434, Test Acc: 0.4491\n",
            "Seed: 45, Epoch: 184, Loss: 1.4349, Val Acc: 0.4277, Test Acc: 0.4491\n",
            "Seed: 45, Epoch: 185, Loss: 1.4294, Val Acc: 0.4190, Test Acc: 0.4508\n",
            "Seed: 45, Epoch: 186, Loss: 1.4238, Val Acc: 0.4207, Test Acc: 0.4413\n",
            "Seed: 45, Epoch: 187, Loss: 1.4219, Val Acc: 0.4286, Test Acc: 0.4500\n",
            "Seed: 45, Epoch: 188, Loss: 1.4218, Val Acc: 0.4294, Test Acc: 0.4413\n",
            "Seed: 45, Epoch: 189, Loss: 1.4181, Val Acc: 0.4268, Test Acc: 0.4482\n",
            "Seed: 45, Epoch: 190, Loss: 1.4169, Val Acc: 0.4216, Test Acc: 0.4508\n",
            "Seed: 45, Epoch: 191, Loss: 1.4148, Val Acc: 0.4416, Test Acc: 0.4508\n",
            "Seed: 45, Epoch: 192, Loss: 1.4144, Val Acc: 0.4425, Test Acc: 0.4508\n",
            "Seed: 45, Epoch: 193, Loss: 1.4138, Val Acc: 0.4207, Test Acc: 0.4508\n",
            "Seed: 45, Epoch: 194, Loss: 1.4088, Val Acc: 0.4329, Test Acc: 0.4447\n",
            "Seed: 45, Epoch: 195, Loss: 1.4137, Val Acc: 0.4477, Test Acc: 0.4526\n",
            "Seed: 45, Epoch: 196, Loss: 1.4082, Val Acc: 0.4364, Test Acc: 0.4517\n",
            "Seed: 45, Epoch: 197, Loss: 1.4136, Val Acc: 0.4207, Test Acc: 0.4482\n",
            "Seed: 45, Epoch: 198, Loss: 1.4064, Val Acc: 0.4216, Test Acc: 0.4473\n",
            "Seed: 45, Epoch: 199, Loss: 1.4065, Val Acc: 0.4190, Test Acc: 0.4595\n",
            "Seed: 45, Epoch: 200, Loss: 1.3998, Val Acc: 0.4242, Test Acc: 0.4665\n",
            "Seed: 46, Epoch: 001, Loss: 2.4052, Val Acc: 0.0601, Test Acc: 0.0722\n",
            "Seed: 46, Epoch: 002, Loss: 2.4034, Val Acc: 0.0601, Test Acc: 0.0722\n",
            "Seed: 46, Epoch: 003, Loss: 2.4010, Val Acc: 0.0627, Test Acc: 0.0740\n",
            "Seed: 46, Epoch: 004, Loss: 2.3981, Val Acc: 0.0706, Test Acc: 0.0844\n",
            "Seed: 46, Epoch: 005, Loss: 2.3942, Val Acc: 0.0767, Test Acc: 0.0923\n",
            "Seed: 46, Epoch: 006, Loss: 2.3885, Val Acc: 0.0740, Test Acc: 0.0975\n",
            "Seed: 46, Epoch: 007, Loss: 2.3813, Val Acc: 0.0688, Test Acc: 0.0862\n",
            "Seed: 46, Epoch: 008, Loss: 2.3721, Val Acc: 0.0688, Test Acc: 0.0783\n",
            "Seed: 46, Epoch: 009, Loss: 2.3596, Val Acc: 0.0566, Test Acc: 0.0696\n",
            "Seed: 46, Epoch: 010, Loss: 2.3438, Val Acc: 0.0557, Test Acc: 0.0696\n",
            "Seed: 46, Epoch: 011, Loss: 2.3228, Val Acc: 0.1098, Test Acc: 0.1297\n",
            "Seed: 46, Epoch: 012, Loss: 2.2974, Val Acc: 0.1516, Test Acc: 0.1654\n",
            "Seed: 46, Epoch: 013, Loss: 2.2654, Val Acc: 0.1707, Test Acc: 0.1828\n",
            "Seed: 46, Epoch: 014, Loss: 2.2310, Val Acc: 0.1742, Test Acc: 0.1915\n",
            "Seed: 46, Epoch: 015, Loss: 2.1963, Val Acc: 0.1794, Test Acc: 0.1950\n",
            "Seed: 46, Epoch: 016, Loss: 2.1675, Val Acc: 0.1716, Test Acc: 0.1915\n",
            "Seed: 46, Epoch: 017, Loss: 2.1429, Val Acc: 0.1829, Test Acc: 0.2054\n",
            "Seed: 46, Epoch: 018, Loss: 2.1223, Val Acc: 0.1794, Test Acc: 0.2028\n",
            "Seed: 46, Epoch: 019, Loss: 2.1046, Val Acc: 0.1847, Test Acc: 0.1976\n",
            "Seed: 46, Epoch: 020, Loss: 2.0832, Val Acc: 0.1855, Test Acc: 0.1958\n",
            "Seed: 46, Epoch: 021, Loss: 2.0675, Val Acc: 0.1925, Test Acc: 0.2054\n",
            "Seed: 46, Epoch: 022, Loss: 2.0502, Val Acc: 0.1803, Test Acc: 0.2176\n",
            "Seed: 46, Epoch: 023, Loss: 2.0496, Val Acc: 0.1899, Test Acc: 0.2254\n",
            "Seed: 46, Epoch: 024, Loss: 2.0407, Val Acc: 0.1969, Test Acc: 0.2193\n",
            "Seed: 46, Epoch: 025, Loss: 2.0193, Val Acc: 0.1969, Test Acc: 0.2176\n",
            "Seed: 46, Epoch: 026, Loss: 2.0109, Val Acc: 0.1751, Test Acc: 0.2089\n",
            "Seed: 46, Epoch: 027, Loss: 2.0024, Val Acc: 0.2056, Test Acc: 0.2254\n",
            "Seed: 46, Epoch: 028, Loss: 1.9913, Val Acc: 0.1890, Test Acc: 0.2202\n",
            "Seed: 46, Epoch: 029, Loss: 1.9871, Val Acc: 0.1934, Test Acc: 0.2150\n",
            "Seed: 46, Epoch: 030, Loss: 1.9783, Val Acc: 0.2178, Test Acc: 0.2272\n",
            "Seed: 46, Epoch: 031, Loss: 1.9749, Val Acc: 0.2056, Test Acc: 0.2341\n",
            "Seed: 46, Epoch: 032, Loss: 1.9604, Val Acc: 0.1960, Test Acc: 0.2193\n",
            "Seed: 46, Epoch: 033, Loss: 1.9574, Val Acc: 0.2099, Test Acc: 0.2332\n",
            "Seed: 46, Epoch: 034, Loss: 1.9446, Val Acc: 0.2134, Test Acc: 0.2402\n",
            "Seed: 46, Epoch: 035, Loss: 1.9365, Val Acc: 0.2073, Test Acc: 0.2289\n",
            "Seed: 46, Epoch: 036, Loss: 1.9293, Val Acc: 0.2108, Test Acc: 0.2341\n",
            "Seed: 46, Epoch: 037, Loss: 1.9237, Val Acc: 0.2125, Test Acc: 0.2298\n",
            "Seed: 46, Epoch: 038, Loss: 1.9148, Val Acc: 0.2213, Test Acc: 0.2350\n",
            "Seed: 46, Epoch: 039, Loss: 1.9137, Val Acc: 0.2160, Test Acc: 0.2419\n",
            "Seed: 46, Epoch: 040, Loss: 1.9061, Val Acc: 0.2169, Test Acc: 0.2263\n",
            "Seed: 46, Epoch: 041, Loss: 1.9006, Val Acc: 0.2213, Test Acc: 0.2402\n",
            "Seed: 46, Epoch: 042, Loss: 1.8935, Val Acc: 0.2361, Test Acc: 0.2402\n",
            "Seed: 46, Epoch: 043, Loss: 1.8893, Val Acc: 0.2247, Test Acc: 0.2428\n",
            "Seed: 46, Epoch: 044, Loss: 1.8849, Val Acc: 0.2291, Test Acc: 0.2402\n",
            "Seed: 46, Epoch: 045, Loss: 1.8895, Val Acc: 0.2221, Test Acc: 0.2454\n",
            "Seed: 46, Epoch: 046, Loss: 1.8781, Val Acc: 0.2308, Test Acc: 0.2489\n",
            "Seed: 46, Epoch: 047, Loss: 1.8708, Val Acc: 0.2326, Test Acc: 0.2507\n",
            "Seed: 46, Epoch: 048, Loss: 1.8680, Val Acc: 0.2291, Test Acc: 0.2498\n",
            "Seed: 46, Epoch: 049, Loss: 1.8636, Val Acc: 0.2352, Test Acc: 0.2524\n",
            "Seed: 46, Epoch: 050, Loss: 1.8650, Val Acc: 0.2474, Test Acc: 0.2559\n",
            "Seed: 46, Epoch: 051, Loss: 1.8572, Val Acc: 0.2474, Test Acc: 0.2620\n",
            "Seed: 46, Epoch: 052, Loss: 1.8584, Val Acc: 0.2483, Test Acc: 0.2620\n",
            "Seed: 46, Epoch: 053, Loss: 1.8524, Val Acc: 0.2413, Test Acc: 0.2698\n",
            "Seed: 46, Epoch: 054, Loss: 1.8417, Val Acc: 0.2491, Test Acc: 0.2768\n",
            "Seed: 46, Epoch: 055, Loss: 1.8378, Val Acc: 0.2491, Test Acc: 0.2637\n",
            "Seed: 46, Epoch: 056, Loss: 1.8403, Val Acc: 0.2509, Test Acc: 0.2768\n",
            "Seed: 46, Epoch: 057, Loss: 1.8291, Val Acc: 0.2544, Test Acc: 0.2785\n",
            "Seed: 46, Epoch: 058, Loss: 1.8260, Val Acc: 0.2587, Test Acc: 0.2820\n",
            "Seed: 46, Epoch: 059, Loss: 1.8249, Val Acc: 0.2552, Test Acc: 0.2863\n",
            "Seed: 46, Epoch: 060, Loss: 1.8243, Val Acc: 0.2578, Test Acc: 0.2916\n",
            "Seed: 46, Epoch: 061, Loss: 1.8142, Val Acc: 0.2613, Test Acc: 0.2802\n",
            "Seed: 46, Epoch: 062, Loss: 1.8101, Val Acc: 0.2622, Test Acc: 0.2863\n",
            "Seed: 46, Epoch: 063, Loss: 1.8169, Val Acc: 0.2787, Test Acc: 0.3011\n",
            "Seed: 46, Epoch: 064, Loss: 1.8058, Val Acc: 0.2683, Test Acc: 0.2820\n",
            "Seed: 46, Epoch: 065, Loss: 1.8032, Val Acc: 0.2700, Test Acc: 0.3029\n",
            "Seed: 46, Epoch: 066, Loss: 1.7937, Val Acc: 0.2822, Test Acc: 0.3037\n",
            "Seed: 46, Epoch: 067, Loss: 1.7899, Val Acc: 0.2753, Test Acc: 0.3098\n",
            "Seed: 46, Epoch: 068, Loss: 1.7882, Val Acc: 0.2848, Test Acc: 0.2950\n",
            "Seed: 46, Epoch: 069, Loss: 1.7818, Val Acc: 0.2770, Test Acc: 0.3142\n",
            "Seed: 46, Epoch: 070, Loss: 1.7835, Val Acc: 0.2883, Test Acc: 0.3116\n",
            "Seed: 46, Epoch: 071, Loss: 1.7823, Val Acc: 0.2761, Test Acc: 0.2959\n",
            "Seed: 46, Epoch: 072, Loss: 1.7789, Val Acc: 0.2848, Test Acc: 0.2950\n",
            "Seed: 46, Epoch: 073, Loss: 1.7742, Val Acc: 0.2927, Test Acc: 0.3116\n",
            "Seed: 46, Epoch: 074, Loss: 1.7672, Val Acc: 0.2962, Test Acc: 0.3177\n",
            "Seed: 46, Epoch: 075, Loss: 1.7603, Val Acc: 0.2909, Test Acc: 0.3098\n",
            "Seed: 46, Epoch: 076, Loss: 1.7537, Val Acc: 0.2997, Test Acc: 0.3046\n",
            "Seed: 46, Epoch: 077, Loss: 1.7505, Val Acc: 0.2875, Test Acc: 0.3142\n",
            "Seed: 46, Epoch: 078, Loss: 1.7481, Val Acc: 0.2883, Test Acc: 0.3064\n",
            "Seed: 46, Epoch: 079, Loss: 1.7435, Val Acc: 0.2927, Test Acc: 0.3090\n",
            "Seed: 46, Epoch: 080, Loss: 1.7468, Val Acc: 0.3031, Test Acc: 0.3116\n",
            "Seed: 46, Epoch: 081, Loss: 1.7427, Val Acc: 0.3162, Test Acc: 0.3142\n",
            "Seed: 46, Epoch: 082, Loss: 1.7425, Val Acc: 0.2909, Test Acc: 0.3133\n",
            "Seed: 46, Epoch: 083, Loss: 1.7352, Val Acc: 0.3092, Test Acc: 0.3185\n",
            "Seed: 46, Epoch: 084, Loss: 1.7332, Val Acc: 0.3188, Test Acc: 0.3307\n",
            "Seed: 46, Epoch: 085, Loss: 1.7208, Val Acc: 0.3092, Test Acc: 0.3220\n",
            "Seed: 46, Epoch: 086, Loss: 1.7161, Val Acc: 0.3145, Test Acc: 0.3255\n",
            "Seed: 46, Epoch: 087, Loss: 1.7173, Val Acc: 0.3110, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 088, Loss: 1.7179, Val Acc: 0.3197, Test Acc: 0.3386\n",
            "Seed: 46, Epoch: 089, Loss: 1.7291, Val Acc: 0.3049, Test Acc: 0.3264\n",
            "Seed: 46, Epoch: 090, Loss: 1.7114, Val Acc: 0.3127, Test Acc: 0.3316\n",
            "Seed: 46, Epoch: 091, Loss: 1.7085, Val Acc: 0.3301, Test Acc: 0.3394\n",
            "Seed: 46, Epoch: 092, Loss: 1.7058, Val Acc: 0.3162, Test Acc: 0.3438\n",
            "Seed: 46, Epoch: 093, Loss: 1.7008, Val Acc: 0.3110, Test Acc: 0.3359\n",
            "Seed: 46, Epoch: 094, Loss: 1.6997, Val Acc: 0.3371, Test Acc: 0.3403\n",
            "Seed: 46, Epoch: 095, Loss: 1.7056, Val Acc: 0.3084, Test Acc: 0.3325\n",
            "Seed: 46, Epoch: 096, Loss: 1.6930, Val Acc: 0.3371, Test Acc: 0.3412\n",
            "Seed: 46, Epoch: 097, Loss: 1.6804, Val Acc: 0.3319, Test Acc: 0.3560\n",
            "Seed: 46, Epoch: 098, Loss: 1.6762, Val Acc: 0.3214, Test Acc: 0.3473\n",
            "Seed: 46, Epoch: 099, Loss: 1.6779, Val Acc: 0.3615, Test Acc: 0.3603\n",
            "Seed: 46, Epoch: 100, Loss: 1.6823, Val Acc: 0.3258, Test Acc: 0.3464\n",
            "Seed: 46, Epoch: 101, Loss: 1.6621, Val Acc: 0.3476, Test Acc: 0.3507\n",
            "Seed: 46, Epoch: 102, Loss: 1.6613, Val Acc: 0.3371, Test Acc: 0.3507\n",
            "Seed: 46, Epoch: 103, Loss: 1.6537, Val Acc: 0.3476, Test Acc: 0.3577\n",
            "Seed: 46, Epoch: 104, Loss: 1.6509, Val Acc: 0.3641, Test Acc: 0.3690\n",
            "Seed: 46, Epoch: 105, Loss: 1.6489, Val Acc: 0.3615, Test Acc: 0.3612\n",
            "Seed: 46, Epoch: 106, Loss: 1.6448, Val Acc: 0.3563, Test Acc: 0.3629\n",
            "Seed: 46, Epoch: 107, Loss: 1.6411, Val Acc: 0.3589, Test Acc: 0.3690\n",
            "Seed: 46, Epoch: 108, Loss: 1.6393, Val Acc: 0.3667, Test Acc: 0.3577\n",
            "Seed: 46, Epoch: 109, Loss: 1.6424, Val Acc: 0.3650, Test Acc: 0.3664\n",
            "Seed: 46, Epoch: 110, Loss: 1.6301, Val Acc: 0.3510, Test Acc: 0.3603\n",
            "Seed: 46, Epoch: 111, Loss: 1.6262, Val Acc: 0.3685, Test Acc: 0.3664\n",
            "Seed: 46, Epoch: 112, Loss: 1.6240, Val Acc: 0.3693, Test Acc: 0.3690\n",
            "Seed: 46, Epoch: 113, Loss: 1.6176, Val Acc: 0.3711, Test Acc: 0.3742\n",
            "Seed: 46, Epoch: 114, Loss: 1.6246, Val Acc: 0.3693, Test Acc: 0.3768\n",
            "Seed: 46, Epoch: 115, Loss: 1.6363, Val Acc: 0.3737, Test Acc: 0.3716\n",
            "Seed: 46, Epoch: 116, Loss: 1.6385, Val Acc: 0.3476, Test Acc: 0.3629\n",
            "Seed: 46, Epoch: 117, Loss: 1.6335, Val Acc: 0.3632, Test Acc: 0.3681\n",
            "Seed: 46, Epoch: 118, Loss: 1.6347, Val Acc: 0.3728, Test Acc: 0.3768\n",
            "Seed: 46, Epoch: 119, Loss: 1.6331, Val Acc: 0.3458, Test Acc: 0.3577\n",
            "Seed: 46, Epoch: 120, Loss: 1.6252, Val Acc: 0.3780, Test Acc: 0.3856\n",
            "Seed: 46, Epoch: 121, Loss: 1.6150, Val Acc: 0.3859, Test Acc: 0.3821\n",
            "Seed: 46, Epoch: 122, Loss: 1.6025, Val Acc: 0.3702, Test Acc: 0.3768\n",
            "Seed: 46, Epoch: 123, Loss: 1.5937, Val Acc: 0.3902, Test Acc: 0.3925\n",
            "Seed: 46, Epoch: 124, Loss: 1.5908, Val Acc: 0.3841, Test Acc: 0.3977\n",
            "Seed: 46, Epoch: 125, Loss: 1.5840, Val Acc: 0.3693, Test Acc: 0.3977\n",
            "Seed: 46, Epoch: 126, Loss: 1.5781, Val Acc: 0.3972, Test Acc: 0.3960\n",
            "Seed: 46, Epoch: 127, Loss: 1.5743, Val Acc: 0.3894, Test Acc: 0.3882\n",
            "Seed: 46, Epoch: 128, Loss: 1.5801, Val Acc: 0.3754, Test Acc: 0.3977\n",
            "Seed: 46, Epoch: 129, Loss: 1.5657, Val Acc: 0.3841, Test Acc: 0.4021\n",
            "Seed: 46, Epoch: 130, Loss: 1.5625, Val Acc: 0.3711, Test Acc: 0.3829\n",
            "Seed: 46, Epoch: 131, Loss: 1.5587, Val Acc: 0.3937, Test Acc: 0.4047\n",
            "Seed: 46, Epoch: 132, Loss: 1.5640, Val Acc: 0.3824, Test Acc: 0.3995\n",
            "Seed: 46, Epoch: 133, Loss: 1.5855, Val Acc: 0.3824, Test Acc: 0.4073\n",
            "Seed: 46, Epoch: 134, Loss: 1.5792, Val Acc: 0.4042, Test Acc: 0.3995\n",
            "Seed: 46, Epoch: 135, Loss: 1.5684, Val Acc: 0.3998, Test Acc: 0.3977\n",
            "Seed: 46, Epoch: 136, Loss: 1.5547, Val Acc: 0.4007, Test Acc: 0.4038\n",
            "Seed: 46, Epoch: 137, Loss: 1.5510, Val Acc: 0.4024, Test Acc: 0.4091\n",
            "Seed: 46, Epoch: 138, Loss: 1.5419, Val Acc: 0.4085, Test Acc: 0.4221\n",
            "Seed: 46, Epoch: 139, Loss: 1.5398, Val Acc: 0.3902, Test Acc: 0.3977\n",
            "Seed: 46, Epoch: 140, Loss: 1.5349, Val Acc: 0.4024, Test Acc: 0.4073\n",
            "Seed: 46, Epoch: 141, Loss: 1.5290, Val Acc: 0.4181, Test Acc: 0.4212\n",
            "Seed: 46, Epoch: 142, Loss: 1.5241, Val Acc: 0.4225, Test Acc: 0.4230\n",
            "Seed: 46, Epoch: 143, Loss: 1.5280, Val Acc: 0.3972, Test Acc: 0.4151\n",
            "Seed: 46, Epoch: 144, Loss: 1.5326, Val Acc: 0.4103, Test Acc: 0.4169\n",
            "Seed: 46, Epoch: 145, Loss: 1.5310, Val Acc: 0.3972, Test Acc: 0.4021\n",
            "Seed: 46, Epoch: 146, Loss: 1.5302, Val Acc: 0.4094, Test Acc: 0.4247\n",
            "Seed: 46, Epoch: 147, Loss: 1.5186, Val Acc: 0.4146, Test Acc: 0.4326\n",
            "Seed: 46, Epoch: 148, Loss: 1.5266, Val Acc: 0.4007, Test Acc: 0.4064\n",
            "Seed: 46, Epoch: 149, Loss: 1.5215, Val Acc: 0.4199, Test Acc: 0.4343\n",
            "Seed: 46, Epoch: 150, Loss: 1.5123, Val Acc: 0.4181, Test Acc: 0.4317\n",
            "Seed: 46, Epoch: 151, Loss: 1.5056, Val Acc: 0.4120, Test Acc: 0.4186\n",
            "Seed: 46, Epoch: 152, Loss: 1.5069, Val Acc: 0.4172, Test Acc: 0.4334\n",
            "Seed: 46, Epoch: 153, Loss: 1.4982, Val Acc: 0.4199, Test Acc: 0.4352\n",
            "Seed: 46, Epoch: 154, Loss: 1.4987, Val Acc: 0.4277, Test Acc: 0.4265\n",
            "Seed: 46, Epoch: 155, Loss: 1.4933, Val Acc: 0.4190, Test Acc: 0.4317\n",
            "Seed: 46, Epoch: 156, Loss: 1.4890, Val Acc: 0.4242, Test Acc: 0.4360\n",
            "Seed: 46, Epoch: 157, Loss: 1.4832, Val Acc: 0.4268, Test Acc: 0.4369\n",
            "Seed: 46, Epoch: 158, Loss: 1.4799, Val Acc: 0.4303, Test Acc: 0.4386\n",
            "Seed: 46, Epoch: 159, Loss: 1.4800, Val Acc: 0.4303, Test Acc: 0.4299\n",
            "Seed: 46, Epoch: 160, Loss: 1.4773, Val Acc: 0.4303, Test Acc: 0.4308\n",
            "Seed: 46, Epoch: 161, Loss: 1.4762, Val Acc: 0.4225, Test Acc: 0.4395\n",
            "Seed: 46, Epoch: 162, Loss: 1.4811, Val Acc: 0.4216, Test Acc: 0.4334\n",
            "Seed: 46, Epoch: 163, Loss: 1.4717, Val Acc: 0.4434, Test Acc: 0.4334\n",
            "Seed: 46, Epoch: 164, Loss: 1.4658, Val Acc: 0.4329, Test Acc: 0.4473\n",
            "Seed: 46, Epoch: 165, Loss: 1.4681, Val Acc: 0.4225, Test Acc: 0.4430\n",
            "Seed: 46, Epoch: 166, Loss: 1.4649, Val Acc: 0.4416, Test Acc: 0.4404\n",
            "Seed: 46, Epoch: 167, Loss: 1.4580, Val Acc: 0.4347, Test Acc: 0.4421\n",
            "Seed: 46, Epoch: 168, Loss: 1.4558, Val Acc: 0.4347, Test Acc: 0.4386\n",
            "Seed: 46, Epoch: 169, Loss: 1.4521, Val Acc: 0.4216, Test Acc: 0.4291\n",
            "Seed: 46, Epoch: 170, Loss: 1.4589, Val Acc: 0.4242, Test Acc: 0.4308\n",
            "Seed: 46, Epoch: 171, Loss: 1.4615, Val Acc: 0.3963, Test Acc: 0.4221\n",
            "Seed: 46, Epoch: 172, Loss: 1.4676, Val Acc: 0.4024, Test Acc: 0.4160\n",
            "Seed: 46, Epoch: 173, Loss: 1.4607, Val Acc: 0.4399, Test Acc: 0.4543\n",
            "Seed: 46, Epoch: 174, Loss: 1.4496, Val Acc: 0.4512, Test Acc: 0.4473\n",
            "Seed: 46, Epoch: 175, Loss: 1.4472, Val Acc: 0.4425, Test Acc: 0.4543\n",
            "Seed: 46, Epoch: 176, Loss: 1.4369, Val Acc: 0.4164, Test Acc: 0.4317\n",
            "Seed: 46, Epoch: 177, Loss: 1.4420, Val Acc: 0.4355, Test Acc: 0.4534\n",
            "Seed: 46, Epoch: 178, Loss: 1.4337, Val Acc: 0.4434, Test Acc: 0.4543\n",
            "Seed: 46, Epoch: 179, Loss: 1.4339, Val Acc: 0.4486, Test Acc: 0.4587\n",
            "Seed: 46, Epoch: 180, Loss: 1.4314, Val Acc: 0.4434, Test Acc: 0.4752\n",
            "Seed: 46, Epoch: 181, Loss: 1.4369, Val Acc: 0.4347, Test Acc: 0.4482\n",
            "Seed: 46, Epoch: 182, Loss: 1.4272, Val Acc: 0.4312, Test Acc: 0.4360\n",
            "Seed: 46, Epoch: 183, Loss: 1.4251, Val Acc: 0.4443, Test Acc: 0.4543\n",
            "Seed: 46, Epoch: 184, Loss: 1.4229, Val Acc: 0.4460, Test Acc: 0.4526\n",
            "Seed: 46, Epoch: 185, Loss: 1.4192, Val Acc: 0.4564, Test Acc: 0.4587\n",
            "Seed: 46, Epoch: 186, Loss: 1.4182, Val Acc: 0.4538, Test Acc: 0.4578\n",
            "Seed: 46, Epoch: 187, Loss: 1.4199, Val Acc: 0.4564, Test Acc: 0.4621\n",
            "Seed: 46, Epoch: 188, Loss: 1.4136, Val Acc: 0.4260, Test Acc: 0.4465\n",
            "Seed: 46, Epoch: 189, Loss: 1.4164, Val Acc: 0.4216, Test Acc: 0.4369\n",
            "Seed: 46, Epoch: 190, Loss: 1.4215, Val Acc: 0.4486, Test Acc: 0.4526\n",
            "Seed: 46, Epoch: 191, Loss: 1.4066, Val Acc: 0.4599, Test Acc: 0.4665\n",
            "Seed: 46, Epoch: 192, Loss: 1.4031, Val Acc: 0.4547, Test Acc: 0.4639\n",
            "Seed: 46, Epoch: 193, Loss: 1.3980, Val Acc: 0.4686, Test Acc: 0.4648\n",
            "Seed: 46, Epoch: 194, Loss: 1.3991, Val Acc: 0.4678, Test Acc: 0.4691\n",
            "Seed: 46, Epoch: 195, Loss: 1.3968, Val Acc: 0.4695, Test Acc: 0.4769\n",
            "Seed: 46, Epoch: 196, Loss: 1.3946, Val Acc: 0.4669, Test Acc: 0.4726\n",
            "Seed: 46, Epoch: 197, Loss: 1.3892, Val Acc: 0.4660, Test Acc: 0.4621\n",
            "Seed: 46, Epoch: 198, Loss: 1.3981, Val Acc: 0.4808, Test Acc: 0.4804\n",
            "Seed: 46, Epoch: 199, Loss: 1.3933, Val Acc: 0.4713, Test Acc: 0.4787\n",
            "Seed: 46, Epoch: 200, Loss: 1.3945, Val Acc: 0.4660, Test Acc: 0.4795\n",
            "Average Time: 192.05 seconds\n",
            "Var Time: 14.74 seconds\n",
            "Average Memory: 212.40 MB\n",
            "Average Best Val Acc: 0.4631\n",
            "Std Best Test Acc: 0.0289\n",
            "Average Test Acc: 0.4527\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, SAGPooling\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "from torch_geometric.nn import BatchNorm\n",
        "\n",
        "class HierarchicalGCN_SAG(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes):\n",
        "        super(HierarchicalGCN_SAG, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.pool1 = SAGPooling(hidden_channels, ratio=0.5)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.pool2 = SAGPooling(hidden_channels, ratio=0.5)\n",
        "        self.conv3 = SAGEConv(hidden_channels, out_channels)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.lin1 = torch.nn.Linear(out_channels, 32)\n",
        "        self.lin2 = torch.nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        # First GCN and pooling layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn1(x)\n",
        "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
        "\n",
        "        # Second GCN and pooling layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn2(x)\n",
        "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
        "\n",
        "        # Third GCN layer\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn3(x)\n",
        "\n",
        "        # Mean pooling over the nodes\n",
        "        x, mask = to_dense_batch(x, batch)\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.lin1(x).relu()\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "num_classes = dataset_sparse.num_classes\n",
        "in_channels = dataset_sparse.num_features\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HierarchicalGCN_SAG(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        data.y = data.y.to(torch.long)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == data.y).sum().item()\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seeds = [42, 43, 44, 45, 46]\n",
        "times = []\n",
        "memories = []\n",
        "best_val_accs = []\n",
        "best_test_accs = []\n",
        "\n",
        "early_stop_patience = 150\n",
        "tolerance = 0.0001\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    model = HierarchicalGCN_SAG(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        val_acc = test(valid_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        if val_acc > best_val_acc + tolerance:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "        if epochs_no_improve >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
        "\n",
        "    times.append(total_time)\n",
        "    memories.append(memory_allocated)\n",
        "    best_val_accs.append(best_val_acc)\n",
        "    best_test_accs.append(best_test_acc)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
        "print(f'Var Time: {np.var(times):.2f} seconds')\n",
        "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
        "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
        "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
        "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YXsgFYnRroD"
      },
      "source": [
        "## ASAPooling with HierarchicalGCN (2020)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "oyhYzjVJR4GO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 001, Loss: 2.3980, Val Acc: 0.0949, Test Acc: 0.0766\n",
            "Seed: 42, Epoch: 002, Loss: 2.3972, Val Acc: 0.0949, Test Acc: 0.0766\n",
            "Seed: 42, Epoch: 003, Loss: 2.3963, Val Acc: 0.0949, Test Acc: 0.0766\n",
            "Seed: 42, Epoch: 004, Loss: 2.3953, Val Acc: 0.0949, Test Acc: 0.0766\n",
            "Seed: 42, Epoch: 005, Loss: 2.3939, Val Acc: 0.0854, Test Acc: 0.0714\n",
            "Seed: 42, Epoch: 006, Loss: 2.3919, Val Acc: 0.0296, Test Acc: 0.0339\n",
            "Seed: 42, Epoch: 007, Loss: 2.3892, Val Acc: 0.0679, Test Acc: 0.0809\n",
            "Seed: 42, Epoch: 008, Loss: 2.3850, Val Acc: 0.0592, Test Acc: 0.0679\n",
            "Seed: 42, Epoch: 009, Loss: 2.3792, Val Acc: 0.0601, Test Acc: 0.0661\n",
            "Seed: 42, Epoch: 010, Loss: 2.3719, Val Acc: 0.0592, Test Acc: 0.0696\n",
            "Seed: 42, Epoch: 011, Loss: 2.3615, Val Acc: 0.0749, Test Acc: 0.0757\n",
            "Seed: 42, Epoch: 012, Loss: 2.3473, Val Acc: 0.1498, Test Acc: 0.1462\n",
            "Seed: 42, Epoch: 013, Loss: 2.3277, Val Acc: 0.1638, Test Acc: 0.1662\n",
            "Seed: 42, Epoch: 014, Loss: 2.3015, Val Acc: 0.1551, Test Acc: 0.1654\n",
            "Seed: 42, Epoch: 015, Loss: 2.2683, Val Acc: 0.1638, Test Acc: 0.1819\n",
            "Seed: 42, Epoch: 016, Loss: 2.2261, Val Acc: 0.1916, Test Acc: 0.1993\n",
            "Seed: 42, Epoch: 017, Loss: 2.1864, Val Acc: 0.1960, Test Acc: 0.2002\n",
            "Seed: 42, Epoch: 018, Loss: 2.1491, Val Acc: 0.2056, Test Acc: 0.2019\n",
            "Seed: 42, Epoch: 019, Loss: 2.1138, Val Acc: 0.1855, Test Acc: 0.1967\n",
            "Seed: 42, Epoch: 020, Loss: 2.0788, Val Acc: 0.1977, Test Acc: 0.2037\n",
            "Seed: 42, Epoch: 021, Loss: 2.0486, Val Acc: 0.1943, Test Acc: 0.2063\n",
            "Seed: 42, Epoch: 022, Loss: 2.0173, Val Acc: 0.2326, Test Acc: 0.2132\n",
            "Seed: 42, Epoch: 023, Loss: 1.9908, Val Acc: 0.2308, Test Acc: 0.2393\n",
            "Seed: 42, Epoch: 024, Loss: 1.9651, Val Acc: 0.2369, Test Acc: 0.2428\n",
            "Seed: 42, Epoch: 025, Loss: 1.9365, Val Acc: 0.2570, Test Acc: 0.2576\n",
            "Seed: 42, Epoch: 026, Loss: 1.9112, Val Acc: 0.2439, Test Acc: 0.2454\n",
            "Seed: 42, Epoch: 027, Loss: 1.9189, Val Acc: 0.2326, Test Acc: 0.2463\n",
            "Seed: 42, Epoch: 028, Loss: 1.9033, Val Acc: 0.2735, Test Acc: 0.2707\n",
            "Seed: 42, Epoch: 029, Loss: 1.8943, Val Acc: 0.2909, Test Acc: 0.2733\n",
            "Seed: 42, Epoch: 030, Loss: 1.8769, Val Acc: 0.2831, Test Acc: 0.2776\n",
            "Seed: 42, Epoch: 031, Loss: 1.8590, Val Acc: 0.3057, Test Acc: 0.3046\n",
            "Seed: 42, Epoch: 032, Loss: 1.8588, Val Acc: 0.3092, Test Acc: 0.3029\n",
            "Seed: 42, Epoch: 033, Loss: 1.8460, Val Acc: 0.3171, Test Acc: 0.3177\n",
            "Seed: 42, Epoch: 034, Loss: 1.8403, Val Acc: 0.3101, Test Acc: 0.3081\n",
            "Seed: 42, Epoch: 035, Loss: 1.8307, Val Acc: 0.3066, Test Acc: 0.3064\n",
            "Seed: 42, Epoch: 036, Loss: 1.8252, Val Acc: 0.3179, Test Acc: 0.3020\n",
            "Seed: 42, Epoch: 037, Loss: 1.8207, Val Acc: 0.3075, Test Acc: 0.3046\n",
            "Seed: 42, Epoch: 038, Loss: 1.8154, Val Acc: 0.3110, Test Acc: 0.3124\n",
            "Seed: 42, Epoch: 039, Loss: 1.8107, Val Acc: 0.3249, Test Acc: 0.3177\n",
            "Seed: 42, Epoch: 040, Loss: 1.8031, Val Acc: 0.3258, Test Acc: 0.3342\n",
            "Seed: 42, Epoch: 041, Loss: 1.8025, Val Acc: 0.3397, Test Acc: 0.3325\n",
            "Seed: 42, Epoch: 042, Loss: 1.8081, Val Acc: 0.3632, Test Acc: 0.3412\n",
            "Seed: 42, Epoch: 043, Loss: 1.8021, Val Acc: 0.3214, Test Acc: 0.3098\n",
            "Seed: 42, Epoch: 044, Loss: 1.7928, Val Acc: 0.3249, Test Acc: 0.3159\n",
            "Seed: 42, Epoch: 045, Loss: 1.7871, Val Acc: 0.3214, Test Acc: 0.3151\n",
            "Seed: 42, Epoch: 046, Loss: 1.7924, Val Acc: 0.3571, Test Acc: 0.3560\n",
            "Seed: 42, Epoch: 047, Loss: 1.7940, Val Acc: 0.3284, Test Acc: 0.3299\n",
            "Seed: 42, Epoch: 048, Loss: 1.7846, Val Acc: 0.3267, Test Acc: 0.3272\n",
            "Seed: 42, Epoch: 049, Loss: 1.7721, Val Acc: 0.3554, Test Acc: 0.3446\n",
            "Seed: 42, Epoch: 050, Loss: 1.7649, Val Acc: 0.3441, Test Acc: 0.3342\n",
            "Seed: 42, Epoch: 051, Loss: 1.7671, Val Acc: 0.3336, Test Acc: 0.3403\n",
            "Seed: 42, Epoch: 052, Loss: 1.7594, Val Acc: 0.3563, Test Acc: 0.3325\n",
            "Seed: 42, Epoch: 053, Loss: 1.7530, Val Acc: 0.3650, Test Acc: 0.3586\n",
            "Seed: 42, Epoch: 054, Loss: 1.7522, Val Acc: 0.3484, Test Acc: 0.3446\n",
            "Seed: 42, Epoch: 055, Loss: 1.7444, Val Acc: 0.3563, Test Acc: 0.3455\n",
            "Seed: 42, Epoch: 056, Loss: 1.7387, Val Acc: 0.3502, Test Acc: 0.3429\n",
            "Seed: 42, Epoch: 057, Loss: 1.7368, Val Acc: 0.3589, Test Acc: 0.3473\n",
            "Seed: 42, Epoch: 058, Loss: 1.7316, Val Acc: 0.3545, Test Acc: 0.3420\n",
            "Seed: 42, Epoch: 059, Loss: 1.7262, Val Acc: 0.3563, Test Acc: 0.3438\n",
            "Seed: 42, Epoch: 060, Loss: 1.7228, Val Acc: 0.3598, Test Acc: 0.3499\n",
            "Seed: 42, Epoch: 061, Loss: 1.7224, Val Acc: 0.3598, Test Acc: 0.3377\n",
            "Seed: 42, Epoch: 062, Loss: 1.7190, Val Acc: 0.3406, Test Acc: 0.3412\n",
            "Seed: 42, Epoch: 063, Loss: 1.7166, Val Acc: 0.3493, Test Acc: 0.3446\n",
            "Seed: 42, Epoch: 064, Loss: 1.7184, Val Acc: 0.3606, Test Acc: 0.3446\n",
            "Seed: 42, Epoch: 065, Loss: 1.7065, Val Acc: 0.3685, Test Acc: 0.3577\n",
            "Seed: 42, Epoch: 066, Loss: 1.6995, Val Acc: 0.3728, Test Acc: 0.3655\n",
            "Seed: 42, Epoch: 067, Loss: 1.6947, Val Acc: 0.3659, Test Acc: 0.3542\n",
            "Seed: 42, Epoch: 068, Loss: 1.6904, Val Acc: 0.3659, Test Acc: 0.3586\n",
            "Seed: 42, Epoch: 069, Loss: 1.6884, Val Acc: 0.3676, Test Acc: 0.3681\n",
            "Seed: 42, Epoch: 070, Loss: 1.7248, Val Acc: 0.3833, Test Acc: 0.3603\n",
            "Seed: 42, Epoch: 071, Loss: 1.7141, Val Acc: 0.3275, Test Acc: 0.3255\n",
            "Seed: 42, Epoch: 072, Loss: 1.7103, Val Acc: 0.3484, Test Acc: 0.3481\n",
            "Seed: 42, Epoch: 073, Loss: 1.6934, Val Acc: 0.3484, Test Acc: 0.3490\n",
            "Seed: 42, Epoch: 074, Loss: 1.7105, Val Acc: 0.3693, Test Acc: 0.3455\n",
            "Seed: 42, Epoch: 075, Loss: 1.6831, Val Acc: 0.3693, Test Acc: 0.3664\n",
            "Seed: 42, Epoch: 076, Loss: 1.6727, Val Acc: 0.3720, Test Acc: 0.3803\n",
            "Seed: 42, Epoch: 077, Loss: 1.6821, Val Acc: 0.3833, Test Acc: 0.3742\n",
            "Seed: 42, Epoch: 078, Loss: 1.6756, Val Acc: 0.3624, Test Acc: 0.3351\n",
            "Seed: 42, Epoch: 079, Loss: 1.6726, Val Acc: 0.3780, Test Acc: 0.3925\n",
            "Seed: 42, Epoch: 080, Loss: 1.6604, Val Acc: 0.3772, Test Acc: 0.3916\n",
            "Seed: 42, Epoch: 081, Loss: 1.6527, Val Acc: 0.3632, Test Acc: 0.3568\n",
            "Seed: 42, Epoch: 082, Loss: 1.6569, Val Acc: 0.3885, Test Acc: 0.3725\n",
            "Seed: 42, Epoch: 083, Loss: 1.6444, Val Acc: 0.3876, Test Acc: 0.3882\n",
            "Seed: 42, Epoch: 084, Loss: 1.6433, Val Acc: 0.3772, Test Acc: 0.3768\n",
            "Seed: 42, Epoch: 085, Loss: 1.6366, Val Acc: 0.3798, Test Acc: 0.3621\n",
            "Seed: 42, Epoch: 086, Loss: 1.6375, Val Acc: 0.3841, Test Acc: 0.3812\n",
            "Seed: 42, Epoch: 087, Loss: 1.6308, Val Acc: 0.3789, Test Acc: 0.3760\n",
            "Seed: 42, Epoch: 088, Loss: 1.6290, Val Acc: 0.3902, Test Acc: 0.3890\n",
            "Seed: 42, Epoch: 089, Loss: 1.6301, Val Acc: 0.3859, Test Acc: 0.3934\n",
            "Seed: 42, Epoch: 090, Loss: 1.6263, Val Acc: 0.3824, Test Acc: 0.3786\n",
            "Seed: 42, Epoch: 091, Loss: 1.6197, Val Acc: 0.3780, Test Acc: 0.3734\n",
            "Seed: 42, Epoch: 092, Loss: 1.6196, Val Acc: 0.3859, Test Acc: 0.3795\n",
            "Seed: 42, Epoch: 093, Loss: 1.6110, Val Acc: 0.3911, Test Acc: 0.3795\n",
            "Seed: 42, Epoch: 094, Loss: 1.6065, Val Acc: 0.3868, Test Acc: 0.3856\n",
            "Seed: 42, Epoch: 095, Loss: 1.6079, Val Acc: 0.3946, Test Acc: 0.3934\n",
            "Seed: 42, Epoch: 096, Loss: 1.6140, Val Acc: 0.3702, Test Acc: 0.3690\n",
            "Seed: 42, Epoch: 097, Loss: 1.6129, Val Acc: 0.3789, Test Acc: 0.3768\n",
            "Seed: 42, Epoch: 098, Loss: 1.6063, Val Acc: 0.3876, Test Acc: 0.3795\n",
            "Seed: 42, Epoch: 099, Loss: 1.5992, Val Acc: 0.3963, Test Acc: 0.3882\n",
            "Seed: 42, Epoch: 100, Loss: 1.6066, Val Acc: 0.3929, Test Acc: 0.3890\n",
            "Seed: 42, Epoch: 101, Loss: 1.5988, Val Acc: 0.3815, Test Acc: 0.3873\n",
            "Seed: 42, Epoch: 102, Loss: 1.5844, Val Acc: 0.3902, Test Acc: 0.3829\n",
            "Seed: 42, Epoch: 103, Loss: 1.5827, Val Acc: 0.3894, Test Acc: 0.3838\n",
            "Seed: 42, Epoch: 104, Loss: 1.5857, Val Acc: 0.4042, Test Acc: 0.4021\n",
            "Seed: 42, Epoch: 105, Loss: 1.5876, Val Acc: 0.3859, Test Acc: 0.3699\n",
            "Seed: 42, Epoch: 106, Loss: 1.5901, Val Acc: 0.3650, Test Acc: 0.3629\n",
            "Seed: 42, Epoch: 107, Loss: 1.5958, Val Acc: 0.4051, Test Acc: 0.3986\n",
            "Seed: 42, Epoch: 108, Loss: 1.5944, Val Acc: 0.3998, Test Acc: 0.3943\n",
            "Seed: 42, Epoch: 109, Loss: 1.5764, Val Acc: 0.3841, Test Acc: 0.3786\n",
            "Seed: 42, Epoch: 110, Loss: 1.5718, Val Acc: 0.3955, Test Acc: 0.3943\n",
            "Seed: 42, Epoch: 111, Loss: 1.5622, Val Acc: 0.4042, Test Acc: 0.3899\n",
            "Seed: 42, Epoch: 112, Loss: 1.5647, Val Acc: 0.3990, Test Acc: 0.3873\n",
            "Seed: 42, Epoch: 113, Loss: 1.5633, Val Acc: 0.4120, Test Acc: 0.3873\n",
            "Seed: 42, Epoch: 114, Loss: 1.5644, Val Acc: 0.4042, Test Acc: 0.3847\n",
            "Seed: 42, Epoch: 115, Loss: 1.5597, Val Acc: 0.3789, Test Acc: 0.3699\n",
            "Seed: 42, Epoch: 116, Loss: 1.5615, Val Acc: 0.3911, Test Acc: 0.4073\n",
            "Seed: 42, Epoch: 117, Loss: 1.5492, Val Acc: 0.4024, Test Acc: 0.3838\n",
            "Seed: 42, Epoch: 118, Loss: 1.5552, Val Acc: 0.4085, Test Acc: 0.3960\n",
            "Seed: 42, Epoch: 119, Loss: 1.5449, Val Acc: 0.4016, Test Acc: 0.4091\n",
            "Seed: 42, Epoch: 120, Loss: 1.5414, Val Acc: 0.3841, Test Acc: 0.4030\n",
            "Seed: 42, Epoch: 121, Loss: 1.5424, Val Acc: 0.3746, Test Acc: 0.3856\n",
            "Seed: 42, Epoch: 122, Loss: 1.5468, Val Acc: 0.4085, Test Acc: 0.4212\n",
            "Seed: 42, Epoch: 123, Loss: 1.5404, Val Acc: 0.4024, Test Acc: 0.3969\n",
            "Seed: 42, Epoch: 124, Loss: 1.5314, Val Acc: 0.3780, Test Acc: 0.3986\n",
            "Seed: 42, Epoch: 125, Loss: 1.5330, Val Acc: 0.3955, Test Acc: 0.4160\n",
            "Seed: 42, Epoch: 126, Loss: 1.5232, Val Acc: 0.3720, Test Acc: 0.3925\n",
            "Seed: 42, Epoch: 127, Loss: 1.5367, Val Acc: 0.3833, Test Acc: 0.3829\n",
            "Seed: 42, Epoch: 128, Loss: 1.5374, Val Acc: 0.4155, Test Acc: 0.3899\n",
            "Seed: 42, Epoch: 129, Loss: 1.5244, Val Acc: 0.4016, Test Acc: 0.4038\n",
            "Seed: 42, Epoch: 130, Loss: 1.5224, Val Acc: 0.3990, Test Acc: 0.3960\n",
            "Seed: 42, Epoch: 131, Loss: 1.5149, Val Acc: 0.4059, Test Acc: 0.4204\n",
            "Seed: 42, Epoch: 132, Loss: 1.5104, Val Acc: 0.4016, Test Acc: 0.3995\n",
            "Seed: 42, Epoch: 133, Loss: 1.5049, Val Acc: 0.4172, Test Acc: 0.4125\n",
            "Seed: 42, Epoch: 134, Loss: 1.5101, Val Acc: 0.4242, Test Acc: 0.4082\n",
            "Seed: 42, Epoch: 135, Loss: 1.5007, Val Acc: 0.4042, Test Acc: 0.4091\n",
            "Seed: 42, Epoch: 136, Loss: 1.5134, Val Acc: 0.4251, Test Acc: 0.4221\n",
            "Seed: 42, Epoch: 137, Loss: 1.5121, Val Acc: 0.3937, Test Acc: 0.3890\n",
            "Seed: 42, Epoch: 138, Loss: 1.5102, Val Acc: 0.3650, Test Acc: 0.3812\n",
            "Seed: 42, Epoch: 139, Loss: 1.5339, Val Acc: 0.4129, Test Acc: 0.3916\n",
            "Seed: 42, Epoch: 140, Loss: 1.5182, Val Acc: 0.4225, Test Acc: 0.3986\n",
            "Seed: 42, Epoch: 141, Loss: 1.5027, Val Acc: 0.3841, Test Acc: 0.3934\n",
            "Seed: 42, Epoch: 142, Loss: 1.5162, Val Acc: 0.4277, Test Acc: 0.4204\n",
            "Seed: 42, Epoch: 143, Loss: 1.5038, Val Acc: 0.4129, Test Acc: 0.3916\n",
            "Seed: 42, Epoch: 144, Loss: 1.5048, Val Acc: 0.4094, Test Acc: 0.4021\n",
            "Seed: 42, Epoch: 145, Loss: 1.4956, Val Acc: 0.4233, Test Acc: 0.4247\n",
            "Seed: 42, Epoch: 146, Loss: 1.4822, Val Acc: 0.4286, Test Acc: 0.4169\n",
            "Seed: 42, Epoch: 147, Loss: 1.4824, Val Acc: 0.4303, Test Acc: 0.4221\n",
            "Seed: 42, Epoch: 148, Loss: 1.4795, Val Acc: 0.4033, Test Acc: 0.3951\n",
            "Seed: 42, Epoch: 149, Loss: 1.4896, Val Acc: 0.4425, Test Acc: 0.4291\n",
            "Seed: 42, Epoch: 150, Loss: 1.4727, Val Acc: 0.4312, Test Acc: 0.4117\n",
            "Seed: 42, Epoch: 151, Loss: 1.4675, Val Acc: 0.4260, Test Acc: 0.4238\n",
            "Seed: 42, Epoch: 152, Loss: 1.4641, Val Acc: 0.4155, Test Acc: 0.4317\n",
            "Seed: 42, Epoch: 153, Loss: 1.4696, Val Acc: 0.4233, Test Acc: 0.4299\n",
            "Seed: 42, Epoch: 154, Loss: 1.4633, Val Acc: 0.4416, Test Acc: 0.4186\n",
            "Seed: 42, Epoch: 155, Loss: 1.4601, Val Acc: 0.4477, Test Acc: 0.4256\n",
            "Seed: 42, Epoch: 156, Loss: 1.4584, Val Acc: 0.4312, Test Acc: 0.4247\n",
            "Seed: 42, Epoch: 157, Loss: 1.4667, Val Acc: 0.4207, Test Acc: 0.4030\n",
            "Seed: 42, Epoch: 158, Loss: 1.4692, Val Acc: 0.4434, Test Acc: 0.4160\n",
            "Seed: 42, Epoch: 159, Loss: 1.4577, Val Acc: 0.4364, Test Acc: 0.4404\n",
            "Seed: 42, Epoch: 160, Loss: 1.4585, Val Acc: 0.4303, Test Acc: 0.4352\n",
            "Seed: 42, Epoch: 161, Loss: 1.4599, Val Acc: 0.4390, Test Acc: 0.4326\n",
            "Seed: 42, Epoch: 162, Loss: 1.4497, Val Acc: 0.4120, Test Acc: 0.4256\n",
            "Seed: 42, Epoch: 163, Loss: 1.4570, Val Acc: 0.4199, Test Acc: 0.4282\n",
            "Seed: 42, Epoch: 164, Loss: 1.4657, Val Acc: 0.4312, Test Acc: 0.4212\n",
            "Seed: 42, Epoch: 165, Loss: 1.4621, Val Acc: 0.4364, Test Acc: 0.4204\n",
            "Seed: 42, Epoch: 166, Loss: 1.4518, Val Acc: 0.4181, Test Acc: 0.4056\n",
            "Seed: 42, Epoch: 167, Loss: 1.4607, Val Acc: 0.4277, Test Acc: 0.4256\n",
            "Seed: 42, Epoch: 168, Loss: 1.4625, Val Acc: 0.4355, Test Acc: 0.4169\n",
            "Seed: 42, Epoch: 169, Loss: 1.4531, Val Acc: 0.4294, Test Acc: 0.4282\n",
            "Seed: 42, Epoch: 170, Loss: 1.4407, Val Acc: 0.4416, Test Acc: 0.4282\n",
            "Seed: 42, Epoch: 171, Loss: 1.4480, Val Acc: 0.4364, Test Acc: 0.4221\n",
            "Seed: 42, Epoch: 172, Loss: 1.4628, Val Acc: 0.4486, Test Acc: 0.4352\n",
            "Seed: 42, Epoch: 173, Loss: 1.4527, Val Acc: 0.4355, Test Acc: 0.4334\n",
            "Seed: 42, Epoch: 174, Loss: 1.4393, Val Acc: 0.4190, Test Acc: 0.4265\n",
            "Seed: 42, Epoch: 175, Loss: 1.4625, Val Acc: 0.4451, Test Acc: 0.4456\n",
            "Seed: 42, Epoch: 176, Loss: 1.4379, Val Acc: 0.4390, Test Acc: 0.4326\n",
            "Seed: 42, Epoch: 177, Loss: 1.4332, Val Acc: 0.4451, Test Acc: 0.4482\n",
            "Seed: 42, Epoch: 178, Loss: 1.4369, Val Acc: 0.4591, Test Acc: 0.4465\n",
            "Seed: 42, Epoch: 179, Loss: 1.4366, Val Acc: 0.4416, Test Acc: 0.4369\n",
            "Seed: 42, Epoch: 180, Loss: 1.4339, Val Acc: 0.4582, Test Acc: 0.4560\n",
            "Seed: 42, Epoch: 181, Loss: 1.4258, Val Acc: 0.4399, Test Acc: 0.4360\n",
            "Seed: 42, Epoch: 182, Loss: 1.4248, Val Acc: 0.4512, Test Acc: 0.4508\n",
            "Seed: 42, Epoch: 183, Loss: 1.4126, Val Acc: 0.4573, Test Acc: 0.4508\n",
            "Seed: 42, Epoch: 184, Loss: 1.4115, Val Acc: 0.4512, Test Acc: 0.4674\n",
            "Seed: 42, Epoch: 185, Loss: 1.4068, Val Acc: 0.4564, Test Acc: 0.4534\n",
            "Seed: 42, Epoch: 186, Loss: 1.4077, Val Acc: 0.4503, Test Acc: 0.4587\n",
            "Seed: 42, Epoch: 187, Loss: 1.4114, Val Acc: 0.4495, Test Acc: 0.4517\n",
            "Seed: 42, Epoch: 188, Loss: 1.4056, Val Acc: 0.4599, Test Acc: 0.4621\n",
            "Seed: 42, Epoch: 189, Loss: 1.4080, Val Acc: 0.4634, Test Acc: 0.4717\n",
            "Seed: 42, Epoch: 190, Loss: 1.4071, Val Acc: 0.4512, Test Acc: 0.4578\n",
            "Seed: 42, Epoch: 191, Loss: 1.4049, Val Acc: 0.4564, Test Acc: 0.4621\n",
            "Seed: 42, Epoch: 192, Loss: 1.4069, Val Acc: 0.4634, Test Acc: 0.4700\n",
            "Seed: 42, Epoch: 193, Loss: 1.4046, Val Acc: 0.4678, Test Acc: 0.4613\n",
            "Seed: 42, Epoch: 194, Loss: 1.3950, Val Acc: 0.4573, Test Acc: 0.4674\n",
            "Seed: 42, Epoch: 195, Loss: 1.3946, Val Acc: 0.4512, Test Acc: 0.4587\n",
            "Seed: 42, Epoch: 196, Loss: 1.4048, Val Acc: 0.4425, Test Acc: 0.4369\n",
            "Seed: 42, Epoch: 197, Loss: 1.4193, Val Acc: 0.4643, Test Acc: 0.4482\n",
            "Seed: 42, Epoch: 198, Loss: 1.4014, Val Acc: 0.4477, Test Acc: 0.4569\n",
            "Seed: 42, Epoch: 199, Loss: 1.3985, Val Acc: 0.4599, Test Acc: 0.4595\n",
            "Seed: 42, Epoch: 200, Loss: 1.4148, Val Acc: 0.4303, Test Acc: 0.4352\n",
            "Seed: 43, Epoch: 001, Loss: 2.4046, Val Acc: 0.1124, Test Acc: 0.1062\n",
            "Seed: 43, Epoch: 002, Loss: 2.4022, Val Acc: 0.1124, Test Acc: 0.1062\n",
            "Seed: 43, Epoch: 003, Loss: 2.4002, Val Acc: 0.1124, Test Acc: 0.1062\n",
            "Seed: 43, Epoch: 004, Loss: 2.3976, Val Acc: 0.1246, Test Acc: 0.1262\n",
            "Seed: 43, Epoch: 005, Loss: 2.3945, Val Acc: 0.1429, Test Acc: 0.1471\n",
            "Seed: 43, Epoch: 006, Loss: 2.3904, Val Acc: 0.1141, Test Acc: 0.1184\n",
            "Seed: 43, Epoch: 007, Loss: 2.3850, Val Acc: 0.1272, Test Acc: 0.1453\n",
            "Seed: 43, Epoch: 008, Loss: 2.3781, Val Acc: 0.1455, Test Acc: 0.1654\n",
            "Seed: 43, Epoch: 009, Loss: 2.3688, Val Acc: 0.1524, Test Acc: 0.1741\n",
            "Seed: 43, Epoch: 010, Loss: 2.3566, Val Acc: 0.1568, Test Acc: 0.1767\n",
            "Seed: 43, Epoch: 011, Loss: 2.3407, Val Acc: 0.1611, Test Acc: 0.1749\n",
            "Seed: 43, Epoch: 012, Loss: 2.3202, Val Acc: 0.1646, Test Acc: 0.1758\n",
            "Seed: 43, Epoch: 013, Loss: 2.2951, Val Acc: 0.1655, Test Acc: 0.1871\n",
            "Seed: 43, Epoch: 014, Loss: 2.2644, Val Acc: 0.1690, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 015, Loss: 2.2286, Val Acc: 0.1672, Test Acc: 0.1836\n",
            "Seed: 43, Epoch: 016, Loss: 2.1928, Val Acc: 0.1524, Test Acc: 0.1767\n",
            "Seed: 43, Epoch: 017, Loss: 2.1599, Val Acc: 0.1472, Test Acc: 0.1654\n",
            "Seed: 43, Epoch: 018, Loss: 2.1296, Val Acc: 0.1307, Test Acc: 0.1628\n",
            "Seed: 43, Epoch: 019, Loss: 2.1014, Val Acc: 0.1307, Test Acc: 0.1584\n",
            "Seed: 43, Epoch: 020, Loss: 2.0755, Val Acc: 0.1455, Test Acc: 0.1819\n",
            "Seed: 43, Epoch: 021, Loss: 2.0508, Val Acc: 0.1594, Test Acc: 0.1993\n",
            "Seed: 43, Epoch: 022, Loss: 2.0324, Val Acc: 0.1751, Test Acc: 0.2037\n",
            "Seed: 43, Epoch: 023, Loss: 2.0130, Val Acc: 0.1908, Test Acc: 0.2097\n",
            "Seed: 43, Epoch: 024, Loss: 1.9953, Val Acc: 0.1934, Test Acc: 0.2193\n",
            "Seed: 43, Epoch: 025, Loss: 1.9792, Val Acc: 0.2099, Test Acc: 0.2272\n",
            "Seed: 43, Epoch: 026, Loss: 1.9602, Val Acc: 0.2326, Test Acc: 0.2402\n",
            "Seed: 43, Epoch: 027, Loss: 1.9450, Val Acc: 0.2439, Test Acc: 0.2515\n",
            "Seed: 43, Epoch: 028, Loss: 1.9302, Val Acc: 0.2456, Test Acc: 0.2498\n",
            "Seed: 43, Epoch: 029, Loss: 1.9159, Val Acc: 0.2552, Test Acc: 0.2602\n",
            "Seed: 43, Epoch: 030, Loss: 1.9022, Val Acc: 0.2544, Test Acc: 0.2594\n",
            "Seed: 43, Epoch: 031, Loss: 1.8899, Val Acc: 0.2666, Test Acc: 0.2637\n",
            "Seed: 43, Epoch: 032, Loss: 1.8810, Val Acc: 0.2613, Test Acc: 0.2620\n",
            "Seed: 43, Epoch: 033, Loss: 1.8731, Val Acc: 0.2779, Test Acc: 0.2742\n",
            "Seed: 43, Epoch: 034, Loss: 1.8642, Val Acc: 0.2831, Test Acc: 0.2898\n",
            "Seed: 43, Epoch: 035, Loss: 1.8561, Val Acc: 0.2753, Test Acc: 0.2829\n",
            "Seed: 43, Epoch: 036, Loss: 1.8506, Val Acc: 0.2848, Test Acc: 0.2907\n",
            "Seed: 43, Epoch: 037, Loss: 1.8439, Val Acc: 0.2822, Test Acc: 0.2863\n",
            "Seed: 43, Epoch: 038, Loss: 1.8372, Val Acc: 0.2875, Test Acc: 0.2933\n",
            "Seed: 43, Epoch: 039, Loss: 1.8322, Val Acc: 0.2779, Test Acc: 0.2881\n",
            "Seed: 43, Epoch: 040, Loss: 1.8263, Val Acc: 0.2988, Test Acc: 0.3159\n",
            "Seed: 43, Epoch: 041, Loss: 1.8252, Val Acc: 0.2892, Test Acc: 0.2950\n",
            "Seed: 43, Epoch: 042, Loss: 1.8193, Val Acc: 0.3049, Test Acc: 0.3020\n",
            "Seed: 43, Epoch: 043, Loss: 1.8144, Val Acc: 0.2953, Test Acc: 0.3037\n",
            "Seed: 43, Epoch: 044, Loss: 1.8098, Val Acc: 0.3005, Test Acc: 0.3168\n",
            "Seed: 43, Epoch: 045, Loss: 1.8062, Val Acc: 0.2979, Test Acc: 0.2985\n",
            "Seed: 43, Epoch: 046, Loss: 1.8025, Val Acc: 0.3110, Test Acc: 0.3037\n",
            "Seed: 43, Epoch: 047, Loss: 1.7988, Val Acc: 0.3040, Test Acc: 0.2985\n",
            "Seed: 43, Epoch: 048, Loss: 1.7949, Val Acc: 0.2997, Test Acc: 0.3098\n",
            "Seed: 43, Epoch: 049, Loss: 1.7907, Val Acc: 0.3057, Test Acc: 0.3211\n",
            "Seed: 43, Epoch: 050, Loss: 1.7863, Val Acc: 0.3206, Test Acc: 0.3159\n",
            "Seed: 43, Epoch: 051, Loss: 1.7835, Val Acc: 0.3049, Test Acc: 0.3081\n",
            "Seed: 43, Epoch: 052, Loss: 1.7799, Val Acc: 0.3153, Test Acc: 0.3142\n",
            "Seed: 43, Epoch: 053, Loss: 1.7763, Val Acc: 0.3162, Test Acc: 0.3246\n",
            "Seed: 43, Epoch: 054, Loss: 1.7719, Val Acc: 0.3118, Test Acc: 0.3246\n",
            "Seed: 43, Epoch: 055, Loss: 1.7691, Val Acc: 0.3188, Test Acc: 0.3098\n",
            "Seed: 43, Epoch: 056, Loss: 1.7635, Val Acc: 0.3214, Test Acc: 0.3325\n",
            "Seed: 43, Epoch: 057, Loss: 1.7609, Val Acc: 0.3258, Test Acc: 0.3238\n",
            "Seed: 43, Epoch: 058, Loss: 1.7566, Val Acc: 0.3310, Test Acc: 0.3281\n",
            "Seed: 43, Epoch: 059, Loss: 1.7532, Val Acc: 0.3145, Test Acc: 0.3211\n",
            "Seed: 43, Epoch: 060, Loss: 1.7500, Val Acc: 0.3336, Test Acc: 0.3403\n",
            "Seed: 43, Epoch: 061, Loss: 1.7491, Val Acc: 0.3258, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 062, Loss: 1.7438, Val Acc: 0.3301, Test Acc: 0.3342\n",
            "Seed: 43, Epoch: 063, Loss: 1.7390, Val Acc: 0.3319, Test Acc: 0.3177\n",
            "Seed: 43, Epoch: 064, Loss: 1.7362, Val Acc: 0.3328, Test Acc: 0.3403\n",
            "Seed: 43, Epoch: 065, Loss: 1.7317, Val Acc: 0.3301, Test Acc: 0.3438\n",
            "Seed: 43, Epoch: 066, Loss: 1.7307, Val Acc: 0.3319, Test Acc: 0.3429\n",
            "Seed: 43, Epoch: 067, Loss: 1.7289, Val Acc: 0.3153, Test Acc: 0.3177\n",
            "Seed: 43, Epoch: 068, Loss: 1.7310, Val Acc: 0.3310, Test Acc: 0.3429\n",
            "Seed: 43, Epoch: 069, Loss: 1.7208, Val Acc: 0.3389, Test Acc: 0.3377\n",
            "Seed: 43, Epoch: 070, Loss: 1.7179, Val Acc: 0.3423, Test Acc: 0.3525\n",
            "Seed: 43, Epoch: 071, Loss: 1.7147, Val Acc: 0.3328, Test Acc: 0.3386\n",
            "Seed: 43, Epoch: 072, Loss: 1.7088, Val Acc: 0.3415, Test Acc: 0.3551\n",
            "Seed: 43, Epoch: 073, Loss: 1.7051, Val Acc: 0.3397, Test Acc: 0.3464\n",
            "Seed: 43, Epoch: 074, Loss: 1.7016, Val Acc: 0.3397, Test Acc: 0.3481\n",
            "Seed: 43, Epoch: 075, Loss: 1.6983, Val Acc: 0.3441, Test Acc: 0.3455\n",
            "Seed: 43, Epoch: 076, Loss: 1.6953, Val Acc: 0.3441, Test Acc: 0.3664\n",
            "Seed: 43, Epoch: 077, Loss: 1.6932, Val Acc: 0.3423, Test Acc: 0.3490\n",
            "Seed: 43, Epoch: 078, Loss: 1.6903, Val Acc: 0.3545, Test Acc: 0.3594\n",
            "Seed: 43, Epoch: 079, Loss: 1.6873, Val Acc: 0.3510, Test Acc: 0.3394\n",
            "Seed: 43, Epoch: 080, Loss: 1.6841, Val Acc: 0.3493, Test Acc: 0.3603\n",
            "Seed: 43, Epoch: 081, Loss: 1.6804, Val Acc: 0.3449, Test Acc: 0.3629\n",
            "Seed: 43, Epoch: 082, Loss: 1.6795, Val Acc: 0.3519, Test Acc: 0.3499\n",
            "Seed: 43, Epoch: 083, Loss: 1.6761, Val Acc: 0.3493, Test Acc: 0.3621\n",
            "Seed: 43, Epoch: 084, Loss: 1.6736, Val Acc: 0.3371, Test Acc: 0.3412\n",
            "Seed: 43, Epoch: 085, Loss: 1.6758, Val Acc: 0.3615, Test Acc: 0.3699\n",
            "Seed: 43, Epoch: 086, Loss: 1.6700, Val Acc: 0.3458, Test Acc: 0.3499\n",
            "Seed: 43, Epoch: 087, Loss: 1.6691, Val Acc: 0.3537, Test Acc: 0.3690\n",
            "Seed: 43, Epoch: 088, Loss: 1.6721, Val Acc: 0.3537, Test Acc: 0.3516\n",
            "Seed: 43, Epoch: 089, Loss: 1.6639, Val Acc: 0.3528, Test Acc: 0.3716\n",
            "Seed: 43, Epoch: 090, Loss: 1.6599, Val Acc: 0.3615, Test Acc: 0.3681\n",
            "Seed: 43, Epoch: 091, Loss: 1.6537, Val Acc: 0.3571, Test Acc: 0.3621\n",
            "Seed: 43, Epoch: 092, Loss: 1.6513, Val Acc: 0.3589, Test Acc: 0.3621\n",
            "Seed: 43, Epoch: 093, Loss: 1.6476, Val Acc: 0.3615, Test Acc: 0.3716\n",
            "Seed: 43, Epoch: 094, Loss: 1.6461, Val Acc: 0.3632, Test Acc: 0.3742\n",
            "Seed: 43, Epoch: 095, Loss: 1.6425, Val Acc: 0.3606, Test Acc: 0.3725\n",
            "Seed: 43, Epoch: 096, Loss: 1.6394, Val Acc: 0.3545, Test Acc: 0.3812\n",
            "Seed: 43, Epoch: 097, Loss: 1.6380, Val Acc: 0.3589, Test Acc: 0.3829\n",
            "Seed: 43, Epoch: 098, Loss: 1.6358, Val Acc: 0.3554, Test Acc: 0.3821\n",
            "Seed: 43, Epoch: 099, Loss: 1.6314, Val Acc: 0.3598, Test Acc: 0.3647\n",
            "Seed: 43, Epoch: 100, Loss: 1.6306, Val Acc: 0.3554, Test Acc: 0.3777\n",
            "Seed: 43, Epoch: 101, Loss: 1.6262, Val Acc: 0.3641, Test Acc: 0.3812\n",
            "Seed: 43, Epoch: 102, Loss: 1.6241, Val Acc: 0.3650, Test Acc: 0.3943\n",
            "Seed: 43, Epoch: 103, Loss: 1.6234, Val Acc: 0.3720, Test Acc: 0.3786\n",
            "Seed: 43, Epoch: 104, Loss: 1.6209, Val Acc: 0.3659, Test Acc: 0.3690\n",
            "Seed: 43, Epoch: 105, Loss: 1.6159, Val Acc: 0.3650, Test Acc: 0.3890\n",
            "Seed: 43, Epoch: 106, Loss: 1.6168, Val Acc: 0.3676, Test Acc: 0.3821\n",
            "Seed: 43, Epoch: 107, Loss: 1.6121, Val Acc: 0.3711, Test Acc: 0.3768\n",
            "Seed: 43, Epoch: 108, Loss: 1.6114, Val Acc: 0.3624, Test Acc: 0.3768\n",
            "Seed: 43, Epoch: 109, Loss: 1.6040, Val Acc: 0.3746, Test Acc: 0.3829\n",
            "Seed: 43, Epoch: 110, Loss: 1.6042, Val Acc: 0.3780, Test Acc: 0.3856\n",
            "Seed: 43, Epoch: 111, Loss: 1.5997, Val Acc: 0.3720, Test Acc: 0.3699\n",
            "Seed: 43, Epoch: 112, Loss: 1.5975, Val Acc: 0.3720, Test Acc: 0.3916\n",
            "Seed: 43, Epoch: 113, Loss: 1.5938, Val Acc: 0.3667, Test Acc: 0.3812\n",
            "Seed: 43, Epoch: 114, Loss: 1.5942, Val Acc: 0.3754, Test Acc: 0.3803\n",
            "Seed: 43, Epoch: 115, Loss: 1.5909, Val Acc: 0.3833, Test Acc: 0.3812\n",
            "Seed: 43, Epoch: 116, Loss: 1.5900, Val Acc: 0.3659, Test Acc: 0.3821\n",
            "Seed: 43, Epoch: 117, Loss: 1.5871, Val Acc: 0.3868, Test Acc: 0.3882\n",
            "Seed: 43, Epoch: 118, Loss: 1.5866, Val Acc: 0.3737, Test Acc: 0.3864\n",
            "Seed: 43, Epoch: 119, Loss: 1.5828, Val Acc: 0.3780, Test Acc: 0.3864\n",
            "Seed: 43, Epoch: 120, Loss: 1.5810, Val Acc: 0.3833, Test Acc: 0.3838\n",
            "Seed: 43, Epoch: 121, Loss: 1.5758, Val Acc: 0.3850, Test Acc: 0.4003\n",
            "Seed: 43, Epoch: 122, Loss: 1.5746, Val Acc: 0.3894, Test Acc: 0.4021\n",
            "Seed: 43, Epoch: 123, Loss: 1.5730, Val Acc: 0.3754, Test Acc: 0.3890\n",
            "Seed: 43, Epoch: 124, Loss: 1.5737, Val Acc: 0.3929, Test Acc: 0.3838\n",
            "Seed: 43, Epoch: 125, Loss: 1.5726, Val Acc: 0.3920, Test Acc: 0.3951\n",
            "Seed: 43, Epoch: 126, Loss: 1.5739, Val Acc: 0.3841, Test Acc: 0.3977\n",
            "Seed: 43, Epoch: 127, Loss: 1.5772, Val Acc: 0.3720, Test Acc: 0.3943\n",
            "Seed: 43, Epoch: 128, Loss: 1.5828, Val Acc: 0.3702, Test Acc: 0.3986\n",
            "Seed: 43, Epoch: 129, Loss: 1.5873, Val Acc: 0.3780, Test Acc: 0.3977\n",
            "Seed: 43, Epoch: 130, Loss: 1.5815, Val Acc: 0.3737, Test Acc: 0.3777\n",
            "Seed: 43, Epoch: 131, Loss: 1.5782, Val Acc: 0.3815, Test Acc: 0.3977\n",
            "Seed: 43, Epoch: 132, Loss: 1.5721, Val Acc: 0.3833, Test Acc: 0.3951\n",
            "Seed: 43, Epoch: 133, Loss: 1.5609, Val Acc: 0.3885, Test Acc: 0.3916\n",
            "Seed: 43, Epoch: 134, Loss: 1.5552, Val Acc: 0.3963, Test Acc: 0.3943\n",
            "Seed: 43, Epoch: 135, Loss: 1.5513, Val Acc: 0.3911, Test Acc: 0.4021\n",
            "Seed: 43, Epoch: 136, Loss: 1.5461, Val Acc: 0.3937, Test Acc: 0.3943\n",
            "Seed: 43, Epoch: 137, Loss: 1.5483, Val Acc: 0.3972, Test Acc: 0.4160\n",
            "Seed: 43, Epoch: 138, Loss: 1.5456, Val Acc: 0.3815, Test Acc: 0.4021\n",
            "Seed: 43, Epoch: 139, Loss: 1.5415, Val Acc: 0.3920, Test Acc: 0.4021\n",
            "Seed: 43, Epoch: 140, Loss: 1.5392, Val Acc: 0.3937, Test Acc: 0.4021\n",
            "Seed: 43, Epoch: 141, Loss: 1.5387, Val Acc: 0.3911, Test Acc: 0.4012\n",
            "Seed: 43, Epoch: 142, Loss: 1.5347, Val Acc: 0.4068, Test Acc: 0.4091\n",
            "Seed: 43, Epoch: 143, Loss: 1.5319, Val Acc: 0.3946, Test Acc: 0.4021\n",
            "Seed: 43, Epoch: 144, Loss: 1.5314, Val Acc: 0.3894, Test Acc: 0.4038\n",
            "Seed: 43, Epoch: 145, Loss: 1.5259, Val Acc: 0.4033, Test Acc: 0.4038\n",
            "Seed: 43, Epoch: 146, Loss: 1.5271, Val Acc: 0.4051, Test Acc: 0.4099\n",
            "Seed: 43, Epoch: 147, Loss: 1.5230, Val Acc: 0.3963, Test Acc: 0.4056\n",
            "Seed: 43, Epoch: 148, Loss: 1.5197, Val Acc: 0.3981, Test Acc: 0.4047\n",
            "Seed: 43, Epoch: 149, Loss: 1.5200, Val Acc: 0.3963, Test Acc: 0.4134\n",
            "Seed: 43, Epoch: 150, Loss: 1.5159, Val Acc: 0.3981, Test Acc: 0.4169\n",
            "Seed: 43, Epoch: 151, Loss: 1.5167, Val Acc: 0.4051, Test Acc: 0.4099\n",
            "Seed: 43, Epoch: 152, Loss: 1.5151, Val Acc: 0.4085, Test Acc: 0.4134\n",
            "Seed: 43, Epoch: 153, Loss: 1.5138, Val Acc: 0.4077, Test Acc: 0.4056\n",
            "Seed: 43, Epoch: 154, Loss: 1.5088, Val Acc: 0.4016, Test Acc: 0.4056\n",
            "Seed: 43, Epoch: 155, Loss: 1.5067, Val Acc: 0.4103, Test Acc: 0.4134\n",
            "Seed: 43, Epoch: 156, Loss: 1.5045, Val Acc: 0.4094, Test Acc: 0.4134\n",
            "Seed: 43, Epoch: 157, Loss: 1.5024, Val Acc: 0.4059, Test Acc: 0.4143\n",
            "Seed: 43, Epoch: 158, Loss: 1.4977, Val Acc: 0.4103, Test Acc: 0.4186\n",
            "Seed: 43, Epoch: 159, Loss: 1.4966, Val Acc: 0.4129, Test Acc: 0.4195\n",
            "Seed: 43, Epoch: 160, Loss: 1.4943, Val Acc: 0.4155, Test Acc: 0.4108\n",
            "Seed: 43, Epoch: 161, Loss: 1.4901, Val Acc: 0.4094, Test Acc: 0.4125\n",
            "Seed: 43, Epoch: 162, Loss: 1.4877, Val Acc: 0.4120, Test Acc: 0.4108\n",
            "Seed: 43, Epoch: 163, Loss: 1.4851, Val Acc: 0.4155, Test Acc: 0.4178\n",
            "Seed: 43, Epoch: 164, Loss: 1.4875, Val Acc: 0.4225, Test Acc: 0.4108\n",
            "Seed: 43, Epoch: 165, Loss: 1.4847, Val Acc: 0.4181, Test Acc: 0.4273\n",
            "Seed: 43, Epoch: 166, Loss: 1.4807, Val Acc: 0.4233, Test Acc: 0.4178\n",
            "Seed: 43, Epoch: 167, Loss: 1.4815, Val Acc: 0.4260, Test Acc: 0.4178\n",
            "Seed: 43, Epoch: 168, Loss: 1.4816, Val Acc: 0.4199, Test Acc: 0.4247\n",
            "Seed: 43, Epoch: 169, Loss: 1.4814, Val Acc: 0.4129, Test Acc: 0.4273\n",
            "Seed: 43, Epoch: 170, Loss: 1.4738, Val Acc: 0.4251, Test Acc: 0.4238\n",
            "Seed: 43, Epoch: 171, Loss: 1.4748, Val Acc: 0.4207, Test Acc: 0.4117\n",
            "Seed: 43, Epoch: 172, Loss: 1.4714, Val Acc: 0.4321, Test Acc: 0.4230\n",
            "Seed: 43, Epoch: 173, Loss: 1.4730, Val Acc: 0.4225, Test Acc: 0.4308\n",
            "Seed: 43, Epoch: 174, Loss: 1.4688, Val Acc: 0.4138, Test Acc: 0.4238\n",
            "Seed: 43, Epoch: 175, Loss: 1.4670, Val Acc: 0.4207, Test Acc: 0.4256\n",
            "Seed: 43, Epoch: 176, Loss: 1.4625, Val Acc: 0.4242, Test Acc: 0.4212\n",
            "Seed: 43, Epoch: 177, Loss: 1.4620, Val Acc: 0.4251, Test Acc: 0.4360\n",
            "Seed: 43, Epoch: 178, Loss: 1.4608, Val Acc: 0.4251, Test Acc: 0.4204\n",
            "Seed: 43, Epoch: 179, Loss: 1.4606, Val Acc: 0.4260, Test Acc: 0.4238\n",
            "Seed: 43, Epoch: 180, Loss: 1.4601, Val Acc: 0.4042, Test Acc: 0.4204\n",
            "Seed: 43, Epoch: 181, Loss: 1.4633, Val Acc: 0.4277, Test Acc: 0.4221\n",
            "Seed: 43, Epoch: 182, Loss: 1.4553, Val Acc: 0.4329, Test Acc: 0.4282\n",
            "Seed: 43, Epoch: 183, Loss: 1.4526, Val Acc: 0.4216, Test Acc: 0.4334\n",
            "Seed: 43, Epoch: 184, Loss: 1.4526, Val Acc: 0.4251, Test Acc: 0.4334\n",
            "Seed: 43, Epoch: 185, Loss: 1.4509, Val Acc: 0.4277, Test Acc: 0.4282\n",
            "Seed: 43, Epoch: 186, Loss: 1.4481, Val Acc: 0.4260, Test Acc: 0.4299\n",
            "Seed: 43, Epoch: 187, Loss: 1.4504, Val Acc: 0.4172, Test Acc: 0.4343\n",
            "Seed: 43, Epoch: 188, Loss: 1.4480, Val Acc: 0.4242, Test Acc: 0.4291\n",
            "Seed: 43, Epoch: 189, Loss: 1.4467, Val Acc: 0.4268, Test Acc: 0.4439\n",
            "Seed: 43, Epoch: 190, Loss: 1.4469, Val Acc: 0.4260, Test Acc: 0.4299\n",
            "Seed: 43, Epoch: 191, Loss: 1.4414, Val Acc: 0.4294, Test Acc: 0.4386\n",
            "Seed: 43, Epoch: 192, Loss: 1.4424, Val Acc: 0.4408, Test Acc: 0.4386\n",
            "Seed: 43, Epoch: 193, Loss: 1.4406, Val Acc: 0.4294, Test Acc: 0.4265\n",
            "Seed: 43, Epoch: 194, Loss: 1.4383, Val Acc: 0.4164, Test Acc: 0.4221\n",
            "Seed: 43, Epoch: 195, Loss: 1.4377, Val Acc: 0.4338, Test Acc: 0.4352\n",
            "Seed: 43, Epoch: 196, Loss: 1.4364, Val Acc: 0.4286, Test Acc: 0.4265\n",
            "Seed: 43, Epoch: 197, Loss: 1.4339, Val Acc: 0.4155, Test Acc: 0.4178\n",
            "Seed: 43, Epoch: 198, Loss: 1.4396, Val Acc: 0.4338, Test Acc: 0.4404\n",
            "Seed: 43, Epoch: 199, Loss: 1.4326, Val Acc: 0.4355, Test Acc: 0.4299\n",
            "Seed: 43, Epoch: 200, Loss: 1.4318, Val Acc: 0.4321, Test Acc: 0.4378\n",
            "Seed: 44, Epoch: 001, Loss: 2.4029, Val Acc: 0.0679, Test Acc: 0.0783\n",
            "Seed: 44, Epoch: 002, Loss: 2.4020, Val Acc: 0.0679, Test Acc: 0.0783\n",
            "Seed: 44, Epoch: 003, Loss: 2.4010, Val Acc: 0.0679, Test Acc: 0.0783\n",
            "Seed: 44, Epoch: 004, Loss: 2.3997, Val Acc: 0.0923, Test Acc: 0.1114\n",
            "Seed: 44, Epoch: 005, Loss: 2.3983, Val Acc: 0.1002, Test Acc: 0.1114\n",
            "Seed: 44, Epoch: 006, Loss: 2.3968, Val Acc: 0.1202, Test Acc: 0.1192\n",
            "Seed: 44, Epoch: 007, Loss: 2.3952, Val Acc: 0.1185, Test Acc: 0.1131\n",
            "Seed: 44, Epoch: 008, Loss: 2.3936, Val Acc: 0.1115, Test Acc: 0.1131\n",
            "Seed: 44, Epoch: 009, Loss: 2.3912, Val Acc: 0.1089, Test Acc: 0.1097\n",
            "Seed: 44, Epoch: 010, Loss: 2.3880, Val Acc: 0.1063, Test Acc: 0.1088\n",
            "Seed: 44, Epoch: 011, Loss: 2.3833, Val Acc: 0.0871, Test Acc: 0.0914\n",
            "Seed: 44, Epoch: 012, Loss: 2.3763, Val Acc: 0.0854, Test Acc: 0.1053\n",
            "Seed: 44, Epoch: 013, Loss: 2.3659, Val Acc: 0.1411, Test Acc: 0.1697\n",
            "Seed: 44, Epoch: 014, Loss: 2.3515, Val Acc: 0.1542, Test Acc: 0.1810\n",
            "Seed: 44, Epoch: 015, Loss: 2.3319, Val Acc: 0.1690, Test Acc: 0.1828\n",
            "Seed: 44, Epoch: 016, Loss: 2.3062, Val Acc: 0.1934, Test Acc: 0.1967\n",
            "Seed: 44, Epoch: 017, Loss: 2.2740, Val Acc: 0.1995, Test Acc: 0.2028\n",
            "Seed: 44, Epoch: 018, Loss: 2.2364, Val Acc: 0.2056, Test Acc: 0.2063\n",
            "Seed: 44, Epoch: 019, Loss: 2.1965, Val Acc: 0.2030, Test Acc: 0.2124\n",
            "Seed: 44, Epoch: 020, Loss: 2.1582, Val Acc: 0.1943, Test Acc: 0.2063\n",
            "Seed: 44, Epoch: 021, Loss: 2.1228, Val Acc: 0.1943, Test Acc: 0.2202\n",
            "Seed: 44, Epoch: 022, Loss: 2.0923, Val Acc: 0.2073, Test Acc: 0.2219\n",
            "Seed: 44, Epoch: 023, Loss: 2.0645, Val Acc: 0.2247, Test Acc: 0.2306\n",
            "Seed: 44, Epoch: 024, Loss: 2.0413, Val Acc: 0.2178, Test Acc: 0.2298\n",
            "Seed: 44, Epoch: 025, Loss: 2.0204, Val Acc: 0.2143, Test Acc: 0.2341\n",
            "Seed: 44, Epoch: 026, Loss: 2.0030, Val Acc: 0.2186, Test Acc: 0.2446\n",
            "Seed: 44, Epoch: 027, Loss: 1.9830, Val Acc: 0.2239, Test Acc: 0.2559\n",
            "Seed: 44, Epoch: 028, Loss: 1.9665, Val Acc: 0.2343, Test Acc: 0.2646\n",
            "Seed: 44, Epoch: 029, Loss: 1.9508, Val Acc: 0.2308, Test Acc: 0.2602\n",
            "Seed: 44, Epoch: 030, Loss: 1.9381, Val Acc: 0.2361, Test Acc: 0.2698\n",
            "Seed: 44, Epoch: 031, Loss: 1.9261, Val Acc: 0.2439, Test Acc: 0.2602\n",
            "Seed: 44, Epoch: 032, Loss: 1.9146, Val Acc: 0.2483, Test Acc: 0.2794\n",
            "Seed: 44, Epoch: 033, Loss: 1.9035, Val Acc: 0.2578, Test Acc: 0.2811\n",
            "Seed: 44, Epoch: 034, Loss: 1.8936, Val Acc: 0.2613, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 035, Loss: 1.8849, Val Acc: 0.2683, Test Acc: 0.2846\n",
            "Seed: 44, Epoch: 036, Loss: 1.8766, Val Acc: 0.2779, Test Acc: 0.2863\n",
            "Seed: 44, Epoch: 037, Loss: 1.8675, Val Acc: 0.2814, Test Acc: 0.3037\n",
            "Seed: 44, Epoch: 038, Loss: 1.8615, Val Acc: 0.2779, Test Acc: 0.2933\n",
            "Seed: 44, Epoch: 039, Loss: 1.8543, Val Acc: 0.2779, Test Acc: 0.2924\n",
            "Seed: 44, Epoch: 040, Loss: 1.8452, Val Acc: 0.2840, Test Acc: 0.3107\n",
            "Seed: 44, Epoch: 041, Loss: 1.8411, Val Acc: 0.2892, Test Acc: 0.3055\n",
            "Seed: 44, Epoch: 042, Loss: 1.8344, Val Acc: 0.2848, Test Acc: 0.2959\n",
            "Seed: 44, Epoch: 043, Loss: 1.8310, Val Acc: 0.2848, Test Acc: 0.3081\n",
            "Seed: 44, Epoch: 044, Loss: 1.8267, Val Acc: 0.2883, Test Acc: 0.3203\n",
            "Seed: 44, Epoch: 045, Loss: 1.8215, Val Acc: 0.2953, Test Acc: 0.3020\n",
            "Seed: 44, Epoch: 046, Loss: 1.8156, Val Acc: 0.2892, Test Acc: 0.3055\n",
            "Seed: 44, Epoch: 047, Loss: 1.8144, Val Acc: 0.2770, Test Acc: 0.3037\n",
            "Seed: 44, Epoch: 048, Loss: 1.8111, Val Acc: 0.3066, Test Acc: 0.3185\n",
            "Seed: 44, Epoch: 049, Loss: 1.8070, Val Acc: 0.2918, Test Acc: 0.3107\n",
            "Seed: 44, Epoch: 050, Loss: 1.8053, Val Acc: 0.2909, Test Acc: 0.2959\n",
            "Seed: 44, Epoch: 051, Loss: 1.7959, Val Acc: 0.3171, Test Acc: 0.3281\n",
            "Seed: 44, Epoch: 052, Loss: 1.7940, Val Acc: 0.2944, Test Acc: 0.3151\n",
            "Seed: 44, Epoch: 053, Loss: 1.7901, Val Acc: 0.3066, Test Acc: 0.3151\n",
            "Seed: 44, Epoch: 054, Loss: 1.7871, Val Acc: 0.2944, Test Acc: 0.3107\n",
            "Seed: 44, Epoch: 055, Loss: 1.7842, Val Acc: 0.3136, Test Acc: 0.3359\n",
            "Seed: 44, Epoch: 056, Loss: 1.7828, Val Acc: 0.2997, Test Acc: 0.3177\n",
            "Seed: 44, Epoch: 057, Loss: 1.7796, Val Acc: 0.3023, Test Acc: 0.3124\n",
            "Seed: 44, Epoch: 058, Loss: 1.7760, Val Acc: 0.3092, Test Acc: 0.3168\n",
            "Seed: 44, Epoch: 059, Loss: 1.7730, Val Acc: 0.3232, Test Acc: 0.3299\n",
            "Seed: 44, Epoch: 060, Loss: 1.7696, Val Acc: 0.3031, Test Acc: 0.3159\n",
            "Seed: 44, Epoch: 061, Loss: 1.7680, Val Acc: 0.3118, Test Acc: 0.3290\n",
            "Seed: 44, Epoch: 062, Loss: 1.7649, Val Acc: 0.3179, Test Acc: 0.3429\n",
            "Seed: 44, Epoch: 063, Loss: 1.7623, Val Acc: 0.3049, Test Acc: 0.3159\n",
            "Seed: 44, Epoch: 064, Loss: 1.7606, Val Acc: 0.3092, Test Acc: 0.3238\n",
            "Seed: 44, Epoch: 065, Loss: 1.7584, Val Acc: 0.3214, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 066, Loss: 1.7545, Val Acc: 0.3232, Test Acc: 0.3264\n",
            "Seed: 44, Epoch: 067, Loss: 1.7512, Val Acc: 0.3145, Test Acc: 0.3281\n",
            "Seed: 44, Epoch: 068, Loss: 1.7507, Val Acc: 0.3136, Test Acc: 0.3194\n",
            "Seed: 44, Epoch: 069, Loss: 1.7444, Val Acc: 0.3258, Test Acc: 0.3420\n",
            "Seed: 44, Epoch: 070, Loss: 1.7430, Val Acc: 0.3197, Test Acc: 0.3325\n",
            "Seed: 44, Epoch: 071, Loss: 1.7430, Val Acc: 0.3328, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 072, Loss: 1.7414, Val Acc: 0.3092, Test Acc: 0.3238\n",
            "Seed: 44, Epoch: 073, Loss: 1.7390, Val Acc: 0.3415, Test Acc: 0.3551\n",
            "Seed: 44, Epoch: 074, Loss: 1.7346, Val Acc: 0.3075, Test Acc: 0.3229\n",
            "Seed: 44, Epoch: 075, Loss: 1.7324, Val Acc: 0.3423, Test Acc: 0.3490\n",
            "Seed: 44, Epoch: 076, Loss: 1.7299, Val Acc: 0.3240, Test Acc: 0.3412\n",
            "Seed: 44, Epoch: 077, Loss: 1.7273, Val Acc: 0.3345, Test Acc: 0.3368\n",
            "Seed: 44, Epoch: 078, Loss: 1.7238, Val Acc: 0.3310, Test Acc: 0.3412\n",
            "Seed: 44, Epoch: 079, Loss: 1.7248, Val Acc: 0.3275, Test Acc: 0.3464\n",
            "Seed: 44, Epoch: 080, Loss: 1.7196, Val Acc: 0.3336, Test Acc: 0.3464\n",
            "Seed: 44, Epoch: 081, Loss: 1.7172, Val Acc: 0.3406, Test Acc: 0.3394\n",
            "Seed: 44, Epoch: 082, Loss: 1.7167, Val Acc: 0.3563, Test Acc: 0.3629\n",
            "Seed: 44, Epoch: 083, Loss: 1.7150, Val Acc: 0.3162, Test Acc: 0.3211\n",
            "Seed: 44, Epoch: 084, Loss: 1.7149, Val Acc: 0.3554, Test Acc: 0.3647\n",
            "Seed: 44, Epoch: 085, Loss: 1.7083, Val Acc: 0.3267, Test Acc: 0.3403\n",
            "Seed: 44, Epoch: 086, Loss: 1.7061, Val Acc: 0.3537, Test Acc: 0.3499\n",
            "Seed: 44, Epoch: 087, Loss: 1.7024, Val Acc: 0.3484, Test Acc: 0.3577\n",
            "Seed: 44, Epoch: 088, Loss: 1.6993, Val Acc: 0.3458, Test Acc: 0.3603\n",
            "Seed: 44, Epoch: 089, Loss: 1.6963, Val Acc: 0.3484, Test Acc: 0.3542\n",
            "Seed: 44, Epoch: 090, Loss: 1.6927, Val Acc: 0.3554, Test Acc: 0.3542\n",
            "Seed: 44, Epoch: 091, Loss: 1.6918, Val Acc: 0.3563, Test Acc: 0.3699\n",
            "Seed: 44, Epoch: 092, Loss: 1.6884, Val Acc: 0.3624, Test Acc: 0.3664\n",
            "Seed: 44, Epoch: 093, Loss: 1.6891, Val Acc: 0.3493, Test Acc: 0.3542\n",
            "Seed: 44, Epoch: 094, Loss: 1.6853, Val Acc: 0.3702, Test Acc: 0.3664\n",
            "Seed: 44, Epoch: 095, Loss: 1.6838, Val Acc: 0.3650, Test Acc: 0.3664\n",
            "Seed: 44, Epoch: 096, Loss: 1.6818, Val Acc: 0.3545, Test Acc: 0.3490\n",
            "Seed: 44, Epoch: 097, Loss: 1.6786, Val Acc: 0.3737, Test Acc: 0.3699\n",
            "Seed: 44, Epoch: 098, Loss: 1.6765, Val Acc: 0.3632, Test Acc: 0.3751\n",
            "Seed: 44, Epoch: 099, Loss: 1.6722, Val Acc: 0.3502, Test Acc: 0.3507\n",
            "Seed: 44, Epoch: 100, Loss: 1.6722, Val Acc: 0.3807, Test Acc: 0.3725\n",
            "Seed: 44, Epoch: 101, Loss: 1.6692, Val Acc: 0.3537, Test Acc: 0.3699\n",
            "Seed: 44, Epoch: 102, Loss: 1.6655, Val Acc: 0.3998, Test Acc: 0.3821\n",
            "Seed: 44, Epoch: 103, Loss: 1.6705, Val Acc: 0.3571, Test Acc: 0.3525\n",
            "Seed: 44, Epoch: 104, Loss: 1.6613, Val Acc: 0.3632, Test Acc: 0.3742\n",
            "Seed: 44, Epoch: 105, Loss: 1.6600, Val Acc: 0.3641, Test Acc: 0.3751\n",
            "Seed: 44, Epoch: 106, Loss: 1.6566, Val Acc: 0.3650, Test Acc: 0.3725\n",
            "Seed: 44, Epoch: 107, Loss: 1.6532, Val Acc: 0.3685, Test Acc: 0.3699\n",
            "Seed: 44, Epoch: 108, Loss: 1.6493, Val Acc: 0.3789, Test Acc: 0.3786\n",
            "Seed: 44, Epoch: 109, Loss: 1.6470, Val Acc: 0.3728, Test Acc: 0.3751\n",
            "Seed: 44, Epoch: 110, Loss: 1.6445, Val Acc: 0.3772, Test Acc: 0.3777\n",
            "Seed: 44, Epoch: 111, Loss: 1.6434, Val Acc: 0.3676, Test Acc: 0.3708\n",
            "Seed: 44, Epoch: 112, Loss: 1.6406, Val Acc: 0.3833, Test Acc: 0.3856\n",
            "Seed: 44, Epoch: 113, Loss: 1.6391, Val Acc: 0.3789, Test Acc: 0.3856\n",
            "Seed: 44, Epoch: 114, Loss: 1.6362, Val Acc: 0.3772, Test Acc: 0.3655\n",
            "Seed: 44, Epoch: 115, Loss: 1.6329, Val Acc: 0.3737, Test Acc: 0.3803\n",
            "Seed: 44, Epoch: 116, Loss: 1.6306, Val Acc: 0.3876, Test Acc: 0.3934\n",
            "Seed: 44, Epoch: 117, Loss: 1.6294, Val Acc: 0.3807, Test Acc: 0.3882\n",
            "Seed: 44, Epoch: 118, Loss: 1.6300, Val Acc: 0.3754, Test Acc: 0.3777\n",
            "Seed: 44, Epoch: 119, Loss: 1.6251, Val Acc: 0.3981, Test Acc: 0.3882\n",
            "Seed: 44, Epoch: 120, Loss: 1.6201, Val Acc: 0.3798, Test Acc: 0.3708\n",
            "Seed: 44, Epoch: 121, Loss: 1.6207, Val Acc: 0.3998, Test Acc: 0.3838\n",
            "Seed: 44, Epoch: 122, Loss: 1.6181, Val Acc: 0.3789, Test Acc: 0.3821\n",
            "Seed: 44, Epoch: 123, Loss: 1.6142, Val Acc: 0.3876, Test Acc: 0.3716\n",
            "Seed: 44, Epoch: 124, Loss: 1.6128, Val Acc: 0.3963, Test Acc: 0.3873\n",
            "Seed: 44, Epoch: 125, Loss: 1.6109, Val Acc: 0.3815, Test Acc: 0.3873\n",
            "Seed: 44, Epoch: 126, Loss: 1.6084, Val Acc: 0.3937, Test Acc: 0.3856\n",
            "Seed: 44, Epoch: 127, Loss: 1.6070, Val Acc: 0.3894, Test Acc: 0.3812\n",
            "Seed: 44, Epoch: 128, Loss: 1.6032, Val Acc: 0.3894, Test Acc: 0.3890\n",
            "Seed: 44, Epoch: 129, Loss: 1.5985, Val Acc: 0.3920, Test Acc: 0.3786\n",
            "Seed: 44, Epoch: 130, Loss: 1.5968, Val Acc: 0.3955, Test Acc: 0.3925\n",
            "Seed: 44, Epoch: 131, Loss: 1.5944, Val Acc: 0.3868, Test Acc: 0.3943\n",
            "Seed: 44, Epoch: 132, Loss: 1.5913, Val Acc: 0.3972, Test Acc: 0.3829\n",
            "Seed: 44, Epoch: 133, Loss: 1.5906, Val Acc: 0.4059, Test Acc: 0.3951\n",
            "Seed: 44, Epoch: 134, Loss: 1.5855, Val Acc: 0.3946, Test Acc: 0.3916\n",
            "Seed: 44, Epoch: 135, Loss: 1.5854, Val Acc: 0.3998, Test Acc: 0.3908\n",
            "Seed: 44, Epoch: 136, Loss: 1.5825, Val Acc: 0.4068, Test Acc: 0.4021\n",
            "Seed: 44, Epoch: 137, Loss: 1.5799, Val Acc: 0.3937, Test Acc: 0.3838\n",
            "Seed: 44, Epoch: 138, Loss: 1.5784, Val Acc: 0.4024, Test Acc: 0.3977\n",
            "Seed: 44, Epoch: 139, Loss: 1.5746, Val Acc: 0.3981, Test Acc: 0.3916\n",
            "Seed: 44, Epoch: 140, Loss: 1.5731, Val Acc: 0.4085, Test Acc: 0.3821\n",
            "Seed: 44, Epoch: 141, Loss: 1.5710, Val Acc: 0.4059, Test Acc: 0.4012\n",
            "Seed: 44, Epoch: 142, Loss: 1.5693, Val Acc: 0.4033, Test Acc: 0.3864\n",
            "Seed: 44, Epoch: 143, Loss: 1.5667, Val Acc: 0.3850, Test Acc: 0.3916\n",
            "Seed: 44, Epoch: 144, Loss: 1.5644, Val Acc: 0.4016, Test Acc: 0.3986\n",
            "Seed: 44, Epoch: 145, Loss: 1.5682, Val Acc: 0.4085, Test Acc: 0.3977\n",
            "Seed: 44, Epoch: 146, Loss: 1.5643, Val Acc: 0.3998, Test Acc: 0.3908\n",
            "Seed: 44, Epoch: 147, Loss: 1.5614, Val Acc: 0.4033, Test Acc: 0.4047\n",
            "Seed: 44, Epoch: 148, Loss: 1.5569, Val Acc: 0.4033, Test Acc: 0.3995\n",
            "Seed: 44, Epoch: 149, Loss: 1.5580, Val Acc: 0.4120, Test Acc: 0.3960\n",
            "Seed: 44, Epoch: 150, Loss: 1.5521, Val Acc: 0.3929, Test Acc: 0.3899\n",
            "Seed: 44, Epoch: 151, Loss: 1.5475, Val Acc: 0.3998, Test Acc: 0.3977\n",
            "Seed: 44, Epoch: 152, Loss: 1.5477, Val Acc: 0.4146, Test Acc: 0.4134\n",
            "Seed: 44, Epoch: 153, Loss: 1.5468, Val Acc: 0.4094, Test Acc: 0.3925\n",
            "Seed: 44, Epoch: 154, Loss: 1.5448, Val Acc: 0.3981, Test Acc: 0.3882\n",
            "Seed: 44, Epoch: 155, Loss: 1.5425, Val Acc: 0.4024, Test Acc: 0.4117\n",
            "Seed: 44, Epoch: 156, Loss: 1.5448, Val Acc: 0.3946, Test Acc: 0.3916\n",
            "Seed: 44, Epoch: 157, Loss: 1.5392, Val Acc: 0.4059, Test Acc: 0.3838\n",
            "Seed: 44, Epoch: 158, Loss: 1.5351, Val Acc: 0.3998, Test Acc: 0.4030\n",
            "Seed: 44, Epoch: 159, Loss: 1.5375, Val Acc: 0.4059, Test Acc: 0.4047\n",
            "Seed: 44, Epoch: 160, Loss: 1.5331, Val Acc: 0.4016, Test Acc: 0.3925\n",
            "Seed: 44, Epoch: 161, Loss: 1.5274, Val Acc: 0.4085, Test Acc: 0.3969\n",
            "Seed: 44, Epoch: 162, Loss: 1.5273, Val Acc: 0.4068, Test Acc: 0.4038\n",
            "Seed: 44, Epoch: 163, Loss: 1.5226, Val Acc: 0.4016, Test Acc: 0.3986\n",
            "Seed: 44, Epoch: 164, Loss: 1.5185, Val Acc: 0.4042, Test Acc: 0.3960\n",
            "Seed: 44, Epoch: 165, Loss: 1.5170, Val Acc: 0.4260, Test Acc: 0.4056\n",
            "Seed: 44, Epoch: 166, Loss: 1.5158, Val Acc: 0.4059, Test Acc: 0.4091\n",
            "Seed: 44, Epoch: 167, Loss: 1.5136, Val Acc: 0.4120, Test Acc: 0.3882\n",
            "Seed: 44, Epoch: 168, Loss: 1.5116, Val Acc: 0.4129, Test Acc: 0.4003\n",
            "Seed: 44, Epoch: 169, Loss: 1.5097, Val Acc: 0.4129, Test Acc: 0.4117\n",
            "Seed: 44, Epoch: 170, Loss: 1.5091, Val Acc: 0.4138, Test Acc: 0.4073\n",
            "Seed: 44, Epoch: 171, Loss: 1.5075, Val Acc: 0.4233, Test Acc: 0.4056\n",
            "Seed: 44, Epoch: 172, Loss: 1.5039, Val Acc: 0.4068, Test Acc: 0.4056\n",
            "Seed: 44, Epoch: 173, Loss: 1.5034, Val Acc: 0.4199, Test Acc: 0.4125\n",
            "Seed: 44, Epoch: 174, Loss: 1.5045, Val Acc: 0.4129, Test Acc: 0.4038\n",
            "Seed: 44, Epoch: 175, Loss: 1.5021, Val Acc: 0.4129, Test Acc: 0.4091\n",
            "Seed: 44, Epoch: 176, Loss: 1.4985, Val Acc: 0.4181, Test Acc: 0.4178\n",
            "Seed: 44, Epoch: 177, Loss: 1.4953, Val Acc: 0.4164, Test Acc: 0.4021\n",
            "Seed: 44, Epoch: 178, Loss: 1.4965, Val Acc: 0.4138, Test Acc: 0.4117\n",
            "Seed: 44, Epoch: 179, Loss: 1.4955, Val Acc: 0.4277, Test Acc: 0.4212\n",
            "Seed: 44, Epoch: 180, Loss: 1.4928, Val Acc: 0.4111, Test Acc: 0.4073\n",
            "Seed: 44, Epoch: 181, Loss: 1.4879, Val Acc: 0.4077, Test Acc: 0.4143\n",
            "Seed: 44, Epoch: 182, Loss: 1.4856, Val Acc: 0.4146, Test Acc: 0.4143\n",
            "Seed: 44, Epoch: 183, Loss: 1.4839, Val Acc: 0.4190, Test Acc: 0.4091\n",
            "Seed: 44, Epoch: 184, Loss: 1.4825, Val Acc: 0.4190, Test Acc: 0.4021\n",
            "Seed: 44, Epoch: 185, Loss: 1.4827, Val Acc: 0.4207, Test Acc: 0.4108\n",
            "Seed: 44, Epoch: 186, Loss: 1.4789, Val Acc: 0.4033, Test Acc: 0.4108\n",
            "Seed: 44, Epoch: 187, Loss: 1.4802, Val Acc: 0.4225, Test Acc: 0.4178\n",
            "Seed: 44, Epoch: 188, Loss: 1.4784, Val Acc: 0.4199, Test Acc: 0.4221\n",
            "Seed: 44, Epoch: 189, Loss: 1.4745, Val Acc: 0.4155, Test Acc: 0.4238\n",
            "Seed: 44, Epoch: 190, Loss: 1.4734, Val Acc: 0.4172, Test Acc: 0.4212\n",
            "Seed: 44, Epoch: 191, Loss: 1.4707, Val Acc: 0.4251, Test Acc: 0.4125\n",
            "Seed: 44, Epoch: 192, Loss: 1.4701, Val Acc: 0.4199, Test Acc: 0.4230\n",
            "Seed: 44, Epoch: 193, Loss: 1.4671, Val Acc: 0.4216, Test Acc: 0.4195\n",
            "Seed: 44, Epoch: 194, Loss: 1.4646, Val Acc: 0.4146, Test Acc: 0.4082\n",
            "Seed: 44, Epoch: 195, Loss: 1.4666, Val Acc: 0.4207, Test Acc: 0.4108\n",
            "Seed: 44, Epoch: 196, Loss: 1.4641, Val Acc: 0.4199, Test Acc: 0.4273\n",
            "Seed: 44, Epoch: 197, Loss: 1.4673, Val Acc: 0.4233, Test Acc: 0.4195\n",
            "Seed: 44, Epoch: 198, Loss: 1.4607, Val Acc: 0.4260, Test Acc: 0.4169\n",
            "Seed: 44, Epoch: 199, Loss: 1.4586, Val Acc: 0.4233, Test Acc: 0.4221\n",
            "Seed: 44, Epoch: 200, Loss: 1.4558, Val Acc: 0.4207, Test Acc: 0.4230\n",
            "Seed: 45, Epoch: 001, Loss: 2.4088, Val Acc: 0.0810, Test Acc: 0.0775\n",
            "Seed: 45, Epoch: 002, Loss: 2.4074, Val Acc: 0.0784, Test Acc: 0.0766\n",
            "Seed: 45, Epoch: 003, Loss: 2.4057, Val Acc: 0.1019, Test Acc: 0.0949\n",
            "Seed: 45, Epoch: 004, Loss: 2.4041, Val Acc: 0.0958, Test Acc: 0.0975\n",
            "Seed: 45, Epoch: 005, Loss: 2.4024, Val Acc: 0.1272, Test Acc: 0.1323\n",
            "Seed: 45, Epoch: 006, Loss: 2.4005, Val Acc: 0.1594, Test Acc: 0.1645\n",
            "Seed: 45, Epoch: 007, Loss: 2.3982, Val Acc: 0.1995, Test Acc: 0.1836\n",
            "Seed: 45, Epoch: 008, Loss: 2.3953, Val Acc: 0.2213, Test Acc: 0.1984\n",
            "Seed: 45, Epoch: 009, Loss: 2.3913, Val Acc: 0.2108, Test Acc: 0.2080\n",
            "Seed: 45, Epoch: 010, Loss: 2.3860, Val Acc: 0.2186, Test Acc: 0.2228\n",
            "Seed: 45, Epoch: 011, Loss: 2.3786, Val Acc: 0.2169, Test Acc: 0.2115\n",
            "Seed: 45, Epoch: 012, Loss: 2.3687, Val Acc: 0.1986, Test Acc: 0.2037\n",
            "Seed: 45, Epoch: 013, Loss: 2.3548, Val Acc: 0.1812, Test Acc: 0.1897\n",
            "Seed: 45, Epoch: 014, Loss: 2.3354, Val Acc: 0.1829, Test Acc: 0.1871\n",
            "Seed: 45, Epoch: 015, Loss: 2.3095, Val Acc: 0.1742, Test Acc: 0.1828\n",
            "Seed: 45, Epoch: 016, Loss: 2.2762, Val Acc: 0.1577, Test Acc: 0.1767\n",
            "Seed: 45, Epoch: 017, Loss: 2.2385, Val Acc: 0.1498, Test Acc: 0.1715\n",
            "Seed: 45, Epoch: 018, Loss: 2.1975, Val Acc: 0.1437, Test Acc: 0.1645\n",
            "Seed: 45, Epoch: 019, Loss: 2.1610, Val Acc: 0.1402, Test Acc: 0.1671\n",
            "Seed: 45, Epoch: 020, Loss: 2.1277, Val Acc: 0.1455, Test Acc: 0.1619\n",
            "Seed: 45, Epoch: 021, Loss: 2.0983, Val Acc: 0.1899, Test Acc: 0.1950\n",
            "Seed: 45, Epoch: 022, Loss: 2.0717, Val Acc: 0.2152, Test Acc: 0.2211\n",
            "Seed: 45, Epoch: 023, Loss: 2.0506, Val Acc: 0.2117, Test Acc: 0.2280\n",
            "Seed: 45, Epoch: 024, Loss: 2.0287, Val Acc: 0.2195, Test Acc: 0.2315\n",
            "Seed: 45, Epoch: 025, Loss: 2.0077, Val Acc: 0.2282, Test Acc: 0.2419\n",
            "Seed: 45, Epoch: 026, Loss: 1.9896, Val Acc: 0.2334, Test Acc: 0.2446\n",
            "Seed: 45, Epoch: 027, Loss: 1.9695, Val Acc: 0.2378, Test Acc: 0.2541\n",
            "Seed: 45, Epoch: 028, Loss: 1.9518, Val Acc: 0.2517, Test Acc: 0.2663\n",
            "Seed: 45, Epoch: 029, Loss: 1.9344, Val Acc: 0.2587, Test Acc: 0.2689\n",
            "Seed: 45, Epoch: 030, Loss: 1.9192, Val Acc: 0.2613, Test Acc: 0.2742\n",
            "Seed: 45, Epoch: 031, Loss: 1.9038, Val Acc: 0.2805, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 032, Loss: 1.8911, Val Acc: 0.2822, Test Acc: 0.2942\n",
            "Seed: 45, Epoch: 033, Loss: 1.8807, Val Acc: 0.2936, Test Acc: 0.2977\n",
            "Seed: 45, Epoch: 034, Loss: 1.8708, Val Acc: 0.2892, Test Acc: 0.2924\n",
            "Seed: 45, Epoch: 035, Loss: 1.8654, Val Acc: 0.2805, Test Acc: 0.3003\n",
            "Seed: 45, Epoch: 036, Loss: 1.8593, Val Acc: 0.3005, Test Acc: 0.3020\n",
            "Seed: 45, Epoch: 037, Loss: 1.8544, Val Acc: 0.2848, Test Acc: 0.2994\n",
            "Seed: 45, Epoch: 038, Loss: 1.8497, Val Acc: 0.2883, Test Acc: 0.3133\n",
            "Seed: 45, Epoch: 039, Loss: 1.8448, Val Acc: 0.3066, Test Acc: 0.3037\n",
            "Seed: 45, Epoch: 040, Loss: 1.8414, Val Acc: 0.3023, Test Acc: 0.3255\n",
            "Seed: 45, Epoch: 041, Loss: 1.8357, Val Acc: 0.2753, Test Acc: 0.3142\n",
            "Seed: 45, Epoch: 042, Loss: 1.8322, Val Acc: 0.3057, Test Acc: 0.3194\n",
            "Seed: 45, Epoch: 043, Loss: 1.8294, Val Acc: 0.3092, Test Acc: 0.3037\n",
            "Seed: 45, Epoch: 044, Loss: 1.8273, Val Acc: 0.2962, Test Acc: 0.3159\n",
            "Seed: 45, Epoch: 045, Loss: 1.8230, Val Acc: 0.2997, Test Acc: 0.3203\n",
            "Seed: 45, Epoch: 046, Loss: 1.8187, Val Acc: 0.2918, Test Acc: 0.2994\n",
            "Seed: 45, Epoch: 047, Loss: 1.8146, Val Acc: 0.3206, Test Acc: 0.3394\n",
            "Seed: 45, Epoch: 048, Loss: 1.8100, Val Acc: 0.3023, Test Acc: 0.3124\n",
            "Seed: 45, Epoch: 049, Loss: 1.8067, Val Acc: 0.3345, Test Acc: 0.3420\n",
            "Seed: 45, Epoch: 050, Loss: 1.8011, Val Acc: 0.3127, Test Acc: 0.3203\n",
            "Seed: 45, Epoch: 051, Loss: 1.7980, Val Acc: 0.3188, Test Acc: 0.3351\n",
            "Seed: 45, Epoch: 052, Loss: 1.7964, Val Acc: 0.3075, Test Acc: 0.3307\n",
            "Seed: 45, Epoch: 053, Loss: 1.7904, Val Acc: 0.3206, Test Acc: 0.3394\n",
            "Seed: 45, Epoch: 054, Loss: 1.7903, Val Acc: 0.3066, Test Acc: 0.3307\n",
            "Seed: 45, Epoch: 055, Loss: 1.7838, Val Acc: 0.3389, Test Acc: 0.3481\n",
            "Seed: 45, Epoch: 056, Loss: 1.7827, Val Acc: 0.3162, Test Acc: 0.3290\n",
            "Seed: 45, Epoch: 057, Loss: 1.7778, Val Acc: 0.3319, Test Acc: 0.3412\n",
            "Seed: 45, Epoch: 058, Loss: 1.7774, Val Acc: 0.3206, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 059, Loss: 1.7720, Val Acc: 0.3197, Test Acc: 0.3342\n",
            "Seed: 45, Epoch: 060, Loss: 1.7681, Val Acc: 0.3136, Test Acc: 0.3307\n",
            "Seed: 45, Epoch: 061, Loss: 1.7642, Val Acc: 0.3293, Test Acc: 0.3438\n",
            "Seed: 45, Epoch: 062, Loss: 1.7590, Val Acc: 0.3214, Test Acc: 0.3464\n",
            "Seed: 45, Epoch: 063, Loss: 1.7574, Val Acc: 0.3336, Test Acc: 0.3351\n",
            "Seed: 45, Epoch: 064, Loss: 1.7522, Val Acc: 0.3345, Test Acc: 0.3394\n",
            "Seed: 45, Epoch: 065, Loss: 1.7491, Val Acc: 0.3328, Test Acc: 0.3351\n",
            "Seed: 45, Epoch: 066, Loss: 1.7465, Val Acc: 0.3362, Test Acc: 0.3534\n",
            "Seed: 45, Epoch: 067, Loss: 1.7428, Val Acc: 0.3240, Test Acc: 0.3325\n",
            "Seed: 45, Epoch: 068, Loss: 1.7401, Val Acc: 0.3397, Test Acc: 0.3603\n",
            "Seed: 45, Epoch: 069, Loss: 1.7390, Val Acc: 0.3362, Test Acc: 0.3412\n",
            "Seed: 45, Epoch: 070, Loss: 1.7345, Val Acc: 0.3484, Test Acc: 0.3490\n",
            "Seed: 45, Epoch: 071, Loss: 1.7329, Val Acc: 0.3345, Test Acc: 0.3525\n",
            "Seed: 45, Epoch: 072, Loss: 1.7273, Val Acc: 0.3423, Test Acc: 0.3603\n",
            "Seed: 45, Epoch: 073, Loss: 1.7259, Val Acc: 0.3502, Test Acc: 0.3464\n",
            "Seed: 45, Epoch: 074, Loss: 1.7218, Val Acc: 0.3484, Test Acc: 0.3560\n",
            "Seed: 45, Epoch: 075, Loss: 1.7215, Val Acc: 0.3406, Test Acc: 0.3568\n",
            "Seed: 45, Epoch: 076, Loss: 1.7175, Val Acc: 0.3484, Test Acc: 0.3516\n",
            "Seed: 45, Epoch: 077, Loss: 1.7148, Val Acc: 0.3571, Test Acc: 0.3673\n",
            "Seed: 45, Epoch: 078, Loss: 1.7116, Val Acc: 0.3537, Test Acc: 0.3621\n",
            "Seed: 45, Epoch: 079, Loss: 1.7084, Val Acc: 0.3510, Test Acc: 0.3612\n",
            "Seed: 45, Epoch: 080, Loss: 1.7060, Val Acc: 0.3537, Test Acc: 0.3681\n",
            "Seed: 45, Epoch: 081, Loss: 1.7030, Val Acc: 0.3458, Test Acc: 0.3603\n",
            "Seed: 45, Epoch: 082, Loss: 1.7008, Val Acc: 0.3537, Test Acc: 0.3699\n",
            "Seed: 45, Epoch: 083, Loss: 1.6988, Val Acc: 0.3563, Test Acc: 0.3655\n",
            "Seed: 45, Epoch: 084, Loss: 1.6958, Val Acc: 0.3493, Test Acc: 0.3577\n",
            "Seed: 45, Epoch: 085, Loss: 1.6954, Val Acc: 0.3754, Test Acc: 0.3795\n",
            "Seed: 45, Epoch: 086, Loss: 1.6906, Val Acc: 0.3519, Test Acc: 0.3751\n",
            "Seed: 45, Epoch: 087, Loss: 1.6882, Val Acc: 0.3772, Test Acc: 0.3681\n",
            "Seed: 45, Epoch: 088, Loss: 1.6848, Val Acc: 0.3650, Test Acc: 0.3890\n",
            "Seed: 45, Epoch: 089, Loss: 1.6822, Val Acc: 0.3850, Test Acc: 0.3847\n",
            "Seed: 45, Epoch: 090, Loss: 1.6838, Val Acc: 0.3563, Test Acc: 0.3638\n",
            "Seed: 45, Epoch: 091, Loss: 1.6785, Val Acc: 0.3789, Test Acc: 0.3751\n",
            "Seed: 45, Epoch: 092, Loss: 1.6750, Val Acc: 0.3894, Test Acc: 0.3838\n",
            "Seed: 45, Epoch: 093, Loss: 1.6728, Val Acc: 0.3650, Test Acc: 0.3803\n",
            "Seed: 45, Epoch: 094, Loss: 1.6694, Val Acc: 0.3667, Test Acc: 0.3725\n",
            "Seed: 45, Epoch: 095, Loss: 1.6689, Val Acc: 0.3728, Test Acc: 0.3751\n",
            "Seed: 45, Epoch: 096, Loss: 1.6669, Val Acc: 0.3737, Test Acc: 0.3795\n",
            "Seed: 45, Epoch: 097, Loss: 1.6638, Val Acc: 0.3798, Test Acc: 0.3882\n",
            "Seed: 45, Epoch: 098, Loss: 1.6621, Val Acc: 0.3798, Test Acc: 0.3795\n",
            "Seed: 45, Epoch: 099, Loss: 1.6593, Val Acc: 0.3868, Test Acc: 0.3838\n",
            "Seed: 45, Epoch: 100, Loss: 1.6575, Val Acc: 0.3902, Test Acc: 0.3829\n",
            "Seed: 45, Epoch: 101, Loss: 1.6543, Val Acc: 0.3815, Test Acc: 0.3882\n",
            "Seed: 45, Epoch: 102, Loss: 1.6536, Val Acc: 0.3650, Test Acc: 0.3760\n",
            "Seed: 45, Epoch: 103, Loss: 1.6519, Val Acc: 0.3815, Test Acc: 0.3890\n",
            "Seed: 45, Epoch: 104, Loss: 1.6496, Val Acc: 0.3859, Test Acc: 0.3847\n",
            "Seed: 45, Epoch: 105, Loss: 1.6455, Val Acc: 0.3859, Test Acc: 0.3882\n",
            "Seed: 45, Epoch: 106, Loss: 1.6435, Val Acc: 0.3902, Test Acc: 0.3969\n",
            "Seed: 45, Epoch: 107, Loss: 1.6409, Val Acc: 0.3815, Test Acc: 0.4056\n",
            "Seed: 45, Epoch: 108, Loss: 1.6392, Val Acc: 0.3841, Test Acc: 0.3916\n",
            "Seed: 45, Epoch: 109, Loss: 1.6355, Val Acc: 0.3859, Test Acc: 0.3847\n",
            "Seed: 45, Epoch: 110, Loss: 1.6336, Val Acc: 0.3841, Test Acc: 0.3951\n",
            "Seed: 45, Epoch: 111, Loss: 1.6333, Val Acc: 0.3824, Test Acc: 0.3995\n",
            "Seed: 45, Epoch: 112, Loss: 1.6298, Val Acc: 0.3911, Test Acc: 0.3977\n",
            "Seed: 45, Epoch: 113, Loss: 1.6244, Val Acc: 0.3807, Test Acc: 0.3847\n",
            "Seed: 45, Epoch: 114, Loss: 1.6241, Val Acc: 0.3850, Test Acc: 0.3916\n",
            "Seed: 45, Epoch: 115, Loss: 1.6188, Val Acc: 0.3885, Test Acc: 0.3934\n",
            "Seed: 45, Epoch: 116, Loss: 1.6207, Val Acc: 0.3937, Test Acc: 0.3899\n",
            "Seed: 45, Epoch: 117, Loss: 1.6152, Val Acc: 0.4007, Test Acc: 0.3873\n",
            "Seed: 45, Epoch: 118, Loss: 1.6149, Val Acc: 0.3990, Test Acc: 0.4134\n",
            "Seed: 45, Epoch: 119, Loss: 1.6112, Val Acc: 0.3920, Test Acc: 0.3934\n",
            "Seed: 45, Epoch: 120, Loss: 1.6116, Val Acc: 0.3990, Test Acc: 0.3960\n",
            "Seed: 45, Epoch: 121, Loss: 1.6082, Val Acc: 0.3955, Test Acc: 0.4056\n",
            "Seed: 45, Epoch: 122, Loss: 1.6071, Val Acc: 0.3798, Test Acc: 0.3995\n",
            "Seed: 45, Epoch: 123, Loss: 1.6040, Val Acc: 0.3981, Test Acc: 0.3908\n",
            "Seed: 45, Epoch: 124, Loss: 1.6015, Val Acc: 0.3833, Test Acc: 0.3882\n",
            "Seed: 45, Epoch: 125, Loss: 1.5998, Val Acc: 0.3885, Test Acc: 0.3951\n",
            "Seed: 45, Epoch: 126, Loss: 1.5980, Val Acc: 0.3850, Test Acc: 0.4056\n",
            "Seed: 45, Epoch: 127, Loss: 1.5948, Val Acc: 0.3850, Test Acc: 0.3908\n",
            "Seed: 45, Epoch: 128, Loss: 1.5910, Val Acc: 0.3937, Test Acc: 0.3890\n",
            "Seed: 45, Epoch: 129, Loss: 1.5895, Val Acc: 0.3894, Test Acc: 0.4082\n",
            "Seed: 45, Epoch: 130, Loss: 1.5926, Val Acc: 0.3885, Test Acc: 0.3951\n",
            "Seed: 45, Epoch: 131, Loss: 1.5907, Val Acc: 0.3981, Test Acc: 0.3943\n",
            "Seed: 45, Epoch: 132, Loss: 1.5833, Val Acc: 0.3911, Test Acc: 0.4117\n",
            "Seed: 45, Epoch: 133, Loss: 1.5818, Val Acc: 0.4024, Test Acc: 0.3960\n",
            "Seed: 45, Epoch: 134, Loss: 1.5804, Val Acc: 0.3868, Test Acc: 0.4117\n",
            "Seed: 45, Epoch: 135, Loss: 1.5762, Val Acc: 0.4059, Test Acc: 0.3995\n",
            "Seed: 45, Epoch: 136, Loss: 1.5764, Val Acc: 0.4042, Test Acc: 0.3925\n",
            "Seed: 45, Epoch: 137, Loss: 1.5754, Val Acc: 0.3990, Test Acc: 0.4099\n",
            "Seed: 45, Epoch: 138, Loss: 1.5718, Val Acc: 0.4051, Test Acc: 0.4186\n",
            "Seed: 45, Epoch: 139, Loss: 1.5704, Val Acc: 0.4007, Test Acc: 0.3986\n",
            "Seed: 45, Epoch: 140, Loss: 1.5692, Val Acc: 0.3937, Test Acc: 0.4117\n",
            "Seed: 45, Epoch: 141, Loss: 1.5672, Val Acc: 0.4068, Test Acc: 0.4204\n",
            "Seed: 45, Epoch: 142, Loss: 1.5674, Val Acc: 0.3963, Test Acc: 0.4091\n",
            "Seed: 45, Epoch: 143, Loss: 1.5654, Val Acc: 0.4042, Test Acc: 0.4186\n",
            "Seed: 45, Epoch: 144, Loss: 1.5650, Val Acc: 0.3946, Test Acc: 0.3969\n",
            "Seed: 45, Epoch: 145, Loss: 1.5676, Val Acc: 0.3955, Test Acc: 0.4221\n",
            "Seed: 45, Epoch: 146, Loss: 1.5640, Val Acc: 0.4051, Test Acc: 0.4047\n",
            "Seed: 45, Epoch: 147, Loss: 1.5663, Val Acc: 0.3998, Test Acc: 0.4143\n",
            "Seed: 45, Epoch: 148, Loss: 1.5656, Val Acc: 0.3929, Test Acc: 0.3977\n",
            "Seed: 45, Epoch: 149, Loss: 1.5604, Val Acc: 0.4155, Test Acc: 0.4247\n",
            "Seed: 45, Epoch: 150, Loss: 1.5626, Val Acc: 0.3955, Test Acc: 0.4178\n",
            "Seed: 45, Epoch: 151, Loss: 1.5601, Val Acc: 0.3876, Test Acc: 0.3977\n",
            "Seed: 45, Epoch: 152, Loss: 1.5680, Val Acc: 0.4077, Test Acc: 0.4195\n",
            "Seed: 45, Epoch: 153, Loss: 1.5613, Val Acc: 0.3981, Test Acc: 0.4195\n",
            "Seed: 45, Epoch: 154, Loss: 1.5595, Val Acc: 0.3998, Test Acc: 0.4064\n",
            "Seed: 45, Epoch: 155, Loss: 1.5717, Val Acc: 0.3859, Test Acc: 0.3986\n",
            "Seed: 45, Epoch: 156, Loss: 1.5860, Val Acc: 0.3737, Test Acc: 0.4108\n",
            "Seed: 45, Epoch: 157, Loss: 1.5787, Val Acc: 0.3894, Test Acc: 0.4012\n",
            "Seed: 45, Epoch: 158, Loss: 1.5715, Val Acc: 0.3902, Test Acc: 0.4082\n",
            "Seed: 45, Epoch: 159, Loss: 1.5654, Val Acc: 0.3894, Test Acc: 0.4178\n",
            "Seed: 45, Epoch: 160, Loss: 1.5583, Val Acc: 0.4042, Test Acc: 0.4169\n",
            "Seed: 45, Epoch: 161, Loss: 1.5575, Val Acc: 0.3990, Test Acc: 0.4108\n",
            "Seed: 45, Epoch: 162, Loss: 1.5535, Val Acc: 0.3937, Test Acc: 0.4091\n",
            "Seed: 45, Epoch: 163, Loss: 1.5512, Val Acc: 0.4051, Test Acc: 0.4056\n",
            "Seed: 45, Epoch: 164, Loss: 1.5511, Val Acc: 0.4120, Test Acc: 0.4091\n",
            "Seed: 45, Epoch: 165, Loss: 1.5479, Val Acc: 0.3981, Test Acc: 0.4021\n",
            "Seed: 45, Epoch: 166, Loss: 1.5460, Val Acc: 0.4120, Test Acc: 0.4160\n",
            "Seed: 45, Epoch: 167, Loss: 1.5472, Val Acc: 0.4016, Test Acc: 0.4038\n",
            "Seed: 45, Epoch: 168, Loss: 1.5419, Val Acc: 0.4120, Test Acc: 0.4073\n",
            "Seed: 45, Epoch: 169, Loss: 1.5411, Val Acc: 0.4172, Test Acc: 0.4064\n",
            "Seed: 45, Epoch: 170, Loss: 1.5343, Val Acc: 0.4172, Test Acc: 0.4082\n",
            "Seed: 45, Epoch: 171, Loss: 1.5331, Val Acc: 0.4085, Test Acc: 0.4125\n",
            "Seed: 45, Epoch: 172, Loss: 1.5325, Val Acc: 0.4059, Test Acc: 0.4082\n",
            "Seed: 45, Epoch: 173, Loss: 1.5310, Val Acc: 0.4181, Test Acc: 0.4195\n",
            "Seed: 45, Epoch: 174, Loss: 1.5284, Val Acc: 0.4042, Test Acc: 0.4143\n",
            "Seed: 45, Epoch: 175, Loss: 1.5252, Val Acc: 0.4120, Test Acc: 0.4091\n",
            "Seed: 45, Epoch: 176, Loss: 1.5227, Val Acc: 0.4120, Test Acc: 0.4299\n",
            "Seed: 45, Epoch: 177, Loss: 1.5191, Val Acc: 0.4146, Test Acc: 0.4317\n",
            "Seed: 45, Epoch: 178, Loss: 1.5141, Val Acc: 0.4077, Test Acc: 0.4247\n",
            "Seed: 45, Epoch: 179, Loss: 1.5108, Val Acc: 0.4103, Test Acc: 0.4230\n",
            "Seed: 45, Epoch: 180, Loss: 1.5135, Val Acc: 0.4190, Test Acc: 0.4282\n",
            "Seed: 45, Epoch: 181, Loss: 1.5090, Val Acc: 0.4051, Test Acc: 0.4125\n",
            "Seed: 45, Epoch: 182, Loss: 1.5058, Val Acc: 0.4164, Test Acc: 0.4195\n",
            "Seed: 45, Epoch: 183, Loss: 1.5025, Val Acc: 0.4181, Test Acc: 0.4195\n",
            "Seed: 45, Epoch: 184, Loss: 1.4985, Val Acc: 0.4181, Test Acc: 0.4343\n",
            "Seed: 45, Epoch: 185, Loss: 1.5008, Val Acc: 0.4251, Test Acc: 0.4143\n",
            "Seed: 45, Epoch: 186, Loss: 1.4975, Val Acc: 0.4242, Test Acc: 0.4169\n",
            "Seed: 45, Epoch: 187, Loss: 1.4930, Val Acc: 0.4164, Test Acc: 0.4186\n",
            "Seed: 45, Epoch: 188, Loss: 1.4920, Val Acc: 0.4068, Test Acc: 0.4195\n",
            "Seed: 45, Epoch: 189, Loss: 1.4954, Val Acc: 0.4033, Test Acc: 0.4247\n",
            "Seed: 45, Epoch: 190, Loss: 1.4988, Val Acc: 0.4138, Test Acc: 0.4134\n",
            "Seed: 45, Epoch: 191, Loss: 1.4930, Val Acc: 0.4111, Test Acc: 0.4230\n",
            "Seed: 45, Epoch: 192, Loss: 1.4983, Val Acc: 0.4155, Test Acc: 0.4378\n",
            "Seed: 45, Epoch: 193, Loss: 1.4987, Val Acc: 0.4042, Test Acc: 0.4256\n",
            "Seed: 45, Epoch: 194, Loss: 1.4947, Val Acc: 0.4033, Test Acc: 0.4212\n",
            "Seed: 45, Epoch: 195, Loss: 1.4884, Val Acc: 0.4181, Test Acc: 0.4343\n",
            "Seed: 45, Epoch: 196, Loss: 1.4908, Val Acc: 0.4111, Test Acc: 0.4247\n",
            "Seed: 45, Epoch: 197, Loss: 1.4824, Val Acc: 0.4094, Test Acc: 0.4282\n",
            "Seed: 45, Epoch: 198, Loss: 1.4905, Val Acc: 0.4146, Test Acc: 0.4273\n",
            "Seed: 45, Epoch: 199, Loss: 1.4835, Val Acc: 0.4111, Test Acc: 0.4282\n",
            "Seed: 45, Epoch: 200, Loss: 1.4789, Val Acc: 0.4138, Test Acc: 0.4343\n",
            "Seed: 46, Epoch: 001, Loss: 2.4025, Val Acc: 0.1080, Test Acc: 0.1097\n",
            "Seed: 46, Epoch: 002, Loss: 2.4012, Val Acc: 0.1080, Test Acc: 0.1079\n",
            "Seed: 46, Epoch: 003, Loss: 2.4000, Val Acc: 0.1080, Test Acc: 0.1079\n",
            "Seed: 46, Epoch: 004, Loss: 2.3983, Val Acc: 0.1368, Test Acc: 0.1393\n",
            "Seed: 46, Epoch: 005, Loss: 2.3961, Val Acc: 0.1446, Test Acc: 0.1427\n",
            "Seed: 46, Epoch: 006, Loss: 2.3931, Val Acc: 0.1638, Test Acc: 0.1636\n",
            "Seed: 46, Epoch: 007, Loss: 2.3892, Val Acc: 0.1725, Test Acc: 0.1732\n",
            "Seed: 46, Epoch: 008, Loss: 2.3842, Val Acc: 0.1873, Test Acc: 0.1828\n",
            "Seed: 46, Epoch: 009, Loss: 2.3783, Val Acc: 0.2021, Test Acc: 0.2002\n",
            "Seed: 46, Epoch: 010, Loss: 2.3705, Val Acc: 0.2117, Test Acc: 0.2054\n",
            "Seed: 46, Epoch: 011, Loss: 2.3611, Val Acc: 0.2117, Test Acc: 0.2019\n",
            "Seed: 46, Epoch: 012, Loss: 2.3488, Val Acc: 0.2134, Test Acc: 0.2115\n",
            "Seed: 46, Epoch: 013, Loss: 2.3322, Val Acc: 0.2143, Test Acc: 0.2141\n",
            "Seed: 46, Epoch: 014, Loss: 2.3097, Val Acc: 0.2064, Test Acc: 0.2028\n",
            "Seed: 46, Epoch: 015, Loss: 2.2807, Val Acc: 0.2195, Test Acc: 0.2237\n",
            "Seed: 46, Epoch: 016, Loss: 2.2455, Val Acc: 0.2108, Test Acc: 0.2237\n",
            "Seed: 46, Epoch: 017, Loss: 2.2051, Val Acc: 0.2030, Test Acc: 0.2141\n",
            "Seed: 46, Epoch: 018, Loss: 2.1634, Val Acc: 0.2038, Test Acc: 0.2350\n",
            "Seed: 46, Epoch: 019, Loss: 2.1221, Val Acc: 0.2195, Test Acc: 0.2315\n",
            "Seed: 46, Epoch: 020, Loss: 2.0857, Val Acc: 0.2282, Test Acc: 0.2341\n",
            "Seed: 46, Epoch: 021, Loss: 2.0547, Val Acc: 0.2265, Test Acc: 0.2341\n",
            "Seed: 46, Epoch: 022, Loss: 2.0291, Val Acc: 0.2169, Test Acc: 0.2332\n",
            "Seed: 46, Epoch: 023, Loss: 2.0085, Val Acc: 0.2030, Test Acc: 0.2306\n",
            "Seed: 46, Epoch: 024, Loss: 1.9887, Val Acc: 0.2030, Test Acc: 0.2289\n",
            "Seed: 46, Epoch: 025, Loss: 1.9714, Val Acc: 0.2456, Test Acc: 0.2567\n",
            "Seed: 46, Epoch: 026, Loss: 1.9560, Val Acc: 0.2570, Test Acc: 0.2628\n",
            "Seed: 46, Epoch: 027, Loss: 1.9424, Val Acc: 0.2474, Test Acc: 0.2567\n",
            "Seed: 46, Epoch: 028, Loss: 1.9287, Val Acc: 0.2300, Test Acc: 0.2541\n",
            "Seed: 46, Epoch: 029, Loss: 1.9177, Val Acc: 0.2500, Test Acc: 0.2628\n",
            "Seed: 46, Epoch: 030, Loss: 1.9090, Val Acc: 0.2465, Test Acc: 0.2637\n",
            "Seed: 46, Epoch: 031, Loss: 1.8998, Val Acc: 0.2439, Test Acc: 0.2559\n",
            "Seed: 46, Epoch: 032, Loss: 1.8939, Val Acc: 0.2474, Test Acc: 0.2663\n",
            "Seed: 46, Epoch: 033, Loss: 1.8875, Val Acc: 0.2552, Test Acc: 0.2707\n",
            "Seed: 46, Epoch: 034, Loss: 1.8813, Val Acc: 0.2535, Test Acc: 0.2733\n",
            "Seed: 46, Epoch: 035, Loss: 1.8793, Val Acc: 0.2465, Test Acc: 0.2594\n",
            "Seed: 46, Epoch: 036, Loss: 1.8754, Val Acc: 0.2535, Test Acc: 0.2637\n",
            "Seed: 46, Epoch: 037, Loss: 1.8725, Val Acc: 0.2561, Test Acc: 0.2646\n",
            "Seed: 46, Epoch: 038, Loss: 1.8668, Val Acc: 0.2683, Test Acc: 0.2872\n",
            "Seed: 46, Epoch: 039, Loss: 1.8620, Val Acc: 0.2631, Test Acc: 0.2742\n",
            "Seed: 46, Epoch: 040, Loss: 1.8567, Val Acc: 0.2570, Test Acc: 0.2654\n",
            "Seed: 46, Epoch: 041, Loss: 1.8521, Val Acc: 0.2639, Test Acc: 0.2768\n",
            "Seed: 46, Epoch: 042, Loss: 1.8500, Val Acc: 0.2613, Test Acc: 0.2742\n",
            "Seed: 46, Epoch: 043, Loss: 1.8454, Val Acc: 0.2718, Test Acc: 0.2837\n",
            "Seed: 46, Epoch: 044, Loss: 1.8446, Val Acc: 0.2639, Test Acc: 0.2829\n",
            "Seed: 46, Epoch: 045, Loss: 1.8391, Val Acc: 0.2613, Test Acc: 0.2698\n",
            "Seed: 46, Epoch: 046, Loss: 1.8372, Val Acc: 0.2674, Test Acc: 0.2768\n",
            "Seed: 46, Epoch: 047, Loss: 1.8339, Val Acc: 0.2674, Test Acc: 0.2837\n",
            "Seed: 46, Epoch: 048, Loss: 1.8332, Val Acc: 0.2700, Test Acc: 0.2820\n",
            "Seed: 46, Epoch: 049, Loss: 1.8278, Val Acc: 0.2700, Test Acc: 0.2750\n",
            "Seed: 46, Epoch: 050, Loss: 1.8253, Val Acc: 0.2875, Test Acc: 0.2977\n",
            "Seed: 46, Epoch: 051, Loss: 1.8206, Val Acc: 0.2866, Test Acc: 0.2916\n",
            "Seed: 46, Epoch: 052, Loss: 1.8185, Val Acc: 0.2787, Test Acc: 0.2924\n",
            "Seed: 46, Epoch: 053, Loss: 1.8162, Val Acc: 0.2753, Test Acc: 0.2820\n",
            "Seed: 46, Epoch: 054, Loss: 1.8151, Val Acc: 0.3057, Test Acc: 0.2924\n",
            "Seed: 46, Epoch: 055, Loss: 1.8102, Val Acc: 0.2875, Test Acc: 0.2942\n",
            "Seed: 46, Epoch: 056, Loss: 1.8073, Val Acc: 0.2883, Test Acc: 0.2942\n",
            "Seed: 46, Epoch: 057, Loss: 1.8021, Val Acc: 0.3031, Test Acc: 0.3020\n",
            "Seed: 46, Epoch: 058, Loss: 1.8010, Val Acc: 0.2918, Test Acc: 0.2881\n",
            "Seed: 46, Epoch: 059, Loss: 1.7982, Val Acc: 0.2883, Test Acc: 0.2942\n",
            "Seed: 46, Epoch: 060, Loss: 1.7939, Val Acc: 0.2979, Test Acc: 0.2942\n",
            "Seed: 46, Epoch: 061, Loss: 1.7919, Val Acc: 0.3057, Test Acc: 0.3090\n",
            "Seed: 46, Epoch: 062, Loss: 1.7898, Val Acc: 0.2979, Test Acc: 0.2959\n",
            "Seed: 46, Epoch: 063, Loss: 1.7887, Val Acc: 0.3014, Test Acc: 0.3029\n",
            "Seed: 46, Epoch: 064, Loss: 1.7848, Val Acc: 0.3127, Test Acc: 0.3264\n",
            "Seed: 46, Epoch: 065, Loss: 1.7808, Val Acc: 0.3179, Test Acc: 0.3229\n",
            "Seed: 46, Epoch: 066, Loss: 1.7785, Val Acc: 0.3005, Test Acc: 0.3037\n",
            "Seed: 46, Epoch: 067, Loss: 1.7753, Val Acc: 0.3127, Test Acc: 0.3185\n",
            "Seed: 46, Epoch: 068, Loss: 1.7733, Val Acc: 0.3101, Test Acc: 0.3185\n",
            "Seed: 46, Epoch: 069, Loss: 1.7718, Val Acc: 0.3206, Test Acc: 0.3194\n",
            "Seed: 46, Epoch: 070, Loss: 1.7697, Val Acc: 0.3057, Test Acc: 0.3116\n",
            "Seed: 46, Epoch: 071, Loss: 1.7657, Val Acc: 0.3267, Test Acc: 0.3107\n",
            "Seed: 46, Epoch: 072, Loss: 1.7624, Val Acc: 0.3197, Test Acc: 0.3194\n",
            "Seed: 46, Epoch: 073, Loss: 1.7608, Val Acc: 0.3136, Test Acc: 0.3264\n",
            "Seed: 46, Epoch: 074, Loss: 1.7576, Val Acc: 0.3092, Test Acc: 0.3133\n",
            "Seed: 46, Epoch: 075, Loss: 1.7563, Val Acc: 0.3275, Test Acc: 0.3307\n",
            "Seed: 46, Epoch: 076, Loss: 1.7523, Val Acc: 0.3162, Test Acc: 0.3229\n",
            "Seed: 46, Epoch: 077, Loss: 1.7514, Val Acc: 0.3040, Test Acc: 0.3194\n",
            "Seed: 46, Epoch: 078, Loss: 1.7492, Val Acc: 0.3380, Test Acc: 0.3299\n",
            "Seed: 46, Epoch: 079, Loss: 1.7489, Val Acc: 0.3206, Test Acc: 0.3264\n",
            "Seed: 46, Epoch: 080, Loss: 1.7438, Val Acc: 0.3328, Test Acc: 0.3316\n",
            "Seed: 46, Epoch: 081, Loss: 1.7416, Val Acc: 0.3319, Test Acc: 0.3412\n",
            "Seed: 46, Epoch: 082, Loss: 1.7411, Val Acc: 0.3110, Test Acc: 0.3090\n",
            "Seed: 46, Epoch: 083, Loss: 1.7388, Val Acc: 0.3249, Test Acc: 0.3299\n",
            "Seed: 46, Epoch: 084, Loss: 1.7353, Val Acc: 0.3301, Test Acc: 0.3429\n",
            "Seed: 46, Epoch: 085, Loss: 1.7327, Val Acc: 0.3310, Test Acc: 0.3325\n",
            "Seed: 46, Epoch: 086, Loss: 1.7315, Val Acc: 0.3275, Test Acc: 0.3403\n",
            "Seed: 46, Epoch: 087, Loss: 1.7285, Val Acc: 0.3232, Test Acc: 0.3281\n",
            "Seed: 46, Epoch: 088, Loss: 1.7258, Val Acc: 0.3484, Test Acc: 0.3455\n",
            "Seed: 46, Epoch: 089, Loss: 1.7221, Val Acc: 0.3223, Test Acc: 0.3290\n",
            "Seed: 46, Epoch: 090, Loss: 1.7195, Val Acc: 0.3362, Test Acc: 0.3359\n",
            "Seed: 46, Epoch: 091, Loss: 1.7175, Val Acc: 0.3449, Test Acc: 0.3299\n",
            "Seed: 46, Epoch: 092, Loss: 1.7163, Val Acc: 0.3476, Test Acc: 0.3542\n",
            "Seed: 46, Epoch: 093, Loss: 1.7138, Val Acc: 0.3293, Test Acc: 0.3359\n",
            "Seed: 46, Epoch: 094, Loss: 1.7113, Val Acc: 0.3406, Test Acc: 0.3455\n",
            "Seed: 46, Epoch: 095, Loss: 1.7095, Val Acc: 0.3267, Test Acc: 0.3386\n",
            "Seed: 46, Epoch: 096, Loss: 1.7059, Val Acc: 0.3589, Test Acc: 0.3568\n",
            "Seed: 46, Epoch: 097, Loss: 1.7050, Val Acc: 0.3545, Test Acc: 0.3473\n",
            "Seed: 46, Epoch: 098, Loss: 1.7002, Val Acc: 0.3293, Test Acc: 0.3438\n",
            "Seed: 46, Epoch: 099, Loss: 1.7008, Val Acc: 0.3528, Test Acc: 0.3542\n",
            "Seed: 46, Epoch: 100, Loss: 1.6965, Val Acc: 0.3606, Test Acc: 0.3542\n",
            "Seed: 46, Epoch: 101, Loss: 1.6955, Val Acc: 0.3580, Test Acc: 0.3534\n",
            "Seed: 46, Epoch: 102, Loss: 1.6923, Val Acc: 0.3502, Test Acc: 0.3507\n",
            "Seed: 46, Epoch: 103, Loss: 1.6912, Val Acc: 0.3432, Test Acc: 0.3438\n",
            "Seed: 46, Epoch: 104, Loss: 1.6882, Val Acc: 0.3537, Test Acc: 0.3629\n",
            "Seed: 46, Epoch: 105, Loss: 1.6854, Val Acc: 0.3484, Test Acc: 0.3577\n",
            "Seed: 46, Epoch: 106, Loss: 1.6845, Val Acc: 0.3510, Test Acc: 0.3594\n",
            "Seed: 46, Epoch: 107, Loss: 1.6825, Val Acc: 0.3641, Test Acc: 0.3664\n",
            "Seed: 46, Epoch: 108, Loss: 1.6798, Val Acc: 0.3467, Test Acc: 0.3499\n",
            "Seed: 46, Epoch: 109, Loss: 1.6800, Val Acc: 0.3641, Test Acc: 0.3734\n",
            "Seed: 46, Epoch: 110, Loss: 1.6794, Val Acc: 0.3310, Test Acc: 0.3568\n",
            "Seed: 46, Epoch: 111, Loss: 1.6739, Val Acc: 0.3571, Test Acc: 0.3708\n",
            "Seed: 46, Epoch: 112, Loss: 1.6718, Val Acc: 0.3502, Test Acc: 0.3568\n",
            "Seed: 46, Epoch: 113, Loss: 1.6704, Val Acc: 0.3650, Test Acc: 0.3638\n",
            "Seed: 46, Epoch: 114, Loss: 1.6684, Val Acc: 0.3685, Test Acc: 0.3664\n",
            "Seed: 46, Epoch: 115, Loss: 1.6642, Val Acc: 0.3632, Test Acc: 0.3673\n",
            "Seed: 46, Epoch: 116, Loss: 1.6618, Val Acc: 0.3537, Test Acc: 0.3690\n",
            "Seed: 46, Epoch: 117, Loss: 1.6615, Val Acc: 0.3493, Test Acc: 0.3655\n",
            "Seed: 46, Epoch: 118, Loss: 1.6600, Val Acc: 0.3624, Test Acc: 0.3699\n",
            "Seed: 46, Epoch: 119, Loss: 1.6545, Val Acc: 0.3589, Test Acc: 0.3629\n",
            "Seed: 46, Epoch: 120, Loss: 1.6533, Val Acc: 0.3659, Test Acc: 0.3708\n",
            "Seed: 46, Epoch: 121, Loss: 1.6521, Val Acc: 0.3711, Test Acc: 0.3751\n",
            "Seed: 46, Epoch: 122, Loss: 1.6486, Val Acc: 0.3624, Test Acc: 0.3612\n",
            "Seed: 46, Epoch: 123, Loss: 1.6459, Val Acc: 0.3693, Test Acc: 0.3664\n",
            "Seed: 46, Epoch: 124, Loss: 1.6436, Val Acc: 0.3693, Test Acc: 0.3716\n",
            "Seed: 46, Epoch: 125, Loss: 1.6407, Val Acc: 0.3598, Test Acc: 0.3734\n",
            "Seed: 46, Epoch: 126, Loss: 1.6398, Val Acc: 0.3650, Test Acc: 0.3725\n",
            "Seed: 46, Epoch: 127, Loss: 1.6376, Val Acc: 0.3606, Test Acc: 0.3629\n",
            "Seed: 46, Epoch: 128, Loss: 1.6358, Val Acc: 0.3685, Test Acc: 0.3638\n",
            "Seed: 46, Epoch: 129, Loss: 1.6353, Val Acc: 0.3702, Test Acc: 0.3786\n",
            "Seed: 46, Epoch: 130, Loss: 1.6295, Val Acc: 0.3632, Test Acc: 0.3699\n",
            "Seed: 46, Epoch: 131, Loss: 1.6289, Val Acc: 0.3667, Test Acc: 0.3760\n",
            "Seed: 46, Epoch: 132, Loss: 1.6262, Val Acc: 0.3580, Test Acc: 0.3734\n",
            "Seed: 46, Epoch: 133, Loss: 1.6251, Val Acc: 0.3798, Test Acc: 0.3603\n",
            "Seed: 46, Epoch: 134, Loss: 1.6234, Val Acc: 0.3789, Test Acc: 0.3751\n",
            "Seed: 46, Epoch: 135, Loss: 1.6223, Val Acc: 0.3641, Test Acc: 0.3768\n",
            "Seed: 46, Epoch: 136, Loss: 1.6183, Val Acc: 0.3685, Test Acc: 0.3873\n",
            "Seed: 46, Epoch: 137, Loss: 1.6149, Val Acc: 0.3676, Test Acc: 0.3681\n",
            "Seed: 46, Epoch: 138, Loss: 1.6143, Val Acc: 0.3737, Test Acc: 0.3786\n",
            "Seed: 46, Epoch: 139, Loss: 1.6126, Val Acc: 0.3632, Test Acc: 0.3760\n",
            "Seed: 46, Epoch: 140, Loss: 1.6105, Val Acc: 0.3754, Test Acc: 0.3882\n",
            "Seed: 46, Epoch: 141, Loss: 1.6093, Val Acc: 0.3798, Test Acc: 0.3890\n",
            "Seed: 46, Epoch: 142, Loss: 1.6055, Val Acc: 0.3528, Test Acc: 0.3690\n",
            "Seed: 46, Epoch: 143, Loss: 1.6064, Val Acc: 0.3746, Test Acc: 0.3838\n",
            "Seed: 46, Epoch: 144, Loss: 1.6021, Val Acc: 0.3807, Test Acc: 0.3882\n",
            "Seed: 46, Epoch: 145, Loss: 1.6000, Val Acc: 0.3841, Test Acc: 0.3777\n",
            "Seed: 46, Epoch: 146, Loss: 1.5985, Val Acc: 0.3780, Test Acc: 0.3890\n",
            "Seed: 46, Epoch: 147, Loss: 1.5938, Val Acc: 0.3693, Test Acc: 0.3856\n",
            "Seed: 46, Epoch: 148, Loss: 1.5927, Val Acc: 0.3772, Test Acc: 0.3890\n",
            "Seed: 46, Epoch: 149, Loss: 1.5921, Val Acc: 0.3911, Test Acc: 0.4030\n",
            "Seed: 46, Epoch: 150, Loss: 1.5892, Val Acc: 0.3824, Test Acc: 0.4003\n",
            "Seed: 46, Epoch: 151, Loss: 1.5891, Val Acc: 0.3789, Test Acc: 0.3847\n",
            "Seed: 46, Epoch: 152, Loss: 1.5874, Val Acc: 0.3894, Test Acc: 0.4003\n",
            "Seed: 46, Epoch: 153, Loss: 1.5917, Val Acc: 0.3859, Test Acc: 0.4047\n",
            "Seed: 46, Epoch: 154, Loss: 1.5878, Val Acc: 0.3737, Test Acc: 0.3890\n",
            "Seed: 46, Epoch: 155, Loss: 1.5827, Val Acc: 0.3885, Test Acc: 0.3951\n",
            "Seed: 46, Epoch: 156, Loss: 1.5822, Val Acc: 0.3746, Test Acc: 0.3812\n",
            "Seed: 46, Epoch: 157, Loss: 1.5769, Val Acc: 0.3824, Test Acc: 0.4082\n",
            "Seed: 46, Epoch: 158, Loss: 1.5720, Val Acc: 0.3876, Test Acc: 0.3943\n",
            "Seed: 46, Epoch: 159, Loss: 1.5708, Val Acc: 0.3824, Test Acc: 0.3847\n",
            "Seed: 46, Epoch: 160, Loss: 1.5690, Val Acc: 0.3859, Test Acc: 0.3969\n",
            "Seed: 46, Epoch: 161, Loss: 1.5674, Val Acc: 0.3789, Test Acc: 0.3873\n",
            "Seed: 46, Epoch: 162, Loss: 1.5671, Val Acc: 0.3702, Test Acc: 0.3916\n",
            "Seed: 46, Epoch: 163, Loss: 1.5648, Val Acc: 0.3876, Test Acc: 0.4003\n",
            "Seed: 46, Epoch: 164, Loss: 1.5632, Val Acc: 0.3972, Test Acc: 0.4047\n",
            "Seed: 46, Epoch: 165, Loss: 1.5592, Val Acc: 0.3850, Test Acc: 0.3969\n",
            "Seed: 46, Epoch: 166, Loss: 1.5583, Val Acc: 0.3833, Test Acc: 0.4056\n",
            "Seed: 46, Epoch: 167, Loss: 1.5567, Val Acc: 0.3902, Test Acc: 0.4047\n",
            "Seed: 46, Epoch: 168, Loss: 1.5539, Val Acc: 0.3876, Test Acc: 0.4003\n",
            "Seed: 46, Epoch: 169, Loss: 1.5545, Val Acc: 0.3772, Test Acc: 0.4021\n",
            "Seed: 46, Epoch: 170, Loss: 1.5522, Val Acc: 0.3772, Test Acc: 0.3977\n",
            "Seed: 46, Epoch: 171, Loss: 1.5524, Val Acc: 0.3885, Test Acc: 0.4021\n",
            "Seed: 46, Epoch: 172, Loss: 1.5472, Val Acc: 0.3955, Test Acc: 0.4012\n",
            "Seed: 46, Epoch: 173, Loss: 1.5440, Val Acc: 0.3868, Test Acc: 0.4038\n",
            "Seed: 46, Epoch: 174, Loss: 1.5413, Val Acc: 0.3946, Test Acc: 0.4064\n",
            "Seed: 46, Epoch: 175, Loss: 1.5393, Val Acc: 0.3815, Test Acc: 0.3969\n",
            "Seed: 46, Epoch: 176, Loss: 1.5392, Val Acc: 0.3955, Test Acc: 0.4125\n",
            "Seed: 46, Epoch: 177, Loss: 1.5364, Val Acc: 0.3937, Test Acc: 0.4047\n",
            "Seed: 46, Epoch: 178, Loss: 1.5343, Val Acc: 0.3929, Test Acc: 0.4030\n",
            "Seed: 46, Epoch: 179, Loss: 1.5324, Val Acc: 0.4033, Test Acc: 0.4021\n",
            "Seed: 46, Epoch: 180, Loss: 1.5293, Val Acc: 0.3981, Test Acc: 0.4038\n",
            "Seed: 46, Epoch: 181, Loss: 1.5280, Val Acc: 0.3963, Test Acc: 0.4056\n",
            "Seed: 46, Epoch: 182, Loss: 1.5266, Val Acc: 0.3894, Test Acc: 0.4064\n",
            "Seed: 46, Epoch: 183, Loss: 1.5244, Val Acc: 0.3937, Test Acc: 0.4003\n",
            "Seed: 46, Epoch: 184, Loss: 1.5234, Val Acc: 0.3911, Test Acc: 0.4047\n",
            "Seed: 46, Epoch: 185, Loss: 1.5243, Val Acc: 0.3937, Test Acc: 0.3995\n",
            "Seed: 46, Epoch: 186, Loss: 1.5216, Val Acc: 0.3998, Test Acc: 0.4064\n",
            "Seed: 46, Epoch: 187, Loss: 1.5216, Val Acc: 0.3972, Test Acc: 0.4047\n",
            "Seed: 46, Epoch: 188, Loss: 1.5174, Val Acc: 0.4033, Test Acc: 0.4160\n",
            "Seed: 46, Epoch: 189, Loss: 1.5158, Val Acc: 0.4085, Test Acc: 0.4143\n",
            "Seed: 46, Epoch: 190, Loss: 1.5138, Val Acc: 0.3911, Test Acc: 0.4021\n",
            "Seed: 46, Epoch: 191, Loss: 1.5141, Val Acc: 0.4042, Test Acc: 0.4108\n",
            "Seed: 46, Epoch: 192, Loss: 1.5109, Val Acc: 0.3946, Test Acc: 0.4038\n",
            "Seed: 46, Epoch: 193, Loss: 1.5088, Val Acc: 0.3911, Test Acc: 0.4082\n",
            "Seed: 46, Epoch: 194, Loss: 1.5089, Val Acc: 0.3990, Test Acc: 0.4169\n",
            "Seed: 46, Epoch: 195, Loss: 1.5062, Val Acc: 0.3946, Test Acc: 0.4021\n",
            "Seed: 46, Epoch: 196, Loss: 1.5059, Val Acc: 0.4103, Test Acc: 0.4038\n",
            "Seed: 46, Epoch: 197, Loss: 1.5030, Val Acc: 0.4016, Test Acc: 0.4117\n",
            "Seed: 46, Epoch: 198, Loss: 1.5026, Val Acc: 0.4033, Test Acc: 0.4056\n",
            "Seed: 46, Epoch: 199, Loss: 1.5000, Val Acc: 0.4007, Test Acc: 0.4091\n",
            "Seed: 46, Epoch: 200, Loss: 1.5008, Val Acc: 0.3990, Test Acc: 0.4117\n",
            "Average Time: 229.91 seconds\n",
            "Var Time: 15.41 seconds\n",
            "Average Memory: 6041.20 MB\n",
            "Average Best Val Acc: 0.4343\n",
            "Std Best Test Acc: 0.0202\n",
            "Average Test Acc: 0.4279\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, ASAPooling\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "from torch_geometric.nn import BatchNorm\n",
        "\n",
        "class HierarchicalGCN_ASA(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes):\n",
        "        super(HierarchicalGCN_ASA, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.pool1 = ASAPooling(hidden_channels, ratio=0.5)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.pool2 = ASAPooling(hidden_channels, ratio=0.5)\n",
        "        self.conv3 = SAGEConv(hidden_channels, out_channels)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.lin1 = torch.nn.Linear(out_channels, 32)\n",
        "        self.lin2 = torch.nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        # First GCN and pooling layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn1(x)\n",
        "        x, edge_index, _, batch, _ = self.pool1(x, edge_index, batch=batch)\n",
        "\n",
        "        # Second GCN and pooling layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn2(x)\n",
        "        x, edge_index, _, batch, _ = self.pool2(x, edge_index, batch=batch)\n",
        "\n",
        "        # Third GCN layer\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn3(x)\n",
        "\n",
        "        # Mean pooling over the nodes\n",
        "        x, mask = to_dense_batch(x, batch)\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.lin1(x).relu()\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "num_classes = dataset_sparse.num_classes\n",
        "in_channels = dataset_sparse.num_features\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HierarchicalGCN_ASA(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        data.y = data.y.to(torch.long)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == data.y).sum().item()\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seeds = [42, 43, 44, 45, 46]\n",
        "times = []\n",
        "memories = []\n",
        "best_val_accs = []\n",
        "best_test_accs = []\n",
        "\n",
        "early_stop_patience = 150\n",
        "tolerance = 0.0001\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    model = HierarchicalGCN_ASA(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        val_acc = test(valid_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        if val_acc > best_val_acc + tolerance:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "        if epochs_no_improve >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
        "\n",
        "    times.append(total_time)\n",
        "    memories.append(memory_allocated)\n",
        "    best_val_accs.append(best_val_acc)\n",
        "    best_test_accs.append(best_test_acc)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
        "print(f'Var Time: {np.var(times):.2f} seconds')\n",
        "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
        "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
        "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
        "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaCvb0TnpjHJ"
      },
      "source": [
        "## PANPooling with HierarchicalGCN (2020)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8Iv2AsUpiVT"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
        "from torch_sparse import spspmm\n",
        "from torch_sparse import coalesce\n",
        "from torch_sparse import eye\n",
        "from torch.nn import Parameter\n",
        "from torch_scatter import scatter_add\n",
        "from torch_scatter import scatter_max\n",
        "\n",
        "class PANPooling(torch.nn.Module):\n",
        "    r\"\"\" General Graph pooling layer based on PAN, which can work with all layers.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, ratio=0.5, pan_pool_weight=None, min_score=None, multiplier=1,\n",
        "                 nonlinearity=torch.tanh, filter_size=3, panpool_filter_weight=None):\n",
        "        super(PANPooling, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.ratio = ratio\n",
        "        self.min_score = min_score\n",
        "        self.multiplier = multiplier\n",
        "        self.nonlinearity = nonlinearity\n",
        "\n",
        "        self.filter_size = filter_size\n",
        "        if panpool_filter_weight is None:\n",
        "            self.panpool_filter_weight = torch.nn.Parameter(0.5 * torch.ones(filter_size), requires_grad=True)\n",
        "\n",
        "        self.transform = Parameter(torch.ones(in_channels), requires_grad=True)\n",
        "\n",
        "        if pan_pool_weight is None:\n",
        "            #self.weight = torch.tensor([0.7, 0.3], device=self.transform.device)\n",
        "            self.pan_pool_weight = torch.nn.Parameter(0.5 * torch.ones(2), requires_grad=True)\n",
        "        else:\n",
        "            self.pan_pool_weight = pan_pool_weight\n",
        "\n",
        "    def forward(self, x, edge_index, M=None, batch=None, num_nodes=None):\n",
        "\n",
        "        \"\"\"\"\"\"\n",
        "        if batch is None:\n",
        "            batch = edge_index.new_zeros(x.size(0))\n",
        "\n",
        "        # Path integral\n",
        "        num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
        "        edge_index, edge_weight = self.panentropy_sparse(edge_index, num_nodes)\n",
        "\n",
        "        # weighted degree\n",
        "        num_nodes = x.size(0)\n",
        "        degree = torch.zeros(num_nodes, device=edge_index.device)\n",
        "        degree = scatter_add(edge_weight, edge_index[0], out=degree)\n",
        "\n",
        "        # linear transform\n",
        "        xtransform = torch.matmul(x, self.transform)\n",
        "\n",
        "        # aggregate score\n",
        "        x_transform_norm = xtransform #/ xtransform.norm(p=2, dim=-1)\n",
        "        degree_norm = degree #/ degree.norm(p=2, dim=-1)\n",
        "        score = self.pan_pool_weight[0] * x_transform_norm + self.pan_pool_weight[1] * degree_norm\n",
        "\n",
        "        if self.min_score is None:\n",
        "            score = self.nonlinearity(score)\n",
        "        else:\n",
        "            score = softmax(score, batch)\n",
        "\n",
        "        perm = self.topk(score, self.ratio, batch, self.min_score)\n",
        "        x = x[perm] * score[perm].view(-1, 1)\n",
        "        x = self.multiplier * x if self.multiplier != 1 else x\n",
        "\n",
        "        batch = batch[perm]\n",
        "        edge_index, edge_weight = self.filter_adj(edge_index, edge_weight, perm, num_nodes=score.size(0))\n",
        "\n",
        "        return x, edge_index, edge_weight, batch, perm, score[perm]\n",
        "\n",
        "    def topk(self, x, ratio, batch, min_score=None, tol=1e-7):\n",
        "\n",
        "        if min_score is not None:\n",
        "            # Make sure that we do not drop all nodes in a graph.\n",
        "            scores_max = scatter_max(x, batch)[0][batch] - tol\n",
        "            scores_min = scores_max.clamp(max=min_score)\n",
        "\n",
        "            perm = torch.nonzero(x > scores_min).view(-1)\n",
        "        else:\n",
        "            num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)\n",
        "            batch_size, max_num_nodes = num_nodes.size(0), num_nodes.max().item()\n",
        "\n",
        "            cum_num_nodes = torch.cat(\n",
        "                [num_nodes.new_zeros(1),\n",
        "                 num_nodes.cumsum(dim=0)[:-1]], dim=0)\n",
        "\n",
        "            index = torch.arange(batch.size(0), dtype=torch.long, device=x.device)\n",
        "            index = (index - cum_num_nodes[batch]) + (batch * max_num_nodes)\n",
        "\n",
        "            dense_x = x.new_full((batch_size * max_num_nodes, ), -2)\n",
        "            dense_x[index] = x\n",
        "            dense_x = dense_x.view(batch_size, max_num_nodes)\n",
        "\n",
        "            _, perm = dense_x.sort(dim=-1, descending=True)\n",
        "\n",
        "            perm = perm + cum_num_nodes.view(-1, 1)\n",
        "            perm = perm.view(-1)\n",
        "\n",
        "            k = (ratio * num_nodes.to(torch.float)).ceil().to(torch.long)\n",
        "            mask = [\n",
        "                torch.arange(k[i], dtype=torch.long, device=x.device) +\n",
        "                i * max_num_nodes for i in range(batch_size)\n",
        "            ]\n",
        "            mask = torch.cat(mask, dim=0)\n",
        "\n",
        "            perm = perm[mask]\n",
        "\n",
        "        return perm\n",
        "\n",
        "    def filter_adj(self, edge_index, edge_weight, perm, num_nodes=None):\n",
        "\n",
        "        num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
        "\n",
        "        mask = perm.new_full((num_nodes, ), -1)\n",
        "        i = torch.arange(perm.size(0), dtype=torch.long, device=perm.device)\n",
        "        mask[perm] = i\n",
        "\n",
        "        row, col = edge_index\n",
        "        row, col = mask[row], mask[col]\n",
        "        mask = (row >= 0) & (col >= 0)\n",
        "        row, col = row[mask], col[mask]\n",
        "\n",
        "        if edge_weight is not None:\n",
        "            edge_weight = edge_weight[mask]\n",
        "\n",
        "        return torch.stack([row, col], dim=0), edge_weight\n",
        "\n",
        "    def panentropy_sparse(self, edge_index, num_nodes):\n",
        "\n",
        "        edge_value = torch.ones(edge_index.size(1), device=edge_index.device)\n",
        "        edge_index, edge_value = coalesce(edge_index, edge_value, num_nodes, num_nodes)\n",
        "\n",
        "        # iteratively add weighted matrix power\n",
        "        pan_index, pan_value = eye(num_nodes, device=edge_index.device)\n",
        "        indextmp = pan_index.clone().to(edge_index.device)\n",
        "        valuetmp = pan_value.clone().to(edge_index.device)\n",
        "\n",
        "        pan_value = self.panpool_filter_weight[0] * pan_value\n",
        "\n",
        "        for i in range(self.filter_size - 1):\n",
        "            #indextmp, valuetmp = coalesce(indextmp, valuetmp, num_nodes, num_nodes)\n",
        "            indextmp, valuetmp = spspmm(indextmp, valuetmp, edge_index, edge_value, num_nodes, num_nodes, num_nodes)\n",
        "            valuetmp = valuetmp * self.panpool_filter_weight[i+1]\n",
        "            indextmp, valuetmp = coalesce(indextmp, valuetmp, num_nodes, num_nodes)\n",
        "            pan_index = torch.cat((pan_index, indextmp), 1)\n",
        "            pan_value = torch.cat((pan_value, valuetmp))\n",
        "\n",
        "        return coalesce(pan_index, pan_value, num_nodes, num_nodes, op='add')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQs0dBf0rVkj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 001, Loss: 1.8030, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 002, Loss: 1.7840, Val Acc: 0.2111, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 003, Loss: 1.7759, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 004, Loss: 1.7684, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 005, Loss: 1.7633, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 006, Loss: 1.7576, Val Acc: 0.2000, Test Acc: 0.2222\n",
            "Seed: 42, Epoch: 007, Loss: 1.7536, Val Acc: 0.2111, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 008, Loss: 1.7470, Val Acc: 0.1889, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 009, Loss: 1.7401, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 010, Loss: 1.7354, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 011, Loss: 1.7289, Val Acc: 0.2000, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 012, Loss: 1.7173, Val Acc: 0.2000, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 013, Loss: 1.7138, Val Acc: 0.2000, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 014, Loss: 1.7093, Val Acc: 0.2111, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 015, Loss: 1.7015, Val Acc: 0.2000, Test Acc: 0.2222\n",
            "Seed: 42, Epoch: 016, Loss: 1.6985, Val Acc: 0.2000, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 017, Loss: 1.6954, Val Acc: 0.1778, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 018, Loss: 1.6825, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 019, Loss: 1.6765, Val Acc: 0.1889, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 020, Loss: 1.6720, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 021, Loss: 1.6805, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 022, Loss: 1.6751, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 023, Loss: 1.6656, Val Acc: 0.2000, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 024, Loss: 1.6731, Val Acc: 0.2000, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 025, Loss: 1.6552, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 026, Loss: 1.6590, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 027, Loss: 1.6517, Val Acc: 0.1889, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 028, Loss: 1.6471, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 029, Loss: 1.6338, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 030, Loss: 1.6325, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 031, Loss: 1.6264, Val Acc: 0.2111, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 032, Loss: 1.6247, Val Acc: 0.2222, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 033, Loss: 1.6227, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 034, Loss: 1.6156, Val Acc: 0.2222, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 035, Loss: 1.6066, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 036, Loss: 1.6187, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 037, Loss: 1.6014, Val Acc: 0.3222, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 038, Loss: 1.6035, Val Acc: 0.2000, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 039, Loss: 1.6041, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 040, Loss: 1.6042, Val Acc: 0.2111, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 041, Loss: 1.5817, Val Acc: 0.2111, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 042, Loss: 1.5871, Val Acc: 0.2000, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 043, Loss: 1.5756, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 044, Loss: 1.5722, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 045, Loss: 1.5743, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 046, Loss: 1.5715, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 047, Loss: 1.5512, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 048, Loss: 1.5600, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 049, Loss: 1.5556, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 050, Loss: 1.5634, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 051, Loss: 1.5497, Val Acc: 0.2000, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 052, Loss: 1.5586, Val Acc: 0.2111, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 053, Loss: 1.5393, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 054, Loss: 1.5369, Val Acc: 0.2222, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 055, Loss: 1.5328, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 056, Loss: 1.5274, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 057, Loss: 1.5397, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 058, Loss: 1.5273, Val Acc: 0.2111, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 059, Loss: 1.5235, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 060, Loss: 1.4903, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 061, Loss: 1.5304, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 062, Loss: 1.5039, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 063, Loss: 1.5150, Val Acc: 0.2000, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 064, Loss: 1.4942, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 065, Loss: 1.5134, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 066, Loss: 1.5165, Val Acc: 0.2222, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 067, Loss: 1.4967, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 068, Loss: 1.4929, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 069, Loss: 1.4804, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 070, Loss: 1.4676, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 071, Loss: 1.5025, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 072, Loss: 1.4720, Val Acc: 0.1889, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 073, Loss: 1.4833, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 074, Loss: 1.5125, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 075, Loss: 1.4963, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 076, Loss: 1.4728, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 077, Loss: 1.4934, Val Acc: 0.2222, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 078, Loss: 1.4800, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 079, Loss: 1.4833, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 080, Loss: 1.4743, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 081, Loss: 1.4497, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 082, Loss: 1.4522, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 083, Loss: 1.4459, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 084, Loss: 1.4168, Val Acc: 0.2111, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 085, Loss: 1.4396, Val Acc: 0.2000, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 086, Loss: 1.4298, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 087, Loss: 1.4306, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 088, Loss: 1.4074, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 089, Loss: 1.4208, Val Acc: 0.2111, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 090, Loss: 1.4256, Val Acc: 0.2222, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 091, Loss: 1.4073, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 092, Loss: 1.4119, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 093, Loss: 1.4266, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 094, Loss: 1.4025, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 095, Loss: 1.4198, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 096, Loss: 1.3998, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 097, Loss: 1.3908, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 098, Loss: 1.3877, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 099, Loss: 1.4093, Val Acc: 0.2222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 100, Loss: 1.3878, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 101, Loss: 1.3791, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 102, Loss: 1.3835, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 103, Loss: 1.3730, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 104, Loss: 1.3483, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 105, Loss: 1.3588, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 106, Loss: 1.3508, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 107, Loss: 1.3648, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 108, Loss: 1.4027, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 109, Loss: 1.4077, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 110, Loss: 1.3668, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 111, Loss: 1.4034, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 112, Loss: 1.3746, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 113, Loss: 1.3587, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 114, Loss: 1.3439, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 115, Loss: 1.3658, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 116, Loss: 1.3463, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 117, Loss: 1.3302, Val Acc: 0.2889, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 118, Loss: 1.3360, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 119, Loss: 1.3100, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 120, Loss: 1.3145, Val Acc: 0.2778, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 121, Loss: 1.2982, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 122, Loss: 1.2910, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 123, Loss: 1.3213, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 124, Loss: 1.3297, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 125, Loss: 1.3124, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 126, Loss: 1.2907, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 127, Loss: 1.3180, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 128, Loss: 1.2801, Val Acc: 0.2444, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 129, Loss: 1.2780, Val Acc: 0.2222, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 130, Loss: 1.2857, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 131, Loss: 1.2740, Val Acc: 0.2444, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 132, Loss: 1.2635, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 133, Loss: 1.2672, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 134, Loss: 1.2482, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 135, Loss: 1.2328, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 136, Loss: 1.2376, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 137, Loss: 1.2413, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 138, Loss: 1.2252, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 139, Loss: 1.2432, Val Acc: 0.2222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 140, Loss: 1.2318, Val Acc: 0.2667, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 141, Loss: 1.2174, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 142, Loss: 1.2287, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 143, Loss: 1.2020, Val Acc: 0.2444, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 144, Loss: 1.2197, Val Acc: 0.2667, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 145, Loss: 1.1960, Val Acc: 0.2667, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 146, Loss: 1.2532, Val Acc: 0.2556, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 147, Loss: 1.2300, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 148, Loss: 1.2081, Val Acc: 0.2667, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 149, Loss: 1.2088, Val Acc: 0.2778, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 150, Loss: 1.2112, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 151, Loss: 1.2058, Val Acc: 0.2444, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 152, Loss: 1.1945, Val Acc: 0.2667, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 153, Loss: 1.1777, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 154, Loss: 1.2255, Val Acc: 0.2444, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 155, Loss: 1.1821, Val Acc: 0.2111, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 156, Loss: 1.1949, Val Acc: 0.2000, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 157, Loss: 1.1703, Val Acc: 0.2778, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 158, Loss: 1.1603, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 159, Loss: 1.1747, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 160, Loss: 1.1706, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 161, Loss: 1.1878, Val Acc: 0.2889, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 162, Loss: 1.1552, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 163, Loss: 1.1523, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 164, Loss: 1.1562, Val Acc: 0.2556, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 165, Loss: 1.1455, Val Acc: 0.2778, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 166, Loss: 1.1375, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 167, Loss: 1.1302, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 168, Loss: 1.1360, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 169, Loss: 1.1197, Val Acc: 0.2556, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 170, Loss: 1.1177, Val Acc: 0.2556, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 171, Loss: 1.1185, Val Acc: 0.2667, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 172, Loss: 1.1147, Val Acc: 0.2889, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 173, Loss: 1.1099, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 174, Loss: 1.2526, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 175, Loss: 1.1387, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 176, Loss: 1.1449, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 177, Loss: 1.1818, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 178, Loss: 1.1444, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 179, Loss: 1.1083, Val Acc: 0.2889, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 180, Loss: 1.1351, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 181, Loss: 1.1082, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 182, Loss: 1.0881, Val Acc: 0.2667, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 183, Loss: 1.0947, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 184, Loss: 1.0565, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 185, Loss: 1.0806, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 186, Loss: 1.0777, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 187, Loss: 1.0846, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Early stopping at epoch 187 for seed 42\n",
            "Seed: 43, Epoch: 001, Loss: 1.8083, Val Acc: 0.2556, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 002, Loss: 1.7878, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 003, Loss: 1.7805, Val Acc: 0.2000, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 004, Loss: 1.7762, Val Acc: 0.2111, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 005, Loss: 1.7726, Val Acc: 0.2111, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 006, Loss: 1.7689, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 007, Loss: 1.7666, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 008, Loss: 1.7728, Val Acc: 0.2111, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 009, Loss: 1.7561, Val Acc: 0.2444, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 010, Loss: 1.7548, Val Acc: 0.2333, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 011, Loss: 1.7557, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 012, Loss: 1.7481, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 013, Loss: 1.7436, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 014, Loss: 1.7322, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 015, Loss: 1.7306, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 016, Loss: 1.7242, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 017, Loss: 1.7182, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 018, Loss: 1.7130, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 019, Loss: 1.7089, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 020, Loss: 1.7061, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 021, Loss: 1.7031, Val Acc: 0.2556, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 022, Loss: 1.7006, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 023, Loss: 1.6958, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 024, Loss: 1.6914, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 025, Loss: 1.6872, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 026, Loss: 1.6827, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 027, Loss: 1.6828, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 028, Loss: 1.6795, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 029, Loss: 1.6690, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 030, Loss: 1.6676, Val Acc: 0.2444, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 031, Loss: 1.6715, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 032, Loss: 1.6638, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 033, Loss: 1.6628, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 034, Loss: 1.6526, Val Acc: 0.2778, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 035, Loss: 1.6540, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 036, Loss: 1.6478, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 037, Loss: 1.6495, Val Acc: 0.2778, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 038, Loss: 1.6425, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 039, Loss: 1.6455, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 040, Loss: 1.6384, Val Acc: 0.2778, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 041, Loss: 1.6408, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 042, Loss: 1.6292, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 043, Loss: 1.6327, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 044, Loss: 1.6314, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 045, Loss: 1.6234, Val Acc: 0.2778, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 046, Loss: 1.6174, Val Acc: 0.2778, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 047, Loss: 1.6291, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 048, Loss: 1.6181, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 049, Loss: 1.6276, Val Acc: 0.2556, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 050, Loss: 1.6190, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 051, Loss: 1.6130, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 052, Loss: 1.6037, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 053, Loss: 1.6000, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 054, Loss: 1.5963, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 055, Loss: 1.5939, Val Acc: 0.2444, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 056, Loss: 1.5956, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 057, Loss: 1.5870, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 058, Loss: 1.5850, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 059, Loss: 1.5817, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 060, Loss: 1.5744, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 061, Loss: 1.5724, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 062, Loss: 1.5732, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 063, Loss: 1.5749, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 064, Loss: 1.5697, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 065, Loss: 1.5603, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 066, Loss: 1.5671, Val Acc: 0.2667, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 067, Loss: 1.5524, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 068, Loss: 1.5637, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 069, Loss: 1.5470, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 070, Loss: 1.5719, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 071, Loss: 1.5566, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 072, Loss: 1.5372, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 073, Loss: 1.5420, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 074, Loss: 1.5282, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 075, Loss: 1.5318, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 076, Loss: 1.5204, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 077, Loss: 1.5190, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 078, Loss: 1.5170, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 079, Loss: 1.5078, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 080, Loss: 1.5028, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 081, Loss: 1.4957, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 082, Loss: 1.4996, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 083, Loss: 1.4794, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 084, Loss: 1.4849, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 085, Loss: 1.4908, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 086, Loss: 1.4902, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 087, Loss: 1.4725, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 088, Loss: 1.4699, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 089, Loss: 1.4793, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 090, Loss: 1.4750, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 091, Loss: 1.4611, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 092, Loss: 1.4630, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 093, Loss: 1.4506, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 094, Loss: 1.4493, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 095, Loss: 1.4559, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 096, Loss: 1.4727, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 097, Loss: 1.4667, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 098, Loss: 1.4930, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 099, Loss: 1.5726, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 100, Loss: 1.4809, Val Acc: 0.2111, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 101, Loss: 1.5179, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 102, Loss: 1.5214, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 103, Loss: 1.4617, Val Acc: 0.2444, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 104, Loss: 1.4839, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 105, Loss: 1.4684, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 106, Loss: 1.4360, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 107, Loss: 1.4563, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 108, Loss: 1.4292, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 109, Loss: 1.5049, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 110, Loss: 1.4977, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 111, Loss: 1.5216, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 112, Loss: 1.4668, Val Acc: 0.2000, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 113, Loss: 1.4798, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 114, Loss: 1.4864, Val Acc: 0.2111, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 115, Loss: 1.4736, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 116, Loss: 1.4567, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 117, Loss: 1.4360, Val Acc: 0.2000, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 118, Loss: 1.4190, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 119, Loss: 1.4155, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 120, Loss: 1.4094, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 121, Loss: 1.4054, Val Acc: 0.2111, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 122, Loss: 1.3780, Val Acc: 0.2222, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 123, Loss: 1.3785, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 124, Loss: 1.3908, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 125, Loss: 1.3574, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 126, Loss: 1.3800, Val Acc: 0.2222, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 127, Loss: 1.3514, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 128, Loss: 1.3602, Val Acc: 0.2333, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 129, Loss: 1.3342, Val Acc: 0.2111, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 130, Loss: 1.3481, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 131, Loss: 1.3564, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 132, Loss: 1.3557, Val Acc: 0.2333, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 133, Loss: 1.3357, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 134, Loss: 1.3299, Val Acc: 0.2889, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 135, Loss: 1.3610, Val Acc: 0.2444, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 136, Loss: 1.3383, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 137, Loss: 1.3379, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 138, Loss: 1.3451, Val Acc: 0.2444, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 139, Loss: 1.3017, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 140, Loss: 1.3206, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 141, Loss: 1.3137, Val Acc: 0.2333, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 142, Loss: 1.2889, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 143, Loss: 1.2906, Val Acc: 0.2111, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 144, Loss: 1.2935, Val Acc: 0.2222, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 145, Loss: 1.2788, Val Acc: 0.2111, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 146, Loss: 1.2599, Val Acc: 0.2444, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 147, Loss: 1.2850, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 148, Loss: 1.2859, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 149, Loss: 1.2731, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 150, Loss: 1.2701, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 151, Loss: 1.2536, Val Acc: 0.2333, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 152, Loss: 1.2593, Val Acc: 0.2222, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 153, Loss: 1.2332, Val Acc: 0.2444, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 154, Loss: 1.2433, Val Acc: 0.2333, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 155, Loss: 1.2534, Val Acc: 0.2444, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 156, Loss: 1.2429, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 157, Loss: 1.2299, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 158, Loss: 1.2261, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 159, Loss: 1.2204, Val Acc: 0.2444, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 160, Loss: 1.2227, Val Acc: 0.2444, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 161, Loss: 1.2168, Val Acc: 0.2111, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 162, Loss: 1.2238, Val Acc: 0.2444, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 163, Loss: 1.2177, Val Acc: 0.2444, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 164, Loss: 1.2441, Val Acc: 0.2222, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 165, Loss: 1.2499, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 166, Loss: 1.2164, Val Acc: 0.2444, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 167, Loss: 1.2023, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 168, Loss: 1.2188, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 169, Loss: 1.2008, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 170, Loss: 1.2128, Val Acc: 0.2111, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 171, Loss: 1.1985, Val Acc: 0.2444, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 172, Loss: 1.1879, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 173, Loss: 1.1941, Val Acc: 0.2222, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 174, Loss: 1.1920, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 175, Loss: 1.1898, Val Acc: 0.2222, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 176, Loss: 1.1825, Val Acc: 0.2222, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 177, Loss: 1.1824, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 178, Loss: 1.1812, Val Acc: 0.2222, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 179, Loss: 1.1833, Val Acc: 0.2333, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 180, Loss: 1.1423, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 181, Loss: 1.1894, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 182, Loss: 1.1849, Val Acc: 0.2222, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 183, Loss: 1.1792, Val Acc: 0.2222, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 184, Loss: 1.1390, Val Acc: 0.2222, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 185, Loss: 1.1624, Val Acc: 0.2111, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 186, Loss: 1.1575, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 187, Loss: 1.1362, Val Acc: 0.2333, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 188, Loss: 1.1347, Val Acc: 0.2556, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 189, Loss: 1.1385, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 190, Loss: 1.1460, Val Acc: 0.2333, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 191, Loss: 1.1187, Val Acc: 0.2222, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 192, Loss: 1.0840, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 193, Loss: 1.1376, Val Acc: 0.2333, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 194, Loss: 1.1068, Val Acc: 0.2444, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 195, Loss: 1.1032, Val Acc: 0.2222, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 196, Loss: 1.1042, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 197, Loss: 1.1028, Val Acc: 0.2333, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 198, Loss: 1.0907, Val Acc: 0.2111, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 199, Loss: 1.0949, Val Acc: 0.2444, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 200, Loss: 1.0993, Val Acc: 0.2333, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 001, Loss: 1.7986, Val Acc: 0.1444, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 002, Loss: 1.7804, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 003, Loss: 1.7748, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 004, Loss: 1.7713, Val Acc: 0.1667, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 005, Loss: 1.7686, Val Acc: 0.1667, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 006, Loss: 1.7654, Val Acc: 0.1889, Test Acc: 0.2111\n",
            "Seed: 44, Epoch: 007, Loss: 1.7607, Val Acc: 0.1778, Test Acc: 0.2111\n",
            "Seed: 44, Epoch: 008, Loss: 1.7565, Val Acc: 0.1778, Test Acc: 0.2111\n",
            "Seed: 44, Epoch: 009, Loss: 1.7538, Val Acc: 0.1778, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 010, Loss: 1.7493, Val Acc: 0.1778, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 011, Loss: 1.7538, Val Acc: 0.1889, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 012, Loss: 1.7376, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 013, Loss: 1.7422, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 014, Loss: 1.7353, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 015, Loss: 1.7271, Val Acc: 0.2333, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 016, Loss: 1.7204, Val Acc: 0.2000, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 017, Loss: 1.7090, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 018, Loss: 1.7075, Val Acc: 0.2778, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 019, Loss: 1.7087, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 020, Loss: 1.6978, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 021, Loss: 1.6871, Val Acc: 0.2222, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 022, Loss: 1.6937, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 023, Loss: 1.6871, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 024, Loss: 1.6811, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 025, Loss: 1.6733, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 026, Loss: 1.6804, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 027, Loss: 1.6712, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 028, Loss: 1.6659, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 029, Loss: 1.6611, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 030, Loss: 1.6600, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 031, Loss: 1.6570, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 032, Loss: 1.6493, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 033, Loss: 1.6428, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 034, Loss: 1.6413, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 035, Loss: 1.6404, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 036, Loss: 1.6373, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 037, Loss: 1.6309, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 038, Loss: 1.6277, Val Acc: 0.3111, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 039, Loss: 1.6291, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 040, Loss: 1.6216, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 041, Loss: 1.6131, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 042, Loss: 1.6111, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 043, Loss: 1.6109, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 044, Loss: 1.6026, Val Acc: 0.3333, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 045, Loss: 1.6106, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 046, Loss: 1.6009, Val Acc: 0.2111, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 047, Loss: 1.5948, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 048, Loss: 1.5920, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 049, Loss: 1.5926, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 050, Loss: 1.5888, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 051, Loss: 1.5920, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 052, Loss: 1.5841, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 053, Loss: 1.5936, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 054, Loss: 1.5749, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 055, Loss: 1.5674, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 056, Loss: 1.5708, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 057, Loss: 1.5496, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 058, Loss: 1.5671, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 059, Loss: 1.5523, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 060, Loss: 1.5578, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 061, Loss: 1.5580, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 062, Loss: 1.5606, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 063, Loss: 1.5515, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 064, Loss: 1.5490, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 065, Loss: 1.5372, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 066, Loss: 1.5451, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 067, Loss: 1.5320, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 068, Loss: 1.5199, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 069, Loss: 1.5259, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 070, Loss: 1.5233, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 071, Loss: 1.5690, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 072, Loss: 1.5551, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 073, Loss: 1.5430, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 074, Loss: 1.5277, Val Acc: 0.2222, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 075, Loss: 1.5270, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 076, Loss: 1.5014, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 077, Loss: 1.5180, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 078, Loss: 1.5002, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 079, Loss: 1.4867, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 080, Loss: 1.4990, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 081, Loss: 1.5007, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 082, Loss: 1.4787, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 083, Loss: 1.4813, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 084, Loss: 1.4782, Val Acc: 0.2444, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 085, Loss: 1.4732, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 086, Loss: 1.4670, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 087, Loss: 1.4624, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 088, Loss: 1.4502, Val Acc: 0.2889, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 089, Loss: 1.4506, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 090, Loss: 1.4577, Val Acc: 0.3111, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 091, Loss: 1.4469, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 092, Loss: 1.4376, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 093, Loss: 1.4509, Val Acc: 0.2778, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 094, Loss: 1.4470, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 095, Loss: 1.4311, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 096, Loss: 1.4403, Val Acc: 0.3000, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 097, Loss: 1.4125, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 098, Loss: 1.4306, Val Acc: 0.2667, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 099, Loss: 1.4023, Val Acc: 0.3000, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 100, Loss: 1.4236, Val Acc: 0.2778, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 101, Loss: 1.3914, Val Acc: 0.2778, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 102, Loss: 1.3789, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 103, Loss: 1.3940, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 104, Loss: 1.3703, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 105, Loss: 1.3899, Val Acc: 0.2889, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 106, Loss: 1.3882, Val Acc: 0.2667, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 107, Loss: 1.3814, Val Acc: 0.2889, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 108, Loss: 1.3772, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 109, Loss: 1.3956, Val Acc: 0.2889, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 110, Loss: 1.3734, Val Acc: 0.2556, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 111, Loss: 1.3418, Val Acc: 0.2000, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 112, Loss: 1.3684, Val Acc: 0.2778, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 113, Loss: 1.4099, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 114, Loss: 1.3732, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 115, Loss: 1.3491, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 116, Loss: 1.3782, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 117, Loss: 1.3552, Val Acc: 0.3111, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 118, Loss: 1.3668, Val Acc: 0.3111, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 119, Loss: 1.3369, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 120, Loss: 1.3590, Val Acc: 0.2778, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 121, Loss: 1.3321, Val Acc: 0.2889, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 122, Loss: 1.3204, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 123, Loss: 1.3261, Val Acc: 0.2889, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 124, Loss: 1.3229, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 125, Loss: 1.2849, Val Acc: 0.3111, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 126, Loss: 1.3144, Val Acc: 0.2667, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 127, Loss: 1.3141, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 128, Loss: 1.3135, Val Acc: 0.2889, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 129, Loss: 1.3099, Val Acc: 0.2889, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 130, Loss: 1.2790, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 131, Loss: 1.2965, Val Acc: 0.2778, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 132, Loss: 1.2866, Val Acc: 0.3000, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 133, Loss: 1.2528, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 134, Loss: 1.2629, Val Acc: 0.2778, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 135, Loss: 1.2747, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 136, Loss: 1.2578, Val Acc: 0.2889, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 137, Loss: 1.2714, Val Acc: 0.2667, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 138, Loss: 1.2570, Val Acc: 0.2889, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 139, Loss: 1.2541, Val Acc: 0.3222, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 140, Loss: 1.2537, Val Acc: 0.2778, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 141, Loss: 1.2337, Val Acc: 0.2556, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 142, Loss: 1.2229, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 143, Loss: 1.2283, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 144, Loss: 1.2372, Val Acc: 0.2778, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 145, Loss: 1.2153, Val Acc: 0.2778, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 146, Loss: 1.2211, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 147, Loss: 1.1768, Val Acc: 0.2778, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 148, Loss: 1.2127, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 149, Loss: 1.1994, Val Acc: 0.3222, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 150, Loss: 1.2071, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 151, Loss: 1.2132, Val Acc: 0.2889, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 152, Loss: 1.2093, Val Acc: 0.2778, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 153, Loss: 1.1773, Val Acc: 0.2778, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 154, Loss: 1.1853, Val Acc: 0.2556, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 155, Loss: 1.1825, Val Acc: 0.2889, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 156, Loss: 1.1798, Val Acc: 0.3111, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 157, Loss: 1.1699, Val Acc: 0.2444, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 158, Loss: 1.1742, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 159, Loss: 1.4890, Val Acc: 0.2556, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 160, Loss: 1.4249, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 161, Loss: 1.2364, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 162, Loss: 1.4032, Val Acc: 0.2222, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 163, Loss: 1.3014, Val Acc: 0.2111, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 164, Loss: 1.2779, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 165, Loss: 1.4361, Val Acc: 0.2889, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 166, Loss: 1.2562, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 167, Loss: 1.3400, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 168, Loss: 1.2695, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 169, Loss: 1.2728, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 170, Loss: 1.2395, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 171, Loss: 1.2231, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 172, Loss: 1.2069, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 173, Loss: 1.1854, Val Acc: 0.2778, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 174, Loss: 1.1661, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 175, Loss: 1.1570, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 176, Loss: 1.1664, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 177, Loss: 1.1736, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 178, Loss: 1.1226, Val Acc: 0.2778, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 179, Loss: 1.1503, Val Acc: 0.2889, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 180, Loss: 1.1265, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 181, Loss: 1.1407, Val Acc: 0.2778, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 182, Loss: 1.1287, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 183, Loss: 1.1705, Val Acc: 0.2889, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 184, Loss: 1.1226, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 185, Loss: 1.1189, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 186, Loss: 1.1011, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 187, Loss: 1.1267, Val Acc: 0.3111, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 188, Loss: 1.1118, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 189, Loss: 1.0964, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 190, Loss: 1.0960, Val Acc: 0.2778, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 191, Loss: 1.1032, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 192, Loss: 1.0927, Val Acc: 0.2889, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 193, Loss: 1.0739, Val Acc: 0.3000, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 194, Loss: 1.0591, Val Acc: 0.2778, Test Acc: 0.4333\n",
            "Early stopping at epoch 194 for seed 44\n",
            "Seed: 45, Epoch: 001, Loss: 1.7969, Val Acc: 0.1889, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 002, Loss: 1.7732, Val Acc: 0.1889, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 003, Loss: 1.7747, Val Acc: 0.1889, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 004, Loss: 1.7714, Val Acc: 0.1889, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 005, Loss: 1.7663, Val Acc: 0.1889, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 006, Loss: 1.7630, Val Acc: 0.1889, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 007, Loss: 1.7607, Val Acc: 0.1778, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 008, Loss: 1.7490, Val Acc: 0.2000, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 009, Loss: 1.7512, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 010, Loss: 1.7450, Val Acc: 0.2111, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 011, Loss: 1.7381, Val Acc: 0.2000, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 012, Loss: 1.7271, Val Acc: 0.2000, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 013, Loss: 1.7238, Val Acc: 0.2000, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 014, Loss: 1.7214, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 015, Loss: 1.7154, Val Acc: 0.1889, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 016, Loss: 1.7111, Val Acc: 0.1889, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 017, Loss: 1.7083, Val Acc: 0.1889, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 018, Loss: 1.7019, Val Acc: 0.1778, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 019, Loss: 1.6989, Val Acc: 0.1778, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 020, Loss: 1.6951, Val Acc: 0.1889, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 021, Loss: 1.6888, Val Acc: 0.2000, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 022, Loss: 1.6836, Val Acc: 0.2556, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 023, Loss: 1.6902, Val Acc: 0.2444, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 024, Loss: 1.6848, Val Acc: 0.2000, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 025, Loss: 1.6760, Val Acc: 0.1778, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 026, Loss: 1.6819, Val Acc: 0.2111, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 027, Loss: 1.6745, Val Acc: 0.2111, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 028, Loss: 1.6678, Val Acc: 0.1778, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 029, Loss: 1.6629, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 030, Loss: 1.6629, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 031, Loss: 1.6573, Val Acc: 0.1778, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 032, Loss: 1.6561, Val Acc: 0.1889, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 033, Loss: 1.6530, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 034, Loss: 1.6400, Val Acc: 0.2444, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 035, Loss: 1.6422, Val Acc: 0.2444, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 036, Loss: 1.6443, Val Acc: 0.1889, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 037, Loss: 1.6475, Val Acc: 0.2111, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 038, Loss: 1.6344, Val Acc: 0.2556, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 039, Loss: 1.6414, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 040, Loss: 1.6296, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 041, Loss: 1.6316, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 042, Loss: 1.6174, Val Acc: 0.2667, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 043, Loss: 1.6290, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 044, Loss: 1.6265, Val Acc: 0.2000, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 045, Loss: 1.6145, Val Acc: 0.2444, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 046, Loss: 1.6123, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 047, Loss: 1.5972, Val Acc: 0.2222, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 048, Loss: 1.6035, Val Acc: 0.2444, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 049, Loss: 1.6036, Val Acc: 0.2556, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 050, Loss: 1.5926, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 051, Loss: 1.5981, Val Acc: 0.2000, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 052, Loss: 1.6142, Val Acc: 0.2444, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 053, Loss: 1.5851, Val Acc: 0.2222, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 054, Loss: 1.5911, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 055, Loss: 1.5827, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 056, Loss: 1.5848, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 057, Loss: 1.5718, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 058, Loss: 1.5657, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 059, Loss: 1.5530, Val Acc: 0.1889, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 060, Loss: 1.5633, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 061, Loss: 1.5483, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 062, Loss: 1.5583, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 063, Loss: 1.5551, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 064, Loss: 1.5502, Val Acc: 0.2000, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 065, Loss: 1.5415, Val Acc: 0.2000, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 066, Loss: 1.5483, Val Acc: 0.2000, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 067, Loss: 1.5382, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 068, Loss: 1.5363, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 069, Loss: 1.5384, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 070, Loss: 1.5222, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 071, Loss: 1.5213, Val Acc: 0.2000, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 072, Loss: 1.5220, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 073, Loss: 1.5087, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 074, Loss: 1.5158, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 075, Loss: 1.4877, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 076, Loss: 1.5093, Val Acc: 0.2222, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 077, Loss: 1.5058, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 078, Loss: 1.4859, Val Acc: 0.2889, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 079, Loss: 1.4749, Val Acc: 0.2222, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 080, Loss: 1.4895, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 081, Loss: 1.4707, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 082, Loss: 1.4746, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 083, Loss: 1.4692, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 084, Loss: 1.4743, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 085, Loss: 1.4659, Val Acc: 0.2889, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 086, Loss: 1.4541, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 087, Loss: 1.4591, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 088, Loss: 1.4502, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 089, Loss: 1.4463, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 090, Loss: 1.4598, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 091, Loss: 1.4337, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 092, Loss: 1.4388, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 093, Loss: 1.4338, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 094, Loss: 1.4261, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 095, Loss: 1.4088, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 096, Loss: 1.4143, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 097, Loss: 1.3948, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 098, Loss: 1.3875, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 099, Loss: 1.3929, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 100, Loss: 1.4060, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 101, Loss: 1.3865, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 102, Loss: 1.3867, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 103, Loss: 1.3864, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 104, Loss: 1.3791, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 105, Loss: 1.3804, Val Acc: 0.2889, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 106, Loss: 1.3778, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 107, Loss: 1.3517, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 108, Loss: 1.3406, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 109, Loss: 1.3661, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 110, Loss: 1.3525, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 111, Loss: 1.3492, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 112, Loss: 1.3443, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 113, Loss: 1.3320, Val Acc: 0.2778, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 114, Loss: 1.3312, Val Acc: 0.2778, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 115, Loss: 1.3271, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 116, Loss: 1.3140, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 117, Loss: 1.3125, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 118, Loss: 1.3174, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 119, Loss: 1.3328, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 120, Loss: 1.2994, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 121, Loss: 1.3028, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 122, Loss: 1.2860, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 123, Loss: 1.2853, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 124, Loss: 1.3232, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 125, Loss: 1.3064, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 126, Loss: 1.3067, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 127, Loss: 1.2727, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 128, Loss: 1.2716, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 129, Loss: 1.3038, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 130, Loss: 1.2571, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 131, Loss: 1.2909, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 132, Loss: 1.3165, Val Acc: 0.2889, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 133, Loss: 1.2744, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 134, Loss: 1.2870, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 135, Loss: 1.2300, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 136, Loss: 1.2406, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 137, Loss: 1.2255, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 138, Loss: 1.2505, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 139, Loss: 1.2312, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 140, Loss: 1.2317, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 141, Loss: 1.2115, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 142, Loss: 1.2258, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 143, Loss: 1.2244, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 144, Loss: 1.1989, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 145, Loss: 1.1877, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 146, Loss: 1.2273, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 147, Loss: 1.1834, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 148, Loss: 1.2038, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 149, Loss: 1.1796, Val Acc: 0.2889, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 150, Loss: 1.1663, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 151, Loss: 1.1661, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 152, Loss: 1.2267, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 153, Loss: 1.2867, Val Acc: 0.2889, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 154, Loss: 1.2050, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 155, Loss: 1.2116, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 156, Loss: 1.2203, Val Acc: 0.2889, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 157, Loss: 1.2307, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 158, Loss: 1.2442, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 159, Loss: 1.2162, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 160, Loss: 1.2267, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 161, Loss: 1.2914, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 162, Loss: 1.1845, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 163, Loss: 1.2328, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 164, Loss: 1.2107, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 165, Loss: 1.1586, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 166, Loss: 1.1879, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 167, Loss: 1.1625, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 168, Loss: 1.1458, Val Acc: 0.2889, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 169, Loss: 1.1722, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 170, Loss: 1.1256, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 171, Loss: 1.1672, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 172, Loss: 1.1568, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 173, Loss: 1.0989, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 174, Loss: 1.1602, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 175, Loss: 1.1261, Val Acc: 0.3333, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 176, Loss: 1.0879, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 177, Loss: 1.1398, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 178, Loss: 1.1281, Val Acc: 0.2778, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 179, Loss: 1.1351, Val Acc: 0.3444, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 180, Loss: 1.1289, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 181, Loss: 1.0870, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 182, Loss: 1.1412, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 183, Loss: 1.1386, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 184, Loss: 1.1156, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 185, Loss: 1.1079, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 186, Loss: 1.1286, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 187, Loss: 1.2185, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 188, Loss: 1.1034, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 189, Loss: 1.0910, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 190, Loss: 1.0984, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 191, Loss: 1.0577, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 192, Loss: 1.0743, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 193, Loss: 1.0487, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 194, Loss: 1.0654, Val Acc: 0.3000, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 195, Loss: 1.0522, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 196, Loss: 1.0505, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 197, Loss: 1.0484, Val Acc: 0.2889, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 198, Loss: 1.0238, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 199, Loss: 1.0393, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 200, Loss: 1.0412, Val Acc: 0.2889, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 001, Loss: 1.8062, Val Acc: 0.1667, Test Acc: 0.2000\n",
            "Seed: 46, Epoch: 002, Loss: 1.7904, Val Acc: 0.1667, Test Acc: 0.1889\n",
            "Seed: 46, Epoch: 003, Loss: 1.7869, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 004, Loss: 1.7791, Val Acc: 0.1889, Test Acc: 0.2000\n",
            "Seed: 46, Epoch: 005, Loss: 1.7768, Val Acc: 0.1778, Test Acc: 0.2111\n",
            "Seed: 46, Epoch: 006, Loss: 1.7731, Val Acc: 0.1667, Test Acc: 0.2111\n",
            "Seed: 46, Epoch: 007, Loss: 1.7688, Val Acc: 0.1778, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 008, Loss: 1.7617, Val Acc: 0.1889, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 009, Loss: 1.7598, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 010, Loss: 1.7606, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 011, Loss: 1.7486, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 012, Loss: 1.7504, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 013, Loss: 1.7509, Val Acc: 0.2111, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 014, Loss: 1.7380, Val Acc: 0.2667, Test Acc: 0.2000\n",
            "Seed: 46, Epoch: 015, Loss: 1.7413, Val Acc: 0.2778, Test Acc: 0.2000\n",
            "Seed: 46, Epoch: 016, Loss: 1.7315, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 017, Loss: 1.7240, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 018, Loss: 1.7190, Val Acc: 0.2111, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 019, Loss: 1.7063, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 020, Loss: 1.7057, Val Acc: 0.2778, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 021, Loss: 1.6972, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 022, Loss: 1.6942, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 023, Loss: 1.6883, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 024, Loss: 1.6862, Val Acc: 0.2778, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 025, Loss: 1.6815, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 026, Loss: 1.6773, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 027, Loss: 1.6662, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 028, Loss: 1.6682, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 029, Loss: 1.6677, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 030, Loss: 1.6642, Val Acc: 0.2667, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 031, Loss: 1.6595, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 032, Loss: 1.6537, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 033, Loss: 1.6552, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 034, Loss: 1.6532, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 035, Loss: 1.6515, Val Acc: 0.2111, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 036, Loss: 1.6357, Val Acc: 0.2111, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 037, Loss: 1.6401, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 038, Loss: 1.6382, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 039, Loss: 1.6238, Val Acc: 0.2000, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 040, Loss: 1.6233, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 041, Loss: 1.6296, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 042, Loss: 1.6236, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 043, Loss: 1.6253, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 044, Loss: 1.6125, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 045, Loss: 1.6049, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 046, Loss: 1.6088, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 047, Loss: 1.6059, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 048, Loss: 1.5987, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 049, Loss: 1.5942, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 050, Loss: 1.5916, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 051, Loss: 1.6005, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 052, Loss: 1.6172, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 053, Loss: 1.6052, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 054, Loss: 1.6134, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 055, Loss: 1.5987, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 056, Loss: 1.6041, Val Acc: 0.2000, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 057, Loss: 1.6024, Val Acc: 0.1889, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 058, Loss: 1.6315, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 059, Loss: 1.6003, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 060, Loss: 1.5929, Val Acc: 0.1889, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 061, Loss: 1.5930, Val Acc: 0.2000, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 062, Loss: 1.6013, Val Acc: 0.2222, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 063, Loss: 1.5634, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 064, Loss: 1.5814, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 065, Loss: 1.5680, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 066, Loss: 1.5724, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 067, Loss: 1.5751, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 068, Loss: 1.5614, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 069, Loss: 1.5556, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 070, Loss: 1.5375, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 071, Loss: 1.5465, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 072, Loss: 1.5409, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 073, Loss: 1.5390, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 074, Loss: 1.5345, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 075, Loss: 1.5283, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 076, Loss: 1.5222, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 077, Loss: 1.5229, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 078, Loss: 1.5149, Val Acc: 0.2111, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 079, Loss: 1.5153, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 080, Loss: 1.5035, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 081, Loss: 1.5035, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 082, Loss: 1.4951, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 083, Loss: 1.4959, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 084, Loss: 1.4947, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 085, Loss: 1.4905, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 086, Loss: 1.4833, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 087, Loss: 1.4824, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 088, Loss: 1.4741, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 089, Loss: 1.4723, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 090, Loss: 1.4877, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 091, Loss: 1.4719, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 092, Loss: 1.4661, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 093, Loss: 1.4719, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 094, Loss: 1.4463, Val Acc: 0.2222, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 095, Loss: 1.4278, Val Acc: 0.2222, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 096, Loss: 1.4643, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 097, Loss: 1.4339, Val Acc: 0.2222, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 098, Loss: 1.4390, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 099, Loss: 1.4272, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 100, Loss: 1.4472, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 101, Loss: 1.4197, Val Acc: 0.2222, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 102, Loss: 1.4217, Val Acc: 0.2111, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 103, Loss: 1.4308, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 104, Loss: 1.4170, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 105, Loss: 1.4009, Val Acc: 0.2222, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 106, Loss: 1.4229, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 107, Loss: 1.3936, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 108, Loss: 1.3832, Val Acc: 0.1889, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 109, Loss: 1.4049, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 110, Loss: 1.4166, Val Acc: 0.2111, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 111, Loss: 1.4176, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 112, Loss: 1.3863, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 113, Loss: 1.3954, Val Acc: 0.2111, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 114, Loss: 1.3656, Val Acc: 0.2889, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 115, Loss: 1.3839, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 116, Loss: 1.3483, Val Acc: 0.2222, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 117, Loss: 1.3390, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 118, Loss: 1.3665, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 119, Loss: 1.3522, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 120, Loss: 1.3621, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 121, Loss: 1.3301, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 122, Loss: 1.3453, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 123, Loss: 1.3348, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 124, Loss: 1.3457, Val Acc: 0.2222, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 125, Loss: 1.3532, Val Acc: 0.2444, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 126, Loss: 1.3362, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 127, Loss: 1.3629, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 128, Loss: 1.3209, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 129, Loss: 1.3395, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 130, Loss: 1.3135, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 131, Loss: 1.3121, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 132, Loss: 1.2999, Val Acc: 0.2111, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 133, Loss: 1.2932, Val Acc: 0.2667, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 134, Loss: 1.2865, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 135, Loss: 1.2935, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 136, Loss: 1.2936, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 137, Loss: 1.2734, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 138, Loss: 1.2765, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 139, Loss: 1.3140, Val Acc: 0.1889, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 140, Loss: 1.3105, Val Acc: 0.2444, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 141, Loss: 1.3043, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 142, Loss: 1.2498, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 143, Loss: 1.2644, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 144, Loss: 1.3163, Val Acc: 0.2222, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 145, Loss: 1.2946, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 146, Loss: 1.2970, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 147, Loss: 1.2557, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 148, Loss: 1.2575, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 149, Loss: 1.2854, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 150, Loss: 1.2740, Val Acc: 0.2222, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 151, Loss: 1.2317, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 152, Loss: 1.2441, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 153, Loss: 1.2362, Val Acc: 0.2667, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 154, Loss: 1.2920, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 155, Loss: 1.2572, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 156, Loss: 1.2420, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 157, Loss: 1.2598, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 158, Loss: 1.2170, Val Acc: 0.2333, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 159, Loss: 1.2099, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 160, Loss: 1.2270, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 161, Loss: 1.1869, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 162, Loss: 1.2246, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 163, Loss: 1.1960, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 164, Loss: 1.1959, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 165, Loss: 1.1923, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 166, Loss: 1.1953, Val Acc: 0.2222, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 167, Loss: 1.1993, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 168, Loss: 1.1764, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 169, Loss: 1.2038, Val Acc: 0.2667, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 170, Loss: 1.1557, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 171, Loss: 1.1494, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 172, Loss: 1.1533, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 173, Loss: 1.1829, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 174, Loss: 1.1824, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 175, Loss: 1.1575, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 176, Loss: 1.1979, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 177, Loss: 1.1468, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 178, Loss: 1.1946, Val Acc: 0.2444, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 179, Loss: 1.1621, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 180, Loss: 1.1595, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 181, Loss: 1.1172, Val Acc: 0.2111, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 182, Loss: 1.1609, Val Acc: 0.2778, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 183, Loss: 1.1683, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 184, Loss: 1.1646, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Early stopping at epoch 184 for seed 46\n",
            "Average Time: 35.97 seconds\n",
            "Var Time: 1.53 seconds\n",
            "Average Memory: 38.00 MB\n",
            "Average Best Val Acc: 0.3178\n",
            "Std Best Test Acc: 0.0368\n",
            "Average Test Acc: 0.3200\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, ASAPooling\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "from torch_geometric.nn import BatchNorm\n",
        "\n",
        "class HierarchicalGCN_PAN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes):\n",
        "        super(HierarchicalGCN_PAN, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.pool1 = PANPooling(hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.pool2 = PANPooling(hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, out_channels)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.lin1 = torch.nn.Linear(out_channels, 32)\n",
        "        self.lin2 = torch.nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        # First GCN and pooling layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn1(x)\n",
        "        x, edge_index, _, batch, perm, score_perm = self.pool1(x, edge_index, batch=batch, M=None)\n",
        "\n",
        "        # Second GCN and pooling layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn2(x)\n",
        "        x, edge_index, _, batch, perm, score_perm = self.pool2(x, edge_index, batch=batch, M=None)\n",
        "\n",
        "        # Third GCN layer\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn3(x)\n",
        "\n",
        "        # Mean pooling over the nodes\n",
        "        x, mask = to_dense_batch(x, batch)\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.lin1(x).relu()\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "num_classes = dataset_sparse.num_classes\n",
        "in_channels = dataset_sparse.num_features\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HierarchicalGCN_PAN(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == data.y).sum().item()\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seeds = [42, 43, 44, 45, 46]\n",
        "times = []\n",
        "memories = []\n",
        "best_val_accs = []\n",
        "best_test_accs = []\n",
        "\n",
        "early_stop_patience = 150\n",
        "tolerance = 0.0001\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    model = HierarchicalGCN_PAN(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        val_acc = test(valid_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        if val_acc > best_val_acc + tolerance:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "        if epochs_no_improve >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
        "\n",
        "    times.append(total_time)\n",
        "    memories.append(memory_allocated)\n",
        "    best_val_accs.append(best_val_acc)\n",
        "    best_test_accs.append(best_test_acc)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
        "print(f'Var Time: {np.var(times):.2f} seconds')\n",
        "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
        "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
        "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
        "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plZfzSa4UZa7"
      },
      "source": [
        "## CoPooling with HierarchicalGCN (2023)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ22viLKUY3U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Parameter\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.utils import add_remaining_self_loops, to_dense_adj, add_self_loops\n",
        "from typing import Callable, Optional, Union\n",
        "from torch_sparse import coalesce, transpose\n",
        "from torch_scatter import scatter\n",
        "from torch import Tensor\n",
        "def cumsum(x: Tensor, dim: int = 0) -> Tensor:\n",
        "    r\"\"\"Returns the cumulative sum of elements of :obj:`x`.\n",
        "    In contrast to :meth:`torch.cumsum`, prepends the output with zero.\n",
        "\n",
        "    Args:\n",
        "        x (torch.Tensor): The input tensor.\n",
        "        dim (int, optional): The dimension to do the operation over.\n",
        "            (default: :obj:`0`)\n",
        "\n",
        "    Example:\n",
        "        >>> x = torch.tensor([2, 4, 1])\n",
        "        >>> cumsum(x)\n",
        "        tensor([0, 2, 6, 7])\n",
        "\n",
        "    \"\"\"\n",
        "    size = x.size()[:dim] + (x.size(dim) + 1, ) + x.size()[dim + 1:]\n",
        "    out = x.new_empty(size)\n",
        "\n",
        "    out.narrow(dim, 0, 1).zero_()\n",
        "    torch.cumsum(x, dim=dim, out=out.narrow(dim, 1, x.size(dim)))\n",
        "\n",
        "    return out\n",
        "\n",
        "def maybe_num_nodes(edge_index, num_nodes=None):\n",
        "    if num_nodes is not None:\n",
        "        return num_nodes\n",
        "    elif isinstance(edge_index, Tensor):\n",
        "        return int(edge_index.max()) + 1 if edge_index.numel() > 0 else 0\n",
        "    else:\n",
        "        return max(edge_index.size(0), edge_index.size(1))\n",
        "\n",
        "def maybe_num_nodes(edge_index, num_nodes=None):\n",
        "    if num_nodes is not None:\n",
        "        return num_nodes\n",
        "    elif isinstance(edge_index, Tensor):\n",
        "        return int(edge_index.max()) + 1 if edge_index.numel() > 0 else 0\n",
        "    else:\n",
        "        return max(edge_index.size(0), edge_index.size(1))\n",
        "\n",
        "def filter_adj(edge_index, edge_attr, perm, num_nodes=None):\n",
        "    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
        "\n",
        "    mask = perm.new_full((num_nodes, ), -1)\n",
        "    i = torch.arange(perm.size(0), dtype=torch.long, device=perm.device)\n",
        "    mask[perm] = i\n",
        "\n",
        "    row, col = edge_index\n",
        "    row, col = mask[row], mask[col]\n",
        "    mask = (row >= 0) & (col >= 0)\n",
        "    row, col = row[mask], col[mask]\n",
        "\n",
        "    if edge_attr is not None:\n",
        "        edge_attr = edge_attr[mask]\n",
        "\n",
        "    return torch.stack([row, col], dim=0), edge_attr\n",
        "\n",
        "def topk(\n",
        "    x: Tensor,\n",
        "    ratio: Optional[Union[float, int]],\n",
        "    batch: Tensor,\n",
        "    min_score: Optional[float] = None,\n",
        "    tol: float = 1e-7,\n",
        ") -> Tensor:\n",
        "    if min_score is not None:\n",
        "        # Make sure that we do not drop all nodes in a graph.\n",
        "        scores_max = scatter(x, batch, reduce='max')[batch] - tol\n",
        "        scores_min = scores_max.clamp(max=min_score)\n",
        "\n",
        "        perm = (x > scores_min).nonzero().view(-1)\n",
        "        return perm\n",
        "\n",
        "    if ratio is not None:\n",
        "        num_nodes = scatter(batch.new_ones(x.size(0)), batch, reduce='sum')\n",
        "\n",
        "        if ratio >= 1:\n",
        "            k = num_nodes.new_full((num_nodes.size(0), ), int(ratio))\n",
        "        else:\n",
        "            k = (float(ratio) * num_nodes.to(x.dtype)).ceil().to(torch.long)\n",
        "\n",
        "        x, x_perm = torch.sort(x.view(-1), descending=True)\n",
        "        batch = batch[x_perm]\n",
        "        batch, batch_perm = torch.sort(batch, descending=False, stable=True)\n",
        "\n",
        "        arange = torch.arange(x.size(0), dtype=torch.long, device=x.device)\n",
        "        ptr = cumsum(num_nodes)\n",
        "        batched_arange = arange - ptr[batch]\n",
        "        mask = batched_arange < k[batch]\n",
        "\n",
        "        return x_perm[batch_perm[mask]]\n",
        "\n",
        "    raise ValueError(\"At least one of the 'ratio' and 'min_score' parameters \"\n",
        "                     \"must be specified\")\n",
        "\n",
        "class GPR_prop(MessagePassing):\n",
        "    '''\n",
        "    propagation class for GPR_GNN\n",
        "    '''\n",
        "\n",
        "    def __init__(self, K, alpha, Init, Gamma=None, bias=True, **kwargs):\n",
        "        super(GPR_prop, self).__init__(aggr='add', **kwargs)\n",
        "        self.K = K\n",
        "        self.Init = Init\n",
        "        self.alpha = alpha\n",
        "\n",
        "        assert Init in ['SGC', 'PPR', 'NPPR', 'Random', 'WS']\n",
        "        if Init == 'SGC':\n",
        "            # SGC-like\n",
        "            TEMP = 0.0*np.ones(K+1)\n",
        "            TEMP[alpha] = 1.0\n",
        "        elif Init == 'PPR':\n",
        "            # PPR-like\n",
        "            TEMP = alpha*(1-alpha)**np.arange(K+1)\n",
        "            TEMP[-1] = (1-alpha)**K\n",
        "        elif Init == 'NPPR':\n",
        "            # Negative PPR\n",
        "            TEMP = (alpha)**np.arange(K+1)\n",
        "            TEMP = TEMP/np.sum(np.abs(TEMP))\n",
        "        elif Init == 'Random':\n",
        "            # Random\n",
        "            bound = np.sqrt(3/(K+1))\n",
        "            TEMP = np.random.uniform(-bound, bound, K+1)\n",
        "            TEMP = TEMP/np.sum(np.abs(TEMP))\n",
        "        elif Init == 'WS':\n",
        "            # Specify Gamma\n",
        "            TEMP = Gamma\n",
        "\n",
        "        self.temp = Parameter(torch.tensor(TEMP))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.zeros_(self.temp)\n",
        "        for k in range(self.K+1):\n",
        "            self.temp.data[k] = self.alpha*(1-self.alpha)**k\n",
        "        self.temp.data[-1] = (1-self.alpha)**self.K\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        edge_index, norm = gcn_norm(\n",
        "            edge_index, edge_weight, num_nodes=x.size(0), dtype=x.dtype)\n",
        "\n",
        "        hidden = x*(self.temp[0])\n",
        "        for k in range(self.K):\n",
        "            x = self.propagate(edge_index, x=x, norm=norm)\n",
        "            gamma = self.temp[k+1]\n",
        "            hidden = hidden + gamma*x\n",
        "        return hidden\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}(K={}, temp={})'.format(self.__class__.__name__, self.K,\n",
        "                                           self.temp)\n",
        "\n",
        "\n",
        "class NodeInformationScore(MessagePassing):\n",
        "    def __init__(self, improved=False, cached=False, **kwargs):\n",
        "        super(NodeInformationScore, self).__init__(aggr='add', **kwargs)\n",
        "\n",
        "        self.improved = improved\n",
        "        self.cached = cached\n",
        "        self.cached_result = None\n",
        "        self.cached_num_edges = None\n",
        "\n",
        "    @staticmethod\n",
        "    def norm(edge_index, num_nodes, edge_weight, dtype=None):\n",
        "        if edge_weight is None:\n",
        "            edge_weight = torch.ones((edge_index.size(1),), dtype=dtype, device=edge_index.device)\n",
        "\n",
        "        edge_index, edge_weight = add_remaining_self_loops(edge_index, edge_weight, 0, num_nodes) # in case all the edges are removed\n",
        "\n",
        "        edge_index = edge_index.type(torch.long)\n",
        "        row, col = edge_index\n",
        "        # print(row, col)\n",
        "        # print(edge_weight.shape, row.shape, num_nodes)\n",
        "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "\n",
        "        # row, col = edge_index\n",
        "        expand_deg = torch.zeros((edge_weight.size(0),), dtype=dtype, device=edge_index.device)\n",
        "        expand_deg[-num_nodes:] = torch.ones((num_nodes,), dtype=dtype, device=edge_index.device)\n",
        "\n",
        "        return edge_index, expand_deg - deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        if self.cached and self.cached_result is not None:\n",
        "            if edge_index.size(1) != self.cached_num_edges:\n",
        "                raise RuntimeError(\n",
        "                    'Cached {} number of edges, but found {}'.format(self.cached_num_edges, edge_index.size(1)))\n",
        "\n",
        "        if not self.cached or self.cached_result is None:\n",
        "            self.cached_num_edges = edge_index.size(1)\n",
        "            edge_index, norm = self.norm(edge_index, x.size(0), edge_weight, x.dtype)\n",
        "            self.cached_result = edge_index, norm\n",
        "\n",
        "        edge_index, norm = self.cached_result\n",
        "\n",
        "        return self.propagate(edge_index, x=x, norm=norm)\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        return aggr_out\n",
        "\n",
        "class graph_attention(torch.nn.Module):\n",
        "    # reference: https://github.com/gordicaleksa/pytorch-GAT/blob/39c8f0ee634477033e8b1a6e9a6da3c7ed71bbd1/models/definitions/GAT.py#L324\n",
        "    src_nodes_dim = 0  # position of source nodes in edge index\n",
        "    trg_nodes_dim = 1  # position of target nodes in edge index\n",
        "\n",
        "    nodes_dim = 0      # node dimension/axis\n",
        "    head_dim = 1       # attention head dimension/axis\n",
        "\n",
        "    def __init__(self, num_in_features, num_out_features, num_of_heads, dropout_prob=0.6, log_attention_weights=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # Saving these as we'll need them in forward propagation in children layers (imp1/2/3)\n",
        "        self.num_of_heads = num_of_heads\n",
        "        self.num_out_features = num_out_features\n",
        "        #\n",
        "        # Trainable weights: linear projection matrix (denoted as \"W\" in the paper), attention target/source\n",
        "        # (denoted as \"a\" in the paper) and bias (not mentioned in the paper but present in the official GAT repo)\n",
        "        #\n",
        "\n",
        "        # You can treat this one matrix as num_of_heads independent W matrices\n",
        "        self.linear_proj = nn.Linear(num_in_features, num_of_heads * num_out_features, bias=False)\n",
        "\n",
        "        # After we concatenate target node (node i) and source node (node j) we apply the additive scoring function\n",
        "        # which gives us un-normalized score \"e\". Here we split the \"a\" vector - but the semantics remain the same.\n",
        "\n",
        "        # Basically instead of doing [x, y] (concatenation, x/y are node feature vectors) and dot product with \"a\"\n",
        "        # we instead do a dot product between x and \"a_left\" and y and \"a_right\" and we sum them up\n",
        "        self.scoring_fn_target = nn.Parameter(torch.Tensor(1, num_of_heads, num_out_features))\n",
        "        self.scoring_fn_source = nn.Parameter(torch.Tensor(1, num_of_heads, num_out_features))\n",
        "\n",
        "        self.init_params()\n",
        "\n",
        "    def init_params(self):\n",
        "        \"\"\"\n",
        "        The reason we're using Glorot (aka Xavier uniform) initialization is because it's a default TF initialization:\n",
        "            https://stackoverflow.com/questions/37350131/what-is-the-default-variable-initializer-in-tensorflow\n",
        "        The original repo was developed in TensorFlow (TF) and they used the default initialization.\n",
        "        Feel free to experiment - there may be better initializations depending on your problem.\n",
        "        \"\"\"\n",
        "        nn.init.xavier_uniform_(self.linear_proj.weight)\n",
        "        nn.init.xavier_uniform_(self.scoring_fn_target)\n",
        "        nn.init.xavier_uniform_(self.scoring_fn_source)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        #\n",
        "        # Step 1: Linear Projection + regularization\n",
        "        #\n",
        "\n",
        "        in_nodes_features = x  # unpack data\n",
        "        num_of_nodes = in_nodes_features.shape[self.nodes_dim]\n",
        "\n",
        "        # shape = (N, FIN) * (FIN, NH*FOUT) -> (N, NH, FOUT) where NH - number of heads, FOUT - num of output features\n",
        "        # We project the input node features into NH independent output features (one for each attention head)\n",
        "        nodes_features_proj = self.linear_proj(in_nodes_features).view(-1, self.num_of_heads, self.num_out_features)\n",
        "\n",
        "        #\n",
        "        # Step 2: Edge attention calculation\n",
        "        #\n",
        "\n",
        "        # Apply the scoring function (* represents element-wise (a.k.a. Hadamard) product)\n",
        "        # shape = (N, NH, FOUT) * (1, NH, FOUT) -> (N, NH, 1) -> (N, NH) because sum squeezes the last dimension\n",
        "        # Optimization note: torch.sum() is as performant as .sum() in my experiments\n",
        "        scores_source = (nodes_features_proj * self.scoring_fn_source).sum(dim=-1)\n",
        "        scores_target = (nodes_features_proj * self.scoring_fn_target).sum(dim=-1)\n",
        "\n",
        "        # We simply copy (lift) the scores for source/target nodes based on the edge index. Instead of preparing all\n",
        "        # the possible combinations of scores we just prepare those that will actually be used and those are defined\n",
        "        # by the edge index.\n",
        "        # scores shape = (E, NH), nodes_features_proj_lifted shape = (E, NH, FOUT), E - number of edges in the graph\n",
        "        scores_source_lifted, scores_target_lifted, nodes_features_proj_lifted = self.lift(scores_source, scores_target, nodes_features_proj, edge_index)\n",
        "        scores_per_edge = scores_source_lifted + scores_target_lifted\n",
        "\n",
        "        return torch.sigmoid(scores_per_edge)\n",
        "\n",
        "    def lift(self, scores_source, scores_target, nodes_features_matrix_proj, edge_index):\n",
        "        \"\"\"\n",
        "        Lifts i.e. duplicates certain vectors depending on the edge index.\n",
        "        One of the tensor dims goes from N -> E (that's where the \"lift\" comes from).\n",
        "        \"\"\"\n",
        "        src_nodes_index = edge_index[self.src_nodes_dim]\n",
        "        trg_nodes_index = edge_index[self.trg_nodes_dim]\n",
        "\n",
        "        # Using index_select is faster than \"normal\" indexing (scores_source[src_nodes_index]) in PyTorch!\n",
        "        scores_source = scores_source.index_select(self.nodes_dim, src_nodes_index)\n",
        "        scores_target = scores_target.index_select(self.nodes_dim, trg_nodes_index)\n",
        "        nodes_features_matrix_proj_lifted = nodes_features_matrix_proj.index_select(self.nodes_dim, src_nodes_index)\n",
        "\n",
        "        return scores_source, scores_target, nodes_features_matrix_proj_lifted\n",
        "\n",
        "\n",
        "\n",
        "class CoPooling(torch.nn.Module):\n",
        "    # reference for GAT code: https://github.com/PetarV-/GAT\n",
        "    # reference for generalized pagerank code: https://github.com/jianhao2016/GPRGNN\n",
        "    def __init__(self, ratio=0.5, K=0.05, edge_ratio=0.6, nhid=64, alpha=0.1, Init='Random', Gamma=None):\n",
        "        super(CoPooling, self).__init__()\n",
        "        self.ratio = ratio\n",
        "        self.calc_information_score = NodeInformationScore()\n",
        "        self.edge_ratio = edge_ratio\n",
        "\n",
        "        self.prop1 = GPR_prop(K, alpha, Init, Gamma)\n",
        "\n",
        "        score_dim = 32\n",
        "        self.G_att = graph_attention(num_in_features=nhid, num_out_features=score_dim, num_of_heads=1)\n",
        "\n",
        "        self.weight = Parameter(torch.Tensor(2*nhid, nhid))\n",
        "        nn.init.xavier_uniform_(self.weight.data)\n",
        "        self.bias = Parameter(torch.Tensor(nhid))\n",
        "        nn.init.zeros_(self.bias.data)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.weight.data)\n",
        "        nn.init.zeros_(self.bias.data)\n",
        "        self.prop1.reset_parameters()\n",
        "        self.G_att.init_params()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch=None, nodes_index=None, node_attr=None):\n",
        "        if batch is None:\n",
        "            batch = edge_index.new_zeros(x.size(0))\n",
        "        ori_batch = batch.clone()\n",
        "        device = x.device\n",
        "        num_nodes = x.shape[0]\n",
        "\n",
        "        # cut edges based on scores\n",
        "        x_cut = self.prop1(x, edge_index) # run generalized pagerank to update features\n",
        "\n",
        "        attention = self.G_att(x_cut, edge_index) # get the attention weights after sigmoid\n",
        "        attention = attention.sum(dim=1) #sum the weights on head dim\n",
        "        edge_index, attention = add_self_loops(edge_index, attention, 1.0, num_nodes) # add self loops in case no edges\n",
        "\n",
        "        # to get a systemitic adj matrix\n",
        "        edge_index_t, attention_t = transpose(edge_index, attention, num_nodes, num_nodes)\n",
        "        edge_tmp = torch.cat((edge_index, edge_index_t), 1)\n",
        "        att_tmp = torch.cat((attention, attention_t),0)\n",
        "        edge_index, attention = coalesce(edge_tmp, att_tmp, num_nodes, num_nodes, 'mean')\n",
        "\n",
        "        attention_np = attention.cpu().data.numpy()\n",
        "        cut_val = np.percentile(attention_np, int(100*(1-self.edge_ratio))) # this is for keep the top edge_ratio edges\n",
        "        attention = attention * (attention >= cut_val) # keep the edge_ratio higher weights of edges\n",
        "\n",
        "        kep_idx = attention > 0.0\n",
        "        cut_edge_index, cut_edge_attr = edge_index[:, kep_idx], attention[kep_idx]\n",
        "\n",
        "        # Graph Pooling based on nodes\n",
        "        x_information_score = self.calc_information_score(x, cut_edge_index, cut_edge_attr)\n",
        "        score = torch.sum(torch.abs(x_information_score), dim=1)\n",
        "        perm = topk(score, self.ratio, batch)\n",
        "        x_topk = x[perm]\n",
        "        batch = batch[perm]\n",
        "        if nodes_index is not None:\n",
        "            nodes_index = nodes_index[perm]\n",
        "\n",
        "        if node_attr is not None:\n",
        "            node_attr = node_attr[perm]\n",
        "        if cut_edge_index is not None or cut_edge_index.nelement() != 0:\n",
        "            induced_edge_index, induced_edge_attr = filter_adj(cut_edge_index, cut_edge_attr, perm, num_nodes=num_nodes)\n",
        "        else:\n",
        "            print('All edges are cut!')\n",
        "            induced_edge_index, induced_edge_attr = cut_edge_index, cut_edge_attr\n",
        "\n",
        "        # update node features\n",
        "        attention_dense = (to_dense_adj(cut_edge_index, edge_attr=cut_edge_attr, max_num_nodes=num_nodes)).squeeze()\n",
        "        x = F.relu(torch.matmul(torch.cat((x_topk, torch.matmul(attention_dense[perm],x)), 1), self.weight) + self.bias)\n",
        "\n",
        "        return x, induced_edge_index, perm, induced_edge_attr, batch, nodes_index, node_attr, attention_dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53DHes51dMZQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 001, Loss: 2.1507, Val Acc: 0.2000, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 002, Loss: 1.8543, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 003, Loss: 1.7985, Val Acc: 0.1333, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 004, Loss: 1.7955, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 005, Loss: 1.7873, Val Acc: 0.2000, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 006, Loss: 1.7800, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 007, Loss: 1.7673, Val Acc: 0.2333, Test Acc: 0.2222\n",
            "Seed: 42, Epoch: 008, Loss: 1.7608, Val Acc: 0.2556, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 009, Loss: 1.7491, Val Acc: 0.2556, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 010, Loss: 1.7408, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 011, Loss: 1.7250, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 012, Loss: 1.7114, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 013, Loss: 1.6971, Val Acc: 0.2222, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 014, Loss: 1.6793, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 015, Loss: 1.6739, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 016, Loss: 1.6860, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 017, Loss: 1.6645, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 018, Loss: 1.6621, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 019, Loss: 1.6437, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 020, Loss: 1.6405, Val Acc: 0.2111, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 021, Loss: 1.6355, Val Acc: 0.2111, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 022, Loss: 1.6358, Val Acc: 0.2222, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 023, Loss: 1.6437, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 024, Loss: 1.6468, Val Acc: 0.2111, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 025, Loss: 1.6399, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 026, Loss: 1.6257, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 027, Loss: 1.6090, Val Acc: 0.2000, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 028, Loss: 1.5965, Val Acc: 0.2556, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 029, Loss: 1.6084, Val Acc: 0.2000, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 030, Loss: 1.5939, Val Acc: 0.2000, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 031, Loss: 1.5832, Val Acc: 0.2000, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 032, Loss: 1.5810, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 033, Loss: 1.5811, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 034, Loss: 1.5846, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 035, Loss: 1.5638, Val Acc: 0.2111, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 036, Loss: 1.5818, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 037, Loss: 1.6023, Val Acc: 0.2444, Test Acc: 0.2222\n",
            "Seed: 42, Epoch: 038, Loss: 1.5873, Val Acc: 0.2444, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 039, Loss: 1.5791, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 040, Loss: 1.5716, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 041, Loss: 1.5391, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 042, Loss: 1.5564, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 043, Loss: 1.5384, Val Acc: 0.2111, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 044, Loss: 1.5221, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 045, Loss: 1.5343, Val Acc: 0.3000, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 046, Loss: 1.5412, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 047, Loss: 1.5170, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 048, Loss: 1.5366, Val Acc: 0.2111, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 049, Loss: 1.5122, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 050, Loss: 1.5036, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 051, Loss: 1.4995, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 052, Loss: 1.5255, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 053, Loss: 1.5092, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 054, Loss: 1.5005, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 055, Loss: 1.4982, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 056, Loss: 1.4859, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 057, Loss: 1.4776, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 058, Loss: 1.4791, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 059, Loss: 1.4697, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 060, Loss: 1.5100, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 061, Loss: 1.4651, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 062, Loss: 1.4707, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 063, Loss: 1.4753, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 064, Loss: 1.4413, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 065, Loss: 1.4411, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 066, Loss: 1.4359, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 067, Loss: 1.4215, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 068, Loss: 1.4215, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 069, Loss: 1.4389, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 070, Loss: 1.4023, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 071, Loss: 1.4514, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 072, Loss: 1.4950, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 073, Loss: 1.5224, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 074, Loss: 1.4641, Val Acc: 0.2111, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 075, Loss: 1.4405, Val Acc: 0.3333, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 076, Loss: 1.4616, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 077, Loss: 1.4276, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 078, Loss: 1.4308, Val Acc: 0.3333, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 079, Loss: 1.4437, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 080, Loss: 1.4373, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 081, Loss: 1.4237, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 082, Loss: 1.4228, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 083, Loss: 1.4114, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 084, Loss: 1.3809, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 085, Loss: 1.3970, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 086, Loss: 1.3656, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 087, Loss: 1.3353, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 088, Loss: 1.3372, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 089, Loss: 1.3163, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 090, Loss: 1.3250, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 091, Loss: 1.3358, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 092, Loss: 1.3280, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 093, Loss: 1.3278, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 094, Loss: 1.3028, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 095, Loss: 1.2943, Val Acc: 0.2889, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 096, Loss: 1.2793, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 097, Loss: 1.2828, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 098, Loss: 1.2536, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 099, Loss: 1.3148, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 100, Loss: 1.2600, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 101, Loss: 1.3244, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 102, Loss: 1.2640, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 103, Loss: 1.2572, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 104, Loss: 1.2541, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 105, Loss: 1.2421, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 106, Loss: 1.2281, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 107, Loss: 1.2362, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 108, Loss: 1.2238, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 109, Loss: 1.2294, Val Acc: 0.3444, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 110, Loss: 1.2152, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 111, Loss: 1.2050, Val Acc: 0.3333, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 112, Loss: 1.2219, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 113, Loss: 1.2184, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 114, Loss: 1.2025, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 115, Loss: 1.2852, Val Acc: 0.3000, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 116, Loss: 1.2318, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 117, Loss: 1.2392, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 118, Loss: 1.2623, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 119, Loss: 1.2279, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 120, Loss: 1.2021, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 121, Loss: 1.2205, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 122, Loss: 1.1882, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 123, Loss: 1.1752, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 124, Loss: 1.1882, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 125, Loss: 1.1719, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 126, Loss: 1.1875, Val Acc: 0.3222, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 127, Loss: 1.1998, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 128, Loss: 1.3030, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 129, Loss: 1.3072, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 130, Loss: 1.2362, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 131, Loss: 1.1866, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 132, Loss: 1.1980, Val Acc: 0.3556, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 133, Loss: 1.1555, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 134, Loss: 1.1707, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 135, Loss: 1.2114, Val Acc: 0.2889, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 136, Loss: 1.2051, Val Acc: 0.3333, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 137, Loss: 1.1582, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 138, Loss: 1.1872, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 139, Loss: 1.1832, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 140, Loss: 1.1385, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 141, Loss: 1.1225, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 142, Loss: 1.1628, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 143, Loss: 1.1476, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 144, Loss: 1.1837, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 145, Loss: 1.1084, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 146, Loss: 1.1627, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 147, Loss: 1.1065, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 148, Loss: 1.0946, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 149, Loss: 1.0980, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 150, Loss: 1.0921, Val Acc: 0.2778, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 151, Loss: 1.0716, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 152, Loss: 1.1035, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 153, Loss: 1.1261, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 154, Loss: 1.1469, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 155, Loss: 1.0783, Val Acc: 0.2778, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 156, Loss: 1.0738, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 157, Loss: 1.0788, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 158, Loss: 1.1116, Val Acc: 0.3444, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 159, Loss: 1.1211, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 160, Loss: 1.1521, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 161, Loss: 1.2355, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 162, Loss: 1.1879, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 163, Loss: 1.1397, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 164, Loss: 1.0729, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 165, Loss: 1.0855, Val Acc: 0.3111, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 166, Loss: 1.0698, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 167, Loss: 1.0558, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 168, Loss: 1.0442, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 169, Loss: 1.0707, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 170, Loss: 1.0562, Val Acc: 0.3000, Test Acc: 0.4444\n",
            "Seed: 42, Epoch: 171, Loss: 1.0261, Val Acc: 0.3444, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 172, Loss: 1.0207, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 173, Loss: 1.0336, Val Acc: 0.3111, Test Acc: 0.4556\n",
            "Seed: 42, Epoch: 174, Loss: 1.0360, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 175, Loss: 1.0160, Val Acc: 0.3778, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 176, Loss: 1.0052, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 177, Loss: 1.0497, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 178, Loss: 1.0272, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 179, Loss: 0.9837, Val Acc: 0.3111, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 180, Loss: 1.1284, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 181, Loss: 1.0696, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 182, Loss: 1.0714, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 183, Loss: 1.0859, Val Acc: 0.2889, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 184, Loss: 1.1625, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 185, Loss: 1.1471, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 186, Loss: 1.0827, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 187, Loss: 1.1240, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 188, Loss: 1.0568, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 189, Loss: 1.0759, Val Acc: 0.3333, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 190, Loss: 1.0525, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 191, Loss: 1.0166, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 192, Loss: 0.9972, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 193, Loss: 0.9823, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 194, Loss: 0.9566, Val Acc: 0.3444, Test Acc: 0.4667\n",
            "Seed: 42, Epoch: 195, Loss: 0.9709, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 196, Loss: 0.9556, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 197, Loss: 0.9328, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 198, Loss: 0.9173, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 199, Loss: 0.8987, Val Acc: 0.2889, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 200, Loss: 0.9253, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 001, Loss: 1.7908, Val Acc: 0.1444, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 002, Loss: 1.7733, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 003, Loss: 1.7659, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 004, Loss: 1.7537, Val Acc: 0.1444, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 005, Loss: 1.7504, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 006, Loss: 1.7429, Val Acc: 0.2111, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 007, Loss: 1.7325, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 008, Loss: 1.7309, Val Acc: 0.1889, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 009, Loss: 1.7258, Val Acc: 0.2000, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 010, Loss: 1.7309, Val Acc: 0.2444, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 011, Loss: 1.7263, Val Acc: 0.1667, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 012, Loss: 1.7236, Val Acc: 0.2222, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 013, Loss: 1.7120, Val Acc: 0.2111, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 014, Loss: 1.7206, Val Acc: 0.1778, Test Acc: 0.1333\n",
            "Seed: 43, Epoch: 015, Loss: 1.7004, Val Acc: 0.2222, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 016, Loss: 1.6903, Val Acc: 0.2444, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 017, Loss: 1.6985, Val Acc: 0.2444, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 018, Loss: 1.6997, Val Acc: 0.2444, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 019, Loss: 1.6867, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 020, Loss: 1.6713, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 021, Loss: 1.6722, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 022, Loss: 1.6579, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 023, Loss: 1.6867, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 024, Loss: 1.6619, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 025, Loss: 1.6547, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 026, Loss: 1.6424, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 027, Loss: 1.6580, Val Acc: 0.2556, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 028, Loss: 1.6843, Val Acc: 0.3222, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 029, Loss: 1.6483, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 030, Loss: 1.6773, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 031, Loss: 1.6330, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 032, Loss: 1.6684, Val Acc: 0.2222, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 033, Loss: 1.6610, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 034, Loss: 1.6314, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 035, Loss: 1.6440, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 036, Loss: 1.6307, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 037, Loss: 1.6165, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 038, Loss: 1.5930, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 039, Loss: 1.5826, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 040, Loss: 1.5986, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 041, Loss: 1.5894, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 042, Loss: 1.5556, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 043, Loss: 1.5614, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 044, Loss: 1.5653, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 045, Loss: 1.5445, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 046, Loss: 1.5571, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 047, Loss: 1.5244, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 048, Loss: 1.5277, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 049, Loss: 1.5179, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 050, Loss: 1.5115, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 051, Loss: 1.5175, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 052, Loss: 1.5129, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 053, Loss: 1.5150, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 054, Loss: 1.5040, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 055, Loss: 1.4747, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 056, Loss: 1.4860, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 057, Loss: 1.5000, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 058, Loss: 1.5075, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 059, Loss: 1.4789, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 060, Loss: 1.4700, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 061, Loss: 1.4640, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 062, Loss: 1.4745, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 063, Loss: 1.4557, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 064, Loss: 1.4597, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 065, Loss: 1.4682, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 066, Loss: 1.4594, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 067, Loss: 1.4715, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 068, Loss: 1.4624, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 069, Loss: 1.4674, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 070, Loss: 1.4177, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 071, Loss: 1.4185, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 072, Loss: 1.4508, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 073, Loss: 1.4213, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 074, Loss: 1.4833, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 075, Loss: 1.5233, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 076, Loss: 1.4362, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 077, Loss: 1.4601, Val Acc: 0.2667, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 078, Loss: 1.4642, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 079, Loss: 1.4372, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 080, Loss: 1.4014, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 081, Loss: 1.4099, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 082, Loss: 1.3861, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 083, Loss: 1.3830, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 084, Loss: 1.3773, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 085, Loss: 1.3467, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 086, Loss: 1.3650, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 087, Loss: 1.3560, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 088, Loss: 1.3306, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 089, Loss: 1.3471, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 090, Loss: 1.3231, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 091, Loss: 1.3102, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 092, Loss: 1.3483, Val Acc: 0.3333, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 093, Loss: 1.3531, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 094, Loss: 1.4427, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 095, Loss: 1.3732, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 096, Loss: 1.3558, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 097, Loss: 1.3829, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 098, Loss: 1.3279, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 099, Loss: 1.2975, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 100, Loss: 1.3311, Val Acc: 0.3000, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 101, Loss: 1.3119, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 102, Loss: 1.3475, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 103, Loss: 1.3099, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 104, Loss: 1.3459, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 105, Loss: 1.3096, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 106, Loss: 1.3332, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 107, Loss: 1.2951, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 108, Loss: 1.3046, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 109, Loss: 1.2716, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 110, Loss: 1.2630, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 111, Loss: 1.2593, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 112, Loss: 1.2252, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 113, Loss: 1.2313, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 114, Loss: 1.2411, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 115, Loss: 1.2391, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 116, Loss: 1.2259, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 117, Loss: 1.2129, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 118, Loss: 1.2222, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 119, Loss: 1.2858, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 120, Loss: 1.2925, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 121, Loss: 1.2506, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 122, Loss: 1.2722, Val Acc: 0.2667, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 123, Loss: 1.2144, Val Acc: 0.2778, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 124, Loss: 1.2123, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 125, Loss: 1.2191, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 126, Loss: 1.2444, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 127, Loss: 1.2162, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 128, Loss: 1.2382, Val Acc: 0.3111, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 129, Loss: 1.2023, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 130, Loss: 1.3035, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 131, Loss: 1.2070, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 132, Loss: 1.2492, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 133, Loss: 1.2516, Val Acc: 0.2333, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 134, Loss: 1.2318, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 135, Loss: 1.1972, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 136, Loss: 1.1770, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 137, Loss: 1.1901, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 138, Loss: 1.1483, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 139, Loss: 1.1672, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 140, Loss: 1.1439, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 141, Loss: 1.1389, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 142, Loss: 1.1336, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 143, Loss: 1.1169, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 144, Loss: 1.1288, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 145, Loss: 1.1486, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 146, Loss: 1.1063, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 147, Loss: 1.1013, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 148, Loss: 1.0973, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 149, Loss: 1.1110, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 150, Loss: 1.0690, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 151, Loss: 1.0832, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 152, Loss: 1.0769, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 153, Loss: 1.0900, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 154, Loss: 1.0967, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 155, Loss: 1.1670, Val Acc: 0.3111, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 156, Loss: 1.1461, Val Acc: 0.2889, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 157, Loss: 1.2731, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 158, Loss: 1.2188, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 159, Loss: 1.2201, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 160, Loss: 1.1859, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 161, Loss: 1.1566, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 162, Loss: 1.1995, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 163, Loss: 1.1477, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 164, Loss: 1.0991, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 165, Loss: 1.1792, Val Acc: 0.3667, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 166, Loss: 1.1101, Val Acc: 0.3111, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 167, Loss: 1.1482, Val Acc: 0.3333, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 168, Loss: 1.0818, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 169, Loss: 1.0861, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 170, Loss: 1.0995, Val Acc: 0.3444, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 171, Loss: 1.0747, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 172, Loss: 1.0730, Val Acc: 0.3111, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 173, Loss: 1.0654, Val Acc: 0.2889, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 174, Loss: 1.0713, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 175, Loss: 1.0665, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 176, Loss: 1.0392, Val Acc: 0.2778, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 177, Loss: 1.0482, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 178, Loss: 1.0623, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 179, Loss: 1.2840, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 180, Loss: 1.1299, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 181, Loss: 1.0440, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 182, Loss: 1.1341, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 183, Loss: 1.0082, Val Acc: 0.3444, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 184, Loss: 0.9910, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 185, Loss: 1.0012, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 186, Loss: 0.9918, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 187, Loss: 1.0103, Val Acc: 0.2667, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 188, Loss: 1.0188, Val Acc: 0.3444, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 189, Loss: 0.9856, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 190, Loss: 0.9530, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 191, Loss: 0.9571, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 192, Loss: 0.9829, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 193, Loss: 0.9624, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 194, Loss: 0.9677, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 195, Loss: 0.9473, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 196, Loss: 0.9272, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 197, Loss: 0.9302, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 198, Loss: 0.9434, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 199, Loss: 0.8952, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 200, Loss: 0.9326, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 001, Loss: 1.8097, Val Acc: 0.1111, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 002, Loss: 1.7805, Val Acc: 0.1333, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 003, Loss: 1.7760, Val Acc: 0.1222, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 004, Loss: 1.7708, Val Acc: 0.1778, Test Acc: 0.2111\n",
            "Seed: 44, Epoch: 005, Loss: 1.7673, Val Acc: 0.2000, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 006, Loss: 1.7603, Val Acc: 0.2000, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 007, Loss: 1.7549, Val Acc: 0.1889, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 008, Loss: 1.7397, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 009, Loss: 1.7259, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 010, Loss: 1.7175, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 011, Loss: 1.7120, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 012, Loss: 1.7149, Val Acc: 0.1889, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 013, Loss: 1.6940, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 014, Loss: 1.7073, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 015, Loss: 1.6768, Val Acc: 0.3111, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 016, Loss: 1.7032, Val Acc: 0.2000, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 017, Loss: 1.7121, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 018, Loss: 1.6741, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 019, Loss: 1.6544, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 020, Loss: 1.6637, Val Acc: 0.2556, Test Acc: 0.2111\n",
            "Seed: 44, Epoch: 021, Loss: 1.6452, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 022, Loss: 1.6427, Val Acc: 0.2222, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 023, Loss: 1.6283, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 024, Loss: 1.6298, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 025, Loss: 1.6465, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 026, Loss: 1.5994, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 027, Loss: 1.6123, Val Acc: 0.2000, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 028, Loss: 1.6763, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 029, Loss: 1.6352, Val Acc: 0.3000, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 030, Loss: 1.6677, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 031, Loss: 1.6386, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 032, Loss: 1.6336, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 033, Loss: 1.6380, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 034, Loss: 1.6249, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 035, Loss: 1.5987, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 036, Loss: 1.5985, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 037, Loss: 1.5846, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 038, Loss: 1.5662, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 039, Loss: 1.5629, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 040, Loss: 1.5509, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 041, Loss: 1.5350, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 042, Loss: 1.5253, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 043, Loss: 1.5079, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 044, Loss: 1.4973, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 045, Loss: 1.4962, Val Acc: 0.3333, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 046, Loss: 1.5033, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 047, Loss: 1.4874, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 048, Loss: 1.4621, Val Acc: 0.3222, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 049, Loss: 1.4681, Val Acc: 0.3111, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 050, Loss: 1.4314, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 051, Loss: 1.4328, Val Acc: 0.3111, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 052, Loss: 1.4092, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 053, Loss: 1.4392, Val Acc: 0.3111, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 054, Loss: 1.4158, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 055, Loss: 1.4339, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 056, Loss: 1.4293, Val Acc: 0.3333, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 057, Loss: 1.4296, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 058, Loss: 1.4021, Val Acc: 0.3444, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 059, Loss: 1.3799, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 060, Loss: 1.3548, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 061, Loss: 1.3625, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 062, Loss: 1.3733, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 063, Loss: 1.3456, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 064, Loss: 1.3293, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 065, Loss: 1.3538, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 066, Loss: 1.3397, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 067, Loss: 1.3482, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 068, Loss: 1.4009, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 069, Loss: 1.4245, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 070, Loss: 1.3794, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 071, Loss: 1.3522, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 072, Loss: 1.4107, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 073, Loss: 1.3779, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 074, Loss: 1.3232, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 075, Loss: 1.3813, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 076, Loss: 1.3082, Val Acc: 0.3333, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 077, Loss: 1.3288, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 078, Loss: 1.3652, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 079, Loss: 1.3578, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 080, Loss: 1.3132, Val Acc: 0.3556, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 081, Loss: 1.3083, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 082, Loss: 1.3057, Val Acc: 0.3444, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 083, Loss: 1.3139, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 084, Loss: 1.2840, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 085, Loss: 1.2602, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 086, Loss: 1.2485, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 087, Loss: 1.2434, Val Acc: 0.3667, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 088, Loss: 1.2217, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 089, Loss: 1.2300, Val Acc: 0.3556, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 090, Loss: 1.2329, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 091, Loss: 1.2364, Val Acc: 0.3444, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 092, Loss: 1.2497, Val Acc: 0.3333, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 093, Loss: 1.2409, Val Acc: 0.3667, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 094, Loss: 1.2222, Val Acc: 0.3222, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 095, Loss: 1.1896, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 096, Loss: 1.2349, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 097, Loss: 1.2096, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 098, Loss: 1.2201, Val Acc: 0.3556, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 099, Loss: 1.2192, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 100, Loss: 1.2040, Val Acc: 0.3667, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 101, Loss: 1.2330, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 102, Loss: 1.2097, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 103, Loss: 1.2192, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 104, Loss: 1.1627, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 105, Loss: 1.2229, Val Acc: 0.3222, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 106, Loss: 1.1805, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 107, Loss: 1.1609, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 108, Loss: 1.1553, Val Acc: 0.3222, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 109, Loss: 1.1303, Val Acc: 0.3444, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 110, Loss: 1.1094, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 111, Loss: 1.1591, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 112, Loss: 1.0999, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 113, Loss: 1.0563, Val Acc: 0.3667, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 114, Loss: 1.0723, Val Acc: 0.3333, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 115, Loss: 1.0849, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 116, Loss: 1.0873, Val Acc: 0.3333, Test Acc: 0.5000\n",
            "Seed: 44, Epoch: 117, Loss: 1.0321, Val Acc: 0.3444, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 118, Loss: 1.0046, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 119, Loss: 0.9967, Val Acc: 0.3667, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 120, Loss: 1.0035, Val Acc: 0.3556, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 121, Loss: 1.0068, Val Acc: 0.3000, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 122, Loss: 0.9749, Val Acc: 0.3667, Test Acc: 0.4667\n",
            "Seed: 44, Epoch: 123, Loss: 1.0214, Val Acc: 0.3556, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 124, Loss: 1.1509, Val Acc: 0.3111, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 125, Loss: 1.0465, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 126, Loss: 1.0857, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 127, Loss: 1.0447, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 128, Loss: 1.0664, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 129, Loss: 1.0317, Val Acc: 0.3222, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 130, Loss: 1.0492, Val Acc: 0.3222, Test Acc: 0.4667\n",
            "Seed: 44, Epoch: 131, Loss: 1.0023, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 132, Loss: 1.0123, Val Acc: 0.3111, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 133, Loss: 1.0266, Val Acc: 0.3667, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 134, Loss: 0.9739, Val Acc: 0.3667, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 135, Loss: 1.0159, Val Acc: 0.3667, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 136, Loss: 0.9690, Val Acc: 0.3667, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 137, Loss: 0.9824, Val Acc: 0.3778, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 138, Loss: 0.9655, Val Acc: 0.3889, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 139, Loss: 0.9096, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 140, Loss: 0.9154, Val Acc: 0.3778, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 141, Loss: 0.9018, Val Acc: 0.4000, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 142, Loss: 0.9096, Val Acc: 0.3778, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 143, Loss: 0.8749, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 144, Loss: 0.9121, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 145, Loss: 0.8844, Val Acc: 0.3667, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 146, Loss: 0.9052, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 147, Loss: 0.8961, Val Acc: 0.3778, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 148, Loss: 0.8614, Val Acc: 0.3667, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 149, Loss: 0.8427, Val Acc: 0.3556, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 150, Loss: 0.8383, Val Acc: 0.3556, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 151, Loss: 0.8498, Val Acc: 0.3667, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 152, Loss: 0.8756, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 153, Loss: 0.9205, Val Acc: 0.3556, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 154, Loss: 0.8747, Val Acc: 0.3444, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 155, Loss: 0.8747, Val Acc: 0.4000, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 156, Loss: 0.8547, Val Acc: 0.3667, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 157, Loss: 0.8643, Val Acc: 0.3778, Test Acc: 0.4667\n",
            "Seed: 44, Epoch: 158, Loss: 0.8043, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 159, Loss: 0.8578, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 160, Loss: 0.9017, Val Acc: 0.3556, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 161, Loss: 0.8759, Val Acc: 0.4000, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 162, Loss: 0.8972, Val Acc: 0.3556, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 163, Loss: 0.8074, Val Acc: 0.3556, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 164, Loss: 0.7915, Val Acc: 0.3889, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 165, Loss: 0.8271, Val Acc: 0.3667, Test Acc: 0.5111\n",
            "Seed: 44, Epoch: 166, Loss: 0.8141, Val Acc: 0.4000, Test Acc: 0.4778\n",
            "Seed: 44, Epoch: 167, Loss: 0.8053, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 168, Loss: 0.8485, Val Acc: 0.4000, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 169, Loss: 0.7886, Val Acc: 0.3778, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 170, Loss: 0.8226, Val Acc: 0.3889, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 171, Loss: 0.8066, Val Acc: 0.3667, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 172, Loss: 0.7607, Val Acc: 0.3778, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 173, Loss: 0.7541, Val Acc: 0.3667, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 174, Loss: 0.7408, Val Acc: 0.4222, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 175, Loss: 0.8044, Val Acc: 0.3889, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 176, Loss: 0.7619, Val Acc: 0.4000, Test Acc: 0.4667\n",
            "Seed: 44, Epoch: 177, Loss: 0.7250, Val Acc: 0.4444, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 178, Loss: 0.7507, Val Acc: 0.4000, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 179, Loss: 0.7187, Val Acc: 0.4111, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 180, Loss: 0.7439, Val Acc: 0.4000, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 181, Loss: 0.7124, Val Acc: 0.3778, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 182, Loss: 0.6769, Val Acc: 0.4111, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 183, Loss: 0.6603, Val Acc: 0.3889, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 184, Loss: 0.6823, Val Acc: 0.4111, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 185, Loss: 0.6849, Val Acc: 0.3889, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 186, Loss: 0.6725, Val Acc: 0.4000, Test Acc: 0.4667\n",
            "Seed: 44, Epoch: 187, Loss: 0.6481, Val Acc: 0.4000, Test Acc: 0.4889\n",
            "Seed: 44, Epoch: 188, Loss: 0.6477, Val Acc: 0.3889, Test Acc: 0.4667\n",
            "Seed: 44, Epoch: 189, Loss: 0.6960, Val Acc: 0.4000, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 190, Loss: 0.6566, Val Acc: 0.4111, Test Acc: 0.4667\n",
            "Seed: 44, Epoch: 191, Loss: 0.6498, Val Acc: 0.3667, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 192, Loss: 0.6193, Val Acc: 0.4111, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 193, Loss: 0.6610, Val Acc: 0.4222, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 194, Loss: 0.6071, Val Acc: 0.4000, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 195, Loss: 0.5996, Val Acc: 0.3889, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 196, Loss: 0.5927, Val Acc: 0.4111, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 197, Loss: 0.5851, Val Acc: 0.4444, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 198, Loss: 0.5865, Val Acc: 0.4000, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 199, Loss: 0.5715, Val Acc: 0.4000, Test Acc: 0.4667\n",
            "Seed: 44, Epoch: 200, Loss: 0.6200, Val Acc: 0.3778, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 001, Loss: 1.8274, Val Acc: 0.1889, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 002, Loss: 1.7911, Val Acc: 0.1667, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 003, Loss: 1.7814, Val Acc: 0.1778, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 004, Loss: 1.7763, Val Acc: 0.1889, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 005, Loss: 1.7685, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 006, Loss: 1.7620, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 007, Loss: 1.7575, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 008, Loss: 1.7524, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 009, Loss: 1.7503, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 010, Loss: 1.7337, Val Acc: 0.2000, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 011, Loss: 1.7292, Val Acc: 0.2000, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 012, Loss: 1.7224, Val Acc: 0.2000, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 013, Loss: 1.7172, Val Acc: 0.2222, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 014, Loss: 1.7109, Val Acc: 0.2444, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 015, Loss: 1.7048, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 016, Loss: 1.6970, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 017, Loss: 1.6999, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 018, Loss: 1.6899, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 019, Loss: 1.6787, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 020, Loss: 1.6793, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 021, Loss: 1.6646, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 022, Loss: 1.6663, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 023, Loss: 1.6625, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 024, Loss: 1.6652, Val Acc: 0.2889, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 025, Loss: 1.6550, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 026, Loss: 1.6507, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 027, Loss: 1.6429, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 028, Loss: 1.6424, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 029, Loss: 1.6304, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 030, Loss: 1.6311, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 031, Loss: 1.6287, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 032, Loss: 1.6083, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 033, Loss: 1.6208, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 034, Loss: 1.6060, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 035, Loss: 1.6082, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 036, Loss: 1.6216, Val Acc: 0.2111, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 037, Loss: 1.5877, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 038, Loss: 1.5735, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 039, Loss: 1.5902, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 040, Loss: 1.5620, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 041, Loss: 1.5678, Val Acc: 0.2444, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 042, Loss: 1.5827, Val Acc: 0.2333, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 043, Loss: 1.5650, Val Acc: 0.2000, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 044, Loss: 1.5759, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 045, Loss: 1.5674, Val Acc: 0.2111, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 046, Loss: 1.5800, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 047, Loss: 1.5596, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 048, Loss: 1.5583, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 049, Loss: 1.5651, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 050, Loss: 1.5577, Val Acc: 0.2000, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 051, Loss: 1.5653, Val Acc: 0.2444, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 052, Loss: 1.5483, Val Acc: 0.2111, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 053, Loss: 1.5558, Val Acc: 0.2111, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 054, Loss: 1.5312, Val Acc: 0.1778, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 055, Loss: 1.5344, Val Acc: 0.2111, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 056, Loss: 1.5322, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 057, Loss: 1.5193, Val Acc: 0.2000, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 058, Loss: 1.5097, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 059, Loss: 1.5169, Val Acc: 0.2111, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 060, Loss: 1.4946, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 061, Loss: 1.4843, Val Acc: 0.2000, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 062, Loss: 1.4835, Val Acc: 0.1778, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 063, Loss: 1.4709, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 064, Loss: 1.4738, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 065, Loss: 1.4908, Val Acc: 0.1667, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 066, Loss: 1.4732, Val Acc: 0.2000, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 067, Loss: 1.4528, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 068, Loss: 1.4535, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 069, Loss: 1.4282, Val Acc: 0.2000, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 070, Loss: 1.4069, Val Acc: 0.2000, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 071, Loss: 1.4103, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 072, Loss: 1.4165, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 073, Loss: 1.3898, Val Acc: 0.2000, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 074, Loss: 1.4294, Val Acc: 0.2111, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 075, Loss: 1.4304, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 076, Loss: 1.4041, Val Acc: 0.2111, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 077, Loss: 1.4183, Val Acc: 0.1778, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 078, Loss: 1.4057, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 079, Loss: 1.3989, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 080, Loss: 1.3781, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 081, Loss: 1.3660, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 082, Loss: 1.3397, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 083, Loss: 1.3511, Val Acc: 0.2000, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 084, Loss: 1.3601, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 085, Loss: 1.3146, Val Acc: 0.2222, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 086, Loss: 1.3121, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 087, Loss: 1.3067, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 088, Loss: 1.3144, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 089, Loss: 1.3174, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 090, Loss: 1.3074, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 091, Loss: 1.2946, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 092, Loss: 1.3052, Val Acc: 0.2222, Test Acc: 0.4444\n",
            "Seed: 45, Epoch: 093, Loss: 1.2902, Val Acc: 0.2111, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 094, Loss: 1.3835, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 095, Loss: 1.3403, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 096, Loss: 1.3528, Val Acc: 0.2111, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 097, Loss: 1.3663, Val Acc: 0.2000, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 098, Loss: 1.3295, Val Acc: 0.3333, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 099, Loss: 1.3237, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 100, Loss: 1.2983, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 101, Loss: 1.2911, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 102, Loss: 1.2827, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 103, Loss: 1.2721, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 104, Loss: 1.2486, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 105, Loss: 1.2483, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 106, Loss: 1.2837, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 107, Loss: 1.2394, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 108, Loss: 1.2282, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 109, Loss: 1.2365, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 110, Loss: 1.2100, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 111, Loss: 1.2387, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 112, Loss: 1.2037, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 113, Loss: 1.1775, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 114, Loss: 1.1890, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 115, Loss: 1.1814, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 116, Loss: 1.1691, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 117, Loss: 1.1753, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 118, Loss: 1.1847, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 119, Loss: 1.1359, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 120, Loss: 1.1372, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 121, Loss: 1.1454, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 122, Loss: 1.1416, Val Acc: 0.3111, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 123, Loss: 1.1713, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 124, Loss: 1.1905, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 125, Loss: 1.2109, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 126, Loss: 1.1701, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 127, Loss: 1.2235, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 128, Loss: 1.2320, Val Acc: 0.3444, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 129, Loss: 1.1896, Val Acc: 0.3444, Test Acc: 0.4222\n",
            "Seed: 45, Epoch: 130, Loss: 1.1696, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 131, Loss: 1.2125, Val Acc: 0.2778, Test Acc: 0.4222\n",
            "Seed: 45, Epoch: 132, Loss: 1.1785, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 133, Loss: 1.1417, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 134, Loss: 1.2086, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 135, Loss: 1.1144, Val Acc: 0.2889, Test Acc: 0.4222\n",
            "Seed: 45, Epoch: 136, Loss: 1.2090, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 137, Loss: 1.2261, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 138, Loss: 1.1277, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 139, Loss: 1.1670, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 140, Loss: 1.1220, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 141, Loss: 1.1385, Val Acc: 0.3333, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 142, Loss: 1.1488, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 143, Loss: 1.1089, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 144, Loss: 1.1221, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 145, Loss: 1.1310, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 146, Loss: 1.1113, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 147, Loss: 1.1660, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 148, Loss: 1.1034, Val Acc: 0.3778, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 149, Loss: 1.0985, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 150, Loss: 1.1584, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 151, Loss: 1.1154, Val Acc: 0.3778, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 152, Loss: 1.0864, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 153, Loss: 1.0971, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 154, Loss: 1.0942, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 155, Loss: 1.0571, Val Acc: 0.3889, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 156, Loss: 1.0787, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 157, Loss: 1.0869, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 158, Loss: 1.0954, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 159, Loss: 1.0512, Val Acc: 0.3444, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 160, Loss: 1.0475, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 161, Loss: 1.0329, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 162, Loss: 1.0389, Val Acc: 0.3333, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 163, Loss: 1.0684, Val Acc: 0.3444, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 164, Loss: 1.0835, Val Acc: 0.3444, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 165, Loss: 1.0828, Val Acc: 0.3667, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 166, Loss: 1.0368, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 167, Loss: 1.0748, Val Acc: 0.3667, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 168, Loss: 1.0429, Val Acc: 0.3667, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 169, Loss: 1.0120, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 170, Loss: 1.0098, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 171, Loss: 1.0033, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 172, Loss: 1.0030, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 173, Loss: 0.9765, Val Acc: 0.3667, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 174, Loss: 1.0224, Val Acc: 0.3444, Test Acc: 0.4333\n",
            "Seed: 45, Epoch: 175, Loss: 1.0087, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 176, Loss: 1.0325, Val Acc: 0.3444, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 177, Loss: 1.0204, Val Acc: 0.3667, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 178, Loss: 0.9939, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 179, Loss: 1.0471, Val Acc: 0.3111, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 180, Loss: 1.0050, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 181, Loss: 0.9543, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 182, Loss: 0.9695, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 183, Loss: 0.9389, Val Acc: 0.3556, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 184, Loss: 0.9383, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 185, Loss: 0.9695, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 186, Loss: 0.9010, Val Acc: 0.4000, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 187, Loss: 0.9115, Val Acc: 0.3778, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 188, Loss: 0.9110, Val Acc: 0.3667, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 189, Loss: 0.8670, Val Acc: 0.3667, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 190, Loss: 0.8828, Val Acc: 0.3444, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 191, Loss: 0.9123, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 192, Loss: 0.9335, Val Acc: 0.3778, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 193, Loss: 0.9771, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 194, Loss: 0.8922, Val Acc: 0.3667, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 195, Loss: 0.9299, Val Acc: 0.3556, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 196, Loss: 0.8931, Val Acc: 0.3444, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 197, Loss: 0.8459, Val Acc: 0.3889, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 198, Loss: 0.8852, Val Acc: 0.4000, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 199, Loss: 0.9412, Val Acc: 0.4111, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 200, Loss: 0.9105, Val Acc: 0.4000, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 001, Loss: 1.7955, Val Acc: 0.2000, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 002, Loss: 1.8173, Val Acc: 0.1444, Test Acc: 0.2111\n",
            "Seed: 46, Epoch: 003, Loss: 1.7852, Val Acc: 0.1444, Test Acc: 0.2000\n",
            "Seed: 46, Epoch: 004, Loss: 1.7782, Val Acc: 0.1556, Test Acc: 0.2222\n",
            "Seed: 46, Epoch: 005, Loss: 1.7815, Val Acc: 0.1556, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 006, Loss: 1.7747, Val Acc: 0.1444, Test Acc: 0.2222\n",
            "Seed: 46, Epoch: 007, Loss: 1.7699, Val Acc: 0.1889, Test Acc: 0.2222\n",
            "Seed: 46, Epoch: 008, Loss: 1.7634, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 009, Loss: 1.7587, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 010, Loss: 1.7494, Val Acc: 0.2000, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 011, Loss: 1.7434, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 012, Loss: 1.7289, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 013, Loss: 1.7228, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 014, Loss: 1.7078, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 015, Loss: 1.6924, Val Acc: 0.2000, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 016, Loss: 1.6826, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 017, Loss: 1.6700, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 018, Loss: 1.6628, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 019, Loss: 1.6665, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 020, Loss: 1.6537, Val Acc: 0.2111, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 021, Loss: 1.6841, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 022, Loss: 1.6518, Val Acc: 0.2889, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 023, Loss: 1.6754, Val Acc: 0.2000, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 024, Loss: 1.6500, Val Acc: 0.2000, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 025, Loss: 1.6516, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 026, Loss: 1.6271, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 027, Loss: 1.6139, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 028, Loss: 1.6398, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 029, Loss: 1.6329, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 030, Loss: 1.6434, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 031, Loss: 1.6090, Val Acc: 0.1667, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 032, Loss: 1.6134, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 033, Loss: 1.5967, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 034, Loss: 1.5966, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 035, Loss: 1.5846, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 036, Loss: 1.5665, Val Acc: 0.2222, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 037, Loss: 1.5714, Val Acc: 0.1889, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 038, Loss: 1.5649, Val Acc: 0.2222, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 039, Loss: 1.5508, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 040, Loss: 1.5383, Val Acc: 0.2222, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 041, Loss: 1.5603, Val Acc: 0.2000, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 042, Loss: 1.5688, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 043, Loss: 1.5346, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 044, Loss: 1.5422, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 045, Loss: 1.5251, Val Acc: 0.2111, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 046, Loss: 1.5207, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 047, Loss: 1.5069, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 048, Loss: 1.5014, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 049, Loss: 1.5032, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 050, Loss: 1.5000, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 051, Loss: 1.4874, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 052, Loss: 1.5047, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 053, Loss: 1.5815, Val Acc: 0.2000, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 054, Loss: 1.5674, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 055, Loss: 1.5304, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 056, Loss: 1.4897, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 057, Loss: 1.4970, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 058, Loss: 1.4843, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 059, Loss: 1.4845, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 060, Loss: 1.4578, Val Acc: 0.3111, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 061, Loss: 1.4688, Val Acc: 0.2222, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 062, Loss: 1.4420, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 063, Loss: 1.4180, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 064, Loss: 1.4154, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 065, Loss: 1.4598, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 066, Loss: 1.4200, Val Acc: 0.3000, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 067, Loss: 1.4018, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 068, Loss: 1.4120, Val Acc: 0.2889, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 069, Loss: 1.3996, Val Acc: 0.2778, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 070, Loss: 1.4085, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 071, Loss: 1.4305, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 072, Loss: 1.4402, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 073, Loss: 1.3999, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 074, Loss: 1.3841, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 075, Loss: 1.3984, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 076, Loss: 1.3679, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 077, Loss: 1.3795, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 078, Loss: 1.3688, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 079, Loss: 1.3525, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 080, Loss: 1.3618, Val Acc: 0.3222, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 081, Loss: 1.3798, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 082, Loss: 1.3905, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 083, Loss: 1.3380, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 084, Loss: 1.3505, Val Acc: 0.3333, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 085, Loss: 1.3184, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 086, Loss: 1.3174, Val Acc: 0.2889, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 087, Loss: 1.3246, Val Acc: 0.3333, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 088, Loss: 1.3127, Val Acc: 0.3222, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 089, Loss: 1.3128, Val Acc: 0.3333, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 090, Loss: 1.2935, Val Acc: 0.3333, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 091, Loss: 1.3244, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 092, Loss: 1.3395, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 093, Loss: 1.5808, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 094, Loss: 1.5152, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 095, Loss: 1.6588, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 096, Loss: 1.5952, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 097, Loss: 1.4589, Val Acc: 0.2444, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 098, Loss: 1.4544, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 099, Loss: 1.4261, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 100, Loss: 1.3977, Val Acc: 0.3111, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 101, Loss: 1.3889, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 102, Loss: 1.3778, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 103, Loss: 1.3609, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 104, Loss: 1.3479, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 105, Loss: 1.3708, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 106, Loss: 1.4539, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 107, Loss: 1.3441, Val Acc: 0.3000, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 108, Loss: 1.2881, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 109, Loss: 1.2996, Val Acc: 0.3444, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 110, Loss: 1.3095, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 111, Loss: 1.3550, Val Acc: 0.3556, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 112, Loss: 1.3759, Val Acc: 0.3444, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 113, Loss: 1.3710, Val Acc: 0.3333, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 114, Loss: 1.3945, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 115, Loss: 1.4707, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 116, Loss: 1.5000, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 117, Loss: 1.4751, Val Acc: 0.2667, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 118, Loss: 1.4478, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 119, Loss: 1.4564, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 120, Loss: 1.4060, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 121, Loss: 1.3929, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 122, Loss: 1.3560, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 123, Loss: 1.3567, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 124, Loss: 1.3243, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 125, Loss: 1.3337, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 126, Loss: 1.2860, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 127, Loss: 1.3054, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 128, Loss: 1.2994, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 129, Loss: 1.2688, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 130, Loss: 1.2619, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 131, Loss: 1.2789, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 132, Loss: 1.2533, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 133, Loss: 1.2601, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 134, Loss: 1.2299, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 135, Loss: 1.2241, Val Acc: 0.2889, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 136, Loss: 1.2340, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 137, Loss: 1.2124, Val Acc: 0.2889, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 138, Loss: 1.2171, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 139, Loss: 1.1735, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 140, Loss: 1.2209, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 141, Loss: 1.1714, Val Acc: 0.3000, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 142, Loss: 1.2073, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 143, Loss: 1.1630, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 144, Loss: 1.1622, Val Acc: 0.3556, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 145, Loss: 1.1510, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 146, Loss: 1.1220, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 147, Loss: 1.1025, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 148, Loss: 1.1274, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 149, Loss: 1.1203, Val Acc: 0.3444, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 150, Loss: 1.0939, Val Acc: 0.3444, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 151, Loss: 1.0961, Val Acc: 0.3222, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 152, Loss: 1.0966, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 153, Loss: 1.0680, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 154, Loss: 1.1028, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 155, Loss: 1.0993, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 156, Loss: 1.0650, Val Acc: 0.3667, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 157, Loss: 1.0467, Val Acc: 0.3667, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 158, Loss: 1.0433, Val Acc: 0.3889, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 159, Loss: 1.0400, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 160, Loss: 1.0856, Val Acc: 0.3889, Test Acc: 0.4778\n",
            "Seed: 46, Epoch: 161, Loss: 1.0822, Val Acc: 0.3444, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 162, Loss: 1.0469, Val Acc: 0.3667, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 163, Loss: 1.0439, Val Acc: 0.3667, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 164, Loss: 1.0091, Val Acc: 0.3667, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 165, Loss: 1.0096, Val Acc: 0.3667, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 166, Loss: 1.0183, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 167, Loss: 1.0667, Val Acc: 0.4111, Test Acc: 0.4556\n",
            "Seed: 46, Epoch: 168, Loss: 1.0360, Val Acc: 0.3778, Test Acc: 0.4333\n",
            "Seed: 46, Epoch: 169, Loss: 0.9722, Val Acc: 0.3889, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 170, Loss: 0.9720, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 171, Loss: 0.9726, Val Acc: 0.3667, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 172, Loss: 0.9916, Val Acc: 0.3889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 173, Loss: 0.9897, Val Acc: 0.4000, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 174, Loss: 0.9868, Val Acc: 0.3889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 175, Loss: 1.0615, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 176, Loss: 1.1987, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 177, Loss: 1.2481, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 178, Loss: 1.2661, Val Acc: 0.4333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 179, Loss: 1.1562, Val Acc: 0.3111, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 180, Loss: 1.1423, Val Acc: 0.3556, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 181, Loss: 1.0464, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 182, Loss: 1.0172, Val Acc: 0.3444, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 183, Loss: 1.0383, Val Acc: 0.3556, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 184, Loss: 0.9961, Val Acc: 0.3556, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 185, Loss: 1.0281, Val Acc: 0.3889, Test Acc: 0.4556\n",
            "Seed: 46, Epoch: 186, Loss: 0.9789, Val Acc: 0.4222, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 187, Loss: 0.9638, Val Acc: 0.3667, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 188, Loss: 0.9205, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 189, Loss: 0.9532, Val Acc: 0.4000, Test Acc: 0.4444\n",
            "Seed: 46, Epoch: 190, Loss: 0.9168, Val Acc: 0.3778, Test Acc: 0.4667\n",
            "Seed: 46, Epoch: 191, Loss: 0.9070, Val Acc: 0.4222, Test Acc: 0.4778\n",
            "Seed: 46, Epoch: 192, Loss: 0.9350, Val Acc: 0.3778, Test Acc: 0.4778\n",
            "Seed: 46, Epoch: 193, Loss: 0.8882, Val Acc: 0.3778, Test Acc: 0.4333\n",
            "Seed: 46, Epoch: 194, Loss: 0.8665, Val Acc: 0.3889, Test Acc: 0.4444\n",
            "Seed: 46, Epoch: 195, Loss: 0.8689, Val Acc: 0.3889, Test Acc: 0.4778\n",
            "Seed: 46, Epoch: 196, Loss: 0.8626, Val Acc: 0.3889, Test Acc: 0.4333\n",
            "Seed: 46, Epoch: 197, Loss: 0.8438, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 198, Loss: 0.8722, Val Acc: 0.3778, Test Acc: 0.4667\n",
            "Seed: 46, Epoch: 199, Loss: 0.8432, Val Acc: 0.3556, Test Acc: 0.4556\n",
            "Seed: 46, Epoch: 200, Loss: 0.8207, Val Acc: 0.3889, Test Acc: 0.4444\n",
            "Average Time: 23.08 seconds\n",
            "Var Time: 0.05 seconds\n",
            "Average Memory: 3954.40 MB\n",
            "Average Best Val Acc: 0.4067\n",
            "Std Best Test Acc: 0.0356\n",
            "Average Test Acc: 0.3844\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.data import DataLoader,Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch.utils.data import random_split\n",
        "import os\n",
        "import os.path as osp\n",
        "import argparse\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, EdgePooling\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "from torch_geometric.nn import BatchNorm\n",
        "\n",
        "\n",
        "class HierarchicalGCN_CoPooling(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes):\n",
        "        super(HierarchicalGCN_CoPooling, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, out_channels)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.lin1 = torch.nn.Linear(out_channels, 32)\n",
        "        self.lin2 = torch.nn.Linear(32, num_classes)\n",
        "        self.pool1 = CoPooling(ratio=0.5, K=1, edge_ratio=0.6, nhid=64, alpha=0.1, Init='Random', Gamma=1.0)\n",
        "        self.pool2 = CoPooling(ratio=0.5, K=1, edge_ratio=0.6, nhid=64, alpha=0.1, Init='Random', Gamma=1.0)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        batch_size = int(batch.max() + 1)\n",
        "\n",
        "        # First GCN and pooling layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn1(x)\n",
        "        x, edge_index, perm, _, batch, _, _, _ = self.pool1(x, edge_index, edge_attr=None, batch=batch)\n",
        "\n",
        "        # Second GCN and pooling layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn2(x)\n",
        "        x, edge_index, perm, _, batch, _, _, _  = self.pool2(x, edge_index, edge_attr=None, batch=batch)\n",
        "\n",
        "        # Third GCN layer\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn3(x)\n",
        "\n",
        "        # Mean pooling over the nodes\n",
        "        x, mask = to_dense_batch(x, batch)\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.lin1(x).relu()\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "num_classes = dataset_sparse.num_classes\n",
        "in_channels = dataset_sparse.num_features\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HierarchicalGCN_CoPooling(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == data.y).sum().item()\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seeds = [42, 43, 44, 45, 46]\n",
        "times = []\n",
        "memories = []\n",
        "best_val_accs = []\n",
        "best_test_accs = []\n",
        "\n",
        "early_stop_patience = 150\n",
        "tolerance = 0.0001\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    model = HierarchicalGCN_CoPooling(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        val_acc = test(valid_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        if val_acc > best_val_acc + tolerance:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "        if epochs_no_improve >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
        "\n",
        "    times.append(total_time)\n",
        "    memories.append(memory_allocated)\n",
        "    best_val_accs.append(best_val_acc)\n",
        "    best_test_accs.append(best_test_acc)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
        "print(f'Var Time: {np.var(times):.2f} seconds')\n",
        "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
        "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
        "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
        "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNlxbMaA0jBh"
      },
      "source": [
        "## CGIPooling with HierarchicalGCN (2021)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EovZXoL0jJB"
      },
      "outputs": [],
      "source": [
        "from torch_scatter import scatter_add, scatter\n",
        "from torch_geometric.nn.inits import uniform\n",
        "from torch_geometric.nn.resolver import activation_resolver\n",
        "from torch_geometric.nn import GCNConv, GATConv, LEConv, SAGEConv, GraphConv\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "@dataclass(init=False)\n",
        "class SelectOutput:\n",
        "    r\"\"\"The output of the :class:`Select` method, which holds an assignment\n",
        "    from selected nodes to their respective cluster(s).\n",
        "\n",
        "    Args:\n",
        "        node_index (torch.Tensor): The indices of the selected nodes.\n",
        "        num_nodes (int): The number of nodes.\n",
        "        cluster_index (torch.Tensor): The indices of the clusters each node in\n",
        "            :obj:`node_index` is assigned to.\n",
        "        num_clusters (int): The number of clusters.\n",
        "        weight (torch.Tensor, optional): A weight vector, denoting the strength\n",
        "            of the assignment of a node to its cluster. (default: :obj:`None`)\n",
        "    \"\"\"\n",
        "    node_index: Tensor\n",
        "    num_nodes: int\n",
        "    cluster_index: Tensor\n",
        "    num_clusters: int\n",
        "    weight: Optional[Tensor] = None\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        node_index: Tensor,\n",
        "        num_nodes: int,\n",
        "        cluster_index: Tensor,\n",
        "        num_clusters: int,\n",
        "        weight: Optional[Tensor] = None,\n",
        "    ):\n",
        "        if node_index.dim() != 1:\n",
        "            raise ValueError(f\"Expected 'node_index' to be one-dimensional \"\n",
        "                             f\"(got {node_index.dim()} dimensions)\")\n",
        "\n",
        "        if cluster_index.dim() != 1:\n",
        "            raise ValueError(f\"Expected 'cluster_index' to be one-dimensional \"\n",
        "                             f\"(got {cluster_index.dim()} dimensions)\")\n",
        "\n",
        "        if node_index.numel() != cluster_index.numel():\n",
        "            raise ValueError(f\"Expected 'node_index' and 'cluster_index' to \"\n",
        "                             f\"hold the same number of values (got \"\n",
        "                             f\"{node_index.numel()} and \"\n",
        "                             f\"{cluster_index.numel()} values)\")\n",
        "\n",
        "        if weight is not None and weight.dim() != 1:\n",
        "            raise ValueError(f\"Expected 'weight' vector to be one-dimensional \"\n",
        "                             f\"(got {weight.dim()} dimensions)\")\n",
        "\n",
        "        if weight is not None and weight.numel() != node_index.numel():\n",
        "            raise ValueError(f\"Expected 'weight' to hold {node_index.numel()} \"\n",
        "                             f\"values (got {weight.numel()} values)\")\n",
        "\n",
        "        self.node_index = node_index\n",
        "        self.num_nodes = num_nodes\n",
        "        self.cluster_index = cluster_index\n",
        "        self.num_clusters = num_clusters\n",
        "        self.weight = weight\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Select(torch.nn.Module):\n",
        "    r\"\"\"An abstract base class for implementing custom node selections as\n",
        "    described in the `\"Understanding Pooling in Graph Neural Networks\"\n",
        "    <https://arxiv.org/abs/1905.05178>`_ paper, which maps the nodes of an\n",
        "    input graph to supernodes in the coarsened graph.\n",
        "\n",
        "    Specifically, :class:`Select` returns a :class:`SelectOutput` output, which\n",
        "    holds a (sparse) mapping :math:`\\mathbf{C} \\in {[0, 1]}^{N \\times C}` that\n",
        "    assigns selected nodes to one or more of :math:`C` super nodes.\n",
        "    \"\"\"\n",
        "    def reset_parameters(self):\n",
        "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def forward(self, *args, **kwargs) -> SelectOutput:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f'{self.__class__.__name__}()'\n",
        "\n",
        "def cumsum(x: Tensor, dim: int = 0) -> Tensor:\n",
        "    r\"\"\"Returns the cumulative sum of elements of :obj:`x`.\n",
        "    In contrast to :meth:`torch.cumsum`, prepends the output with zero.\n",
        "\n",
        "    Args:\n",
        "        x (torch.Tensor): The input tensor.\n",
        "        dim (int, optional): The dimension to do the operation over.\n",
        "            (default: :obj:`0`)\n",
        "\n",
        "    Example:\n",
        "        >>> x = torch.tensor([2, 4, 1])\n",
        "        >>> cumsum(x)\n",
        "        tensor([0, 2, 6, 7])\n",
        "\n",
        "    \"\"\"\n",
        "    size = x.size()[:dim] + (x.size(dim) + 1, ) + x.size()[dim + 1:]\n",
        "    out = x.new_empty(size)\n",
        "\n",
        "    out.narrow(dim, 0, 1).zero_()\n",
        "    torch.cumsum(x, dim=dim, out=out.narrow(dim, 1, x.size(dim)))\n",
        "\n",
        "    return out\n",
        "\n",
        "def maybe_num_nodes(edge_index, num_nodes=None):\n",
        "    if num_nodes is not None:\n",
        "        return num_nodes\n",
        "    elif isinstance(edge_index, Tensor):\n",
        "        return int(edge_index.max()) + 1 if edge_index.numel() > 0 else 0\n",
        "    else:\n",
        "        return max(edge_index.size(0), edge_index.size(1))\n",
        "\n",
        "def maybe_num_nodes(edge_index, num_nodes=None):\n",
        "    if num_nodes is not None:\n",
        "        return num_nodes\n",
        "    elif isinstance(edge_index, Tensor):\n",
        "        return int(edge_index.max()) + 1 if edge_index.numel() > 0 else 0\n",
        "    else:\n",
        "        return max(edge_index.size(0), edge_index.size(1))\n",
        "\n",
        "def filter_adj(edge_index, edge_attr, perm, num_nodes=None):\n",
        "    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
        "\n",
        "    mask = perm.new_full((num_nodes, ), -1)\n",
        "    i = torch.arange(perm.size(0), dtype=torch.long, device=perm.device)\n",
        "    mask[perm] = i\n",
        "\n",
        "    row, col = edge_index\n",
        "    row, col = mask[row], mask[col]\n",
        "    mask = (row >= 0) & (col >= 0)\n",
        "    row, col = row[mask], col[mask]\n",
        "\n",
        "    if edge_attr is not None:\n",
        "        edge_attr = edge_attr[mask]\n",
        "\n",
        "    return torch.stack([row, col], dim=0), edge_attr\n",
        "\n",
        "def topk(\n",
        "    x: Tensor,\n",
        "    ratio: Optional[Union[float, int]],\n",
        "    batch: Tensor,\n",
        "    min_score: Optional[float] = None,\n",
        "    tol: float = 1e-7,\n",
        ") -> Tensor:\n",
        "    if min_score is not None:\n",
        "        # Make sure that we do not drop all nodes in a graph.\n",
        "        scores_max = scatter(x, batch, reduce='max')[batch] - tol\n",
        "        scores_min = scores_max.clamp(max=min_score)\n",
        "\n",
        "        perm = (x > scores_min).nonzero().view(-1)\n",
        "        return perm\n",
        "\n",
        "    if ratio is not None:\n",
        "        num_nodes = scatter(batch.new_ones(x.size(0)), batch, reduce='sum')\n",
        "\n",
        "        if ratio >= 1:\n",
        "            k = num_nodes.new_full((num_nodes.size(0), ), int(ratio))\n",
        "        else:\n",
        "            k = (float(ratio) * num_nodes.to(x.dtype)).ceil().to(torch.long)\n",
        "\n",
        "        x, x_perm = torch.sort(x.view(-1), descending=True)\n",
        "        batch = batch[x_perm]\n",
        "        batch, batch_perm = torch.sort(batch, descending=False, stable=True)\n",
        "\n",
        "        arange = torch.arange(x.size(0), dtype=torch.long, device=x.device)\n",
        "        ptr = cumsum(num_nodes)\n",
        "        batched_arange = arange - ptr[batch]\n",
        "        mask = batched_arange < k[batch]\n",
        "\n",
        "        return x_perm[batch_perm[mask]]\n",
        "\n",
        "    raise ValueError(\"At least one of the 'ratio' and 'min_score' parameters \"\n",
        "                     \"must be specified\")\n",
        "\n",
        "class Discriminator(torch.nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_channels * 2, in_channels)\n",
        "        self.fc2 = nn.Linear(in_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class CGIPool(torch.nn.Module):\n",
        "    def __init__(self, in_channels, ratio=0.5, non_lin=torch.tanh):\n",
        "        super(CGIPool, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.ratio = ratio\n",
        "        self.non_lin = non_lin\n",
        "        self.hidden_dim = in_channels\n",
        "        self.transform = GraphConv(in_channels, self.hidden_dim)\n",
        "        self.pp_conv = GraphConv(self.hidden_dim, self.hidden_dim)\n",
        "        self.np_conv = GraphConv(self.hidden_dim, self.hidden_dim)\n",
        "\n",
        "        self.positive_pooling = GraphConv(self.hidden_dim, 1)\n",
        "        self.negative_pooling = GraphConv(self.hidden_dim, 1)\n",
        "\n",
        "        self.discriminator = Discriminator(self.hidden_dim)\n",
        "        self.loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr=None, batch=None):\n",
        "        device = x.device  # \n",
        "\n",
        "        if batch is None:\n",
        "            batch = edge_index.new_zeros(x.size(0))\n",
        "\n",
        "        x_transform = F.leaky_relu(self.transform(x, edge_index), 0.2)\n",
        "        x_tp = F.leaky_relu(self.pp_conv(x, edge_index), 0.2)\n",
        "        x_tn = F.leaky_relu(self.np_conv(x, edge_index), 0.2)\n",
        "        s_pp = self.positive_pooling(x_tp, edge_index).squeeze()\n",
        "        s_np = self.negative_pooling(x_tn, edge_index).squeeze()\n",
        "\n",
        "        perm_positive = topk(s_pp, 1, batch)\n",
        "        perm_negative = topk(s_np, 1, batch)\n",
        "        x_pp = x_transform[perm_positive] * self.non_lin(s_pp[perm_positive]).view(-1, 1)\n",
        "        x_np = x_transform[perm_negative] * self.non_lin(s_np[perm_negative]).view(-1, 1)\n",
        "\n",
        "        x_pp_readout = gap(x_pp, batch[perm_positive])\n",
        "        x_np_readout = gap(x_np, batch[perm_negative])\n",
        "        x_readout = gap(x_transform, batch)\n",
        "\n",
        "        positive_pair = torch.cat([x_pp_readout, x_readout], dim=1)\n",
        "        negative_pair = torch.cat([x_np_readout, x_readout], dim=1)\n",
        "\n",
        "        real = torch.ones(positive_pair.shape[0], device=device)  # \n",
        "        fake = torch.zeros(negative_pair.shape[0], device=device)  # \n",
        "        #real_loss = self.loss_fn(self.discriminator(positive_pair), real)\n",
        "        #fake_loss = self.loss_fn(self.discriminator(negative_pair), fake)\n",
        "        #discrimination_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        score = (s_pp - s_np)\n",
        "\n",
        "        perm = topk(score, self.ratio, batch)\n",
        "        x = x_transform[perm] * self.non_lin(score[perm]).view(-1, 1)\n",
        "        batch = batch[perm]\n",
        "\n",
        "        filter_edge_index, filter_edge_attr = filter_adj(edge_index, edge_attr, perm, num_nodes=score.size(0))\n",
        "        return x, filter_edge_index, filter_edge_attr, batch, perm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw3rZwN_1KD5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 001, Loss: 1.8476, Val Acc: 0.1556, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 002, Loss: 1.7889, Val Acc: 0.1667, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 003, Loss: 1.7784, Val Acc: 0.1222, Test Acc: 0.1333\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 004, Loss: 1.7688, Val Acc: 0.1667, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 005, Loss: 1.7612, Val Acc: 0.1667, Test Acc: 0.2000\n",
            "Seed: 42, Epoch: 006, Loss: 1.7546, Val Acc: 0.1444, Test Acc: 0.1778\n",
            "Seed: 42, Epoch: 007, Loss: 1.7429, Val Acc: 0.1778, Test Acc: 0.2000\n",
            "Seed: 42, Epoch: 008, Loss: 1.7346, Val Acc: 0.1778, Test Acc: 0.2000\n",
            "Seed: 42, Epoch: 009, Loss: 1.7209, Val Acc: 0.2000, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 010, Loss: 1.7116, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 011, Loss: 1.7057, Val Acc: 0.1778, Test Acc: 0.2000\n",
            "Seed: 42, Epoch: 012, Loss: 1.6954, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 013, Loss: 1.6762, Val Acc: 0.2000, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 014, Loss: 1.6853, Val Acc: 0.2111, Test Acc: 0.2111\n",
            "Seed: 42, Epoch: 015, Loss: 1.6705, Val Acc: 0.2222, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 016, Loss: 1.6721, Val Acc: 0.1889, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 017, Loss: 1.6616, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 018, Loss: 1.6567, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 019, Loss: 1.6518, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 020, Loss: 1.6525, Val Acc: 0.1778, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 021, Loss: 1.6442, Val Acc: 0.2556, Test Acc: 0.2111\n",
            "Seed: 42, Epoch: 022, Loss: 1.6408, Val Acc: 0.2222, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 023, Loss: 1.6288, Val Acc: 0.2111, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 024, Loss: 1.6175, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 025, Loss: 1.6333, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 026, Loss: 1.6245, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 027, Loss: 1.6006, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 028, Loss: 1.6071, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 029, Loss: 1.6043, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 030, Loss: 1.5825, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 031, Loss: 1.5940, Val Acc: 0.2000, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 032, Loss: 1.5902, Val Acc: 0.2000, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 033, Loss: 1.5770, Val Acc: 0.2667, Test Acc: 0.2222\n",
            "Seed: 42, Epoch: 034, Loss: 1.5843, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 035, Loss: 1.5963, Val Acc: 0.3222, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 036, Loss: 1.5571, Val Acc: 0.2556, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 037, Loss: 1.5795, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 038, Loss: 1.5547, Val Acc: 0.2667, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 039, Loss: 1.5966, Val Acc: 0.2667, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 040, Loss: 1.5903, Val Acc: 0.2222, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 041, Loss: 1.5681, Val Acc: 0.3111, Test Acc: 0.2111\n",
            "Seed: 42, Epoch: 042, Loss: 1.6271, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 043, Loss: 1.5619, Val Acc: 0.2111, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 044, Loss: 1.5865, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 045, Loss: 1.5538, Val Acc: 0.3000, Test Acc: 0.2111\n",
            "Seed: 42, Epoch: 046, Loss: 1.5517, Val Acc: 0.2778, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 047, Loss: 1.5442, Val Acc: 0.2778, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 048, Loss: 1.5332, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 049, Loss: 1.5298, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 050, Loss: 1.5293, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 051, Loss: 1.5096, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 052, Loss: 1.5030, Val Acc: 0.3111, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 053, Loss: 1.5103, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 054, Loss: 1.4999, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 055, Loss: 1.5078, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 056, Loss: 1.4984, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 057, Loss: 1.4827, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 058, Loss: 1.4959, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 059, Loss: 1.4752, Val Acc: 0.2889, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 060, Loss: 1.4672, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 061, Loss: 1.4849, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 062, Loss: 1.4906, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 063, Loss: 1.4663, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 064, Loss: 1.4605, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 065, Loss: 1.4707, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 066, Loss: 1.4654, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 067, Loss: 1.4394, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 068, Loss: 1.4466, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 069, Loss: 1.4164, Val Acc: 0.2889, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 070, Loss: 1.4137, Val Acc: 0.3111, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 071, Loss: 1.4136, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 072, Loss: 1.4118, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 073, Loss: 1.4013, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 074, Loss: 1.3963, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 075, Loss: 1.4056, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 076, Loss: 1.3805, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 077, Loss: 1.3867, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 078, Loss: 1.3853, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 079, Loss: 1.4274, Val Acc: 0.2111, Test Acc: 0.2222\n",
            "Seed: 42, Epoch: 080, Loss: 1.5139, Val Acc: 0.2111, Test Acc: 0.2222\n",
            "Seed: 42, Epoch: 081, Loss: 1.5476, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 082, Loss: 1.5921, Val Acc: 0.2000, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 083, Loss: 1.5187, Val Acc: 0.1778, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 084, Loss: 1.4857, Val Acc: 0.1889, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 085, Loss: 1.4668, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 086, Loss: 1.4712, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 087, Loss: 1.4370, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 088, Loss: 1.4250, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 089, Loss: 1.3865, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 090, Loss: 1.3867, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 091, Loss: 1.3563, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 092, Loss: 1.4025, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 093, Loss: 1.4155, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 094, Loss: 1.3733, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 095, Loss: 1.3773, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 096, Loss: 1.3683, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 097, Loss: 1.3434, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 098, Loss: 1.3558, Val Acc: 0.3000, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 099, Loss: 1.3313, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 100, Loss: 1.3245, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 101, Loss: 1.3028, Val Acc: 0.3222, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 102, Loss: 1.2997, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 103, Loss: 1.2984, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 104, Loss: 1.2913, Val Acc: 0.3556, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 105, Loss: 1.2850, Val Acc: 0.3111, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 106, Loss: 1.2781, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 107, Loss: 1.2566, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 108, Loss: 1.2753, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 109, Loss: 1.2407, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 110, Loss: 1.2526, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 111, Loss: 1.2242, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 112, Loss: 1.2289, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 113, Loss: 1.2136, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 114, Loss: 1.1824, Val Acc: 0.3333, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 115, Loss: 1.2220, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 116, Loss: 1.2884, Val Acc: 0.3000, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 117, Loss: 1.2355, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 118, Loss: 1.2104, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 119, Loss: 1.2106, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 120, Loss: 1.1795, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 121, Loss: 1.1944, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 122, Loss: 1.1585, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 123, Loss: 1.1765, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 124, Loss: 1.1593, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 125, Loss: 1.2188, Val Acc: 0.3111, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 126, Loss: 1.1621, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 127, Loss: 1.1471, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 128, Loss: 1.1654, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 129, Loss: 1.1467, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 130, Loss: 1.1242, Val Acc: 0.3000, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 131, Loss: 1.1208, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 132, Loss: 1.1011, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 133, Loss: 1.1058, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 134, Loss: 1.0918, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 135, Loss: 1.0524, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 136, Loss: 1.0545, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 137, Loss: 1.0488, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 138, Loss: 1.0351, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 139, Loss: 1.0443, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 140, Loss: 1.0537, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 141, Loss: 1.0218, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 142, Loss: 1.0979, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 143, Loss: 1.1274, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 144, Loss: 1.0908, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 145, Loss: 1.1236, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 146, Loss: 1.0300, Val Acc: 0.3000, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 147, Loss: 1.0619, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 148, Loss: 1.0384, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 149, Loss: 1.0322, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 150, Loss: 1.0427, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 151, Loss: 1.0486, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 152, Loss: 1.0520, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 153, Loss: 1.2594, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 154, Loss: 1.1632, Val Acc: 0.3778, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 155, Loss: 1.0877, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 156, Loss: 1.0852, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 157, Loss: 1.0357, Val Acc: 0.3111, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 158, Loss: 1.0583, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 159, Loss: 0.9793, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 160, Loss: 1.0561, Val Acc: 0.3444, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 161, Loss: 0.9999, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 162, Loss: 0.9815, Val Acc: 0.3556, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 163, Loss: 0.9579, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 164, Loss: 1.0086, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 165, Loss: 0.9306, Val Acc: 0.3333, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 166, Loss: 0.9397, Val Acc: 0.3333, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 167, Loss: 0.9164, Val Acc: 0.3444, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 168, Loss: 0.9077, Val Acc: 0.3667, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 169, Loss: 0.8955, Val Acc: 0.3556, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 170, Loss: 0.9020, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 171, Loss: 0.8569, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 172, Loss: 0.9201, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 173, Loss: 0.8733, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 174, Loss: 0.8935, Val Acc: 0.3556, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 175, Loss: 0.8854, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 176, Loss: 0.9531, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 177, Loss: 0.9121, Val Acc: 0.3444, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 178, Loss: 0.8663, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 179, Loss: 0.8572, Val Acc: 0.3556, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 180, Loss: 0.8885, Val Acc: 0.3667, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 181, Loss: 0.8722, Val Acc: 0.3444, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 182, Loss: 0.8659, Val Acc: 0.3667, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 183, Loss: 0.8766, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 184, Loss: 0.8495, Val Acc: 0.3444, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 185, Loss: 0.8501, Val Acc: 0.3444, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 186, Loss: 0.8339, Val Acc: 0.3667, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 187, Loss: 0.8400, Val Acc: 0.3333, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 188, Loss: 0.8405, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 189, Loss: 1.0170, Val Acc: 0.3333, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 190, Loss: 1.2794, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 191, Loss: 2.0978, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 192, Loss: 1.4608, Val Acc: 0.1889, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 193, Loss: 1.7807, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 194, Loss: 1.5551, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 195, Loss: 1.4648, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 196, Loss: 1.4265, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 197, Loss: 1.4290, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 198, Loss: 1.4615, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 199, Loss: 1.4326, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 200, Loss: 1.3187, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 001, Loss: 1.7900, Val Acc: 0.2000, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 002, Loss: 1.7755, Val Acc: 0.1333, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 003, Loss: 1.7680, Val Acc: 0.1333, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 004, Loss: 1.7633, Val Acc: 0.1667, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 005, Loss: 1.7698, Val Acc: 0.2000, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 006, Loss: 1.7608, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 007, Loss: 1.7556, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 008, Loss: 1.7599, Val Acc: 0.1444, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 009, Loss: 1.7511, Val Acc: 0.2222, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 010, Loss: 1.7511, Val Acc: 0.2222, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 011, Loss: 1.7520, Val Acc: 0.1778, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 012, Loss: 1.7451, Val Acc: 0.1667, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 013, Loss: 1.7381, Val Acc: 0.2111, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 014, Loss: 1.7378, Val Acc: 0.1778, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 015, Loss: 1.7294, Val Acc: 0.1667, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 016, Loss: 1.7250, Val Acc: 0.1889, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 017, Loss: 1.7171, Val Acc: 0.1667, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 018, Loss: 1.7106, Val Acc: 0.1889, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 019, Loss: 1.6998, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 020, Loss: 1.6984, Val Acc: 0.1889, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 021, Loss: 1.6775, Val Acc: 0.2111, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 022, Loss: 1.6693, Val Acc: 0.2000, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 023, Loss: 1.6742, Val Acc: 0.1889, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 024, Loss: 1.6549, Val Acc: 0.1333, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 025, Loss: 1.7385, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 026, Loss: 1.6665, Val Acc: 0.2000, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 027, Loss: 1.6838, Val Acc: 0.2556, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 028, Loss: 1.6773, Val Acc: 0.2444, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 029, Loss: 1.6778, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 030, Loss: 1.6333, Val Acc: 0.2222, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 031, Loss: 1.6461, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 032, Loss: 1.6631, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 033, Loss: 1.6274, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 034, Loss: 1.6360, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 035, Loss: 1.6056, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 036, Loss: 1.6256, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 037, Loss: 1.6143, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 038, Loss: 1.5822, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 039, Loss: 1.5976, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 040, Loss: 1.5802, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 041, Loss: 1.5676, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 042, Loss: 1.5754, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 043, Loss: 1.5500, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 044, Loss: 1.5501, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 045, Loss: 1.5587, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 046, Loss: 1.5540, Val Acc: 0.2556, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 047, Loss: 1.5390, Val Acc: 0.2111, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 048, Loss: 1.5289, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 049, Loss: 1.5133, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 050, Loss: 1.5064, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 051, Loss: 1.5140, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 052, Loss: 1.4920, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 053, Loss: 1.5062, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 054, Loss: 1.4914, Val Acc: 0.2222, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 055, Loss: 1.4760, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 056, Loss: 1.4856, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 057, Loss: 1.4657, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 058, Loss: 1.4524, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 059, Loss: 1.4640, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 060, Loss: 1.4389, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 061, Loss: 1.4349, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 062, Loss: 1.4097, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 063, Loss: 1.4243, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 064, Loss: 1.3973, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 065, Loss: 1.3905, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 066, Loss: 1.3642, Val Acc: 0.2111, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 067, Loss: 1.3681, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 068, Loss: 1.3771, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 069, Loss: 1.3896, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 070, Loss: 1.3835, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 071, Loss: 1.3271, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 072, Loss: 1.3641, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 073, Loss: 1.3607, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 074, Loss: 1.3291, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 075, Loss: 1.3492, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 076, Loss: 1.4865, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 077, Loss: 1.4221, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 078, Loss: 1.4244, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 079, Loss: 1.4012, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 080, Loss: 1.3564, Val Acc: 0.2222, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 081, Loss: 1.3752, Val Acc: 0.2667, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 082, Loss: 1.3278, Val Acc: 0.2889, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 083, Loss: 1.3251, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 084, Loss: 1.3057, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 085, Loss: 1.2771, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 086, Loss: 1.2858, Val Acc: 0.2667, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 087, Loss: 1.2606, Val Acc: 0.2333, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 088, Loss: 1.2713, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 089, Loss: 1.2571, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 090, Loss: 1.3894, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 091, Loss: 1.2756, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 092, Loss: 1.2605, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 093, Loss: 1.2423, Val Acc: 0.3556, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 094, Loss: 1.2699, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 095, Loss: 1.2281, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 096, Loss: 1.2239, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 097, Loss: 1.2374, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 098, Loss: 1.2329, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 099, Loss: 1.2497, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 100, Loss: 1.1881, Val Acc: 0.3556, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 101, Loss: 1.2096, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 102, Loss: 1.2053, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 103, Loss: 1.2084, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 104, Loss: 1.1806, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 105, Loss: 1.1661, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 106, Loss: 1.1808, Val Acc: 0.2889, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 107, Loss: 1.1546, Val Acc: 0.3111, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 108, Loss: 1.1591, Val Acc: 0.3000, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 109, Loss: 1.0937, Val Acc: 0.3111, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 110, Loss: 1.1555, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 111, Loss: 1.1255, Val Acc: 0.2889, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 112, Loss: 1.1756, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 113, Loss: 1.1538, Val Acc: 0.2778, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 114, Loss: 1.1685, Val Acc: 0.3444, Test Acc: 0.4444\n",
            "Seed: 43, Epoch: 115, Loss: 1.1396, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 116, Loss: 1.1211, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 117, Loss: 1.1199, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 118, Loss: 1.0950, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 119, Loss: 1.0925, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 120, Loss: 1.0796, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 121, Loss: 1.1429, Val Acc: 0.3222, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 122, Loss: 1.0897, Val Acc: 0.2667, Test Acc: 0.4444\n",
            "Seed: 43, Epoch: 123, Loss: 1.1195, Val Acc: 0.3333, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 124, Loss: 1.0669, Val Acc: 0.2778, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 125, Loss: 1.0847, Val Acc: 0.3222, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 126, Loss: 1.0913, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 127, Loss: 1.0987, Val Acc: 0.3667, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 128, Loss: 1.1247, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 129, Loss: 1.0877, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 130, Loss: 1.0912, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 131, Loss: 1.0445, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 132, Loss: 1.0483, Val Acc: 0.2889, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 133, Loss: 1.0276, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 134, Loss: 1.0076, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 135, Loss: 1.0182, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 136, Loss: 1.0169, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 137, Loss: 1.0112, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 138, Loss: 1.0003, Val Acc: 0.3667, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 139, Loss: 1.0209, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 140, Loss: 1.0015, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 141, Loss: 0.9610, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 142, Loss: 0.9667, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 143, Loss: 1.0112, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 144, Loss: 0.9957, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 145, Loss: 0.9882, Val Acc: 0.3111, Test Acc: 0.4778\n",
            "Seed: 43, Epoch: 146, Loss: 0.9718, Val Acc: 0.2889, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 147, Loss: 0.9505, Val Acc: 0.3444, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 148, Loss: 0.9831, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 149, Loss: 0.9510, Val Acc: 0.3111, Test Acc: 0.4667\n",
            "Seed: 43, Epoch: 150, Loss: 0.9692, Val Acc: 0.2889, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 151, Loss: 0.9389, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 152, Loss: 0.9855, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 153, Loss: 0.8994, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 154, Loss: 0.9189, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 155, Loss: 0.9149, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 156, Loss: 0.8923, Val Acc: 0.3333, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 157, Loss: 0.8582, Val Acc: 0.3333, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 158, Loss: 0.8847, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 159, Loss: 0.9313, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 160, Loss: 1.1808, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 161, Loss: 1.1673, Val Acc: 0.3222, Test Acc: 0.4444\n",
            "Seed: 43, Epoch: 162, Loss: 1.0795, Val Acc: 0.3111, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 163, Loss: 0.9931, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 164, Loss: 1.0947, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 165, Loss: 0.9833, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 166, Loss: 1.0120, Val Acc: 0.2778, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 167, Loss: 0.9409, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 168, Loss: 0.9554, Val Acc: 0.2889, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 169, Loss: 0.9211, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 170, Loss: 0.8968, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 171, Loss: 0.8972, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 172, Loss: 0.8951, Val Acc: 0.3444, Test Acc: 0.4667\n",
            "Seed: 43, Epoch: 173, Loss: 0.8851, Val Acc: 0.3000, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 174, Loss: 0.8751, Val Acc: 0.3000, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 175, Loss: 0.8539, Val Acc: 0.3333, Test Acc: 0.4778\n",
            "Seed: 43, Epoch: 176, Loss: 0.7975, Val Acc: 0.2889, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 177, Loss: 0.8185, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 178, Loss: 0.8063, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 179, Loss: 0.7883, Val Acc: 0.3333, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 180, Loss: 0.7748, Val Acc: 0.3444, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 181, Loss: 0.7856, Val Acc: 0.3556, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 182, Loss: 0.7313, Val Acc: 0.3333, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 183, Loss: 0.7209, Val Acc: 0.3778, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 184, Loss: 0.7296, Val Acc: 0.3556, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 185, Loss: 0.7513, Val Acc: 0.3667, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 186, Loss: 0.7250, Val Acc: 0.3556, Test Acc: 0.4444\n",
            "Seed: 43, Epoch: 187, Loss: 0.7627, Val Acc: 0.3667, Test Acc: 0.4556\n",
            "Seed: 43, Epoch: 188, Loss: 0.7337, Val Acc: 0.3556, Test Acc: 0.4444\n",
            "Seed: 43, Epoch: 189, Loss: 0.7380, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 190, Loss: 0.7387, Val Acc: 0.3889, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 191, Loss: 0.7050, Val Acc: 0.3556, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 192, Loss: 0.6708, Val Acc: 0.3778, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 193, Loss: 0.7192, Val Acc: 0.3667, Test Acc: 0.4556\n",
            "Seed: 43, Epoch: 194, Loss: 0.7000, Val Acc: 0.3556, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 195, Loss: 0.6984, Val Acc: 0.3556, Test Acc: 0.4778\n",
            "Seed: 43, Epoch: 196, Loss: 0.6745, Val Acc: 0.3667, Test Acc: 0.4444\n",
            "Seed: 43, Epoch: 197, Loss: 0.6478, Val Acc: 0.3889, Test Acc: 0.4556\n",
            "Seed: 43, Epoch: 198, Loss: 0.6510, Val Acc: 0.3444, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 199, Loss: 0.6675, Val Acc: 0.3889, Test Acc: 0.4556\n",
            "Seed: 43, Epoch: 200, Loss: 0.6748, Val Acc: 0.3444, Test Acc: 0.4778\n",
            "Seed: 44, Epoch: 001, Loss: 1.7926, Val Acc: 0.2000, Test Acc: 0.2000\n",
            "Seed: 44, Epoch: 002, Loss: 1.7761, Val Acc: 0.2111, Test Acc: 0.2111\n",
            "Seed: 44, Epoch: 003, Loss: 1.7742, Val Acc: 0.2000, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 004, Loss: 1.7657, Val Acc: 0.2000, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 005, Loss: 1.7600, Val Acc: 0.1778, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 006, Loss: 1.7627, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 007, Loss: 1.7511, Val Acc: 0.1778, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 008, Loss: 1.7543, Val Acc: 0.1778, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 009, Loss: 1.7484, Val Acc: 0.1778, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 010, Loss: 1.7445, Val Acc: 0.2000, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 011, Loss: 1.7444, Val Acc: 0.2000, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 012, Loss: 1.7330, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 013, Loss: 1.7452, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 014, Loss: 1.7252, Val Acc: 0.2444, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 015, Loss: 1.7220, Val Acc: 0.2222, Test Acc: 0.2000\n",
            "Seed: 44, Epoch: 016, Loss: 1.7214, Val Acc: 0.2222, Test Acc: 0.2111\n",
            "Seed: 44, Epoch: 017, Loss: 1.7071, Val Acc: 0.2222, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 018, Loss: 1.6985, Val Acc: 0.2889, Test Acc: 0.2111\n",
            "Seed: 44, Epoch: 019, Loss: 1.7026, Val Acc: 0.2556, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 020, Loss: 1.6978, Val Acc: 0.2778, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 021, Loss: 1.6850, Val Acc: 0.2556, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 022, Loss: 1.6803, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 023, Loss: 1.6677, Val Acc: 0.2778, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 024, Loss: 1.6719, Val Acc: 0.2889, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 025, Loss: 1.6605, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 026, Loss: 1.6613, Val Acc: 0.1556, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 027, Loss: 1.6741, Val Acc: 0.2444, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 028, Loss: 1.7033, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 029, Loss: 1.6530, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 030, Loss: 1.6854, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 031, Loss: 1.6320, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 032, Loss: 1.6384, Val Acc: 0.2000, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 033, Loss: 1.6334, Val Acc: 0.2222, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 034, Loss: 1.6258, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 035, Loss: 1.6197, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 036, Loss: 1.6064, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 037, Loss: 1.5858, Val Acc: 0.2778, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 038, Loss: 1.5824, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 039, Loss: 1.5884, Val Acc: 0.2667, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 040, Loss: 1.6250, Val Acc: 0.3222, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 041, Loss: 1.5957, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 042, Loss: 1.5960, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 043, Loss: 1.5587, Val Acc: 0.3111, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 044, Loss: 1.5649, Val Acc: 0.2778, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 045, Loss: 1.5392, Val Acc: 0.3000, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 046, Loss: 1.5343, Val Acc: 0.2556, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 047, Loss: 1.5422, Val Acc: 0.2889, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 048, Loss: 1.5139, Val Acc: 0.3222, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 049, Loss: 1.5146, Val Acc: 0.3667, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 050, Loss: 1.5122, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 051, Loss: 1.5137, Val Acc: 0.3000, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 052, Loss: 1.4893, Val Acc: 0.3111, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 053, Loss: 1.4955, Val Acc: 0.3000, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 054, Loss: 1.4968, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 055, Loss: 1.5018, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 056, Loss: 1.4541, Val Acc: 0.3000, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 057, Loss: 1.4991, Val Acc: 0.3111, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 058, Loss: 1.4488, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 059, Loss: 1.4712, Val Acc: 0.3444, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 060, Loss: 1.5146, Val Acc: 0.3222, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 061, Loss: 1.4699, Val Acc: 0.3000, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 062, Loss: 1.4934, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 063, Loss: 1.4626, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 064, Loss: 1.4347, Val Acc: 0.3556, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 065, Loss: 1.4142, Val Acc: 0.3333, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 066, Loss: 1.4416, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 067, Loss: 1.4391, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 068, Loss: 1.4143, Val Acc: 0.3444, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 069, Loss: 1.4276, Val Acc: 0.3333, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 070, Loss: 1.3714, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 071, Loss: 1.4053, Val Acc: 0.3222, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 072, Loss: 1.3784, Val Acc: 0.3444, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 073, Loss: 1.3690, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 074, Loss: 1.3630, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 075, Loss: 1.3599, Val Acc: 0.3333, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 076, Loss: 1.3239, Val Acc: 0.3222, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 077, Loss: 1.3609, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 078, Loss: 1.3337, Val Acc: 0.3111, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 079, Loss: 1.3305, Val Acc: 0.3444, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 080, Loss: 1.3497, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 081, Loss: 1.3122, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 082, Loss: 1.3280, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 083, Loss: 1.3007, Val Acc: 0.3444, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 084, Loss: 1.3346, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 085, Loss: 1.2750, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 086, Loss: 1.2931, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 087, Loss: 1.2965, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 088, Loss: 1.2863, Val Acc: 0.3556, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 089, Loss: 1.2985, Val Acc: 0.3778, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 090, Loss: 1.2669, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 091, Loss: 1.2573, Val Acc: 0.3444, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 092, Loss: 1.2617, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 093, Loss: 1.2534, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 094, Loss: 1.2253, Val Acc: 0.3333, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 095, Loss: 1.2341, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 096, Loss: 1.2458, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 097, Loss: 1.2334, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 098, Loss: 1.2147, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 099, Loss: 1.2092, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 100, Loss: 1.1838, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 101, Loss: 1.1998, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 102, Loss: 1.1843, Val Acc: 0.3667, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 103, Loss: 1.1574, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 104, Loss: 1.1630, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 105, Loss: 1.1632, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 106, Loss: 1.1561, Val Acc: 0.3778, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 107, Loss: 1.1867, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 108, Loss: 1.2315, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 109, Loss: 1.2520, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 110, Loss: 1.2866, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 111, Loss: 1.1867, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 112, Loss: 1.3174, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 113, Loss: 1.3824, Val Acc: 0.3444, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 114, Loss: 1.2739, Val Acc: 0.3333, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 115, Loss: 1.2546, Val Acc: 0.3111, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 116, Loss: 1.2743, Val Acc: 0.3111, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 117, Loss: 1.2167, Val Acc: 0.3556, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 118, Loss: 1.1801, Val Acc: 0.3444, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 119, Loss: 1.2525, Val Acc: 0.4111, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 120, Loss: 1.1805, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 121, Loss: 1.1922, Val Acc: 0.3556, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 122, Loss: 1.1723, Val Acc: 0.3111, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 123, Loss: 1.1757, Val Acc: 0.3667, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 124, Loss: 1.1628, Val Acc: 0.3556, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 125, Loss: 1.1615, Val Acc: 0.3556, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 126, Loss: 1.1639, Val Acc: 0.3333, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 127, Loss: 1.1199, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 128, Loss: 1.1316, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 129, Loss: 1.1443, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 130, Loss: 1.1144, Val Acc: 0.3778, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 131, Loss: 1.0907, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 132, Loss: 1.1105, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 133, Loss: 1.0892, Val Acc: 0.3667, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 134, Loss: 1.0748, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 135, Loss: 1.0600, Val Acc: 0.3333, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 136, Loss: 1.0496, Val Acc: 0.3444, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 137, Loss: 1.0307, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 138, Loss: 1.0167, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 139, Loss: 1.0237, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 140, Loss: 0.9921, Val Acc: 0.3444, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 141, Loss: 1.0019, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 142, Loss: 1.0377, Val Acc: 0.3556, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 143, Loss: 1.0311, Val Acc: 0.3111, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 144, Loss: 1.0725, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 145, Loss: 1.0232, Val Acc: 0.3556, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 146, Loss: 0.9718, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 147, Loss: 1.0123, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 148, Loss: 1.0100, Val Acc: 0.4000, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 149, Loss: 1.0126, Val Acc: 0.3444, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 150, Loss: 0.9932, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 151, Loss: 1.0068, Val Acc: 0.3556, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 152, Loss: 1.0638, Val Acc: 0.3778, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 153, Loss: 1.0080, Val Acc: 0.3556, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 154, Loss: 1.0439, Val Acc: 0.3556, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 155, Loss: 0.9994, Val Acc: 0.3333, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 156, Loss: 0.9874, Val Acc: 0.3556, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 157, Loss: 1.0748, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 158, Loss: 0.9870, Val Acc: 0.3667, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 159, Loss: 1.0339, Val Acc: 0.3556, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 160, Loss: 0.9674, Val Acc: 0.3667, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 161, Loss: 1.0147, Val Acc: 0.3444, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 162, Loss: 0.9385, Val Acc: 0.3444, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 163, Loss: 1.0044, Val Acc: 0.3667, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 164, Loss: 0.9423, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 165, Loss: 0.9435, Val Acc: 0.3556, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 166, Loss: 0.8979, Val Acc: 0.3889, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 167, Loss: 0.9665, Val Acc: 0.3889, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 168, Loss: 0.9363, Val Acc: 0.3556, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 169, Loss: 0.9756, Val Acc: 0.3556, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 170, Loss: 0.9294, Val Acc: 0.3333, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 171, Loss: 0.9346, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 172, Loss: 0.8722, Val Acc: 0.3556, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 173, Loss: 0.9235, Val Acc: 0.3778, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 174, Loss: 0.9142, Val Acc: 0.3556, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 175, Loss: 0.8698, Val Acc: 0.3889, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 176, Loss: 0.8733, Val Acc: 0.3889, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 177, Loss: 0.8775, Val Acc: 0.3556, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 178, Loss: 0.8273, Val Acc: 0.3444, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 179, Loss: 0.8415, Val Acc: 0.3444, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 180, Loss: 0.9276, Val Acc: 0.3444, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 181, Loss: 0.9035, Val Acc: 0.4000, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 182, Loss: 0.9322, Val Acc: 0.3556, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 183, Loss: 0.8828, Val Acc: 0.3444, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 184, Loss: 0.9243, Val Acc: 0.3667, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 185, Loss: 0.8824, Val Acc: 0.3667, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 186, Loss: 0.9141, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 187, Loss: 0.8584, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 188, Loss: 0.9066, Val Acc: 0.3778, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 189, Loss: 0.8435, Val Acc: 0.3667, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 190, Loss: 0.8638, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 191, Loss: 0.7991, Val Acc: 0.3778, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 192, Loss: 0.8422, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 193, Loss: 0.8179, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 194, Loss: 0.7876, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 195, Loss: 0.7910, Val Acc: 0.3778, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 196, Loss: 0.7647, Val Acc: 0.3778, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 197, Loss: 0.7656, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 198, Loss: 0.7698, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 199, Loss: 0.7616, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 200, Loss: 0.7737, Val Acc: 0.3556, Test Acc: 0.4222\n",
            "Seed: 45, Epoch: 001, Loss: 1.8060, Val Acc: 0.1667, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 002, Loss: 1.7690, Val Acc: 0.1667, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 003, Loss: 1.7627, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 004, Loss: 1.7462, Val Acc: 0.2333, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 005, Loss: 1.7311, Val Acc: 0.1889, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 006, Loss: 1.7285, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 007, Loss: 1.7332, Val Acc: 0.2667, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 008, Loss: 1.7231, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 009, Loss: 1.7118, Val Acc: 0.2111, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 010, Loss: 1.7061, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 011, Loss: 1.7000, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 012, Loss: 1.7003, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 013, Loss: 1.6895, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 014, Loss: 1.6862, Val Acc: 0.2889, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 015, Loss: 1.6759, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 016, Loss: 1.6736, Val Acc: 0.3111, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 017, Loss: 1.6781, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 018, Loss: 1.6752, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 019, Loss: 1.6723, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 020, Loss: 1.6597, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 021, Loss: 1.6721, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 022, Loss: 1.6658, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 023, Loss: 1.6530, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 024, Loss: 1.6567, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 025, Loss: 1.6429, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 026, Loss: 1.6351, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 027, Loss: 1.6529, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 028, Loss: 7.8128, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 029, Loss: 1.6898, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 030, Loss: 1.7282, Val Acc: 0.2333, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 031, Loss: 1.7347, Val Acc: 0.2222, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 032, Loss: 1.7205, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 033, Loss: 1.7206, Val Acc: 0.2222, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 034, Loss: 1.7156, Val Acc: 0.2333, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 035, Loss: 1.7241, Val Acc: 0.1667, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 036, Loss: 1.7226, Val Acc: 0.1889, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 037, Loss: 1.7121, Val Acc: 0.2667, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 038, Loss: 1.7171, Val Acc: 0.2778, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 039, Loss: 1.6986, Val Acc: 0.2111, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 040, Loss: 1.7164, Val Acc: 0.3000, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 041, Loss: 1.6971, Val Acc: 0.2778, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 042, Loss: 1.6962, Val Acc: 0.2111, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 043, Loss: 1.6868, Val Acc: 0.2556, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 044, Loss: 1.6830, Val Acc: 0.2889, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 045, Loss: 1.6831, Val Acc: 0.2444, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 046, Loss: 1.6737, Val Acc: 0.2444, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 047, Loss: 1.6689, Val Acc: 0.3000, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 048, Loss: 1.6714, Val Acc: 0.3000, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 049, Loss: 1.6613, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 050, Loss: 1.6584, Val Acc: 0.2667, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 051, Loss: 1.6660, Val Acc: 0.3000, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 052, Loss: 1.6659, Val Acc: 0.2333, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 053, Loss: 1.6492, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 054, Loss: 1.6458, Val Acc: 0.3111, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 055, Loss: 1.6445, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 056, Loss: 1.6299, Val Acc: 0.3000, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 057, Loss: 1.6349, Val Acc: 0.3111, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 058, Loss: 1.6222, Val Acc: 0.3111, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 059, Loss: 1.6155, Val Acc: 0.3111, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 060, Loss: 1.6158, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 061, Loss: 1.6097, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 062, Loss: 1.6058, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 063, Loss: 1.6047, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 064, Loss: 1.6005, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 065, Loss: 1.6022, Val Acc: 0.2444, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 066, Loss: 1.6051, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 067, Loss: 1.6144, Val Acc: 0.2778, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 068, Loss: 1.5836, Val Acc: 0.2556, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 069, Loss: 1.6077, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 070, Loss: 1.5838, Val Acc: 0.2778, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 071, Loss: 1.5861, Val Acc: 0.2889, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 072, Loss: 1.5804, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 073, Loss: 1.5800, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 074, Loss: 1.5723, Val Acc: 0.3000, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 075, Loss: 1.5847, Val Acc: 0.3000, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 076, Loss: 1.5676, Val Acc: 0.3222, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 077, Loss: 1.5564, Val Acc: 0.2889, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 078, Loss: 1.5542, Val Acc: 0.2556, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 079, Loss: 1.5553, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 080, Loss: 1.5535, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 081, Loss: 1.5515, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 082, Loss: 1.5511, Val Acc: 0.2667, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 083, Loss: 1.5491, Val Acc: 0.3111, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 084, Loss: 1.5412, Val Acc: 0.3111, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 085, Loss: 1.5375, Val Acc: 0.2889, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 086, Loss: 1.5251, Val Acc: 0.3000, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 087, Loss: 1.5335, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 088, Loss: 1.5515, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 089, Loss: 1.5311, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 090, Loss: 1.5203, Val Acc: 0.2889, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 091, Loss: 1.5007, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 092, Loss: 1.5205, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 093, Loss: 1.4948, Val Acc: 0.2889, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 094, Loss: 1.5575, Val Acc: 0.2111, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 095, Loss: 1.6076, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 096, Loss: 1.5746, Val Acc: 0.2667, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 097, Loss: 1.5388, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 098, Loss: 1.5378, Val Acc: 0.3000, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 099, Loss: 1.5638, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 100, Loss: 1.5278, Val Acc: 0.3111, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 101, Loss: 1.4954, Val Acc: 0.2556, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 102, Loss: 1.5113, Val Acc: 0.3222, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 103, Loss: 1.5044, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 104, Loss: 1.4848, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 105, Loss: 1.4785, Val Acc: 0.3000, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 106, Loss: 1.4971, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 107, Loss: 1.4569, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 108, Loss: 1.4854, Val Acc: 0.3111, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 109, Loss: 1.4751, Val Acc: 0.3222, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 110, Loss: 1.4669, Val Acc: 0.3111, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 111, Loss: 1.4680, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 112, Loss: 1.4461, Val Acc: 0.2889, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 113, Loss: 1.4483, Val Acc: 0.3000, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 114, Loss: 1.4426, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 115, Loss: 1.4445, Val Acc: 0.3333, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 116, Loss: 1.4429, Val Acc: 0.3000, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 117, Loss: 1.4131, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 118, Loss: 1.4255, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 119, Loss: 1.4158, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 120, Loss: 1.4066, Val Acc: 0.3222, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 121, Loss: 1.4039, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 122, Loss: 1.3981, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 123, Loss: 1.3958, Val Acc: 0.3111, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 124, Loss: 1.4047, Val Acc: 0.3333, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 125, Loss: 1.4263, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 126, Loss: 1.3859, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 127, Loss: 1.4002, Val Acc: 0.3111, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 128, Loss: 1.3892, Val Acc: 0.2111, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 129, Loss: 1.4281, Val Acc: 0.3444, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 130, Loss: 1.4054, Val Acc: 0.3000, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 131, Loss: 1.3801, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 132, Loss: 1.4045, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 133, Loss: 1.4004, Val Acc: 0.3111, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 134, Loss: 1.4003, Val Acc: 0.3333, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 135, Loss: 1.3782, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 136, Loss: 1.3297, Val Acc: 0.3111, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 137, Loss: 1.3800, Val Acc: 0.3333, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 138, Loss: 1.3257, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 139, Loss: 1.3593, Val Acc: 0.4000, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 140, Loss: 1.2936, Val Acc: 0.3444, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 141, Loss: 1.3360, Val Acc: 0.3667, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 142, Loss: 1.3203, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 143, Loss: 1.3577, Val Acc: 0.3333, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 144, Loss: 1.3527, Val Acc: 0.3333, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 145, Loss: 1.3140, Val Acc: 0.2556, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 146, Loss: 1.3852, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 147, Loss: 1.3581, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 148, Loss: 1.2898, Val Acc: 0.3333, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 149, Loss: 1.3503, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 150, Loss: 1.3102, Val Acc: 0.3333, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 151, Loss: 1.2922, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 152, Loss: 1.2927, Val Acc: 0.3222, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 153, Loss: 1.2740, Val Acc: 0.3222, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 154, Loss: 1.2804, Val Acc: 0.3444, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 155, Loss: 1.2655, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 156, Loss: 1.2469, Val Acc: 0.3444, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 157, Loss: 1.2437, Val Acc: 0.3778, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 158, Loss: 1.2286, Val Acc: 0.3667, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 159, Loss: 1.2348, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 160, Loss: 1.2764, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 161, Loss: 1.2253, Val Acc: 0.3778, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 162, Loss: 1.2089, Val Acc: 0.3333, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 163, Loss: 1.2682, Val Acc: 0.3333, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 164, Loss: 1.2569, Val Acc: 0.3222, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 165, Loss: 1.1850, Val Acc: 0.3556, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 166, Loss: 1.1742, Val Acc: 0.3333, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 167, Loss: 1.2759, Val Acc: 0.3556, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 168, Loss: 1.2232, Val Acc: 0.3444, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 169, Loss: 1.2075, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 170, Loss: 1.2045, Val Acc: 0.3778, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 171, Loss: 1.1886, Val Acc: 0.3556, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 172, Loss: 1.1596, Val Acc: 0.3556, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 173, Loss: 1.1456, Val Acc: 0.3444, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 174, Loss: 1.1498, Val Acc: 0.3667, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 175, Loss: 1.1584, Val Acc: 0.3778, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 176, Loss: 1.1974, Val Acc: 0.3556, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 177, Loss: 1.1810, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 178, Loss: 1.2477, Val Acc: 0.3333, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 179, Loss: 1.1763, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 180, Loss: 1.1381, Val Acc: 0.3333, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 181, Loss: 1.1584, Val Acc: 0.3778, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 182, Loss: 1.1801, Val Acc: 0.3222, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 183, Loss: 1.1410, Val Acc: 0.3444, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 184, Loss: 1.1179, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 185, Loss: 1.1583, Val Acc: 0.3333, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 186, Loss: 1.1451, Val Acc: 0.3556, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 187, Loss: 1.0705, Val Acc: 0.3444, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 188, Loss: 1.0800, Val Acc: 0.3444, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 189, Loss: 1.0788, Val Acc: 0.3556, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 190, Loss: 1.0576, Val Acc: 0.3556, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 191, Loss: 1.0427, Val Acc: 0.3667, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 192, Loss: 1.0730, Val Acc: 0.3778, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 193, Loss: 1.0631, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 194, Loss: 1.1033, Val Acc: 0.3667, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 195, Loss: 1.0801, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 196, Loss: 1.0692, Val Acc: 0.3333, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 197, Loss: 1.0375, Val Acc: 0.3444, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 198, Loss: 1.0644, Val Acc: 0.3667, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 199, Loss: 1.0251, Val Acc: 0.3111, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 200, Loss: 1.0777, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 001, Loss: 1.8218, Val Acc: 0.2000, Test Acc: 0.2000\n",
            "Seed: 46, Epoch: 002, Loss: 1.7723, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 003, Loss: 1.7712, Val Acc: 0.1889, Test Acc: 0.2111\n",
            "Seed: 46, Epoch: 004, Loss: 1.7644, Val Acc: 0.2000, Test Acc: 0.2222\n",
            "Seed: 46, Epoch: 005, Loss: 1.7569, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 006, Loss: 1.7414, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 007, Loss: 1.7346, Val Acc: 0.2000, Test Acc: 0.2222\n",
            "Seed: 46, Epoch: 008, Loss: 1.7311, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 009, Loss: 1.7267, Val Acc: 0.2667, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 010, Loss: 1.7137, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 011, Loss: 1.7134, Val Acc: 0.2222, Test Acc: 0.2222\n",
            "Seed: 46, Epoch: 012, Loss: 1.7060, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 013, Loss: 1.7016, Val Acc: 0.2889, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 014, Loss: 1.6983, Val Acc: 0.1778, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 015, Loss: 1.6864, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 016, Loss: 1.6774, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 017, Loss: 1.6952, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 018, Loss: 1.6732, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 019, Loss: 1.6882, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 020, Loss: 1.6770, Val Acc: 0.2556, Test Acc: 0.2222\n",
            "Seed: 46, Epoch: 021, Loss: 1.6736, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 022, Loss: 1.6596, Val Acc: 0.1778, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 023, Loss: 1.6744, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 024, Loss: 1.6454, Val Acc: 0.3111, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 025, Loss: 1.6497, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 026, Loss: 1.6507, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 027, Loss: 1.6346, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 028, Loss: 1.6312, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 029, Loss: 1.6342, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 030, Loss: 1.6164, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 031, Loss: 1.6465, Val Acc: 0.3111, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 032, Loss: 1.6237, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 033, Loss: 1.6454, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 034, Loss: 1.6005, Val Acc: 0.3111, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 035, Loss: 1.6240, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 036, Loss: 1.6017, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 037, Loss: 1.6083, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 038, Loss: 1.5961, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 039, Loss: 1.5970, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 040, Loss: 1.5568, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 041, Loss: 1.5859, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 042, Loss: 1.5752, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 043, Loss: 1.5586, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 044, Loss: 1.5627, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 045, Loss: 1.5518, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 046, Loss: 1.5418, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 047, Loss: 1.5343, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 048, Loss: 1.5346, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 049, Loss: 1.5204, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 050, Loss: 1.5135, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 051, Loss: 1.5287, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 052, Loss: 1.4989, Val Acc: 0.2889, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 053, Loss: 1.5033, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 054, Loss: 1.4963, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 055, Loss: 1.4852, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 056, Loss: 1.5512, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 057, Loss: 1.5019, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 058, Loss: 1.5160, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 059, Loss: 1.4974, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 060, Loss: 1.4919, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 061, Loss: 1.4859, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 062, Loss: 1.4648, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 063, Loss: 1.4850, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 064, Loss: 1.4319, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 065, Loss: 1.4561, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 066, Loss: 1.4478, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 067, Loss: 1.4877, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 068, Loss: 1.5182, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 069, Loss: 1.4936, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 070, Loss: 1.4509, Val Acc: 0.2000, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 071, Loss: 1.4615, Val Acc: 0.2000, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 072, Loss: 1.4339, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 073, Loss: 1.3954, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 074, Loss: 1.4028, Val Acc: 0.3333, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 075, Loss: 1.4019, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 076, Loss: 1.3854, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 077, Loss: 1.3814, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 078, Loss: 1.3439, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 079, Loss: 1.3656, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 080, Loss: 1.3556, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 081, Loss: 1.3522, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 082, Loss: 1.3704, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 083, Loss: 1.3610, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 084, Loss: 1.3381, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 085, Loss: 1.3256, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 086, Loss: 1.3380, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 087, Loss: 1.3160, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 088, Loss: 1.3255, Val Acc: 0.3111, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 089, Loss: 1.2892, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 090, Loss: 1.2718, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 091, Loss: 1.2890, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 092, Loss: 1.2748, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 093, Loss: 1.2757, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 094, Loss: 1.2540, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 095, Loss: 1.2770, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 096, Loss: 1.2528, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 097, Loss: 1.2229, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 098, Loss: 1.2255, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 099, Loss: 1.2738, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 100, Loss: 1.2172, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 101, Loss: 1.2200, Val Acc: 0.2778, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 102, Loss: 1.1767, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 103, Loss: 1.1850, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 104, Loss: 1.2117, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 105, Loss: 1.1672, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 106, Loss: 1.1482, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 107, Loss: 1.1308, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 108, Loss: 1.1287, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 109, Loss: 1.1295, Val Acc: 0.3778, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 110, Loss: 1.0945, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 111, Loss: 1.1241, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 112, Loss: 1.1050, Val Acc: 0.3778, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 113, Loss: 1.0911, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 114, Loss: 1.0798, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 115, Loss: 1.0820, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 116, Loss: 1.0904, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 117, Loss: 1.0572, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 118, Loss: 1.0700, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 119, Loss: 1.0522, Val Acc: 0.3444, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 120, Loss: 1.0587, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 121, Loss: 1.0274, Val Acc: 0.3667, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 122, Loss: 1.0131, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 123, Loss: 1.0129, Val Acc: 0.3444, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 124, Loss: 0.9966, Val Acc: 0.3556, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 125, Loss: 0.9996, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 126, Loss: 1.0107, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 127, Loss: 0.9822, Val Acc: 0.3889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 128, Loss: 0.9768, Val Acc: 0.3333, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 129, Loss: 0.9747, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 130, Loss: 1.0244, Val Acc: 0.3111, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 131, Loss: 0.9405, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 132, Loss: 1.0444, Val Acc: 0.3556, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 133, Loss: 0.9838, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 134, Loss: 1.0042, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 135, Loss: 0.9894, Val Acc: 0.3556, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 136, Loss: 1.0201, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 137, Loss: 1.0026, Val Acc: 0.3444, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 138, Loss: 0.9439, Val Acc: 0.3556, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 139, Loss: 0.9334, Val Acc: 0.3667, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 140, Loss: 0.9540, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 141, Loss: 0.9615, Val Acc: 0.3556, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 142, Loss: 0.9355, Val Acc: 0.3667, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 143, Loss: 1.0570, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 144, Loss: 0.9579, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 145, Loss: 0.9186, Val Acc: 0.3667, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 146, Loss: 1.0091, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 147, Loss: 0.9379, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 148, Loss: 0.9131, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 149, Loss: 0.9214, Val Acc: 0.3667, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 150, Loss: 0.9101, Val Acc: 0.3556, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 151, Loss: 0.8964, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 152, Loss: 0.8800, Val Acc: 0.3556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 153, Loss: 0.8767, Val Acc: 0.3667, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 154, Loss: 0.8366, Val Acc: 0.3667, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 155, Loss: 0.8515, Val Acc: 0.3667, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 156, Loss: 0.8407, Val Acc: 0.3889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 157, Loss: 0.8053, Val Acc: 0.4333, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 158, Loss: 0.7862, Val Acc: 0.3667, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 159, Loss: 0.7957, Val Acc: 0.3889, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 160, Loss: 0.7970, Val Acc: 0.4222, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 161, Loss: 0.7803, Val Acc: 0.3556, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 162, Loss: 0.8095, Val Acc: 0.4000, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 163, Loss: 0.7484, Val Acc: 0.3889, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 164, Loss: 0.7886, Val Acc: 0.3778, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 165, Loss: 0.8170, Val Acc: 0.3556, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 166, Loss: 0.8520, Val Acc: 0.4000, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 167, Loss: 0.7969, Val Acc: 0.3556, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 168, Loss: 0.8346, Val Acc: 0.4000, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 169, Loss: 0.7827, Val Acc: 0.4111, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 170, Loss: 0.7697, Val Acc: 0.3667, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 171, Loss: 0.7850, Val Acc: 0.3889, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 172, Loss: 0.7468, Val Acc: 0.3667, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 173, Loss: 0.7590, Val Acc: 0.4111, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 174, Loss: 0.7318, Val Acc: 0.4444, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 175, Loss: 0.8206, Val Acc: 0.3889, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 176, Loss: 0.9112, Val Acc: 0.4111, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 177, Loss: 0.8179, Val Acc: 0.4111, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 178, Loss: 0.7734, Val Acc: 0.4111, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 179, Loss: 0.8441, Val Acc: 0.3778, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 180, Loss: 0.7687, Val Acc: 0.3667, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 181, Loss: 0.7890, Val Acc: 0.4000, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 182, Loss: 0.7349, Val Acc: 0.4333, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 183, Loss: 0.7467, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 184, Loss: 0.7718, Val Acc: 0.4111, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 185, Loss: 0.6986, Val Acc: 0.4111, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 186, Loss: 0.7316, Val Acc: 0.3778, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 187, Loss: 0.6871, Val Acc: 0.3889, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 188, Loss: 0.7049, Val Acc: 0.3667, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 189, Loss: 0.6905, Val Acc: 0.3667, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 190, Loss: 0.7089, Val Acc: 0.4111, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 191, Loss: 0.6671, Val Acc: 0.4111, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 192, Loss: 0.6682, Val Acc: 0.4222, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 193, Loss: 0.6584, Val Acc: 0.4222, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 194, Loss: 0.6591, Val Acc: 0.4333, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 195, Loss: 0.6365, Val Acc: 0.4333, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 196, Loss: 0.6283, Val Acc: 0.4222, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 197, Loss: 0.6299, Val Acc: 0.4111, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 198, Loss: 0.6101, Val Acc: 0.4222, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 199, Loss: 0.6197, Val Acc: 0.4444, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 200, Loss: 0.5947, Val Acc: 0.4222, Test Acc: 0.3778\n",
            "Average Time: 14.36 seconds\n",
            "Var Time: 0.03 seconds\n",
            "Average Memory: 90.40 MB\n",
            "Average Best Val Acc: 0.4044\n",
            "Std Best Test Acc: 0.0535\n",
            "Average Test Acc: 0.3778\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, SAGPooling\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "from torch_geometric.nn import BatchNorm\n",
        "\n",
        "class HierarchicalGCN_CGI(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes):\n",
        "        super(HierarchicalGCN_CGI, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.pool1 = CGIPool(hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.pool2 = CGIPool(hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, out_channels)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.lin1 = torch.nn.Linear(out_channels, 32)\n",
        "        self.lin2 = torch.nn.Linear(32, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        # First GCN and pooling layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn1(x)\n",
        "        x, edge_index, _, batch, perm = self.pool1(x, edge_index, None, batch)\n",
        "\n",
        "        # Second GCN and pooling layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn2(x)\n",
        "        x, edge_index, _, batch, perm= self.pool1(x, edge_index, None, batch)\n",
        "\n",
        "        # Third GCN layer\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn3(x)\n",
        "\n",
        "        # Mean pooling over the nodes\n",
        "        x, mask = to_dense_batch(x, batch)\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.lin1(x).relu()\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "num_classes = dataset_sparse.num_classes\n",
        "in_channels = dataset_sparse.num_features\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HierarchicalGCN_CGI(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == data.y).sum().item()\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seeds = [42, 43, 44, 45, 46]\n",
        "times = []\n",
        "memories = []\n",
        "best_val_accs = []\n",
        "best_test_accs = []\n",
        "\n",
        "early_stop_patience = 150\n",
        "tolerance = 0.0001\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    model = HierarchicalGCN_CGI(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        val_acc = test(valid_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        if val_acc > best_val_acc + tolerance:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "        if epochs_no_improve >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
        "\n",
        "    times.append(total_time)\n",
        "    memories.append(memory_allocated)\n",
        "    best_val_accs.append(best_val_acc)\n",
        "    best_test_accs.append(best_test_acc)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
        "print(f'Var Time: {np.var(times):.2f} seconds')\n",
        "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
        "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
        "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
        "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQN_x3aw759Q"
      },
      "source": [
        "## KMISPooling with HierarchicalGCN (2023)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBILPmR977A7"
      },
      "outputs": [],
      "source": [
        "from typing import Callable, Optional, Tuple, Union\n",
        "\n",
        "import torch\n",
        "from torch.nn import Module\n",
        "from torch_scatter import scatter, scatter_add, scatter_min\n",
        "from torch_sparse import SparseTensor, remove_diag\n",
        "\n",
        "from torch_geometric.nn.aggr import Aggregation\n",
        "from torch_geometric.nn.dense import Linear\n",
        "from torch_geometric.typing import Adj, OptTensor, PairTensor, Tensor\n",
        "\n",
        "Scorer = Callable[[Tensor, Adj, OptTensor, OptTensor], Tensor]\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch_scatter import scatter_max, scatter_min\n",
        "\n",
        "from torch_geometric.typing import Adj, OptTensor, SparseTensor, Tensor\n",
        "\n",
        "\n",
        "def maximal_independent_set(edge_index: Adj, k: int = 1,\n",
        "                            perm: OptTensor = None) -> Tensor:\n",
        "    r\"\"\"Returns a Maximal :math:`k`-Independent Set of a graph, i.e., a set of\n",
        "    nodes (as a :class:`ByteTensor`) such that none of them are :math:`k`-hop\n",
        "    neighbors, and any node in the graph has a :math:`k`-hop neighbor in the\n",
        "    returned set.\n",
        "    The algorithm greedily selects the nodes in their canonical order. If a\n",
        "    permutation :obj:`perm` is provided, the nodes are extracted following\n",
        "    that permutation instead.\n",
        "    This method follows `Blelloch's Alogirithm\n",
        "    <https://arxiv.org/abs/1202.3205>`_ for :math:`k = 1`, and its\n",
        "    generalization by `Bacciu et al. <https://arxiv.org/abs/2208.03523>`_ for\n",
        "    higher values of :math:`k`.\n",
        "    Args:\n",
        "        edge_index (Tensor or SparseTensor): The graph connectivity.\n",
        "        k (int): The :math:`k` value (defaults to 1).\n",
        "        perm (LongTensor, optional): Permutation vector. Must be of size\n",
        "            :obj:`(n,)` (defaults to :obj:`None`).\n",
        "    :rtype: :class:`ByteTensor`\n",
        "    \"\"\"\n",
        "    if isinstance(edge_index, SparseTensor):\n",
        "        row, col, _ = edge_index.coo()\n",
        "        device = edge_index.device()\n",
        "        n = edge_index.size(0)\n",
        "    else:\n",
        "        row, col = edge_index[0], edge_index[1]\n",
        "        device = row.device\n",
        "        n = edge_index.max().item() + 1\n",
        "\n",
        "    if perm is None:\n",
        "        rank = torch.arange(n, dtype=torch.long, device=device)\n",
        "    else:\n",
        "        rank = torch.zeros_like(perm)\n",
        "        rank[perm] = torch.arange(n, dtype=torch.long, device=device)\n",
        "\n",
        "    mis = torch.zeros(n, dtype=torch.bool, device=device)\n",
        "    mask = mis.clone()\n",
        "    min_rank = rank.clone()\n",
        "\n",
        "    while not mask.all():\n",
        "        for _ in range(k):\n",
        "            min_neigh = torch.full_like(min_rank, fill_value=n)\n",
        "            scatter_min(min_rank[row], col, out=min_neigh)\n",
        "            torch.minimum(min_neigh, min_rank, out=min_rank)  # self-loops\n",
        "\n",
        "        mis = mis | torch.eq(rank, min_rank)\n",
        "        mask = mis.clone().byte()\n",
        "\n",
        "        for _ in range(k):\n",
        "            max_neigh = torch.full_like(mask, fill_value=0)\n",
        "            scatter_max(mask[row], col, out=max_neigh)\n",
        "            torch.maximum(max_neigh, mask, out=mask)  # self-loops\n",
        "\n",
        "        mask = mask.to(dtype=torch.bool)\n",
        "        min_rank = rank.clone()\n",
        "        min_rank[mask] = n\n",
        "\n",
        "    return mis\n",
        "\n",
        "def maximal_independent_set_cluster(edge_index: Adj, k: int = 1,\n",
        "                                    perm: OptTensor = None) -> PairTensor:\n",
        "    r\"\"\"Computes the Maximal :math:`k`-Independent Set (:math:`k`-MIS)\n",
        "    clustering of a graph, as defined in `\"Generalizing Downsampling from\n",
        "    Regular Data to Graphs\" <https://arxiv.org/abs/2208.03523>`_.\n",
        "    The algorithm greedily selects the nodes in their canonical order. If a\n",
        "    permutation :obj:`perm` is provided, the nodes are extracted following\n",
        "    that permutation instead.\n",
        "    This method returns both the :math:`k`-MIS and the clustering, where the\n",
        "    :math:`c`-th cluster refers to the :math:`c`-th element of the\n",
        "    :math:`k`-MIS.\n",
        "    Args:\n",
        "        edge_index (Tensor or SparseTensor): The graph connectivity.\n",
        "        k (int): The :math:`k` value (defaults to 1).\n",
        "        perm (LongTensor, optional): Permutation vector. Must be of size\n",
        "            :obj:`(n,)` (defaults to :obj:`None`).\n",
        "    :rtype: (:class:`ByteTensor`, :class:`LongTensor`)\n",
        "    \"\"\"\n",
        "    mis = maximal_independent_set(edge_index=edge_index, k=k, perm=perm)\n",
        "    n, device = mis.size(0), mis.device\n",
        "\n",
        "    if isinstance(edge_index, SparseTensor):\n",
        "        row, col, _ = edge_index.coo()\n",
        "    else:\n",
        "        row, col = edge_index[0], edge_index[1]\n",
        "\n",
        "    if perm is None:\n",
        "        rank = torch.arange(n, dtype=torch.long, device=device)\n",
        "    else:\n",
        "        rank = torch.zeros_like(perm)\n",
        "        rank[perm] = torch.arange(n, dtype=torch.long, device=device)\n",
        "\n",
        "    min_rank = torch.full((n, ), fill_value=n, dtype=torch.long, device=device)\n",
        "    rank_mis = rank[mis]\n",
        "    min_rank[mis] = rank_mis\n",
        "\n",
        "    for _ in range(k):\n",
        "        min_neigh = torch.full_like(min_rank, fill_value=n)\n",
        "        scatter_min(min_rank[row], col, out=min_neigh)\n",
        "        torch.minimum(min_neigh, min_rank, out=min_rank)\n",
        "\n",
        "    _, clusters = torch.unique(min_rank, return_inverse=True)\n",
        "    perm = torch.argsort(rank_mis)\n",
        "    return mis, perm[clusters]\n",
        "\n",
        "\n",
        "class KMISPooling(Module):\n",
        "\n",
        "    _heuristics = {None, 'greedy', 'w-greedy'}\n",
        "    _passthroughs = {None, 'before', 'after'}\n",
        "    _scorers = {\n",
        "        'linear',\n",
        "        'random',\n",
        "        'constant',\n",
        "        'canonical',\n",
        "        'first',\n",
        "        'last',\n",
        "    }\n",
        "\n",
        "    def __init__(self, in_channels: Optional[int] = None, k: int = 1,\n",
        "                 scorer: Union[Scorer, str] = 'linear',\n",
        "                 score_heuristic: Optional[str] = 'greedy',\n",
        "                 score_passthrough: Optional[str] = 'before',\n",
        "                 aggr_x: Optional[Union[str, Aggregation]] = None,\n",
        "                 aggr_edge: str = 'sum',\n",
        "                 aggr_score: Callable[[Tensor, Tensor], Tensor] = torch.mul,\n",
        "                 remove_self_loops: bool = True) -> None:\n",
        "        super(KMISPooling, self).__init__()\n",
        "        assert score_heuristic in self._heuristics, \\\n",
        "            \"Unrecognized `score_heuristic` value.\"\n",
        "        assert score_passthrough in self._passthroughs, \\\n",
        "            \"Unrecognized `score_passthrough` value.\"\n",
        "\n",
        "        if not callable(scorer):\n",
        "            assert scorer in self._scorers, \\\n",
        "                \"Unrecognized `scorer` value.\"\n",
        "\n",
        "        self.k = k\n",
        "        self.scorer = scorer\n",
        "        self.score_heuristic = score_heuristic\n",
        "        self.score_passthrough = score_passthrough\n",
        "\n",
        "        self.aggr_x = aggr_x\n",
        "        self.aggr_edge = aggr_edge\n",
        "        self.aggr_score = aggr_score\n",
        "        self.remove_self_loops = remove_self_loops\n",
        "\n",
        "        if scorer == 'linear':\n",
        "            assert self.score_passthrough is not None, \\\n",
        "                \"`'score_passthrough'` must not be `None`\" \\\n",
        "                \" when using `'linear'` scorer\"\n",
        "\n",
        "            self.lin = Linear(in_features=in_channels, out_features=1)\n",
        "\n",
        "    def _apply_heuristic(self, x: Tensor, adj: SparseTensor) -> Tensor:\n",
        "        if self.score_heuristic is None:\n",
        "            return x\n",
        "\n",
        "        row, col, _ = adj.coo()\n",
        "        x = x.view(-1)\n",
        "\n",
        "        if self.score_heuristic == 'greedy':\n",
        "            k_sums = torch.ones_like(x)\n",
        "        else:\n",
        "            k_sums = x.clone()\n",
        "\n",
        "        for _ in range(self.k):\n",
        "            scatter_add(k_sums[row], col, out=k_sums)\n",
        "\n",
        "        return x / k_sums\n",
        "\n",
        "    def _scorer(self, x: Tensor, edge_index: Adj, edge_attr: OptTensor = None,\n",
        "                batch: OptTensor = None) -> Tensor:\n",
        "        if self.scorer == 'linear':\n",
        "            return self.lin(x).sigmoid()\n",
        "\n",
        "        if self.scorer == 'random':\n",
        "            return torch.rand((x.size(0), 1), device=x.device)\n",
        "\n",
        "        if self.scorer == 'constant':\n",
        "            return torch.ones((x.size(0), 1), device=x.device)\n",
        "\n",
        "        if self.scorer == 'canonical':\n",
        "            return -torch.arange(x.size(0), device=x.device).view(-1, 1)\n",
        "\n",
        "        if self.scorer == 'first':\n",
        "            return x[..., [0]]\n",
        "\n",
        "        if self.scorer == 'last':\n",
        "            return x[..., [-1]]\n",
        "\n",
        "        return self.scorer(x, edge_index, edge_attr, batch)\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Adj,\n",
        "                edge_attr: OptTensor = None,\n",
        "                batch: OptTensor = None) \\\n",
        "            -> Tuple[Tensor, Adj, OptTensor, OptTensor, Tensor, Tensor]:\n",
        "        \"\"\"\"\"\"\n",
        "        edge_index = edge_index.long()\n",
        "        adj, n = edge_index, x.size(0)\n",
        "\n",
        "        if not isinstance(edge_index, SparseTensor):\n",
        "            adj = SparseTensor.from_edge_index(edge_index, edge_attr, (n, n))\n",
        "\n",
        "        score = self._scorer(x, edge_index, edge_attr, batch)\n",
        "        updated_score = self._apply_heuristic(score, adj)\n",
        "        perm = torch.argsort(updated_score.view(-1), 0, descending=True)\n",
        "\n",
        "        mis, cluster = maximal_independent_set_cluster(adj, self.k, perm)\n",
        "\n",
        "        row, col, val = adj.coo()\n",
        "        c = mis.sum()\n",
        "\n",
        "        if val is None:\n",
        "            val = torch.ones_like(row, dtype=torch.float)\n",
        "\n",
        "        adj = SparseTensor(row=cluster[row], col=cluster[col], value=val,\n",
        "                           is_sorted=False,\n",
        "                           sparse_sizes=(c, c)).coalesce(self.aggr_edge)\n",
        "\n",
        "        if self.remove_self_loops:\n",
        "            adj = remove_diag(adj)\n",
        "\n",
        "        if self.score_passthrough == 'before':\n",
        "            x = self.aggr_score(x, score)\n",
        "\n",
        "        if self.aggr_x is None:\n",
        "            x = x[mis]\n",
        "        elif isinstance(self.aggr_x, str):\n",
        "            x = scatter(x, cluster, dim=0, dim_size=mis.sum(),\n",
        "                        reduce=self.aggr_x)\n",
        "        else:\n",
        "            x = self.aggr_x(x, cluster, dim_size=c)\n",
        "\n",
        "        if self.score_passthrough == 'after':\n",
        "            x = self.aggr_score(x, score[mis])\n",
        "\n",
        "        if isinstance(edge_index, SparseTensor):\n",
        "            edge_index, edge_attr = adj, None\n",
        "\n",
        "        else:\n",
        "            row, col, edge_attr = adj.coo()\n",
        "            edge_index = torch.stack([row, col])\n",
        "\n",
        "        if batch is not None:\n",
        "            batch = batch[mis]\n",
        "\n",
        "\n",
        "        return x, edge_index, edge_attr, batch, mis, cluster\n",
        "\n",
        "    def __repr__(self):\n",
        "        if self.scorer == 'linear':\n",
        "            channels = f\"in_channels={self.lin.in_channels}, \"\n",
        "        else:\n",
        "            channels = \"\"\n",
        "\n",
        "        return f'{self.__class__.__name__}({channels}k={self.k})'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IsCxHyx5X_t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 001, Loss: 1.8079, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 002, Loss: 1.7974, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 003, Loss: 1.7970, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 004, Loss: 1.7965, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 005, Loss: 1.7964, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 006, Loss: 1.7960, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 007, Loss: 1.7956, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 008, Loss: 1.7952, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 009, Loss: 1.7950, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 010, Loss: 1.7945, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 011, Loss: 1.7945, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 012, Loss: 1.7940, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 013, Loss: 1.7938, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 014, Loss: 1.7935, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 015, Loss: 1.7933, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 016, Loss: 1.7932, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 017, Loss: 1.7928, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 018, Loss: 1.7926, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 019, Loss: 1.7926, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 020, Loss: 1.7922, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 021, Loss: 1.7916, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 022, Loss: 1.7914, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 023, Loss: 1.7917, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 024, Loss: 1.7914, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 025, Loss: 1.7912, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 026, Loss: 1.7910, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 027, Loss: 1.7904, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 028, Loss: 1.7898, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 029, Loss: 1.7893, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 030, Loss: 1.7892, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 031, Loss: 1.7879, Val Acc: 0.1222, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 032, Loss: 1.7850, Val Acc: 0.1222, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 033, Loss: 1.7840, Val Acc: 0.1333, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 034, Loss: 4.2288, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 035, Loss: 1.7969, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 036, Loss: 1.7886, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 037, Loss: 1.7877, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 038, Loss: 1.7897, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 039, Loss: 1.7881, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 040, Loss: 1.7881, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 041, Loss: 1.7889, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 042, Loss: 1.7899, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 043, Loss: 1.7896, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 044, Loss: 1.7883, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 045, Loss: 1.7892, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 046, Loss: 1.7891, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 047, Loss: 1.7891, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 048, Loss: 1.7876, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 049, Loss: 1.7894, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 050, Loss: 1.7893, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 051, Loss: 1.7884, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 052, Loss: 1.7882, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 053, Loss: 1.7884, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 054, Loss: 1.7873, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 055, Loss: 1.7858, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 056, Loss: 1.7876, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 057, Loss: 1.7869, Val Acc: 0.1222, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 058, Loss: 1.7873, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 059, Loss: 1.7870, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 060, Loss: 1.7831, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 061, Loss: 1.7856, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 062, Loss: 1.7790, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 063, Loss: 1.7848, Val Acc: 0.1556, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 064, Loss: 1.7794, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 065, Loss: 1.7811, Val Acc: 0.1556, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 066, Loss: 1.7838, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 067, Loss: 1.7860, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 068, Loss: 1.7765, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 069, Loss: 1.7786, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 070, Loss: 1.7751, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 071, Loss: 1.7808, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 072, Loss: 1.7778, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 073, Loss: 1.7740, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 074, Loss: 1.7759, Val Acc: 0.2000, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 075, Loss: 1.8083, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 076, Loss: 1.7805, Val Acc: 0.1556, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 077, Loss: 1.7736, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 078, Loss: 1.7784, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 079, Loss: 1.7798, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 080, Loss: 1.7831, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 081, Loss: 1.7822, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 082, Loss: 1.7806, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 083, Loss: 1.7833, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 084, Loss: 1.7823, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 085, Loss: 1.7829, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 086, Loss: 1.7841, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 087, Loss: 1.7798, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 088, Loss: 1.7789, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 089, Loss: 1.7812, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 090, Loss: 1.7787, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 091, Loss: 1.7773, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 092, Loss: 1.7821, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 093, Loss: 1.7801, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 094, Loss: 1.7775, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 095, Loss: 1.7829, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 096, Loss: 1.7771, Val Acc: 0.1889, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 097, Loss: 1.7751, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 098, Loss: 1.7769, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 099, Loss: 1.7844, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 100, Loss: 1.7736, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 101, Loss: 1.7766, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 102, Loss: 1.7770, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 103, Loss: 1.7793, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 104, Loss: 1.7762, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 105, Loss: 1.7776, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 106, Loss: 1.7734, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 107, Loss: 1.7781, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 108, Loss: 1.7708, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 109, Loss: 1.7711, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 110, Loss: 1.7768, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 111, Loss: 1.7766, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 112, Loss: 1.7764, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 113, Loss: 1.7721, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 114, Loss: 1.7736, Val Acc: 0.1778, Test Acc: 0.1222\n",
            "Seed: 42, Epoch: 115, Loss: 1.7736, Val Acc: 0.1778, Test Acc: 0.1222\n",
            "Seed: 42, Epoch: 116, Loss: 1.7696, Val Acc: 0.1778, Test Acc: 0.1333\n",
            "Seed: 42, Epoch: 117, Loss: 1.7676, Val Acc: 0.1778, Test Acc: 0.1333\n",
            "Seed: 42, Epoch: 118, Loss: 1.7729, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 119, Loss: 1.7803, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 120, Loss: 1.7730, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 42, Epoch: 121, Loss: 1.7723, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 122, Loss: 1.7768, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 123, Loss: 1.7760, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 124, Loss: 1.7729, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 125, Loss: 1.7714, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 126, Loss: 1.7653, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 127, Loss: 1.7638, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 128, Loss: 1.7893, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 129, Loss: 1.7612, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 130, Loss: 1.7624, Val Acc: 0.2000, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 131, Loss: 1.7717, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 132, Loss: 1.7654, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 133, Loss: 1.7674, Val Acc: 0.2111, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 134, Loss: 1.7634, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 135, Loss: 1.7709, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 136, Loss: 1.7617, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 137, Loss: 1.7664, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 138, Loss: 1.7699, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 139, Loss: 1.7684, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 140, Loss: 1.7783, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 141, Loss: 1.7598, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 142, Loss: 1.7787, Val Acc: 0.2000, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 143, Loss: 1.7600, Val Acc: 0.2000, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 144, Loss: 1.7583, Val Acc: 0.2000, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 145, Loss: 1.7738, Val Acc: 0.2000, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 146, Loss: 1.7682, Val Acc: 0.1889, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 147, Loss: 1.7606, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 148, Loss: 1.7650, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 149, Loss: 1.7543, Val Acc: 0.1889, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 150, Loss: 1.7562, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 151, Loss: 1.7701, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 152, Loss: 1.7644, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 153, Loss: 1.7637, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 154, Loss: 1.7548, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 155, Loss: 1.7620, Val Acc: 0.1889, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 156, Loss: 1.7571, Val Acc: 0.1889, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 157, Loss: 1.7571, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 158, Loss: 1.7527, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 42, Epoch: 159, Loss: 1.7526, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 160, Loss: 1.7688, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 161, Loss: 1.7660, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 162, Loss: 1.7359, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 163, Loss: 1.7532, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 164, Loss: 1.7469, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 165, Loss: 1.7595, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 166, Loss: 1.7684, Val Acc: 0.1889, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 167, Loss: 1.7738, Val Acc: 0.2333, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 168, Loss: 1.7545, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 169, Loss: 1.7616, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 42, Epoch: 170, Loss: 1.7754, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 171, Loss: 1.7523, Val Acc: 0.2000, Test Acc: 0.1333\n",
            "Seed: 42, Epoch: 172, Loss: 1.7605, Val Acc: 0.2111, Test Acc: 0.1444\n",
            "Seed: 42, Epoch: 173, Loss: 1.7454, Val Acc: 0.1889, Test Acc: 0.1778\n",
            "Seed: 42, Epoch: 174, Loss: 1.7692, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 175, Loss: 1.7490, Val Acc: 0.1667, Test Acc: 0.1778\n",
            "Seed: 42, Epoch: 176, Loss: 1.7524, Val Acc: 0.1667, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 177, Loss: 1.7477, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 178, Loss: 1.7433, Val Acc: 0.2000, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 179, Loss: 1.7526, Val Acc: 0.2000, Test Acc: 0.1778\n",
            "Seed: 42, Epoch: 180, Loss: 1.7537, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 181, Loss: 1.7438, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 182, Loss: 1.7306, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 183, Loss: 1.7557, Val Acc: 0.2111, Test Acc: 0.2000\n",
            "Seed: 42, Epoch: 184, Loss: 1.7525, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 185, Loss: 1.7534, Val Acc: 0.2000, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 186, Loss: 1.7607, Val Acc: 0.2000, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 187, Loss: 1.7440, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 188, Loss: 1.7332, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 189, Loss: 1.7513, Val Acc: 0.2000, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 190, Loss: 1.7524, Val Acc: 0.2111, Test Acc: 0.1778\n",
            "Seed: 42, Epoch: 191, Loss: 1.7255, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 42, Epoch: 192, Loss: 1.7557, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 193, Loss: 1.7524, Val Acc: 0.2444, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 194, Loss: 1.7243, Val Acc: 0.2222, Test Acc: 0.2222\n",
            "Seed: 42, Epoch: 195, Loss: 1.7336, Val Acc: 0.2222, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 196, Loss: 1.7460, Val Acc: 0.2111, Test Acc: 0.1778\n",
            "Seed: 42, Epoch: 197, Loss: 1.7534, Val Acc: 0.1889, Test Acc: 0.1778\n",
            "Seed: 42, Epoch: 198, Loss: 1.7445, Val Acc: 0.2333, Test Acc: 0.2111\n",
            "Seed: 42, Epoch: 199, Loss: 1.7334, Val Acc: 0.2333, Test Acc: 0.2222\n",
            "Seed: 42, Epoch: 200, Loss: 1.7418, Val Acc: 0.1889, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 001, Loss: 2.3761, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 002, Loss: 1.7972, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 003, Loss: 1.7968, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 004, Loss: 1.7967, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 005, Loss: 1.7962, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 006, Loss: 1.7961, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 007, Loss: 1.7958, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 008, Loss: 1.7955, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 009, Loss: 1.7955, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 010, Loss: 1.7953, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 011, Loss: 1.7950, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 012, Loss: 1.7946, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 013, Loss: 1.7944, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 014, Loss: 1.7943, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 015, Loss: 1.7943, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 016, Loss: 1.7939, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 017, Loss: 1.7937, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 018, Loss: 1.7932, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 019, Loss: 1.7922, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 020, Loss: 1.7919, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 021, Loss: 1.7900, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 022, Loss: 1.7896, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 023, Loss: 1.7973, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 024, Loss: 1.7860, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 025, Loss: 1.7876, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 026, Loss: 1.7887, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 027, Loss: 1.7828, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 028, Loss: 1.7845, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 029, Loss: 1.7839, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 030, Loss: 1.7880, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 031, Loss: 1.7804, Val Acc: 0.1444, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 032, Loss: 1.7852, Val Acc: 0.1444, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 033, Loss: 1.7812, Val Acc: 0.1444, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 034, Loss: 1.7830, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 035, Loss: 1.7844, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 036, Loss: 1.7740, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 037, Loss: 1.7778, Val Acc: 0.1333, Test Acc: 0.1444\n",
            "Seed: 43, Epoch: 038, Loss: 1.7764, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 43, Epoch: 039, Loss: 1.7799, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 43, Epoch: 040, Loss: 1.7721, Val Acc: 0.2333, Test Acc: 0.1444\n",
            "Seed: 43, Epoch: 041, Loss: 1.7574, Val Acc: 0.2444, Test Acc: 0.1444\n",
            "Seed: 43, Epoch: 042, Loss: 1.7712, Val Acc: 0.2222, Test Acc: 0.1444\n",
            "Seed: 43, Epoch: 043, Loss: 1.7682, Val Acc: 0.2222, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 044, Loss: 1.7789, Val Acc: 0.2444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 045, Loss: 1.7679, Val Acc: 0.2222, Test Acc: 0.1444\n",
            "Seed: 43, Epoch: 046, Loss: 1.7676, Val Acc: 0.2222, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 047, Loss: 1.7798, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 048, Loss: 1.7711, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 049, Loss: 1.7733, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 050, Loss: 1.7723, Val Acc: 0.2111, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 051, Loss: 1.7667, Val Acc: 0.2333, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 052, Loss: 1.7624, Val Acc: 0.2444, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 053, Loss: 1.7794, Val Acc: 0.2222, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 054, Loss: 1.7618, Val Acc: 0.2111, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 055, Loss: 1.7633, Val Acc: 0.2111, Test Acc: 0.1444\n",
            "Seed: 43, Epoch: 056, Loss: 1.7614, Val Acc: 0.2111, Test Acc: 0.1444\n",
            "Seed: 43, Epoch: 057, Loss: 1.7502, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 058, Loss: 1.7664, Val Acc: 0.2222, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 059, Loss: 1.7715, Val Acc: 0.2444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 060, Loss: 1.7575, Val Acc: 0.2444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 061, Loss: 1.7644, Val Acc: 0.2444, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 062, Loss: 1.7578, Val Acc: 0.2556, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 063, Loss: 1.7548, Val Acc: 0.2556, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 064, Loss: 1.7882, Val Acc: 0.2444, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 065, Loss: 1.7471, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 066, Loss: 1.7519, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 067, Loss: 1.7695, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 068, Loss: 1.7701, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 069, Loss: 1.7700, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 070, Loss: 1.7736, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 071, Loss: 1.7688, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 072, Loss: 1.7786, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 073, Loss: 1.7418, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 074, Loss: 1.7592, Val Acc: 0.1889, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 075, Loss: 1.7625, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 43, Epoch: 076, Loss: 1.7691, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 077, Loss: 1.7644, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 078, Loss: 1.7607, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 079, Loss: 1.7651, Val Acc: 0.2333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 080, Loss: 1.7597, Val Acc: 0.2222, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 081, Loss: 1.7638, Val Acc: 0.2222, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 082, Loss: 1.7519, Val Acc: 0.2222, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 083, Loss: 1.7592, Val Acc: 0.2222, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 084, Loss: 1.7629, Val Acc: 0.2222, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 085, Loss: 1.7627, Val Acc: 0.2111, Test Acc: 0.1444\n",
            "Seed: 43, Epoch: 086, Loss: 1.7474, Val Acc: 0.2222, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 087, Loss: 1.7601, Val Acc: 0.2333, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 088, Loss: 1.7477, Val Acc: 0.2333, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 089, Loss: 1.7692, Val Acc: 0.2333, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 090, Loss: 1.7466, Val Acc: 0.2222, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 091, Loss: 1.7369, Val Acc: 0.2111, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 092, Loss: 1.7660, Val Acc: 0.2111, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 093, Loss: 1.7459, Val Acc: 0.2000, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 094, Loss: 1.7456, Val Acc: 0.2000, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 095, Loss: 1.7501, Val Acc: 0.2000, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 096, Loss: 1.7565, Val Acc: 0.2000, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 097, Loss: 1.7471, Val Acc: 0.2444, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 098, Loss: 1.7592, Val Acc: 0.2444, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 099, Loss: 1.7819, Val Acc: 0.2222, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 100, Loss: 1.7543, Val Acc: 0.2111, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 101, Loss: 1.7670, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 102, Loss: 1.7624, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 43, Epoch: 103, Loss: 1.7586, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 104, Loss: 1.7578, Val Acc: 0.2222, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 105, Loss: 1.7369, Val Acc: 0.2333, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 106, Loss: 1.7666, Val Acc: 0.2444, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 107, Loss: 1.7592, Val Acc: 0.2222, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 108, Loss: 1.7469, Val Acc: 0.2111, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 109, Loss: 1.7561, Val Acc: 0.2111, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 110, Loss: 1.7616, Val Acc: 0.2222, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 111, Loss: 1.7660, Val Acc: 0.2333, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 112, Loss: 1.7501, Val Acc: 0.2333, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 113, Loss: 1.7569, Val Acc: 0.2444, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 114, Loss: 1.7425, Val Acc: 0.2333, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 115, Loss: 1.7309, Val Acc: 0.2222, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 116, Loss: 1.7353, Val Acc: 0.2333, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 117, Loss: 1.7404, Val Acc: 0.2222, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 118, Loss: 1.7230, Val Acc: 0.2222, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 119, Loss: 1.7751, Val Acc: 0.2111, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 120, Loss: 1.7334, Val Acc: 0.2111, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 121, Loss: 1.7465, Val Acc: 0.1889, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 122, Loss: 1.7291, Val Acc: 0.2111, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 123, Loss: 1.7548, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 124, Loss: 1.7299, Val Acc: 0.2111, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 125, Loss: 1.7536, Val Acc: 0.2333, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 126, Loss: 1.7330, Val Acc: 0.2333, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 127, Loss: 1.7620, Val Acc: 0.2000, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 128, Loss: 1.7386, Val Acc: 0.2000, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 129, Loss: 1.7307, Val Acc: 0.2000, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 130, Loss: 1.7543, Val Acc: 0.2000, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 131, Loss: 1.7547, Val Acc: 0.1778, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 132, Loss: 1.7532, Val Acc: 0.2000, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 133, Loss: 1.7470, Val Acc: 0.2111, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 134, Loss: 1.7518, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 135, Loss: 1.7525, Val Acc: 0.2222, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 136, Loss: 1.7454, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 137, Loss: 1.7466, Val Acc: 0.2000, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 138, Loss: 1.7639, Val Acc: 0.2111, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 139, Loss: 1.7498, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 140, Loss: 1.7582, Val Acc: 0.1667, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 141, Loss: 1.7466, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 142, Loss: 1.7405, Val Acc: 0.2000, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 143, Loss: 1.7479, Val Acc: 0.2222, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 144, Loss: 1.7437, Val Acc: 0.2333, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 145, Loss: 1.7476, Val Acc: 0.2333, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 146, Loss: 1.7276, Val Acc: 0.2333, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 147, Loss: 1.7563, Val Acc: 0.1778, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 148, Loss: 1.7514, Val Acc: 0.1778, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 149, Loss: 1.7459, Val Acc: 0.2111, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 150, Loss: 1.7510, Val Acc: 0.2222, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 151, Loss: 1.7485, Val Acc: 0.2111, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 152, Loss: 1.7460, Val Acc: 0.2333, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 153, Loss: 1.7595, Val Acc: 0.2556, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 154, Loss: 1.7418, Val Acc: 0.2000, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 155, Loss: 1.7517, Val Acc: 0.1778, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 156, Loss: 1.7486, Val Acc: 0.1667, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 157, Loss: 1.7317, Val Acc: 0.2000, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 158, Loss: 1.7520, Val Acc: 0.2222, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 159, Loss: 1.7296, Val Acc: 0.2444, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 160, Loss: 1.7336, Val Acc: 0.2556, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 161, Loss: 1.7614, Val Acc: 0.2333, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 162, Loss: 1.7214, Val Acc: 0.2111, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 163, Loss: 1.7374, Val Acc: 0.2000, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 164, Loss: 1.7423, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 165, Loss: 1.7536, Val Acc: 0.2222, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 166, Loss: 1.7482, Val Acc: 0.2111, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 167, Loss: 1.7348, Val Acc: 0.1889, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 168, Loss: 1.7404, Val Acc: 0.2111, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 169, Loss: 1.7557, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 170, Loss: 1.7374, Val Acc: 0.2222, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 171, Loss: 1.7225, Val Acc: 0.2111, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 172, Loss: 1.7562, Val Acc: 0.2222, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 173, Loss: 1.7450, Val Acc: 0.2222, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 174, Loss: 1.7406, Val Acc: 0.2222, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 175, Loss: 1.7465, Val Acc: 0.2333, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 176, Loss: 1.7291, Val Acc: 0.1889, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 177, Loss: 1.7553, Val Acc: 0.2111, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 178, Loss: 1.7451, Val Acc: 0.2000, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 179, Loss: 1.7338, Val Acc: 0.2000, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 180, Loss: 1.7323, Val Acc: 0.1778, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 181, Loss: 1.7318, Val Acc: 0.2111, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 182, Loss: 1.7221, Val Acc: 0.2222, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 183, Loss: 1.7410, Val Acc: 0.2444, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 184, Loss: 1.7670, Val Acc: 0.2111, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 185, Loss: 1.7194, Val Acc: 0.2333, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 186, Loss: 1.7450, Val Acc: 0.2333, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 187, Loss: 1.7405, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 188, Loss: 1.7418, Val Acc: 0.2222, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 189, Loss: 1.7578, Val Acc: 0.1889, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 190, Loss: 1.7537, Val Acc: 0.1667, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 191, Loss: 1.7538, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 192, Loss: 1.7569, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 193, Loss: 1.7517, Val Acc: 0.1778, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 194, Loss: 1.7519, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 195, Loss: 1.7507, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 196, Loss: 1.7462, Val Acc: 0.2222, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 197, Loss: 1.7283, Val Acc: 0.2222, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 198, Loss: 1.7300, Val Acc: 0.2333, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 199, Loss: 1.7366, Val Acc: 0.2111, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 200, Loss: 1.7631, Val Acc: 0.2111, Test Acc: 0.2111\n",
            "Seed: 44, Epoch: 001, Loss: 1.8125, Val Acc: 0.1333, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 002, Loss: 1.7924, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 003, Loss: 1.7917, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 004, Loss: 1.7916, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 005, Loss: 1.7912, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 006, Loss: 1.7915, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 007, Loss: 1.7910, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 008, Loss: 1.7911, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 009, Loss: 1.7910, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 010, Loss: 1.7912, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 011, Loss: 1.7910, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 012, Loss: 1.7905, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 013, Loss: 1.7906, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 014, Loss: 1.7907, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 015, Loss: 1.7905, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 016, Loss: 1.7902, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 017, Loss: 1.7903, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 018, Loss: 1.7904, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 019, Loss: 1.7896, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 020, Loss: 1.7900, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 021, Loss: 1.7899, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 022, Loss: 1.7893, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 023, Loss: 1.7893, Val Acc: 0.1556, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 024, Loss: 1.7889, Val Acc: 0.1222, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 025, Loss: 1.7894, Val Acc: 0.1333, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 026, Loss: 1.7885, Val Acc: 0.1333, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 027, Loss: 1.7853, Val Acc: 0.1556, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 028, Loss: 1.7887, Val Acc: 0.1444, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 029, Loss: 1.7857, Val Acc: 0.1556, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 030, Loss: 1.7844, Val Acc: 0.1333, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 031, Loss: 1.7813, Val Acc: 0.1556, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 032, Loss: 1.7828, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 033, Loss: 1.7702, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 034, Loss: 1.7755, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 035, Loss: 1.7732, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 036, Loss: 1.7739, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 037, Loss: 1.7649, Val Acc: 0.1556, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 038, Loss: 1.7745, Val Acc: 0.1556, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 039, Loss: 1.7650, Val Acc: 0.1556, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 040, Loss: 1.7651, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 041, Loss: 1.7584, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 042, Loss: 1.7502, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 043, Loss: 1.7556, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 044, Loss: 1.7506, Val Acc: 0.1889, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 045, Loss: 1.7400, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 046, Loss: 1.7444, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 047, Loss: 1.7548, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 048, Loss: 1.7425, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 049, Loss: 1.7581, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 050, Loss: 1.7474, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 051, Loss: 1.7542, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 052, Loss: 1.7545, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 053, Loss: 1.7396, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 054, Loss: 1.7516, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 055, Loss: 1.7456, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 056, Loss: 1.7692, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 057, Loss: 1.7459, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 058, Loss: 1.7452, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 059, Loss: 1.7308, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 060, Loss: 1.7610, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 061, Loss: 1.7274, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 062, Loss: 1.7386, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 063, Loss: 1.7482, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 064, Loss: 1.7505, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 065, Loss: 1.7379, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 066, Loss: 1.7538, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 067, Loss: 1.7457, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 068, Loss: 1.7454, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 069, Loss: 1.7294, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 070, Loss: 1.7393, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 071, Loss: 1.7443, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 072, Loss: 1.7385, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 073, Loss: 1.7723, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 074, Loss: 1.7354, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 075, Loss: 1.7556, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 076, Loss: 1.7357, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 077, Loss: 1.7336, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 078, Loss: 1.7477, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 079, Loss: 1.7453, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 080, Loss: 1.7602, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 081, Loss: 1.7535, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 082, Loss: 1.7339, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 083, Loss: 1.7374, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 084, Loss: 1.7388, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 085, Loss: 1.7333, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 086, Loss: 1.7530, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 087, Loss: 1.7387, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 088, Loss: 1.7365, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 089, Loss: 1.7411, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 090, Loss: 1.7324, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 091, Loss: 1.7356, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 092, Loss: 1.7273, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 093, Loss: 1.7486, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 094, Loss: 1.7349, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 095, Loss: 1.7584, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 096, Loss: 1.7288, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 097, Loss: 1.7425, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 098, Loss: 1.7256, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 099, Loss: 1.7411, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 100, Loss: 1.7482, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 101, Loss: 1.7449, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 102, Loss: 1.7509, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 103, Loss: 1.7335, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 104, Loss: 1.7389, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 105, Loss: 1.7491, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 106, Loss: 1.7443, Val Acc: 0.1556, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 107, Loss: 1.7448, Val Acc: 0.1556, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 108, Loss: 1.7436, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 109, Loss: 1.7431, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 110, Loss: 1.7639, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 111, Loss: 1.7442, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 112, Loss: 1.7366, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 113, Loss: 1.7430, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 114, Loss: 1.7281, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 115, Loss: 1.7243, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 116, Loss: 1.7417, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 117, Loss: 1.7443, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 118, Loss: 1.7354, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 119, Loss: 1.7400, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 120, Loss: 1.7193, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 121, Loss: 1.7325, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 122, Loss: 1.7382, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 123, Loss: 1.7355, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 124, Loss: 1.7296, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 125, Loss: 1.7325, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 126, Loss: 1.7439, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 127, Loss: 1.7168, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 128, Loss: 1.7462, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 129, Loss: 1.7270, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 130, Loss: 1.7189, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 131, Loss: 1.7228, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 132, Loss: 1.7152, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 133, Loss: 1.7361, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 134, Loss: 1.7339, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 135, Loss: 1.7244, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 136, Loss: 1.7295, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 137, Loss: 1.7309, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 138, Loss: 1.7213, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 139, Loss: 1.7141, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 140, Loss: 1.7218, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 141, Loss: 1.7288, Val Acc: 0.1667, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 142, Loss: 1.7196, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 143, Loss: 1.7333, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 144, Loss: 1.7150, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 145, Loss: 1.7181, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 146, Loss: 1.7166, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 147, Loss: 1.7380, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 148, Loss: 1.7143, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 149, Loss: 1.7201, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 150, Loss: 1.7273, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 151, Loss: 1.7282, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 44, Epoch: 152, Loss: 1.7168, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 153, Loss: 1.7211, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 154, Loss: 1.7222, Val Acc: 0.1556, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 155, Loss: 1.7093, Val Acc: 0.1556, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 156, Loss: 1.7200, Val Acc: 0.1556, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 157, Loss: 1.7441, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 158, Loss: 1.7217, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 159, Loss: 1.7162, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 160, Loss: 1.7241, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 161, Loss: 1.7162, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 162, Loss: 1.7207, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 163, Loss: 1.7194, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 164, Loss: 1.7086, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 165, Loss: 1.7138, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 166, Loss: 1.7092, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 167, Loss: 1.7116, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 168, Loss: 1.7190, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 169, Loss: 1.7284, Val Acc: 0.1667, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 170, Loss: 1.7055, Val Acc: 0.1556, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 171, Loss: 1.7093, Val Acc: 0.1556, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 172, Loss: 1.7089, Val Acc: 0.1444, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 173, Loss: 1.7149, Val Acc: 0.1444, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 174, Loss: 1.7025, Val Acc: 0.1667, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 175, Loss: 1.6970, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 176, Loss: 1.7197, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 177, Loss: 1.7034, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 178, Loss: 1.7106, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 179, Loss: 1.7252, Val Acc: 0.1667, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 180, Loss: 1.6991, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 181, Loss: 1.7172, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 182, Loss: 1.7095, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 183, Loss: 1.7438, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 184, Loss: 1.6929, Val Acc: 0.1444, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 185, Loss: 1.7051, Val Acc: 0.1444, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 186, Loss: 1.7041, Val Acc: 0.1667, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 187, Loss: 1.7096, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 188, Loss: 1.7157, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 189, Loss: 1.7086, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 190, Loss: 1.7089, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 191, Loss: 1.6914, Val Acc: 0.1667, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 192, Loss: 1.6927, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 193, Loss: 1.7019, Val Acc: 0.1889, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 194, Loss: 1.6749, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Early stopping at epoch 194 for seed 44\n",
            "Seed: 45, Epoch: 001, Loss: 1.8111, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 002, Loss: 2.0744, Val Acc: 0.1444, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 003, Loss: 1.8242, Val Acc: 0.1667, Test Acc: 0.1333\n",
            "Seed: 45, Epoch: 004, Loss: 1.7923, Val Acc: 0.1667, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 005, Loss: 1.7972, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 006, Loss: 1.8032, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 007, Loss: 1.7840, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 008, Loss: 1.7904, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 009, Loss: 1.7692, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 010, Loss: 1.7944, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 011, Loss: 1.7912, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 012, Loss: 1.7775, Val Acc: 0.2000, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 013, Loss: 1.7926, Val Acc: 0.2000, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 014, Loss: 1.7742, Val Acc: 0.2333, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 015, Loss: 1.7792, Val Acc: 0.2333, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 016, Loss: 1.7845, Val Acc: 0.2333, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 017, Loss: 1.7859, Val Acc: 0.2333, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 018, Loss: 1.7773, Val Acc: 0.2333, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 019, Loss: 1.7821, Val Acc: 0.2333, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 020, Loss: 1.7593, Val Acc: 0.2333, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 021, Loss: 1.7880, Val Acc: 0.2333, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 022, Loss: 1.7647, Val Acc: 0.2333, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 023, Loss: 1.7671, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 024, Loss: 1.7766, Val Acc: 0.2222, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 025, Loss: 1.7740, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 026, Loss: 1.7583, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 027, Loss: 1.7593, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 028, Loss: 1.7570, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 029, Loss: 1.7562, Val Acc: 0.2222, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 030, Loss: 1.7656, Val Acc: 0.2333, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 031, Loss: 1.7532, Val Acc: 0.2222, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 032, Loss: 1.7560, Val Acc: 0.2222, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 033, Loss: 1.7475, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 034, Loss: 1.7682, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 035, Loss: 1.7595, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 036, Loss: 1.7490, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 037, Loss: 1.7733, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 038, Loss: 1.7475, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 039, Loss: 1.7371, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 040, Loss: 1.7503, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 041, Loss: 1.7323, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 042, Loss: 1.7407, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 043, Loss: 1.7367, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 044, Loss: 1.7433, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 045, Loss: 1.7320, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 046, Loss: 1.7359, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 047, Loss: 1.7483, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 048, Loss: 1.7604, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 049, Loss: 1.7464, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 050, Loss: 1.7453, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 051, Loss: 1.7539, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 052, Loss: 1.7464, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 053, Loss: 1.7513, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 054, Loss: 1.7408, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 055, Loss: 1.7528, Val Acc: 0.2111, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 056, Loss: 1.9295, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 057, Loss: 1.7304, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 058, Loss: 1.7477, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 059, Loss: 1.7510, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 060, Loss: 1.7415, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 061, Loss: 1.7356, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 062, Loss: 1.7213, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 063, Loss: 1.7414, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 064, Loss: 1.7394, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 065, Loss: 1.7424, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 066, Loss: 1.7381, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 067, Loss: 1.7502, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 068, Loss: 1.7380, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 069, Loss: 1.7286, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 070, Loss: 1.7312, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 071, Loss: 1.7277, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 072, Loss: 1.7251, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 073, Loss: 1.7562, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 074, Loss: 1.7436, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 075, Loss: 1.7417, Val Acc: 0.1667, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 076, Loss: 1.7313, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 077, Loss: 1.7320, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 078, Loss: 1.7418, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 079, Loss: 1.7466, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 080, Loss: 1.7404, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 081, Loss: 1.7299, Val Acc: 0.1444, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 082, Loss: 1.7402, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 083, Loss: 1.7561, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 084, Loss: 1.7353, Val Acc: 0.1444, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 085, Loss: 1.7230, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 086, Loss: 1.7537, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 087, Loss: 1.7315, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 088, Loss: 1.7430, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 089, Loss: 1.7304, Val Acc: 0.1444, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 090, Loss: 1.7452, Val Acc: 0.1444, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 091, Loss: 1.7442, Val Acc: 0.1444, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 092, Loss: 1.7301, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 093, Loss: 1.7410, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 094, Loss: 1.7205, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 095, Loss: 1.7341, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 096, Loss: 1.7447, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 097, Loss: 1.7272, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 098, Loss: 1.7470, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 099, Loss: 1.7377, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 100, Loss: 1.7195, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 101, Loss: 1.7406, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 102, Loss: 1.7352, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 103, Loss: 1.7371, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 104, Loss: 1.7447, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 105, Loss: 1.7247, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 106, Loss: 1.7195, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 107, Loss: 1.7225, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 108, Loss: 1.7264, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 109, Loss: 1.7341, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 110, Loss: 1.7238, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 111, Loss: 1.7352, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 112, Loss: 1.7291, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 113, Loss: 1.7460, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 114, Loss: 1.7191, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 115, Loss: 1.7085, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 116, Loss: 1.7326, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 117, Loss: 1.7501, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 118, Loss: 1.7337, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 119, Loss: 1.7207, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 120, Loss: 1.7297, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 121, Loss: 1.7318, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 122, Loss: 1.7354, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 123, Loss: 1.7087, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 124, Loss: 1.7018, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 125, Loss: 1.7457, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 126, Loss: 1.7230, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 127, Loss: 1.7247, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 128, Loss: 1.7282, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 129, Loss: 1.7252, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 130, Loss: 1.7250, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 131, Loss: 1.7215, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 132, Loss: 1.7196, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 133, Loss: 1.7236, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 134, Loss: 1.7372, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 135, Loss: 1.7016, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 136, Loss: 1.7058, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 137, Loss: 1.7252, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 138, Loss: 1.6988, Val Acc: 0.1444, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 139, Loss: 1.7106, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 140, Loss: 1.7184, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 141, Loss: 1.7164, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 142, Loss: 1.7217, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 143, Loss: 1.7290, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 144, Loss: 1.7005, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 145, Loss: 1.7374, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 146, Loss: 1.7405, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 147, Loss: 1.7071, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 148, Loss: 1.7264, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 149, Loss: 1.7234, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 150, Loss: 1.7342, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 45, Epoch: 151, Loss: 1.7383, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 152, Loss: 1.7029, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 153, Loss: 1.7220, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 154, Loss: 1.7044, Val Acc: 0.1556, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 155, Loss: 1.7355, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 156, Loss: 1.7097, Val Acc: 0.1667, Test Acc: 0.1667\n",
            "Seed: 45, Epoch: 157, Loss: 1.7261, Val Acc: 0.1667, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 158, Loss: 1.7362, Val Acc: 0.1667, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 159, Loss: 1.7214, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 160, Loss: 1.7287, Val Acc: 0.1444, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 161, Loss: 1.7085, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 162, Loss: 1.7266, Val Acc: 0.1444, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 163, Loss: 1.7328, Val Acc: 0.1444, Test Acc: 0.1778\n",
            "Seed: 45, Epoch: 164, Loss: 1.6982, Val Acc: 0.1444, Test Acc: 0.1778\n",
            "Early stopping at epoch 164 for seed 45\n",
            "Seed: 46, Epoch: 001, Loss: 1.7908, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 002, Loss: 1.7984, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 003, Loss: 1.7894, Val Acc: 0.1333, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 004, Loss: 1.7894, Val Acc: 0.1556, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 005, Loss: 1.7917, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 006, Loss: 1.7884, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 007, Loss: 1.7873, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 008, Loss: 1.7843, Val Acc: 0.2333, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 009, Loss: 1.7747, Val Acc: 0.2556, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 010, Loss: 1.7930, Val Acc: 0.2556, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 011, Loss: 1.7819, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 012, Loss: 1.7760, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 013, Loss: 1.7851, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 014, Loss: 1.7823, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 015, Loss: 1.7845, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 016, Loss: 1.7843, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 017, Loss: 1.7821, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 018, Loss: 1.7803, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 019, Loss: 1.7854, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 020, Loss: 1.7774, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 021, Loss: 1.7811, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 022, Loss: 1.7805, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 023, Loss: 1.7723, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 024, Loss: 1.7784, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 025, Loss: 1.7754, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 026, Loss: 1.7697, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 027, Loss: 1.7719, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 028, Loss: 1.7648, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 029, Loss: 1.7719, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 030, Loss: 1.7704, Val Acc: 0.1556, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 031, Loss: 1.7683, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 032, Loss: 1.7712, Val Acc: 0.2111, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 033, Loss: 1.7594, Val Acc: 0.2333, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 034, Loss: 1.7718, Val Acc: 0.2333, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 035, Loss: 1.7511, Val Acc: 0.2667, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 036, Loss: 1.7544, Val Acc: 0.2778, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 037, Loss: 1.7666, Val Acc: 0.2667, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 038, Loss: 1.7481, Val Acc: 0.2222, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 039, Loss: 1.7541, Val Acc: 0.2222, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 040, Loss: 1.7537, Val Acc: 0.2222, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 041, Loss: 1.7623, Val Acc: 0.2111, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 042, Loss: 1.7261, Val Acc: 0.2333, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 043, Loss: 1.7632, Val Acc: 0.2222, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 044, Loss: 1.7580, Val Acc: 0.2556, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 045, Loss: 1.7315, Val Acc: 0.2222, Test Acc: 0.1222\n",
            "Seed: 46, Epoch: 046, Loss: 1.8192, Val Acc: 0.2778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 047, Loss: 1.7559, Val Acc: 0.3000, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 048, Loss: 1.7571, Val Acc: 0.2556, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 049, Loss: 1.7665, Val Acc: 0.2667, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 050, Loss: 1.7370, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 051, Loss: 1.7658, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 052, Loss: 1.7714, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 053, Loss: 1.7783, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 054, Loss: 1.7652, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 055, Loss: 1.7683, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 056, Loss: 1.7701, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 057, Loss: 1.7744, Val Acc: 0.1889, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 058, Loss: 1.7760, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 059, Loss: 1.7673, Val Acc: 0.1889, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 060, Loss: 1.7652, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 061, Loss: 1.7823, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 062, Loss: 1.7556, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 063, Loss: 1.7594, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 064, Loss: 1.7671, Val Acc: 0.1556, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 065, Loss: 1.7638, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 066, Loss: 1.7600, Val Acc: 0.1667, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 067, Loss: 1.7569, Val Acc: 0.2222, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 068, Loss: 1.7640, Val Acc: 0.2333, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 069, Loss: 1.7618, Val Acc: 0.2333, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 070, Loss: 1.7435, Val Acc: 0.2444, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 071, Loss: 1.7483, Val Acc: 0.2667, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 072, Loss: 1.7506, Val Acc: 0.2667, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 073, Loss: 1.7488, Val Acc: 0.2667, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 074, Loss: 1.7535, Val Acc: 0.2778, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 075, Loss: 1.7307, Val Acc: 0.2333, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 076, Loss: 1.7618, Val Acc: 0.2333, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 077, Loss: 1.7619, Val Acc: 0.2444, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 078, Loss: 1.7359, Val Acc: 0.2667, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 079, Loss: 1.7367, Val Acc: 0.2556, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 080, Loss: 1.7282, Val Acc: 0.2667, Test Acc: 0.1889\n",
            "Seed: 46, Epoch: 081, Loss: 1.7421, Val Acc: 0.2556, Test Acc: 0.1889\n",
            "Seed: 46, Epoch: 082, Loss: 1.7417, Val Acc: 0.2667, Test Acc: 0.1889\n",
            "Seed: 46, Epoch: 083, Loss: 1.7360, Val Acc: 0.2222, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 084, Loss: 1.7053, Val Acc: 0.1444, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 085, Loss: 1.7354, Val Acc: 0.1667, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 086, Loss: 1.7412, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 087, Loss: 1.7618, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 088, Loss: 1.7576, Val Acc: 0.1778, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 089, Loss: 1.7441, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 090, Loss: 1.7478, Val Acc: 0.2222, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 091, Loss: 1.7504, Val Acc: 0.2444, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 092, Loss: 1.7473, Val Acc: 0.2000, Test Acc: 0.1889\n",
            "Seed: 46, Epoch: 093, Loss: 1.7488, Val Acc: 0.2000, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 094, Loss: 1.7060, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 095, Loss: 1.6992, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 096, Loss: 1.6775, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 097, Loss: 1.6892, Val Acc: 0.2111, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 098, Loss: 1.6791, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 099, Loss: 1.7202, Val Acc: 0.2111, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 100, Loss: 1.7074, Val Acc: 0.2111, Test Acc: 0.1444\n",
            "Seed: 46, Epoch: 101, Loss: 1.7094, Val Acc: 0.2333, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 102, Loss: 1.7279, Val Acc: 0.2444, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 103, Loss: 1.7098, Val Acc: 0.2778, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 104, Loss: 1.6883, Val Acc: 0.2889, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 105, Loss: 1.7583, Val Acc: 0.2556, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 106, Loss: 1.7136, Val Acc: 0.2556, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 107, Loss: 1.7310, Val Acc: 0.2222, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 108, Loss: 1.7124, Val Acc: 0.2222, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 109, Loss: 1.7479, Val Acc: 0.1889, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 110, Loss: 1.7530, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 111, Loss: 1.7254, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 112, Loss: 1.7420, Val Acc: 0.1889, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 113, Loss: 1.7336, Val Acc: 0.2000, Test Acc: 0.1556\n",
            "Seed: 46, Epoch: 114, Loss: 1.7151, Val Acc: 0.2222, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 115, Loss: 1.7236, Val Acc: 0.2111, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 116, Loss: 1.6895, Val Acc: 0.2444, Test Acc: 0.1889\n",
            "Seed: 46, Epoch: 117, Loss: 1.6891, Val Acc: 0.2556, Test Acc: 0.1889\n",
            "Seed: 46, Epoch: 118, Loss: 1.6683, Val Acc: 0.2444, Test Acc: 0.1889\n",
            "Seed: 46, Epoch: 119, Loss: 1.6572, Val Acc: 0.2333, Test Acc: 0.2111\n",
            "Seed: 46, Epoch: 120, Loss: 1.7062, Val Acc: 0.2222, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 121, Loss: 1.6538, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 122, Loss: 1.6842, Val Acc: 0.3000, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 123, Loss: 1.6934, Val Acc: 0.2889, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 124, Loss: 1.6120, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 125, Loss: 1.7374, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 126, Loss: 1.6795, Val Acc: 0.2556, Test Acc: 0.2111\n",
            "Seed: 46, Epoch: 127, Loss: 1.6904, Val Acc: 0.2667, Test Acc: 0.2000\n",
            "Seed: 46, Epoch: 128, Loss: 1.7101, Val Acc: 0.2667, Test Acc: 0.2111\n",
            "Seed: 46, Epoch: 129, Loss: 1.6960, Val Acc: 0.2556, Test Acc: 0.2111\n",
            "Seed: 46, Epoch: 130, Loss: 1.6691, Val Acc: 0.2222, Test Acc: 0.2222\n",
            "Seed: 46, Epoch: 131, Loss: 1.6897, Val Acc: 0.2778, Test Acc: 0.2222\n",
            "Seed: 46, Epoch: 132, Loss: 1.6446, Val Acc: 0.3222, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 133, Loss: 1.6143, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 134, Loss: 1.6221, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 135, Loss: 1.6620, Val Acc: 0.3000, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 136, Loss: 1.6581, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 137, Loss: 1.6688, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 138, Loss: 1.6926, Val Acc: 0.2667, Test Acc: 0.2111\n",
            "Seed: 46, Epoch: 139, Loss: 1.6459, Val Acc: 0.2222, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 140, Loss: 1.6245, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 141, Loss: 1.6646, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 142, Loss: 1.5872, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 143, Loss: 1.6653, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 144, Loss: 1.5955, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 145, Loss: 1.6616, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 146, Loss: 1.6992, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 147, Loss: 1.6749, Val Acc: 0.3111, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 148, Loss: 1.7086, Val Acc: 0.2889, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 149, Loss: 1.7230, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 150, Loss: 1.7193, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 151, Loss: 1.6967, Val Acc: 0.2889, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 152, Loss: 1.6767, Val Acc: 0.3111, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 153, Loss: 1.6604, Val Acc: 0.3111, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 154, Loss: 1.6567, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 155, Loss: 1.6951, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 156, Loss: 1.6686, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 157, Loss: 1.6775, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 158, Loss: 1.6174, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 159, Loss: 1.6551, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 160, Loss: 1.5826, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 161, Loss: 1.6732, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 162, Loss: 1.6415, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 163, Loss: 1.5949, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 164, Loss: 1.5781, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 165, Loss: 1.6505, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 166, Loss: 1.6397, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 167, Loss: 1.6303, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 168, Loss: 1.5792, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 169, Loss: 1.6564, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 170, Loss: 1.6074, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 171, Loss: 1.6302, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 172, Loss: 1.5937, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 173, Loss: 1.6425, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 174, Loss: 1.5813, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 175, Loss: 1.6730, Val Acc: 0.3111, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 176, Loss: 1.6432, Val Acc: 0.3222, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 177, Loss: 1.5895, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 178, Loss: 1.6185, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 179, Loss: 1.6158, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 180, Loss: 1.6179, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 181, Loss: 1.6292, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 182, Loss: 1.5494, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 183, Loss: 1.5931, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 184, Loss: 1.5345, Val Acc: 0.3111, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 185, Loss: 1.5620, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 186, Loss: 1.5665, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 187, Loss: 1.5810, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 188, Loss: 1.4824, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 189, Loss: 1.6015, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 190, Loss: 1.6645, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 191, Loss: 1.6276, Val Acc: 0.2556, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 192, Loss: 1.6029, Val Acc: 0.2667, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 193, Loss: 1.5941, Val Acc: 0.2667, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 194, Loss: 1.6568, Val Acc: 0.2667, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 195, Loss: 1.6631, Val Acc: 0.2667, Test Acc: 0.2000\n",
            "Seed: 46, Epoch: 196, Loss: 1.6649, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 197, Loss: 1.5796, Val Acc: 0.2000, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 198, Loss: 1.5477, Val Acc: 0.1889, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 199, Loss: 1.5585, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 200, Loss: 1.5217, Val Acc: 0.2889, Test Acc: 0.2556\n",
            "Average Time: 11.51 seconds\n",
            "Var Time: 1.15 seconds\n",
            "Average Memory: 29.20 MB\n",
            "Average Best Val Acc: 0.2489\n",
            "Std Best Test Acc: 0.0376\n",
            "Average Test Acc: 0.2067\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, EdgePooling\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "from torch_geometric.nn import BatchNorm\n",
        "\n",
        "class HierarchicalGCN_KMIS(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes):\n",
        "        super(HierarchicalGCN_KMIS, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, out_channels)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.lin1 = torch.nn.Linear(out_channels, 32)\n",
        "        self.lin2 = torch.nn.Linear(32, num_classes)\n",
        "\n",
        "        self.pool1 = KMISPooling(64, k=5, aggr_x='sum')\n",
        "        self.pool2 = KMISPooling(64, k=5, aggr_x='sum')\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        # First GCN and pooling layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn1(x)\n",
        "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, batch=batch)\n",
        "\n",
        "        # Second GCN and pooling layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn2(x)\n",
        "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, batch=batch)\n",
        "\n",
        "        # Third GCN layer\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn3(x)\n",
        "\n",
        "        # Mean pooling over the nodes\n",
        "        x, mask = to_dense_batch(x, batch)\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.lin1(x).relu()\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "num_classes = dataset_sparse.num_classes\n",
        "in_channels = dataset_sparse.num_features\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HierarchicalGCN_KMIS(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == data.y).sum().item()\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seeds = [42, 43, 44, 45, 46]\n",
        "times = []\n",
        "memories = []\n",
        "best_val_accs = []\n",
        "best_test_accs = []\n",
        "\n",
        "early_stop_patience = 150\n",
        "tolerance = 0.0001\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    model = HierarchicalGCN_KMIS(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        val_acc = test(valid_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        if val_acc > best_val_acc + tolerance:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "        if epochs_no_improve >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
        "\n",
        "    times.append(total_time)\n",
        "    memories.append(memory_allocated)\n",
        "    best_val_accs.append(best_val_acc)\n",
        "    best_test_accs.append(best_test_acc)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
        "print(f'Var Time: {np.var(times):.2f} seconds')\n",
        "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
        "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
        "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
        "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNoTg_-ZHInG"
      },
      "source": [
        "## GSAPooling with HierarchicalGCN (2021)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cr58OulBHIvv"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "from torch.nn import Parameter\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from typing import Union, Optional, Callable\n",
        "from torch_scatter import scatter_add, scatter_max\n",
        "from torch_geometric.utils import softmax\n",
        "\n",
        "import math\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, ChebConv, GraphConv\n",
        "\n",
        "\n",
        "def uniform(size, tensor):\n",
        "    if tensor is not None:\n",
        "        bound = 1.0 / math.sqrt(size)\n",
        "        tensor.data.uniform_(-bound, bound)\n",
        "\n",
        "\n",
        "def maybe_num_nodes(edge_index, num_nodes=None):\n",
        "    if num_nodes is not None:\n",
        "        return num_nodes\n",
        "    elif isinstance(edge_index, Tensor):\n",
        "        return int(edge_index.max()) + 1 if edge_index.numel() > 0 else 0\n",
        "    else:\n",
        "        return max(edge_index.size(0), edge_index.size(1))\n",
        "\n",
        "\n",
        "def topk(x, ratio, batch, min_score=None, tol=1e-7):\n",
        "    if min_score is not None:\n",
        "        # Make sure that we do not drop all nodes in a graph.\n",
        "        scores_max = scatter_max(x, batch)[0][batch] - tol\n",
        "        scores_min = scores_max.clamp(max=min_score)\n",
        "\n",
        "        perm = (x > scores_min).nonzero(as_tuple=False).view(-1)\n",
        "    else:\n",
        "        num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)\n",
        "        batch_size, max_num_nodes = num_nodes.size(0), num_nodes.max().item()\n",
        "\n",
        "        cum_num_nodes = torch.cat(\n",
        "            [num_nodes.new_zeros(1),\n",
        "             num_nodes.cumsum(dim=0)[:-1]], dim=0)\n",
        "\n",
        "        index = torch.arange(batch.size(0), dtype=torch.long, device=x.device)\n",
        "        index = (index - cum_num_nodes[batch]) + (batch * max_num_nodes)\n",
        "\n",
        "        dense_x = x.new_full((batch_size * max_num_nodes, ),\n",
        "                             torch.finfo(x.dtype).min)\n",
        "        dense_x[index] = x\n",
        "        dense_x = dense_x.view(batch_size, max_num_nodes)\n",
        "\n",
        "        _, perm = dense_x.sort(dim=-1, descending=True)\n",
        "\n",
        "        perm = perm + cum_num_nodes.view(-1, 1)\n",
        "        perm = perm.view(-1)\n",
        "\n",
        "        if isinstance(ratio, int):\n",
        "            k = num_nodes.new_full((num_nodes.size(0), ), ratio)\n",
        "            k = torch.min(k, num_nodes)\n",
        "        else:\n",
        "            k = (ratio * num_nodes.to(torch.float)).ceil().to(torch.long)\n",
        "\n",
        "        mask = [\n",
        "            torch.arange(k[i], dtype=torch.long, device=x.device) +\n",
        "            i * max_num_nodes for i in range(batch_size)\n",
        "        ]\n",
        "        mask = torch.cat(mask, dim=0)\n",
        "\n",
        "        perm = perm[mask]\n",
        "\n",
        "    return perm\n",
        "\n",
        "\n",
        "def filter_adj(edge_index, edge_attr, perm, num_nodes=None):\n",
        "    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
        "\n",
        "    mask = perm.new_full((num_nodes, ), -1)\n",
        "    i = torch.arange(perm.size(0), dtype=torch.long, device=perm.device)\n",
        "    mask[perm] = i\n",
        "\n",
        "    row, col = edge_index\n",
        "    row, col = mask[row], mask[col]\n",
        "    mask = (row >= 0) & (col >= 0)\n",
        "    row, col = row[mask], col[mask]\n",
        "\n",
        "    if edge_attr is not None:\n",
        "        edge_attr = edge_attr[mask]\n",
        "\n",
        "    return torch.stack([row, col], dim=0), edge_attr\n",
        "\n",
        "\n",
        "class GSAPool(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, pooling_ratio=0.5, alpha=0.6,\n",
        "                        min_score=None, multiplier=1,\n",
        "                        non_linearity=torch.tanh,\n",
        "                        cus_drop_ratio =0):\n",
        "        super(GSAPool,self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        self.ratio = pooling_ratio\n",
        "        self.alpha = alpha\n",
        "\n",
        "        self.sbtl_layer = GCNConv(in_channels,1)\n",
        "        self.fbtl_layer = nn.Linear(in_channels, 1)\n",
        "        self.fusion = GCNConv(in_channels,in_channels)\n",
        "\n",
        "        self.min_score = min_score\n",
        "        self.multiplier = multiplier\n",
        "        self.fusion_flag = 0\n",
        "        self.non_linearity = non_linearity\n",
        "\n",
        "        self.dropout = torch.nn.Dropout(cus_drop_ratio)\n",
        "\n",
        "    def conv_selection(self, conv, in_channels, conv_type=0):\n",
        "        if(conv_type == 0):\n",
        "            out_channels = 1\n",
        "        elif(conv_type == 1):\n",
        "            out_channels = in_channels\n",
        "        if(conv == \"GCNConv\"):\n",
        "            return GCNConv(in_channels,out_channels)\n",
        "        elif(conv == \"ChebConv\"):\n",
        "            return ChebConv(in_channels,out_channels,1)\n",
        "        elif(conv == \"SAGEConv\"):\n",
        "            return SAGEConv(in_channels,out_channels)\n",
        "        elif(conv == \"GATConv\"):\n",
        "            return GATConv(in_channels,out_channels, heads=1, concat=True)\n",
        "        elif(conv == \"GraphConv\"):\n",
        "            return GraphConv(in_channels,out_channels)\n",
        "        else:\n",
        "            raise ValueError\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr=None, batch=None):\n",
        "        if batch is None:\n",
        "            batch = edge_index.new_zeros(x.size(0))\n",
        "        x = x.unsqueeze(-1) if x.dim() == 1 else x\n",
        "\n",
        "        #SBTL\n",
        "        score_s = self.sbtl_layer(x,edge_index).squeeze()\n",
        "        #FBTL\n",
        "        score_f = self.fbtl_layer(x).squeeze()\n",
        "        #hyperparametr alpha\n",
        "        score = score_s*self.alpha + score_f*(1-self.alpha)\n",
        "\n",
        "        score = score.unsqueeze(-1) if score.dim()==0 else score\n",
        "\n",
        "        if self.min_score is None:\n",
        "            score = self.non_linearity(score)\n",
        "        else:\n",
        "            score = softmax(score, batch)\n",
        "\n",
        "        sc = self.dropout(score)\n",
        "        perm = topk(sc, self.ratio, batch)\n",
        "\n",
        "        #fusion\n",
        "        if(self.fusion_flag == 1):\n",
        "            x = self.fusion(x, edge_index)\n",
        "        x_ae = x[perm]\n",
        "        x = x[perm] * score[perm].view(-1, 1)\n",
        "        x = self.multiplier * x if self.multiplier != 1 else x\n",
        "\n",
        "        batch = batch[perm]\n",
        "        edge_index, edge_attr = filter_adj(\n",
        "            edge_index, edge_attr, perm, num_nodes=score.size(0))\n",
        "\n",
        "        return x, edge_index, edge_attr, batch, perm, x_ae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep3ELTOTHiwQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 001, Loss: 1.7995, Val Acc: 0.1889, Test Acc: 0.1667\n",
            "Seed: 42, Epoch: 002, Loss: 1.7825, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 42, Epoch: 003, Loss: 1.7828, Val Acc: 0.1667, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 004, Loss: 1.7658, Val Acc: 0.1333, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 005, Loss: 1.7604, Val Acc: 0.1556, Test Acc: 0.2111\n",
            "Seed: 42, Epoch: 006, Loss: 1.7554, Val Acc: 0.1667, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 007, Loss: 1.7488, Val Acc: 0.1444, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 008, Loss: 1.7514, Val Acc: 0.1444, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 009, Loss: 1.7454, Val Acc: 0.1667, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 010, Loss: 1.7412, Val Acc: 0.1556, Test Acc: 0.2111\n",
            "Seed: 42, Epoch: 011, Loss: 1.7344, Val Acc: 0.1667, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 012, Loss: 1.7251, Val Acc: 0.1778, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 013, Loss: 1.7250, Val Acc: 0.1889, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 014, Loss: 1.7130, Val Acc: 0.1889, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 015, Loss: 1.7058, Val Acc: 0.2000, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 016, Loss: 1.6977, Val Acc: 0.2000, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 017, Loss: 1.6894, Val Acc: 0.1778, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 018, Loss: 1.6766, Val Acc: 0.2000, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 019, Loss: 1.6673, Val Acc: 0.1667, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 020, Loss: 1.6491, Val Acc: 0.1667, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 021, Loss: 1.6358, Val Acc: 0.1778, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 022, Loss: 1.6474, Val Acc: 0.2000, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 023, Loss: 1.6265, Val Acc: 0.2111, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 024, Loss: 1.6172, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 025, Loss: 1.6313, Val Acc: 0.1889, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 026, Loss: 1.5999, Val Acc: 0.1667, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 027, Loss: 1.6069, Val Acc: 0.1778, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 028, Loss: 1.5961, Val Acc: 0.2000, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 029, Loss: 1.5987, Val Acc: 0.1556, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 030, Loss: 1.5775, Val Acc: 0.1444, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 031, Loss: 1.5783, Val Acc: 0.1778, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 032, Loss: 1.5608, Val Acc: 0.1556, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 033, Loss: 1.5551, Val Acc: 0.1778, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 034, Loss: 1.5578, Val Acc: 0.1667, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 035, Loss: 1.5496, Val Acc: 0.1889, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 036, Loss: 1.5665, Val Acc: 0.1333, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 037, Loss: 1.5852, Val Acc: 0.1778, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 038, Loss: 1.6050, Val Acc: 0.1556, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 039, Loss: 1.5827, Val Acc: 0.1444, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 040, Loss: 1.5586, Val Acc: 0.1778, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 041, Loss: 1.5598, Val Acc: 0.1556, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 042, Loss: 1.5458, Val Acc: 0.1778, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 043, Loss: 1.5349, Val Acc: 0.2111, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 044, Loss: 1.5805, Val Acc: 0.1889, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 045, Loss: 1.6201, Val Acc: 0.1333, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 046, Loss: 1.5822, Val Acc: 0.1333, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 047, Loss: 1.5873, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 048, Loss: 1.5288, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 049, Loss: 1.5376, Val Acc: 0.2000, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 050, Loss: 1.5322, Val Acc: 0.1778, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 051, Loss: 1.5336, Val Acc: 0.1889, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 052, Loss: 1.5301, Val Acc: 0.2111, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 053, Loss: 1.5107, Val Acc: 0.1556, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 054, Loss: 1.5398, Val Acc: 0.2000, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 055, Loss: 1.5310, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 056, Loss: 1.4867, Val Acc: 0.2000, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 057, Loss: 1.4945, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 058, Loss: 1.4727, Val Acc: 0.1889, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 059, Loss: 1.4873, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 060, Loss: 1.4805, Val Acc: 0.1889, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 061, Loss: 1.4753, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 062, Loss: 1.4711, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 063, Loss: 1.4733, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 064, Loss: 1.4616, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 065, Loss: 1.4859, Val Acc: 0.2000, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 066, Loss: 1.5238, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 067, Loss: 1.4851, Val Acc: 0.1778, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 068, Loss: 1.4916, Val Acc: 0.2000, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 069, Loss: 1.4646, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 070, Loss: 1.4503, Val Acc: 0.1889, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 071, Loss: 1.4521, Val Acc: 0.1778, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 072, Loss: 1.4468, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 073, Loss: 1.4256, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 074, Loss: 1.4228, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 075, Loss: 1.4307, Val Acc: 0.1889, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 076, Loss: 1.4322, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 077, Loss: 1.4258, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 078, Loss: 1.3960, Val Acc: 0.2111, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 079, Loss: 1.3817, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 080, Loss: 1.3867, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 081, Loss: 1.3873, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 082, Loss: 1.3779, Val Acc: 0.2000, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 083, Loss: 1.4017, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 084, Loss: 1.3863, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 085, Loss: 1.3692, Val Acc: 0.2222, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 086, Loss: 1.3496, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 087, Loss: 1.3373, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 088, Loss: 1.3476, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 089, Loss: 1.3248, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 090, Loss: 1.3443, Val Acc: 0.2222, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 091, Loss: 1.3438, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 092, Loss: 1.3508, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 093, Loss: 1.3338, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 094, Loss: 1.3242, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 095, Loss: 1.3465, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 096, Loss: 1.3336, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 097, Loss: 1.3890, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 098, Loss: 1.3648, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 099, Loss: 1.4060, Val Acc: 0.2111, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 100, Loss: 1.3561, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 101, Loss: 1.3337, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 102, Loss: 1.3427, Val Acc: 0.2111, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 103, Loss: 1.3160, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 104, Loss: 1.3328, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 105, Loss: 1.3049, Val Acc: 0.2222, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 106, Loss: 1.3260, Val Acc: 0.2556, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 107, Loss: 1.3262, Val Acc: 0.2444, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 108, Loss: 1.3098, Val Acc: 0.2111, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 109, Loss: 1.3035, Val Acc: 0.2222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 110, Loss: 1.2824, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 111, Loss: 1.2800, Val Acc: 0.2333, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 112, Loss: 1.2776, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 113, Loss: 1.2874, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 114, Loss: 1.2564, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 115, Loss: 1.2732, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 116, Loss: 1.2587, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 117, Loss: 1.2514, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 118, Loss: 1.2662, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 119, Loss: 1.3479, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 120, Loss: 1.3459, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 121, Loss: 1.3564, Val Acc: 0.2111, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 122, Loss: 1.3228, Val Acc: 0.2111, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 123, Loss: 1.2785, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 124, Loss: 1.3185, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 125, Loss: 1.2549, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 126, Loss: 1.2502, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 127, Loss: 1.2377, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 128, Loss: 1.2407, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 129, Loss: 1.2493, Val Acc: 0.1889, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 130, Loss: 1.2221, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 131, Loss: 1.2267, Val Acc: 0.2222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 132, Loss: 1.2555, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 133, Loss: 1.2267, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 134, Loss: 1.2372, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 135, Loss: 1.3368, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 136, Loss: 1.2404, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 137, Loss: 1.2402, Val Acc: 0.2222, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 138, Loss: 1.2475, Val Acc: 0.2111, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 139, Loss: 1.2651, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 140, Loss: 1.2065, Val Acc: 0.2111, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 141, Loss: 1.1701, Val Acc: 0.2222, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 142, Loss: 1.1945, Val Acc: 0.2000, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 143, Loss: 1.2067, Val Acc: 0.2111, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 144, Loss: 1.1898, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 145, Loss: 1.1627, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 146, Loss: 1.1879, Val Acc: 0.2000, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 147, Loss: 1.1960, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 148, Loss: 1.1845, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 149, Loss: 1.1768, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 150, Loss: 1.1765, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 151, Loss: 1.2021, Val Acc: 0.2000, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 152, Loss: 1.1484, Val Acc: 0.2222, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 153, Loss: 1.1426, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 154, Loss: 1.1625, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 155, Loss: 1.1443, Val Acc: 0.2000, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 156, Loss: 1.1384, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 157, Loss: 1.1329, Val Acc: 0.1889, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 158, Loss: 1.1411, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 159, Loss: 1.1269, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 160, Loss: 1.2098, Val Acc: 0.2222, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 161, Loss: 1.1267, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 162, Loss: 1.1527, Val Acc: 0.2556, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 163, Loss: 1.1409, Val Acc: 0.2000, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 164, Loss: 1.1779, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 165, Loss: 1.1932, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 166, Loss: 1.2415, Val Acc: 0.2222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 167, Loss: 1.2475, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 168, Loss: 1.1895, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 169, Loss: 1.2993, Val Acc: 0.2222, Test Acc: 0.4556\n",
            "Seed: 42, Epoch: 170, Loss: 1.1693, Val Acc: 0.2222, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 171, Loss: 1.2471, Val Acc: 0.2333, Test Acc: 0.4667\n",
            "Seed: 42, Epoch: 172, Loss: 1.3110, Val Acc: 0.2333, Test Acc: 0.4889\n",
            "Seed: 42, Epoch: 173, Loss: 1.2584, Val Acc: 0.2111, Test Acc: 0.4778\n",
            "Seed: 42, Epoch: 174, Loss: 1.3233, Val Acc: 0.2556, Test Acc: 0.4556\n",
            "Seed: 42, Epoch: 175, Loss: 1.3718, Val Acc: 0.2556, Test Acc: 0.4444\n",
            "Seed: 42, Epoch: 176, Loss: 1.2495, Val Acc: 0.1889, Test Acc: 0.4556\n",
            "Seed: 42, Epoch: 177, Loss: 1.2372, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 178, Loss: 1.2314, Val Acc: 0.2000, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 179, Loss: 1.2257, Val Acc: 0.2000, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 180, Loss: 1.2466, Val Acc: 0.2000, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 181, Loss: 1.1902, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 182, Loss: 1.1817, Val Acc: 0.2333, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 183, Loss: 1.1939, Val Acc: 0.2000, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 184, Loss: 1.1661, Val Acc: 0.1889, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 185, Loss: 1.1618, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 186, Loss: 1.1485, Val Acc: 0.2111, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 187, Loss: 1.1625, Val Acc: 0.2111, Test Acc: 0.4556\n",
            "Seed: 42, Epoch: 188, Loss: 1.1407, Val Acc: 0.1889, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 189, Loss: 1.1265, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 190, Loss: 1.0896, Val Acc: 0.2333, Test Acc: 0.4556\n",
            "Seed: 42, Epoch: 191, Loss: 1.0994, Val Acc: 0.2333, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 192, Loss: 1.1084, Val Acc: 0.2333, Test Acc: 0.4889\n",
            "Seed: 42, Epoch: 193, Loss: 1.1073, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 194, Loss: 1.0897, Val Acc: 0.2222, Test Acc: 0.4556\n",
            "Seed: 42, Epoch: 195, Loss: 1.0959, Val Acc: 0.2222, Test Acc: 0.4667\n",
            "Seed: 42, Epoch: 196, Loss: 1.0669, Val Acc: 0.2333, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 197, Loss: 1.0703, Val Acc: 0.2667, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 198, Loss: 1.0708, Val Acc: 0.2000, Test Acc: 0.4444\n",
            "Seed: 42, Epoch: 199, Loss: 1.0779, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 200, Loss: 1.0819, Val Acc: 0.2000, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 001, Loss: 1.7878, Val Acc: 0.1667, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 002, Loss: 1.7775, Val Acc: 0.1667, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 003, Loss: 1.7714, Val Acc: 0.1667, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 004, Loss: 1.7702, Val Acc: 0.1778, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 005, Loss: 1.7672, Val Acc: 0.1778, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 006, Loss: 1.7669, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 007, Loss: 1.7667, Val Acc: 0.1778, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 008, Loss: 1.7646, Val Acc: 0.2000, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 009, Loss: 1.7608, Val Acc: 0.2000, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 010, Loss: 1.7593, Val Acc: 0.2000, Test Acc: 0.1778\n",
            "Seed: 43, Epoch: 011, Loss: 1.7564, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 012, Loss: 1.7512, Val Acc: 0.1889, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 013, Loss: 1.7424, Val Acc: 0.2000, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 014, Loss: 1.7531, Val Acc: 0.2000, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 015, Loss: 1.7336, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 016, Loss: 1.7318, Val Acc: 0.2333, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 017, Loss: 1.7257, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 018, Loss: 1.7183, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 019, Loss: 1.7188, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 020, Loss: 1.7168, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 021, Loss: 1.7016, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 022, Loss: 1.6981, Val Acc: 0.2111, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 023, Loss: 1.6951, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 024, Loss: 1.6870, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 025, Loss: 1.6878, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 026, Loss: 1.6931, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 027, Loss: 1.6916, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 028, Loss: 1.6938, Val Acc: 0.2556, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 029, Loss: 1.6881, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 030, Loss: 1.6939, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 031, Loss: 1.6963, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 032, Loss: 1.7066, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 033, Loss: 1.6901, Val Acc: 0.2111, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 034, Loss: 1.6946, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 035, Loss: 1.6810, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 036, Loss: 1.6829, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 037, Loss: 1.6765, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 038, Loss: 1.6650, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 039, Loss: 1.6517, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 040, Loss: 1.6485, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 041, Loss: 1.6414, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 042, Loss: 1.6382, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 043, Loss: 1.6372, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 044, Loss: 1.6443, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 045, Loss: 1.6501, Val Acc: 0.2111, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 046, Loss: 1.6379, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 047, Loss: 1.6315, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 048, Loss: 1.6304, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 049, Loss: 1.6220, Val Acc: 0.2111, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 050, Loss: 1.6208, Val Acc: 0.1889, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 051, Loss: 1.6287, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 052, Loss: 1.6109, Val Acc: 0.2222, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 053, Loss: 1.6357, Val Acc: 0.1778, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 054, Loss: 1.6086, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 055, Loss: 1.6327, Val Acc: 0.2111, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 056, Loss: 1.6061, Val Acc: 0.1889, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 057, Loss: 1.5867, Val Acc: 0.2333, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 058, Loss: 1.5947, Val Acc: 0.2111, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 059, Loss: 1.5999, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 060, Loss: 1.6087, Val Acc: 0.2000, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 061, Loss: 1.6150, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 062, Loss: 1.5895, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 063, Loss: 1.5747, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 064, Loss: 1.5878, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 065, Loss: 1.5685, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 066, Loss: 1.5635, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 067, Loss: 1.5721, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 068, Loss: 1.5718, Val Acc: 0.2111, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 069, Loss: 1.5630, Val Acc: 0.2111, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 070, Loss: 1.5520, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 071, Loss: 1.5476, Val Acc: 0.2111, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 072, Loss: 1.5479, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 073, Loss: 1.5492, Val Acc: 0.2000, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 074, Loss: 1.5308, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 075, Loss: 1.5092, Val Acc: 0.2000, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 076, Loss: 1.5069, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 077, Loss: 1.5197, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 078, Loss: 1.5258, Val Acc: 0.1778, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 079, Loss: 1.5357, Val Acc: 0.2000, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 080, Loss: 1.5245, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 081, Loss: 1.5461, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 082, Loss: 1.5238, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 083, Loss: 1.5102, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 084, Loss: 1.5027, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 085, Loss: 1.5096, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 086, Loss: 1.4980, Val Acc: 0.2000, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 087, Loss: 1.4739, Val Acc: 0.2111, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 088, Loss: 1.4824, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 089, Loss: 1.4927, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 090, Loss: 1.4924, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 091, Loss: 1.4892, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 092, Loss: 1.4775, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 093, Loss: 1.4734, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 094, Loss: 1.4717, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 095, Loss: 1.4572, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 096, Loss: 1.4557, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 097, Loss: 1.4569, Val Acc: 0.2000, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 098, Loss: 1.4225, Val Acc: 0.2111, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 099, Loss: 1.4469, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 100, Loss: 1.4493, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 101, Loss: 1.4352, Val Acc: 0.2000, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 102, Loss: 1.4280, Val Acc: 0.1889, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 103, Loss: 1.4096, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 104, Loss: 1.4269, Val Acc: 0.1889, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 105, Loss: 1.3937, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 106, Loss: 1.3844, Val Acc: 0.1889, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 107, Loss: 1.4010, Val Acc: 0.1889, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 108, Loss: 1.3992, Val Acc: 0.1889, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 109, Loss: 1.3790, Val Acc: 0.2000, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 110, Loss: 1.3703, Val Acc: 0.2000, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 111, Loss: 1.3714, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 112, Loss: 1.3759, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 113, Loss: 1.3453, Val Acc: 0.2222, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 114, Loss: 1.3553, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 115, Loss: 1.3518, Val Acc: 0.1778, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 116, Loss: 1.3242, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 117, Loss: 1.3393, Val Acc: 0.2111, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 118, Loss: 1.3084, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 119, Loss: 1.3105, Val Acc: 0.2111, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 120, Loss: 1.3016, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 121, Loss: 1.3071, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 122, Loss: 1.3143, Val Acc: 0.2222, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 123, Loss: 1.3224, Val Acc: 0.2000, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 124, Loss: 1.2891, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 125, Loss: 1.2954, Val Acc: 0.2111, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 126, Loss: 1.3605, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 127, Loss: 1.3023, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 128, Loss: 1.3204, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 129, Loss: 1.2941, Val Acc: 0.2222, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 130, Loss: 1.2940, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 131, Loss: 1.3306, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 132, Loss: 1.2754, Val Acc: 0.2111, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 133, Loss: 1.2823, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 134, Loss: 1.3169, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 135, Loss: 1.2769, Val Acc: 0.2222, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 136, Loss: 1.2923, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 137, Loss: 1.2861, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 138, Loss: 1.2766, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 139, Loss: 1.3083, Val Acc: 0.2222, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 140, Loss: 1.2476, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 141, Loss: 1.2655, Val Acc: 0.2889, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 142, Loss: 1.2620, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 143, Loss: 1.2232, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 144, Loss: 1.2230, Val Acc: 0.2333, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 145, Loss: 1.2352, Val Acc: 0.2556, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 146, Loss: 1.2351, Val Acc: 0.2444, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 147, Loss: 1.2067, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 148, Loss: 1.2191, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 149, Loss: 1.2190, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 150, Loss: 1.2036, Val Acc: 0.2111, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 151, Loss: 1.1733, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 152, Loss: 1.1868, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 153, Loss: 1.1901, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 154, Loss: 1.1776, Val Acc: 0.2222, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 155, Loss: 1.1771, Val Acc: 0.2444, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 156, Loss: 1.1648, Val Acc: 0.2556, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 157, Loss: 1.1373, Val Acc: 0.2111, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 158, Loss: 1.1531, Val Acc: 0.2222, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 159, Loss: 1.1704, Val Acc: 0.2222, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 160, Loss: 1.1663, Val Acc: 0.2667, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 161, Loss: 1.1529, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 162, Loss: 1.1507, Val Acc: 0.2111, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 163, Loss: 1.1544, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 164, Loss: 1.1352, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 165, Loss: 1.1291, Val Acc: 0.2444, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 166, Loss: 1.1073, Val Acc: 0.2333, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 167, Loss: 1.1345, Val Acc: 0.2111, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 168, Loss: 1.1214, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 169, Loss: 1.1311, Val Acc: 0.2444, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 170, Loss: 1.1051, Val Acc: 0.1889, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 171, Loss: 1.1428, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 172, Loss: 1.1135, Val Acc: 0.2444, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 173, Loss: 1.0754, Val Acc: 0.2444, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 174, Loss: 1.0934, Val Acc: 0.2444, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 175, Loss: 1.0716, Val Acc: 0.2444, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 176, Loss: 1.0489, Val Acc: 0.2222, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 177, Loss: 1.0791, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 178, Loss: 1.1083, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 179, Loss: 1.0635, Val Acc: 0.2444, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 180, Loss: 1.0468, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 181, Loss: 1.0524, Val Acc: 0.2556, Test Acc: 0.4222\n",
            "Early stopping at epoch 181 for seed 43\n",
            "Seed: 44, Epoch: 001, Loss: 1.7875, Val Acc: 0.1333, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 002, Loss: 1.7820, Val Acc: 0.1444, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 003, Loss: 1.7777, Val Acc: 0.1444, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 004, Loss: 1.7731, Val Acc: 0.1444, Test Acc: 0.2000\n",
            "Seed: 44, Epoch: 005, Loss: 1.7722, Val Acc: 0.1444, Test Acc: 0.2000\n",
            "Seed: 44, Epoch: 006, Loss: 1.7691, Val Acc: 0.1444, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 007, Loss: 1.7655, Val Acc: 0.1333, Test Acc: 0.2000\n",
            "Seed: 44, Epoch: 008, Loss: 1.7643, Val Acc: 0.1333, Test Acc: 0.1889\n",
            "Seed: 44, Epoch: 009, Loss: 1.7635, Val Acc: 0.1667, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 010, Loss: 1.7554, Val Acc: 0.2333, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 011, Loss: 1.7543, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 012, Loss: 1.7514, Val Acc: 0.2000, Test Acc: 0.2111\n",
            "Seed: 44, Epoch: 013, Loss: 1.7461, Val Acc: 0.2000, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 014, Loss: 1.7450, Val Acc: 0.2111, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 015, Loss: 1.7329, Val Acc: 0.2111, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 016, Loss: 1.7310, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 017, Loss: 1.7211, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 018, Loss: 1.7126, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 019, Loss: 1.7047, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 020, Loss: 1.6924, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 021, Loss: 1.6825, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 022, Loss: 1.6765, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 023, Loss: 1.6652, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 024, Loss: 1.6707, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 025, Loss: 1.6695, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 026, Loss: 1.6567, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 027, Loss: 1.6431, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 028, Loss: 1.6429, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 029, Loss: 1.6326, Val Acc: 0.2000, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 030, Loss: 1.6322, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 031, Loss: 1.6415, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 032, Loss: 1.6362, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 033, Loss: 1.6148, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 034, Loss: 1.6246, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 035, Loss: 1.6187, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 036, Loss: 1.6120, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 037, Loss: 1.6146, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 038, Loss: 1.6135, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 039, Loss: 1.6032, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 040, Loss: 1.5956, Val Acc: 0.2000, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 041, Loss: 1.5869, Val Acc: 0.2000, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 042, Loss: 1.5895, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 043, Loss: 1.5751, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 044, Loss: 1.5793, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 045, Loss: 1.5797, Val Acc: 0.2000, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 046, Loss: 1.5792, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 047, Loss: 1.5572, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 048, Loss: 1.5617, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 049, Loss: 1.5856, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 050, Loss: 1.5873, Val Acc: 0.1889, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 051, Loss: 1.5814, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 052, Loss: 1.5748, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 053, Loss: 1.5771, Val Acc: 0.2000, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 054, Loss: 1.5587, Val Acc: 0.2000, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 055, Loss: 1.5413, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 056, Loss: 1.5379, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 057, Loss: 1.5477, Val Acc: 0.1889, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 058, Loss: 1.5413, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 059, Loss: 1.5302, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 060, Loss: 1.5294, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 061, Loss: 1.5230, Val Acc: 0.1889, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 062, Loss: 1.5187, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 063, Loss: 1.5361, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 064, Loss: 1.5098, Val Acc: 0.1778, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 065, Loss: 1.5088, Val Acc: 0.2222, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 066, Loss: 1.5011, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 067, Loss: 1.5095, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 068, Loss: 1.5135, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 069, Loss: 1.5054, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 070, Loss: 1.5221, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 071, Loss: 1.5356, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 072, Loss: 1.5370, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 073, Loss: 1.5335, Val Acc: 0.1778, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 074, Loss: 1.5248, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 075, Loss: 1.5280, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 076, Loss: 1.4798, Val Acc: 0.2111, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 077, Loss: 1.5151, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 078, Loss: 1.4830, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 079, Loss: 1.4837, Val Acc: 0.1889, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 080, Loss: 1.4674, Val Acc: 0.2000, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 081, Loss: 1.4380, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 082, Loss: 1.4821, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 083, Loss: 1.4765, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 084, Loss: 1.4944, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 085, Loss: 1.4825, Val Acc: 0.2222, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 086, Loss: 1.4762, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 087, Loss: 1.4698, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 088, Loss: 1.4424, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 089, Loss: 1.4454, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 090, Loss: 1.4718, Val Acc: 0.2111, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 091, Loss: 1.4759, Val Acc: 0.1889, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 092, Loss: 1.4921, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 093, Loss: 1.5257, Val Acc: 0.2222, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 094, Loss: 1.4983, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 095, Loss: 1.4892, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 096, Loss: 1.4887, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 097, Loss: 1.4710, Val Acc: 0.2556, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 098, Loss: 1.4705, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 099, Loss: 1.4671, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 100, Loss: 1.4423, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 101, Loss: 1.4606, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 102, Loss: 1.4278, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 103, Loss: 1.4357, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 104, Loss: 1.4200, Val Acc: 0.2889, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 105, Loss: 1.4243, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 106, Loss: 1.4085, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 107, Loss: 1.4146, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 108, Loss: 1.4173, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 109, Loss: 1.4325, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 110, Loss: 1.4288, Val Acc: 0.2222, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 111, Loss: 1.4068, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 112, Loss: 1.4445, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 113, Loss: 1.4072, Val Acc: 0.2778, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 114, Loss: 1.4074, Val Acc: 0.2889, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 115, Loss: 1.3821, Val Acc: 0.2889, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 116, Loss: 1.3821, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 117, Loss: 1.3839, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 118, Loss: 1.3745, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 119, Loss: 1.3604, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 120, Loss: 1.3498, Val Acc: 0.2889, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 121, Loss: 1.3409, Val Acc: 0.2778, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 122, Loss: 1.3317, Val Acc: 0.2667, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 123, Loss: 1.3581, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 124, Loss: 1.3385, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 125, Loss: 1.4207, Val Acc: 0.2778, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 126, Loss: 1.3360, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 127, Loss: 1.3744, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 128, Loss: 1.3445, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 129, Loss: 1.3345, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 130, Loss: 1.3263, Val Acc: 0.2667, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 131, Loss: 1.3108, Val Acc: 0.2889, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 132, Loss: 1.3074, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 133, Loss: 1.3345, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 134, Loss: 1.3080, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 135, Loss: 1.2984, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 136, Loss: 1.3042, Val Acc: 0.2889, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 137, Loss: 1.2887, Val Acc: 0.2889, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 138, Loss: 1.3014, Val Acc: 0.2778, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 139, Loss: 1.3331, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 140, Loss: 1.3659, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 141, Loss: 1.3753, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 142, Loss: 1.3560, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 143, Loss: 1.3666, Val Acc: 0.3333, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 144, Loss: 1.3953, Val Acc: 0.2889, Test Acc: 0.4778\n",
            "Seed: 44, Epoch: 145, Loss: 1.3940, Val Acc: 0.2889, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 146, Loss: 1.4148, Val Acc: 0.2444, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 147, Loss: 1.3930, Val Acc: 0.2778, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 148, Loss: 1.4056, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 149, Loss: 1.4299, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 150, Loss: 1.3878, Val Acc: 0.2667, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 151, Loss: 1.4016, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 152, Loss: 1.3881, Val Acc: 0.2222, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 153, Loss: 1.4426, Val Acc: 0.2778, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 154, Loss: 1.3736, Val Acc: 0.2889, Test Acc: 0.4667\n",
            "Seed: 44, Epoch: 155, Loss: 1.3178, Val Acc: 0.3111, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 156, Loss: 1.3357, Val Acc: 0.2778, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 157, Loss: 1.3473, Val Acc: 0.2778, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 158, Loss: 1.3189, Val Acc: 0.2889, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 159, Loss: 1.3410, Val Acc: 0.2556, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 160, Loss: 1.3472, Val Acc: 0.2889, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 161, Loss: 1.3195, Val Acc: 0.3000, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 162, Loss: 1.3451, Val Acc: 0.3000, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 163, Loss: 1.3000, Val Acc: 0.2889, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 164, Loss: 1.2908, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 165, Loss: 1.2924, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 166, Loss: 1.2749, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 167, Loss: 1.2972, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 168, Loss: 1.2914, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 169, Loss: 1.2909, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 170, Loss: 1.2996, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 171, Loss: 1.2847, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 172, Loss: 1.2883, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 173, Loss: 1.2782, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 174, Loss: 1.2727, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 175, Loss: 1.2441, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 176, Loss: 1.2372, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 177, Loss: 1.2534, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 178, Loss: 1.2272, Val Acc: 0.3111, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 179, Loss: 1.2635, Val Acc: 0.3000, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 180, Loss: 1.2163, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 181, Loss: 1.2321, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 182, Loss: 1.2160, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 183, Loss: 1.2281, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 184, Loss: 1.1966, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 185, Loss: 1.1998, Val Acc: 0.3222, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 186, Loss: 1.1772, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 187, Loss: 1.1911, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 188, Loss: 1.1664, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 189, Loss: 1.1949, Val Acc: 0.3667, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 190, Loss: 1.1832, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 191, Loss: 1.1597, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 192, Loss: 1.1779, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 193, Loss: 1.1672, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 194, Loss: 1.1650, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 195, Loss: 1.1231, Val Acc: 0.3333, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 196, Loss: 1.1643, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 197, Loss: 1.1510, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 198, Loss: 1.1396, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 199, Loss: 1.1518, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 200, Loss: 1.1516, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 001, Loss: 1.7892, Val Acc: 0.2222, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 002, Loss: 1.7905, Val Acc: 0.1778, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 003, Loss: 1.7794, Val Acc: 0.1556, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 004, Loss: 1.7739, Val Acc: 0.1778, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 005, Loss: 1.7647, Val Acc: 0.2222, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 006, Loss: 1.7629, Val Acc: 0.2444, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 007, Loss: 1.7601, Val Acc: 0.2000, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 008, Loss: 1.7541, Val Acc: 0.2000, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 009, Loss: 1.7504, Val Acc: 0.2000, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 010, Loss: 1.7268, Val Acc: 0.2222, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 011, Loss: 1.7361, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 012, Loss: 1.7169, Val Acc: 0.2000, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 013, Loss: 1.7159, Val Acc: 0.1889, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 014, Loss: 1.7115, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 015, Loss: 1.6994, Val Acc: 0.2222, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 016, Loss: 1.6931, Val Acc: 0.2667, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 017, Loss: 1.6934, Val Acc: 0.2667, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 018, Loss: 1.6854, Val Acc: 0.2444, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 019, Loss: 1.6760, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 020, Loss: 1.6938, Val Acc: 0.2333, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 021, Loss: 1.6779, Val Acc: 0.2667, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 022, Loss: 1.6809, Val Acc: 0.2889, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 023, Loss: 1.6725, Val Acc: 0.2556, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 024, Loss: 1.6732, Val Acc: 0.1778, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 025, Loss: 1.6691, Val Acc: 0.2333, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 026, Loss: 1.6587, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 027, Loss: 1.6650, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 028, Loss: 1.6628, Val Acc: 0.2556, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 029, Loss: 1.6559, Val Acc: 0.1889, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 030, Loss: 1.6602, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 031, Loss: 1.6555, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 032, Loss: 1.6721, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 033, Loss: 1.6512, Val Acc: 0.2111, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 034, Loss: 1.6573, Val Acc: 0.2000, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 035, Loss: 1.6456, Val Acc: 0.2556, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 036, Loss: 1.6458, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 037, Loss: 1.6362, Val Acc: 0.2444, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 038, Loss: 1.6260, Val Acc: 0.2222, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 039, Loss: 1.6286, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 040, Loss: 1.6221, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 041, Loss: 1.6255, Val Acc: 0.2556, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 042, Loss: 1.6202, Val Acc: 0.2333, Test Acc: 0.2111\n",
            "Seed: 45, Epoch: 043, Loss: 1.6144, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 044, Loss: 1.6161, Val Acc: 0.2444, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 045, Loss: 1.6171, Val Acc: 0.2000, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 046, Loss: 1.6080, Val Acc: 0.2000, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 047, Loss: 1.6121, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 048, Loss: 1.6061, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 049, Loss: 1.6007, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 050, Loss: 1.5949, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 051, Loss: 1.6065, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 052, Loss: 1.6023, Val Acc: 0.2111, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 053, Loss: 1.6021, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 054, Loss: 1.5832, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 055, Loss: 1.5736, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 056, Loss: 1.5753, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 057, Loss: 1.5690, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 058, Loss: 1.5873, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 059, Loss: 1.5853, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 060, Loss: 1.5866, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 061, Loss: 1.5786, Val Acc: 0.2778, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 062, Loss: 1.5982, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 063, Loss: 1.5878, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 064, Loss: 1.5579, Val Acc: 0.3000, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 065, Loss: 1.5575, Val Acc: 0.3111, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 066, Loss: 1.5521, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 067, Loss: 1.5795, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 068, Loss: 1.5936, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 069, Loss: 1.6187, Val Acc: 0.2667, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 070, Loss: 1.5783, Val Acc: 0.2000, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 071, Loss: 1.5855, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 072, Loss: 1.5466, Val Acc: 0.3000, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 073, Loss: 1.5516, Val Acc: 0.3111, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 074, Loss: 1.5469, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 075, Loss: 1.5236, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 076, Loss: 1.5185, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 077, Loss: 1.5095, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 078, Loss: 1.5183, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 079, Loss: 1.5576, Val Acc: 0.1667, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 080, Loss: 1.5275, Val Acc: 0.2111, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 081, Loss: 1.5512, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 082, Loss: 1.5117, Val Acc: 0.2444, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 083, Loss: 1.5487, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 084, Loss: 1.5077, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 085, Loss: 1.5417, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 086, Loss: 1.5032, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 087, Loss: 1.5290, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 088, Loss: 1.4858, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 089, Loss: 1.4954, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 090, Loss: 1.5303, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 091, Loss: 1.4884, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 092, Loss: 1.4979, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 093, Loss: 1.4817, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 094, Loss: 1.4857, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 095, Loss: 1.4820, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 096, Loss: 1.4519, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 097, Loss: 1.4583, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 098, Loss: 1.4620, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 099, Loss: 1.4743, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 100, Loss: 1.4740, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 101, Loss: 1.4605, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 102, Loss: 1.4501, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 103, Loss: 1.4430, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 104, Loss: 1.4381, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 105, Loss: 1.4371, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 106, Loss: 1.4412, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 107, Loss: 1.4233, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 108, Loss: 1.4305, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 109, Loss: 1.4207, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 110, Loss: 1.4097, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 111, Loss: 1.4424, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 112, Loss: 1.4151, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 113, Loss: 1.4320, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 114, Loss: 1.4216, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 115, Loss: 1.4130, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 116, Loss: 1.4283, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 117, Loss: 1.4187, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 118, Loss: 1.4319, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 119, Loss: 1.4392, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 120, Loss: 1.4055, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 121, Loss: 1.4106, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 122, Loss: 1.3823, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 123, Loss: 1.4062, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 124, Loss: 1.4126, Val Acc: 0.3222, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 125, Loss: 1.3775, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 126, Loss: 1.3855, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 127, Loss: 1.3719, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 128, Loss: 1.3860, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 129, Loss: 1.3734, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 130, Loss: 1.3658, Val Acc: 0.2000, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 131, Loss: 1.3736, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 132, Loss: 1.3556, Val Acc: 0.3111, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 133, Loss: 1.3815, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 134, Loss: 1.3835, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 135, Loss: 1.3907, Val Acc: 0.3111, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 136, Loss: 1.3700, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 137, Loss: 1.3638, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 138, Loss: 1.3830, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 139, Loss: 1.3516, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 140, Loss: 1.4075, Val Acc: 0.3222, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 141, Loss: 1.4088, Val Acc: 0.3333, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 142, Loss: 1.4193, Val Acc: 0.3000, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 143, Loss: 1.4117, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 144, Loss: 1.4307, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 145, Loss: 1.4247, Val Acc: 0.3000, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 146, Loss: 1.4239, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 147, Loss: 1.3944, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 148, Loss: 1.4092, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 149, Loss: 1.3928, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 150, Loss: 1.3830, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 151, Loss: 1.3911, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 152, Loss: 1.3757, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 153, Loss: 1.3872, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 154, Loss: 1.3851, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 155, Loss: 1.3930, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 156, Loss: 1.3760, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 157, Loss: 1.3806, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 158, Loss: 1.3568, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 159, Loss: 1.3382, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 160, Loss: 1.3605, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 161, Loss: 1.3383, Val Acc: 0.3333, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 162, Loss: 1.3474, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 163, Loss: 1.3420, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 164, Loss: 1.3315, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 165, Loss: 1.3442, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 166, Loss: 1.3325, Val Acc: 0.3444, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 167, Loss: 1.3496, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 168, Loss: 1.3259, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 169, Loss: 1.3341, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 170, Loss: 1.3456, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 171, Loss: 1.3212, Val Acc: 0.2556, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 172, Loss: 1.3176, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 173, Loss: 1.3150, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 174, Loss: 1.3164, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 175, Loss: 1.3370, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 176, Loss: 1.3245, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 177, Loss: 1.2899, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 178, Loss: 1.3114, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 179, Loss: 1.3253, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 180, Loss: 1.3070, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 181, Loss: 1.3004, Val Acc: 0.3444, Test Acc: 0.4556\n",
            "Seed: 45, Epoch: 182, Loss: 1.3073, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 183, Loss: 1.2905, Val Acc: 0.2889, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 184, Loss: 1.3117, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 185, Loss: 1.2776, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 186, Loss: 1.2913, Val Acc: 0.3000, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 187, Loss: 1.3313, Val Acc: 0.3333, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 188, Loss: 1.2829, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 189, Loss: 1.3020, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 190, Loss: 1.2776, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 191, Loss: 1.2801, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 192, Loss: 1.2565, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 193, Loss: 1.2659, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 194, Loss: 1.2520, Val Acc: 0.3000, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 195, Loss: 1.2681, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 196, Loss: 1.2587, Val Acc: 0.3222, Test Acc: 0.4444\n",
            "Seed: 45, Epoch: 197, Loss: 1.2701, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 198, Loss: 1.3531, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 199, Loss: 1.2802, Val Acc: 0.3778, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 200, Loss: 1.2752, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 001, Loss: 1.8082, Val Acc: 0.1111, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 002, Loss: 1.7898, Val Acc: 0.1667, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 003, Loss: 1.7856, Val Acc: 0.1556, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 004, Loss: 1.7842, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 46, Epoch: 005, Loss: 1.7823, Val Acc: 0.1667, Test Acc: 0.2000\n",
            "Seed: 46, Epoch: 006, Loss: 1.7749, Val Acc: 0.1333, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 007, Loss: 1.7736, Val Acc: 0.1556, Test Acc: 0.2000\n",
            "Seed: 46, Epoch: 008, Loss: 1.7701, Val Acc: 0.2000, Test Acc: 0.1889\n",
            "Seed: 46, Epoch: 009, Loss: 1.7595, Val Acc: 0.2000, Test Acc: 0.2111\n",
            "Seed: 46, Epoch: 010, Loss: 1.7613, Val Acc: 0.1778, Test Acc: 0.1889\n",
            "Seed: 46, Epoch: 011, Loss: 1.7590, Val Acc: 0.2111, Test Acc: 0.1778\n",
            "Seed: 46, Epoch: 012, Loss: 1.7524, Val Acc: 0.1889, Test Acc: 0.2111\n",
            "Seed: 46, Epoch: 013, Loss: 1.7493, Val Acc: 0.1889, Test Acc: 0.2111\n",
            "Seed: 46, Epoch: 014, Loss: 1.7433, Val Acc: 0.1889, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 015, Loss: 1.7376, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 016, Loss: 1.7344, Val Acc: 0.2000, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 017, Loss: 1.7346, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 018, Loss: 1.7286, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 019, Loss: 1.7252, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 020, Loss: 1.7187, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 021, Loss: 1.7443, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 022, Loss: 1.7081, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 023, Loss: 1.7270, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 024, Loss: 1.7104, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 025, Loss: 1.6974, Val Acc: 0.2778, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 026, Loss: 1.6985, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 027, Loss: 1.6864, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 028, Loss: 1.6859, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 029, Loss: 1.6866, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 030, Loss: 1.6783, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 031, Loss: 1.6845, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 032, Loss: 1.6903, Val Acc: 0.2111, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 033, Loss: 1.6722, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 034, Loss: 1.6655, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 035, Loss: 1.6744, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 036, Loss: 1.6658, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 037, Loss: 1.6495, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 038, Loss: 1.6568, Val Acc: 0.2222, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 039, Loss: 1.6503, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 040, Loss: 1.6494, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 041, Loss: 1.6420, Val Acc: 0.2111, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 042, Loss: 1.6290, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 043, Loss: 1.6145, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 044, Loss: 1.6320, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 045, Loss: 1.6155, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 046, Loss: 1.6121, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 047, Loss: 1.6184, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 048, Loss: 1.6168, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 049, Loss: 1.6076, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 050, Loss: 1.6118, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 051, Loss: 1.6036, Val Acc: 0.2889, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 052, Loss: 1.5995, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 053, Loss: 1.5969, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 054, Loss: 1.6014, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 055, Loss: 1.5819, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 056, Loss: 1.6049, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 057, Loss: 1.5962, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 058, Loss: 1.5891, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 059, Loss: 1.5785, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 060, Loss: 1.5852, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 061, Loss: 1.5733, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 062, Loss: 1.5675, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 063, Loss: 1.5642, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 064, Loss: 1.5500, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 065, Loss: 1.5763, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 066, Loss: 1.5490, Val Acc: 0.2556, Test Acc: 0.2222\n",
            "Seed: 46, Epoch: 067, Loss: 1.5486, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 068, Loss: 1.5355, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 069, Loss: 1.5277, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 070, Loss: 1.5190, Val Acc: 0.2222, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 071, Loss: 1.5177, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 072, Loss: 1.5101, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 073, Loss: 1.5089, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 074, Loss: 1.5021, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 075, Loss: 1.4981, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 076, Loss: 1.4849, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 077, Loss: 1.4965, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 078, Loss: 1.4672, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 079, Loss: 1.4978, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 080, Loss: 1.4826, Val Acc: 0.2000, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 081, Loss: 1.4788, Val Acc: 0.2000, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 082, Loss: 1.4709, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 083, Loss: 1.4624, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 084, Loss: 1.4705, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 085, Loss: 1.4417, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 086, Loss: 1.4591, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 087, Loss: 1.4656, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 088, Loss: 1.4476, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 089, Loss: 1.4398, Val Acc: 0.2000, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 090, Loss: 1.4380, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 091, Loss: 1.4517, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 092, Loss: 1.4543, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 093, Loss: 1.4288, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 094, Loss: 1.4402, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 095, Loss: 1.4498, Val Acc: 0.1889, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 096, Loss: 1.4473, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 097, Loss: 1.4423, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 098, Loss: 1.4343, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 099, Loss: 1.4190, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 100, Loss: 1.4201, Val Acc: 0.3000, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 101, Loss: 1.3990, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 102, Loss: 1.3766, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 103, Loss: 1.3839, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 104, Loss: 1.3798, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 105, Loss: 1.3758, Val Acc: 0.2333, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 106, Loss: 1.3754, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 107, Loss: 1.3741, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 108, Loss: 1.3662, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 109, Loss: 1.3574, Val Acc: 0.2111, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 110, Loss: 1.3748, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 111, Loss: 1.3536, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 112, Loss: 1.3413, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 113, Loss: 1.3123, Val Acc: 0.2222, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 114, Loss: 1.3214, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 115, Loss: 1.3168, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 116, Loss: 1.3321, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 117, Loss: 1.3168, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 118, Loss: 1.2866, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 119, Loss: 1.3130, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 120, Loss: 1.3465, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 121, Loss: 1.3084, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 122, Loss: 1.3296, Val Acc: 0.2333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 123, Loss: 1.2863, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 124, Loss: 1.2987, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 125, Loss: 1.2965, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 126, Loss: 1.2624, Val Acc: 0.2222, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 127, Loss: 1.2569, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 128, Loss: 1.2888, Val Acc: 0.2556, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 129, Loss: 1.2756, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 130, Loss: 1.2722, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 131, Loss: 1.2737, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 132, Loss: 1.2436, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 133, Loss: 1.2659, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 134, Loss: 1.3313, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 135, Loss: 1.2840, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 136, Loss: 1.3489, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 137, Loss: 1.2589, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 138, Loss: 1.3162, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 139, Loss: 1.4057, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 140, Loss: 1.3187, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 141, Loss: 1.2474, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 142, Loss: 1.2701, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 143, Loss: 1.2480, Val Acc: 0.2222, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 144, Loss: 1.2337, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 145, Loss: 1.2324, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 146, Loss: 1.1915, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 147, Loss: 1.1937, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 148, Loss: 1.1889, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 149, Loss: 1.1586, Val Acc: 0.2333, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 150, Loss: 1.1734, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 151, Loss: 1.1749, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 152, Loss: 1.1860, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 153, Loss: 1.1907, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 154, Loss: 1.1960, Val Acc: 0.2667, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 155, Loss: 1.1512, Val Acc: 0.2667, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 156, Loss: 1.1414, Val Acc: 0.2889, Test Acc: 0.4333\n",
            "Seed: 46, Epoch: 157, Loss: 1.1429, Val Acc: 0.3000, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 158, Loss: 1.1604, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 159, Loss: 1.1275, Val Acc: 0.2778, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 160, Loss: 1.1395, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 161, Loss: 1.1521, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 162, Loss: 1.1482, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 163, Loss: 1.1340, Val Acc: 0.3111, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 164, Loss: 1.1230, Val Acc: 0.3000, Test Acc: 0.4333\n",
            "Seed: 46, Epoch: 165, Loss: 1.1115, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 166, Loss: 1.1271, Val Acc: 0.3333, Test Acc: 0.4333\n",
            "Seed: 46, Epoch: 167, Loss: 1.1096, Val Acc: 0.3333, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 168, Loss: 1.1372, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 169, Loss: 1.1127, Val Acc: 0.2667, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 170, Loss: 1.1029, Val Acc: 0.3333, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 171, Loss: 1.1154, Val Acc: 0.3000, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 172, Loss: 1.0746, Val Acc: 0.2778, Test Acc: 0.4556\n",
            "Seed: 46, Epoch: 173, Loss: 1.0997, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 174, Loss: 1.1410, Val Acc: 0.3000, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 175, Loss: 1.0944, Val Acc: 0.2889, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 176, Loss: 1.1300, Val Acc: 0.3333, Test Acc: 0.4333\n",
            "Seed: 46, Epoch: 177, Loss: 1.1375, Val Acc: 0.3111, Test Acc: 0.4333\n",
            "Seed: 46, Epoch: 178, Loss: 1.0707, Val Acc: 0.2333, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 179, Loss: 1.0728, Val Acc: 0.3222, Test Acc: 0.4222\n",
            "Seed: 46, Epoch: 180, Loss: 1.0804, Val Acc: 0.3000, Test Acc: 0.4444\n",
            "Seed: 46, Epoch: 181, Loss: 1.0478, Val Acc: 0.2556, Test Acc: 0.4333\n",
            "Seed: 46, Epoch: 182, Loss: 1.0851, Val Acc: 0.2889, Test Acc: 0.4444\n",
            "Seed: 46, Epoch: 183, Loss: 1.1105, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 184, Loss: 1.2258, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 185, Loss: 1.3140, Val Acc: 0.2889, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 186, Loss: 1.2583, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 187, Loss: 1.2410, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 188, Loss: 1.2235, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 189, Loss: 1.2169, Val Acc: 0.2333, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 190, Loss: 1.1967, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 191, Loss: 1.1607, Val Acc: 0.2556, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 192, Loss: 1.1732, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 193, Loss: 1.1772, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 194, Loss: 1.1703, Val Acc: 0.1889, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 195, Loss: 1.1685, Val Acc: 0.2000, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 196, Loss: 1.1677, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 197, Loss: 1.1668, Val Acc: 0.2333, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 198, Loss: 1.1653, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 199, Loss: 1.1569, Val Acc: 0.2222, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 200, Loss: 1.1614, Val Acc: 0.2333, Test Acc: 0.4000\n",
            "Average Time: 17.01 seconds\n",
            "Var Time: 0.53 seconds\n",
            "Average Memory: 34.00 MB\n",
            "Average Best Val Acc: 0.3333\n",
            "Std Best Test Acc: 0.0419\n",
            "Average Test Acc: 0.3844\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, EdgePooling\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "from torch_geometric.nn import BatchNorm\n",
        "\n",
        "class HierarchicalGCN_GSA(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes):\n",
        "        super(HierarchicalGCN_GSA, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, out_channels)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.lin1 = torch.nn.Linear(out_channels, 32)\n",
        "        self.lin2 = torch.nn.Linear(32, num_classes)\n",
        "\n",
        "        self.pool1 = GSAPool(64, pooling_ratio=0.5, alpha = 0.6, cus_drop_ratio = 0)\n",
        "        self.pool2 = GSAPool(64, pooling_ratio=0.5, alpha = 0.6, cus_drop_ratio = 0)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        # First GCN and pooling layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn1(x)\n",
        "        x, edge_index, _, batch, perm_1, x_ae1 = self.pool1(x, edge_index, None, batch)\n",
        "\n",
        "        # Second GCN and pooling layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn2(x)\n",
        "        x, edge_index, _, batch, perm_1, x_ae1 = self.pool1(x, edge_index, None, batch)\n",
        "\n",
        "        # Third GCN layer\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn3(x)\n",
        "\n",
        "        # Mean pooling over the nodes\n",
        "        x, mask = to_dense_batch(x, batch)\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.lin1(x).relu()\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "num_classes = dataset_sparse.num_classes\n",
        "in_channels = dataset_sparse.num_features\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HierarchicalGCN_GSA(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == data.y).sum().item()\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seeds = [42, 43, 44, 45, 46]\n",
        "times = []\n",
        "memories = []\n",
        "best_val_accs = []\n",
        "best_test_accs = []\n",
        "\n",
        "early_stop_patience = 150\n",
        "tolerance = 0.0001\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    model = HierarchicalGCN_GSA(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        val_acc = test(valid_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        if val_acc > best_val_acc + tolerance:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "        if epochs_no_improve >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
        "\n",
        "    times.append(total_time)\n",
        "    memories.append(memory_allocated)\n",
        "    best_val_accs.append(best_val_acc)\n",
        "    best_test_accs.append(best_test_acc)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
        "print(f'Var Time: {np.var(times):.2f} seconds')\n",
        "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
        "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
        "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
        "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IpO_-mBYVLp"
      },
      "source": [
        "## HGPSLPooling with HierarchicalGCN (2019)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZR2Q2FUYVaV",
        "outputId": "12fe81a8-a4e3-49b2-aa43-2216cffba837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.5344, 0.0000, 0.0000, 0.4656, 0.0613, 0.0000, 0.0000, 0.0000, 0.5640,\n",
            "        0.3748])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Parameter\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.utils import softmax, dense_to_sparse, add_remaining_self_loops\n",
        "from torch_scatter import scatter_add\n",
        "from torch_sparse import spspmm, coalesce\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "from torch_scatter import scatter_add, scatter_max\n",
        "\n",
        "def topk(x, ratio, batch, min_score=None, tol=1e-7):\n",
        "\n",
        "    if min_score is not None:\n",
        "        # Make sure that we do not drop all nodes in a graph.\n",
        "        scores_max = scatter_max(x, batch)[0][batch] - tol\n",
        "        scores_min = scores_max.clamp(max=min_score)\n",
        "\n",
        "        perm = torch.nonzero(x > scores_min).view(-1)\n",
        "    else:\n",
        "        num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)\n",
        "        batch_size, max_num_nodes = num_nodes.size(0), num_nodes.max().item()\n",
        "\n",
        "        cum_num_nodes = torch.cat(\n",
        "            [num_nodes.new_zeros(1),\n",
        "            num_nodes.cumsum(dim=0)[:-1]], dim=0)\n",
        "\n",
        "        index = torch.arange(batch.size(0), dtype=torch.long, device=x.device)\n",
        "        index = (index - cum_num_nodes[batch]) + (batch * max_num_nodes)\n",
        "\n",
        "        dense_x = x.new_full((batch_size * max_num_nodes, ), -2)\n",
        "        dense_x[index] = x\n",
        "        dense_x = dense_x.view(batch_size, max_num_nodes)\n",
        "\n",
        "        _, perm = dense_x.sort(dim=-1, descending=True)\n",
        "\n",
        "        perm = perm + cum_num_nodes.view(-1, 1)\n",
        "        perm = perm.view(-1)\n",
        "\n",
        "        k = (ratio * num_nodes.to(torch.float)).ceil().to(torch.long)\n",
        "        mask = [\n",
        "            torch.arange(k[i], dtype=torch.long, device=x.device) +\n",
        "            i * max_num_nodes for i in range(batch_size)\n",
        "        ]\n",
        "        mask = torch.cat(mask, dim=0)\n",
        "\n",
        "        perm = perm[mask]\n",
        "\n",
        "    return perm\n",
        "\n",
        "def filter_adj(edge_index, edge_weight, perm, num_nodes=None):\n",
        "\n",
        "        num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
        "\n",
        "        mask = perm.new_full((num_nodes, ), -1)\n",
        "        i = torch.arange(perm.size(0), dtype=torch.long, device=perm.device)\n",
        "        mask[perm] = i\n",
        "\n",
        "        row, col = edge_index\n",
        "        row, col = mask[row], mask[col]\n",
        "        mask = (row >= 0) & (col >= 0)\n",
        "        row, col = row[mask], col[mask]\n",
        "\n",
        "        if edge_weight is not None:\n",
        "            edge_weight = edge_weight[mask]\n",
        "\n",
        "        return torch.stack([row, col], dim=0), edge_weight\n",
        "\n",
        "def scatter_sort(x, batch, fill_value=-1e16):\n",
        "    num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)\n",
        "    batch_size, max_num_nodes = num_nodes.size(0), num_nodes.max().item()\n",
        "\n",
        "    cum_num_nodes = torch.cat([num_nodes.new_zeros(1), num_nodes.cumsum(dim=0)[:-1]], dim=0)\n",
        "\n",
        "    index = torch.arange(batch.size(0), dtype=torch.long, device=x.device)\n",
        "    index = (index - cum_num_nodes[batch]) + (batch * max_num_nodes)\n",
        "\n",
        "    dense_x = x.new_full((batch_size * max_num_nodes,), fill_value)\n",
        "    dense_x[index] = x\n",
        "    dense_x = dense_x.view(batch_size, max_num_nodes)\n",
        "\n",
        "    sorted_x, _ = dense_x.sort(dim=-1, descending=True)\n",
        "    cumsum_sorted_x = sorted_x.cumsum(dim=-1)\n",
        "    cumsum_sorted_x = cumsum_sorted_x.view(-1)\n",
        "\n",
        "    sorted_x = sorted_x.view(-1)\n",
        "    filled_index = sorted_x != fill_value\n",
        "\n",
        "    sorted_x = sorted_x[filled_index]\n",
        "    cumsum_sorted_x = cumsum_sorted_x[filled_index]\n",
        "\n",
        "    return sorted_x, cumsum_sorted_x\n",
        "\n",
        "\n",
        "def _make_ix_like(batch):\n",
        "    num_nodes = scatter_add(batch.new_ones(batch.size(0)), batch, dim=0)\n",
        "    idx = [torch.arange(1, i + 1, dtype=torch.long, device=batch.device) for i in num_nodes]\n",
        "    idx = torch.cat(idx, dim=0)\n",
        "\n",
        "    return idx\n",
        "\n",
        "\n",
        "def _threshold_and_support(x, batch):\n",
        "    \"\"\"Sparsemax building block: compute the threshold\n",
        "    Args:\n",
        "        x: input tensor to apply the sparsemax\n",
        "        batch: group indicators\n",
        "    Returns:\n",
        "        the threshold value\n",
        "    \"\"\"\n",
        "    num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)\n",
        "    cum_num_nodes = torch.cat([num_nodes.new_zeros(1), num_nodes.cumsum(dim=0)[:-1]], dim=0)\n",
        "\n",
        "    sorted_input, input_cumsum = scatter_sort(x, batch)\n",
        "    input_cumsum = input_cumsum - 1.0\n",
        "    rhos = _make_ix_like(batch).to(x.dtype)\n",
        "    support = rhos * sorted_input > input_cumsum\n",
        "\n",
        "    support_size = scatter_add(support.to(batch.dtype), batch)\n",
        "    # mask invalid index, for example, if batch is not start from 0 or not continuous, it may result in negative index\n",
        "    idx = support_size + cum_num_nodes - 1\n",
        "    mask = idx < 0\n",
        "    idx[mask] = 0\n",
        "    tau = input_cumsum.gather(0, idx)\n",
        "    tau /= support_size.to(x.dtype)\n",
        "\n",
        "    return tau, support_size\n",
        "\n",
        "\n",
        "class SparsemaxFunction(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, batch):\n",
        "        \"\"\"sparsemax: normalizing sparse transform\n",
        "        Parameters:\n",
        "            ctx: context object\n",
        "            x (Tensor): shape (N, )\n",
        "            batch: group indicator\n",
        "        Returns:\n",
        "            output (Tensor): same shape as input\n",
        "        \"\"\"\n",
        "        max_val, _ = scatter_max(x, batch)\n",
        "        x -= max_val[batch]\n",
        "        tau, supp_size = _threshold_and_support(x, batch)\n",
        "        output = torch.clamp(x - tau[batch], min=0)\n",
        "        ctx.save_for_backward(supp_size, output, batch)\n",
        "\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        supp_size, output, batch = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[output == 0] = 0\n",
        "\n",
        "        v_hat = scatter_add(grad_input, batch) / supp_size.to(output.dtype)\n",
        "        grad_input = torch.where(output != 0, grad_input - v_hat[batch], grad_input)\n",
        "\n",
        "        return grad_input, None\n",
        "\n",
        "\n",
        "sparsemax = SparsemaxFunction.apply\n",
        "\n",
        "\n",
        "class Sparsemax(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Sparsemax, self).__init__()\n",
        "\n",
        "    def forward(self, x, batch):\n",
        "        return sparsemax(x, batch)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sparse_attention = Sparsemax()\n",
        "    input_x = torch.tensor([1.7301, 0.6792, -1.0565, 1.6614, -0.3196, -0.7790, -0.3877, -0.4943, 0.1831, -0.0061])\n",
        "    input_batch = torch.cat([torch.zeros(4, dtype=torch.long), torch.ones(6, dtype=torch.long)], dim=0)\n",
        "    res = sparse_attention(input_x, input_batch)\n",
        "    print(res)\n",
        "\n",
        "class TwoHopNeighborhood(object):\n",
        "    def __call__(self, data):\n",
        "        edge_index, edge_attr = data.edge_index, data.edge_attr\n",
        "        n = data.num_nodes\n",
        "\n",
        "        fill = 1e16\n",
        "        value = edge_index.new_full((edge_index.size(1),), fill, dtype=torch.float)\n",
        "\n",
        "        index, value = spspmm(edge_index, value, edge_index, value, n, n, n, True)\n",
        "\n",
        "        edge_index = torch.cat([edge_index, index], dim=1)\n",
        "        if edge_attr is None:\n",
        "            data.edge_index, _ = coalesce(edge_index, None, n, n)\n",
        "        else:\n",
        "            value = value.view(-1, *[1 for _ in range(edge_attr.dim() - 1)])\n",
        "            value = value.expand(-1, *list(edge_attr.size())[1:])\n",
        "            edge_attr = torch.cat([edge_attr, value], dim=0)\n",
        "            data.edge_index, edge_attr = coalesce(edge_index, edge_attr, n, n, op='min', fill_value=fill)\n",
        "            edge_attr[edge_attr >= fill] = 0\n",
        "            data.edge_attr = edge_attr\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}()'.format(self.__class__.__name__)\n",
        "\n",
        "\n",
        "class GCN(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, cached=False, bias=True, **kwargs):\n",
        "        super(GCN, self).__init__(aggr='add', **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.cached = cached\n",
        "        self.cached_result = None\n",
        "        self.cached_num_edges = None\n",
        "\n",
        "        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n",
        "        nn.init.xavier_uniform_(self.weight.data)\n",
        "\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(out_channels))\n",
        "            nn.init.zeros_(self.bias.data)\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.cached_result = None\n",
        "        self.cached_num_edges = None\n",
        "\n",
        "    @staticmethod\n",
        "    def norm(edge_index, num_nodes, edge_weight, dtype=None):\n",
        "        if edge_weight is None:\n",
        "            edge_weight = torch.ones((edge_index.size(1),), dtype=dtype, device=edge_index.device)\n",
        "\n",
        "        row, col = edge_index\n",
        "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "\n",
        "        return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        x = torch.matmul(x, self.weight)\n",
        "\n",
        "        if self.cached and self.cached_result is not None:\n",
        "            if edge_index.size(1) != self.cached_num_edges:\n",
        "                raise RuntimeError(\n",
        "                    'Cached {} number of edges, but found {}'.format(self.cached_num_edges, edge_index.size(1)))\n",
        "\n",
        "        if not self.cached or self.cached_result is None:\n",
        "            self.cached_num_edges = edge_index.size(1)\n",
        "            edge_index, norm = self.norm(edge_index, x.size(0), edge_weight, x.dtype)\n",
        "            self.cached_result = edge_index, norm\n",
        "\n",
        "        edge_index, norm = self.cached_result\n",
        "\n",
        "        return self.propagate(edge_index, x=x, norm=norm)\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        if self.bias is not None:\n",
        "            aggr_out = aggr_out + self.bias\n",
        "        return aggr_out\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels, self.out_channels)\n",
        "\n",
        "\n",
        "class NodeInformationScore(MessagePassing):\n",
        "    def __init__(self, improved=False, cached=False, **kwargs):\n",
        "        super(NodeInformationScore, self).__init__(aggr='add', **kwargs)\n",
        "\n",
        "        self.improved = improved\n",
        "        self.cached = cached\n",
        "        self.cached_result = None\n",
        "        self.cached_num_edges = None\n",
        "\n",
        "    @staticmethod\n",
        "    def norm(edge_index, num_nodes, edge_weight, dtype=None):\n",
        "        if edge_weight is None:\n",
        "            edge_weight = torch.ones((edge_index.size(1),), dtype=dtype, device=edge_index.device)\n",
        "\n",
        "        row, col = edge_index\n",
        "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "\n",
        "        edge_index, edge_weight = add_remaining_self_loops(edge_index, edge_weight, 0, num_nodes)\n",
        "\n",
        "        row, col = edge_index\n",
        "        expand_deg = torch.zeros((edge_weight.size(0),), dtype=dtype, device=edge_index.device)\n",
        "        expand_deg[-num_nodes:] = torch.ones((num_nodes,), dtype=dtype, device=edge_index.device)\n",
        "\n",
        "        return edge_index, expand_deg - deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        if self.cached and self.cached_result is not None:\n",
        "            if edge_index.size(1) != self.cached_num_edges:\n",
        "                raise RuntimeError(\n",
        "                    'Cached {} number of edges, but found {}'.format(self.cached_num_edges, edge_index.size(1)))\n",
        "\n",
        "        if not self.cached or self.cached_result is None:\n",
        "            self.cached_num_edges = edge_index.size(1)\n",
        "            edge_index, norm = self.norm(edge_index, x.size(0), edge_weight, x.dtype)\n",
        "            self.cached_result = edge_index, norm\n",
        "\n",
        "        edge_index, norm = self.cached_result\n",
        "\n",
        "        return self.propagate(edge_index, x=x, norm=norm)\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        return aggr_out\n",
        "\n",
        "\n",
        "class HGPSLPool(torch.nn.Module):\n",
        "    def __init__(self, in_channels, ratio=0.5, sample=False, sparse=False, sl=True, lamb=1.0, negative_slop=0.2):\n",
        "        super(HGPSLPool, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.ratio = ratio\n",
        "        self.sample = sample\n",
        "        self.sparse = sparse\n",
        "        self.sl = sl\n",
        "        self.negative_slop = negative_slop\n",
        "        self.lamb = lamb\n",
        "\n",
        "        self.att = Parameter(torch.Tensor(1, self.in_channels * 2))\n",
        "        nn.init.xavier_uniform_(self.att.data)\n",
        "        self.sparse_attention = Sparsemax()\n",
        "        self.neighbor_augment = TwoHopNeighborhood()\n",
        "        self.calc_information_score = NodeInformationScore()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch):\n",
        "        if batch is None:\n",
        "            batch = edge_index.new_zeros(x.size(0))\n",
        "\n",
        "        x_information_score = self.calc_information_score(x, edge_index, edge_attr)\n",
        "        score = torch.sum(torch.abs(x_information_score), dim=1)\n",
        "\n",
        "        # Graph Pooling\n",
        "        original_x = x\n",
        "        perm = topk(score, self.ratio, batch)\n",
        "        x = x[perm]\n",
        "        batch = batch[perm]\n",
        "        induced_edge_index, induced_edge_attr = filter_adj(edge_index, edge_attr, perm, num_nodes=score.size(0))\n",
        "\n",
        "        # Discard structure learning layer, directly return\n",
        "        if self.sl is False:\n",
        "            return x, induced_edge_index, induced_edge_attr, batch\n",
        "\n",
        "        # Structure Learning\n",
        "        if self.sample:\n",
        "            # A fast mode for large graphs.\n",
        "            # In large graphs, learning the possible edge weights between each pair of nodes is time consuming.\n",
        "            # To accelerate this process, we sample it's K-Hop neighbors for each node and then learn the\n",
        "            # edge weights between them.\n",
        "            k_hop = 3\n",
        "            if edge_attr is None:\n",
        "                edge_attr = torch.ones((edge_index.size(1),), dtype=torch.float, device=edge_index.device)\n",
        "\n",
        "            hop_data = Data(x=original_x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "            for _ in range(k_hop - 1):\n",
        "                hop_data = self.neighbor_augment(hop_data)\n",
        "            hop_edge_index = hop_data.edge_index\n",
        "            hop_edge_attr = hop_data.edge_attr\n",
        "            new_edge_index, new_edge_attr = filter_adj(hop_edge_index, hop_edge_attr, perm, num_nodes=score.size(0))\n",
        "\n",
        "            new_edge_index, new_edge_attr = add_remaining_self_loops(new_edge_index, new_edge_attr, 0, x.size(0))\n",
        "            row, col = new_edge_index\n",
        "            weights = (torch.cat([x[row], x[col]], dim=1) * self.att).sum(dim=-1)\n",
        "            weights = F.leaky_relu(weights, self.negative_slop) + new_edge_attr * self.lamb\n",
        "            adj = torch.zeros((x.size(0), x.size(0)), dtype=torch.float, device=x.device)\n",
        "            adj[row, col] = weights\n",
        "            new_edge_index, weights = dense_to_sparse(adj)\n",
        "            row, col = new_edge_index\n",
        "            if self.sparse:\n",
        "                new_edge_attr = self.sparse_attention(weights, row)\n",
        "            else:\n",
        "                new_edge_attr = softmax(weights, row, x.size(0))\n",
        "            # filter out zero weight edges\n",
        "            adj[row, col] = new_edge_attr\n",
        "            new_edge_index, new_edge_attr = dense_to_sparse(adj)\n",
        "            # release gpu memory\n",
        "            del adj\n",
        "            torch.cuda.empty_cache()\n",
        "        else:\n",
        "            # Learning the possible edge weights between each pair of nodes in the pooled subgraph, relative slower.\n",
        "            if edge_attr is None:\n",
        "                induced_edge_attr = torch.ones((induced_edge_index.size(1),), dtype=x.dtype,\n",
        "                                               device=induced_edge_index.device)\n",
        "            num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)\n",
        "            shift_cum_num_nodes = torch.cat([num_nodes.new_zeros(1), num_nodes.cumsum(dim=0)[:-1]], dim=0)\n",
        "            cum_num_nodes = num_nodes.cumsum(dim=0)\n",
        "            adj = torch.zeros((x.size(0), x.size(0)), dtype=torch.float, device=x.device)\n",
        "            # Construct batch fully connected graph in block diagonal matirx format\n",
        "            for idx_i, idx_j in zip(shift_cum_num_nodes, cum_num_nodes):\n",
        "                adj[idx_i:idx_j, idx_i:idx_j] = 1.0\n",
        "            new_edge_index, _ = dense_to_sparse(adj)\n",
        "            row, col = new_edge_index\n",
        "\n",
        "            weights = (torch.cat([x[row], x[col]], dim=1) * self.att).sum(dim=-1)\n",
        "            weights = F.leaky_relu(weights, self.negative_slop)\n",
        "            adj[row, col] = weights\n",
        "            induced_row, induced_col = induced_edge_index\n",
        "\n",
        "            adj[induced_row, induced_col] += induced_edge_attr * self.lamb\n",
        "            weights = adj[row, col]\n",
        "            if self.sparse:\n",
        "                new_edge_attr = self.sparse_attention(weights, row)\n",
        "            else:\n",
        "                new_edge_attr = softmax(weights, row, num_nodes=x.size(0))\n",
        "            # filter out zero weight edges\n",
        "            adj[row, col] = new_edge_attr\n",
        "            new_edge_index, new_edge_attr = dense_to_sparse(adj)\n",
        "            # release gpu memory\n",
        "            del adj\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        return x, new_edge_index, new_edge_attr, batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVoq5MDZZteJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 001, Loss: 1.8156, Val Acc: 0.2000, Test Acc: 0.1556\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 002, Loss: 1.7885, Val Acc: 0.2222, Test Acc: 0.1778\n",
            "Seed: 42, Epoch: 003, Loss: 1.7791, Val Acc: 0.1222, Test Acc: 0.1778\n",
            "Seed: 42, Epoch: 004, Loss: 1.7760, Val Acc: 0.1889, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 005, Loss: 1.7683, Val Acc: 0.1778, Test Acc: 0.2111\n",
            "Seed: 42, Epoch: 006, Loss: 1.7603, Val Acc: 0.1889, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 007, Loss: 1.7573, Val Acc: 0.2222, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 008, Loss: 1.7505, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 009, Loss: 1.7390, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 010, Loss: 1.7352, Val Acc: 0.1889, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 011, Loss: 1.7221, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 012, Loss: 1.7154, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 013, Loss: 1.7121, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 014, Loss: 1.7018, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 015, Loss: 1.6920, Val Acc: 0.2111, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 016, Loss: 1.6870, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 017, Loss: 1.6862, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 018, Loss: 1.6834, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 019, Loss: 1.6749, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 42, Epoch: 020, Loss: 1.6750, Val Acc: 0.2778, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 021, Loss: 1.6638, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 022, Loss: 1.6570, Val Acc: 0.2111, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 023, Loss: 1.6547, Val Acc: 0.2111, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 024, Loss: 1.6422, Val Acc: 0.3111, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 025, Loss: 1.6449, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 026, Loss: 1.6362, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 027, Loss: 1.6410, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 028, Loss: 1.6304, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 029, Loss: 1.6143, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 030, Loss: 1.6165, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 031, Loss: 1.6196, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 032, Loss: 1.6062, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 033, Loss: 1.6082, Val Acc: 0.2111, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 034, Loss: 1.6067, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 035, Loss: 1.5896, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 036, Loss: 1.6017, Val Acc: 0.3111, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 037, Loss: 1.5930, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 038, Loss: 1.5850, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 039, Loss: 1.5758, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 040, Loss: 1.5785, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 041, Loss: 1.5650, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 042, Loss: 1.5763, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 42, Epoch: 043, Loss: 1.5733, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 044, Loss: 1.5563, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 42, Epoch: 045, Loss: 1.5736, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 046, Loss: 1.5741, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 047, Loss: 1.5587, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 048, Loss: 1.5616, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 049, Loss: 1.5385, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 050, Loss: 1.5474, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 051, Loss: 1.5253, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 052, Loss: 1.5227, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 053, Loss: 1.5351, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 054, Loss: 1.5165, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 055, Loss: 1.5303, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 056, Loss: 1.5107, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 057, Loss: 1.5309, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 058, Loss: 1.5187, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 059, Loss: 1.5110, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 060, Loss: 1.5242, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 061, Loss: 1.5043, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 42, Epoch: 062, Loss: 1.5241, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 063, Loss: 1.4817, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 064, Loss: 1.5126, Val Acc: 0.2444, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 065, Loss: 1.4681, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 42, Epoch: 066, Loss: 1.4910, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 067, Loss: 1.4801, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 068, Loss: 1.4808, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 069, Loss: 1.4478, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 42, Epoch: 070, Loss: 1.4668, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 071, Loss: 1.4651, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 072, Loss: 1.4373, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 073, Loss: 1.4393, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 074, Loss: 1.4159, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 075, Loss: 1.4256, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 076, Loss: 1.4724, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 077, Loss: 1.4243, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 078, Loss: 1.4676, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 079, Loss: 1.4086, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 080, Loss: 1.4535, Val Acc: 0.3444, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 081, Loss: 1.4205, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 082, Loss: 1.4305, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 083, Loss: 1.4042, Val Acc: 0.3556, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 084, Loss: 1.4231, Val Acc: 0.3333, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 085, Loss: 1.4003, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 086, Loss: 1.4054, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 087, Loss: 1.3945, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 088, Loss: 1.3965, Val Acc: 0.3333, Test Acc: 0.3111\n",
            "Seed: 42, Epoch: 089, Loss: 1.3942, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 090, Loss: 1.3692, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 091, Loss: 1.3619, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 092, Loss: 1.3868, Val Acc: 0.3333, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 093, Loss: 1.3742, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 094, Loss: 1.3504, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 095, Loss: 1.3604, Val Acc: 0.3333, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 096, Loss: 1.3483, Val Acc: 0.3556, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 097, Loss: 1.3423, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 098, Loss: 1.3494, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 099, Loss: 1.3373, Val Acc: 0.3444, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 100, Loss: 1.3288, Val Acc: 0.2778, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 101, Loss: 1.3391, Val Acc: 0.3222, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 102, Loss: 1.3176, Val Acc: 0.3667, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 103, Loss: 1.3097, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 104, Loss: 1.3022, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 105, Loss: 1.3233, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 106, Loss: 1.3076, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 107, Loss: 1.3093, Val Acc: 0.3444, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 108, Loss: 1.2963, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 109, Loss: 1.2936, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 110, Loss: 1.3078, Val Acc: 0.3444, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 111, Loss: 1.2851, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 112, Loss: 1.3015, Val Acc: 0.3333, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 113, Loss: 1.3160, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 114, Loss: 1.4255, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 115, Loss: 1.4016, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 116, Loss: 1.3421, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 117, Loss: 1.3025, Val Acc: 0.2667, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 118, Loss: 1.3534, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 119, Loss: 1.3031, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 120, Loss: 1.3097, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 121, Loss: 1.2408, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 122, Loss: 1.3283, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 123, Loss: 1.2725, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 124, Loss: 1.2885, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 125, Loss: 1.2659, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 126, Loss: 1.2647, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 127, Loss: 1.2819, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 128, Loss: 1.2348, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 129, Loss: 1.2450, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 130, Loss: 1.2168, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 131, Loss: 1.2304, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 132, Loss: 1.2250, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 133, Loss: 1.2181, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 134, Loss: 1.2060, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 135, Loss: 1.1830, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 136, Loss: 1.1909, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 137, Loss: 1.1945, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 138, Loss: 1.1972, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 139, Loss: 1.1796, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 140, Loss: 1.1799, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 141, Loss: 1.1651, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 142, Loss: 1.1752, Val Acc: 0.3111, Test Acc: 0.2889\n",
            "Seed: 42, Epoch: 143, Loss: 1.2823, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 42, Epoch: 144, Loss: 1.3215, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 145, Loss: 1.3067, Val Acc: 0.3778, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 146, Loss: 1.1954, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 42, Epoch: 147, Loss: 1.2881, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 42, Epoch: 148, Loss: 1.2118, Val Acc: 0.2778, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 149, Loss: 1.2529, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 150, Loss: 1.1955, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 151, Loss: 1.2030, Val Acc: 0.3333, Test Acc: 0.3556\n",
            "Seed: 42, Epoch: 152, Loss: 1.1842, Val Acc: 0.3222, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 153, Loss: 1.1613, Val Acc: 0.3111, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 154, Loss: 1.1876, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 42, Epoch: 155, Loss: 1.1378, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 156, Loss: 1.1594, Val Acc: 0.3556, Test Acc: 0.4444\n",
            "Seed: 42, Epoch: 157, Loss: 1.1374, Val Acc: 0.3444, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 158, Loss: 1.1253, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 159, Loss: 1.1267, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 160, Loss: 1.1327, Val Acc: 0.3444, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 161, Loss: 1.1296, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 162, Loss: 1.1101, Val Acc: 0.3444, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 163, Loss: 1.1195, Val Acc: 0.3556, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 164, Loss: 1.1116, Val Acc: 0.3444, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 165, Loss: 1.1099, Val Acc: 0.3556, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 166, Loss: 1.0557, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 167, Loss: 1.1179, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 168, Loss: 1.0901, Val Acc: 0.3556, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 169, Loss: 1.0956, Val Acc: 0.3333, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 170, Loss: 1.0943, Val Acc: 0.3222, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 171, Loss: 1.0618, Val Acc: 0.3556, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 172, Loss: 1.0796, Val Acc: 0.3333, Test Acc: 0.4444\n",
            "Seed: 42, Epoch: 173, Loss: 1.0757, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 174, Loss: 1.0793, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 175, Loss: 1.0908, Val Acc: 0.3333, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 176, Loss: 1.0778, Val Acc: 0.3444, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 177, Loss: 1.0725, Val Acc: 0.3556, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 178, Loss: 1.0681, Val Acc: 0.3444, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 179, Loss: 1.0530, Val Acc: 0.3556, Test Acc: 0.4444\n",
            "Seed: 42, Epoch: 180, Loss: 1.0657, Val Acc: 0.3333, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 181, Loss: 1.0372, Val Acc: 0.3778, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 182, Loss: 1.0749, Val Acc: 0.3556, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 183, Loss: 1.0441, Val Acc: 0.3778, Test Acc: 0.4444\n",
            "Seed: 42, Epoch: 184, Loss: 1.0378, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 185, Loss: 1.0610, Val Acc: 0.4000, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 186, Loss: 1.0971, Val Acc: 0.3556, Test Acc: 0.4000\n",
            "Seed: 42, Epoch: 187, Loss: 1.0639, Val Acc: 0.3444, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 188, Loss: 1.0564, Val Acc: 0.3667, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 189, Loss: 1.0645, Val Acc: 0.3556, Test Acc: 0.4556\n",
            "Seed: 42, Epoch: 190, Loss: 1.0408, Val Acc: 0.3778, Test Acc: 0.4556\n",
            "Seed: 42, Epoch: 191, Loss: 1.0379, Val Acc: 0.3444, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 192, Loss: 1.0556, Val Acc: 0.3444, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 193, Loss: 1.0188, Val Acc: 0.3333, Test Acc: 0.4444\n",
            "Seed: 42, Epoch: 194, Loss: 1.0315, Val Acc: 0.3778, Test Acc: 0.4111\n",
            "Seed: 42, Epoch: 195, Loss: 0.9836, Val Acc: 0.3556, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 196, Loss: 1.0030, Val Acc: 0.3556, Test Acc: 0.4333\n",
            "Seed: 42, Epoch: 197, Loss: 1.0061, Val Acc: 0.3556, Test Acc: 0.4222\n",
            "Seed: 42, Epoch: 198, Loss: 0.9901, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 42, Epoch: 199, Loss: 0.9987, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 42, Epoch: 200, Loss: 0.9800, Val Acc: 0.3667, Test Acc: 0.4444\n",
            "Seed: 43, Epoch: 001, Loss: 1.8155, Val Acc: 0.2556, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 002, Loss: 1.7913, Val Acc: 0.2111, Test Acc: 0.1667\n",
            "Seed: 43, Epoch: 003, Loss: 1.7821, Val Acc: 0.1889, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 004, Loss: 1.7760, Val Acc: 0.1889, Test Acc: 0.2000\n",
            "Seed: 43, Epoch: 005, Loss: 1.7709, Val Acc: 0.2111, Test Acc: 0.1889\n",
            "Seed: 43, Epoch: 006, Loss: 1.7672, Val Acc: 0.2111, Test Acc: 0.2111\n",
            "Seed: 43, Epoch: 007, Loss: 1.7678, Val Acc: 0.2111, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 008, Loss: 1.7605, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 009, Loss: 1.7570, Val Acc: 0.2222, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 010, Loss: 1.7533, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 011, Loss: 1.7487, Val Acc: 0.2444, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 012, Loss: 1.7397, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 43, Epoch: 013, Loss: 1.7322, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 014, Loss: 1.7269, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 015, Loss: 1.7223, Val Acc: 0.2778, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 016, Loss: 1.7166, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 017, Loss: 1.7090, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 018, Loss: 1.6962, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 019, Loss: 1.6985, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 020, Loss: 1.6913, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 021, Loss: 1.6842, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 022, Loss: 1.6821, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 023, Loss: 1.6762, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 024, Loss: 1.6716, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 025, Loss: 1.6694, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 026, Loss: 1.6546, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 027, Loss: 1.6565, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 028, Loss: 1.6449, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 029, Loss: 1.6367, Val Acc: 0.2444, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 030, Loss: 1.6403, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 031, Loss: 1.6391, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 032, Loss: 1.6222, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 033, Loss: 1.6222, Val Acc: 0.2778, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 034, Loss: 1.6189, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 035, Loss: 1.6240, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 036, Loss: 1.6230, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 037, Loss: 1.5963, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 038, Loss: 1.6154, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 039, Loss: 1.6109, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 040, Loss: 1.5845, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 041, Loss: 1.6077, Val Acc: 0.3111, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 042, Loss: 1.5891, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 043, Loss: 1.5914, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 044, Loss: 1.5727, Val Acc: 0.3222, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 045, Loss: 1.5818, Val Acc: 0.3000, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 046, Loss: 1.5692, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 047, Loss: 1.5588, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 048, Loss: 1.5484, Val Acc: 0.3111, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 049, Loss: 1.5454, Val Acc: 0.3111, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 050, Loss: 1.5479, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 051, Loss: 1.5291, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 052, Loss: 1.5244, Val Acc: 0.3222, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 053, Loss: 1.5302, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 054, Loss: 1.5317, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 055, Loss: 1.5251, Val Acc: 0.3000, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 056, Loss: 1.5182, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 057, Loss: 1.5069, Val Acc: 0.3111, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 058, Loss: 1.5196, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 43, Epoch: 059, Loss: 1.5016, Val Acc: 0.2444, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 060, Loss: 1.5040, Val Acc: 0.3000, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 061, Loss: 1.4994, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 062, Loss: 1.4878, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 43, Epoch: 063, Loss: 1.4788, Val Acc: 0.3111, Test Acc: 0.2222\n",
            "Seed: 43, Epoch: 064, Loss: 1.4883, Val Acc: 0.3222, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 065, Loss: 1.4665, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 066, Loss: 1.4967, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 067, Loss: 1.5141, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 068, Loss: 1.4921, Val Acc: 0.3444, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 069, Loss: 1.5070, Val Acc: 0.3556, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 070, Loss: 1.4974, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 071, Loss: 1.4762, Val Acc: 0.2444, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 072, Loss: 1.4993, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 073, Loss: 1.4686, Val Acc: 0.3333, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 074, Loss: 1.4611, Val Acc: 0.3333, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 075, Loss: 1.4596, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 076, Loss: 1.4229, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 077, Loss: 1.4387, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 078, Loss: 1.4497, Val Acc: 0.3556, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 079, Loss: 1.4607, Val Acc: 0.3111, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 080, Loss: 1.4218, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 081, Loss: 1.4243, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 082, Loss: 1.4278, Val Acc: 0.3333, Test Acc: 0.2556\n",
            "Seed: 43, Epoch: 083, Loss: 1.4114, Val Acc: 0.3667, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 084, Loss: 1.4172, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 085, Loss: 1.3987, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 086, Loss: 1.4065, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 087, Loss: 1.3869, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 088, Loss: 1.3814, Val Acc: 0.3333, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 089, Loss: 1.3767, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 090, Loss: 1.3706, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 091, Loss: 1.3935, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 092, Loss: 1.3696, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 093, Loss: 1.3911, Val Acc: 0.3111, Test Acc: 0.2667\n",
            "Seed: 43, Epoch: 094, Loss: 1.4056, Val Acc: 0.3222, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 095, Loss: 1.3638, Val Acc: 0.2889, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 096, Loss: 1.3337, Val Acc: 0.3111, Test Acc: 0.2778\n",
            "Seed: 43, Epoch: 097, Loss: 1.3405, Val Acc: 0.3444, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 098, Loss: 1.3423, Val Acc: 0.3556, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 099, Loss: 1.3488, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 100, Loss: 1.3220, Val Acc: 0.3444, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 101, Loss: 1.3034, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 102, Loss: 1.3001, Val Acc: 0.3333, Test Acc: 0.3111\n",
            "Seed: 43, Epoch: 103, Loss: 1.3122, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 104, Loss: 1.2860, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 105, Loss: 1.3006, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 106, Loss: 1.2916, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 107, Loss: 1.2788, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 43, Epoch: 108, Loss: 1.2749, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 109, Loss: 1.2788, Val Acc: 0.3000, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 110, Loss: 1.2795, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 111, Loss: 1.2614, Val Acc: 0.3222, Test Acc: 0.3000\n",
            "Seed: 43, Epoch: 112, Loss: 1.2647, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 113, Loss: 1.2680, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 114, Loss: 1.2353, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 115, Loss: 1.2509, Val Acc: 0.3556, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 116, Loss: 1.2467, Val Acc: 0.3333, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 117, Loss: 1.2417, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 118, Loss: 1.2321, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 119, Loss: 1.2208, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 120, Loss: 1.2255, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 121, Loss: 1.2092, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 122, Loss: 1.1988, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 123, Loss: 1.2236, Val Acc: 0.3556, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 124, Loss: 1.2172, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 125, Loss: 1.1944, Val Acc: 0.3333, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 126, Loss: 1.2051, Val Acc: 0.3444, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 127, Loss: 1.1773, Val Acc: 0.3333, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 128, Loss: 1.1781, Val Acc: 0.3778, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 129, Loss: 1.1742, Val Acc: 0.3556, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 130, Loss: 1.1779, Val Acc: 0.3444, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 131, Loss: 1.1546, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 132, Loss: 1.1935, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 133, Loss: 1.1754, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 134, Loss: 1.1670, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 135, Loss: 1.1660, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 136, Loss: 1.1561, Val Acc: 0.3556, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 137, Loss: 1.1700, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 138, Loss: 1.1552, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 139, Loss: 1.1672, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 140, Loss: 1.1525, Val Acc: 0.2889, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 141, Loss: 1.1539, Val Acc: 0.3556, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 142, Loss: 1.1468, Val Acc: 0.3667, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 143, Loss: 1.1355, Val Acc: 0.3556, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 144, Loss: 1.1236, Val Acc: 0.4000, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 145, Loss: 1.1643, Val Acc: 0.3444, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 146, Loss: 1.1298, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 147, Loss: 1.1012, Val Acc: 0.3333, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 148, Loss: 1.1130, Val Acc: 0.4000, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 149, Loss: 1.0958, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 150, Loss: 1.1070, Val Acc: 0.3444, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 151, Loss: 1.0758, Val Acc: 0.3889, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 152, Loss: 1.0634, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 153, Loss: 1.0943, Val Acc: 0.3667, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 154, Loss: 1.0720, Val Acc: 0.4000, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 155, Loss: 1.0621, Val Acc: 0.3333, Test Acc: 0.4444\n",
            "Seed: 43, Epoch: 156, Loss: 1.1068, Val Acc: 0.4000, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 157, Loss: 1.1281, Val Acc: 0.3667, Test Acc: 0.3444\n",
            "Seed: 43, Epoch: 158, Loss: 1.0820, Val Acc: 0.2778, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 159, Loss: 1.1304, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 160, Loss: 1.0372, Val Acc: 0.3667, Test Acc: 0.3333\n",
            "Seed: 43, Epoch: 161, Loss: 1.0952, Val Acc: 0.3667, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 162, Loss: 1.0765, Val Acc: 0.3778, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 163, Loss: 1.0623, Val Acc: 0.3778, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 164, Loss: 1.0622, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 43, Epoch: 165, Loss: 1.0610, Val Acc: 0.3556, Test Acc: 0.4444\n",
            "Seed: 43, Epoch: 166, Loss: 1.0320, Val Acc: 0.4000, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 167, Loss: 1.0283, Val Acc: 0.3667, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 168, Loss: 1.0281, Val Acc: 0.3667, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 169, Loss: 1.0071, Val Acc: 0.3444, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 170, Loss: 0.9941, Val Acc: 0.3889, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 171, Loss: 0.9999, Val Acc: 0.3667, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 172, Loss: 1.0192, Val Acc: 0.3778, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 173, Loss: 1.0048, Val Acc: 0.3889, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 174, Loss: 0.9750, Val Acc: 0.3889, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 175, Loss: 0.9960, Val Acc: 0.3889, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 176, Loss: 1.0123, Val Acc: 0.3778, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 177, Loss: 0.9968, Val Acc: 0.4000, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 178, Loss: 0.9818, Val Acc: 0.4000, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 179, Loss: 0.9388, Val Acc: 0.3778, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 180, Loss: 0.9511, Val Acc: 0.3778, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 181, Loss: 0.9446, Val Acc: 0.4111, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 182, Loss: 0.9321, Val Acc: 0.3333, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 183, Loss: 0.9507, Val Acc: 0.3889, Test Acc: 0.4222\n",
            "Seed: 43, Epoch: 184, Loss: 0.9522, Val Acc: 0.3889, Test Acc: 0.3667\n",
            "Seed: 43, Epoch: 185, Loss: 0.9419, Val Acc: 0.3778, Test Acc: 0.4667\n",
            "Seed: 43, Epoch: 186, Loss: 0.9551, Val Acc: 0.3889, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 187, Loss: 0.9135, Val Acc: 0.3889, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 188, Loss: 0.9407, Val Acc: 0.3444, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 189, Loss: 0.8974, Val Acc: 0.3556, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 190, Loss: 0.9303, Val Acc: 0.4000, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 191, Loss: 0.9170, Val Acc: 0.3667, Test Acc: 0.4000\n",
            "Seed: 43, Epoch: 192, Loss: 0.9235, Val Acc: 0.3889, Test Acc: 0.4444\n",
            "Seed: 43, Epoch: 193, Loss: 0.9035, Val Acc: 0.3667, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 194, Loss: 0.9068, Val Acc: 0.3889, Test Acc: 0.3889\n",
            "Seed: 43, Epoch: 195, Loss: 0.9116, Val Acc: 0.3556, Test Acc: 0.4333\n",
            "Seed: 43, Epoch: 196, Loss: 0.8922, Val Acc: 0.3778, Test Acc: 0.3778\n",
            "Seed: 43, Epoch: 197, Loss: 0.8791, Val Acc: 0.3667, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 198, Loss: 0.8824, Val Acc: 0.3889, Test Acc: 0.4111\n",
            "Seed: 43, Epoch: 199, Loss: 0.8957, Val Acc: 0.4222, Test Acc: 0.4444\n",
            "Seed: 43, Epoch: 200, Loss: 0.8623, Val Acc: 0.3778, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 001, Loss: 1.8011, Val Acc: 0.1444, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 002, Loss: 1.7916, Val Acc: 0.1111, Test Acc: 0.1333\n",
            "Seed: 44, Epoch: 003, Loss: 1.7790, Val Acc: 0.1222, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 004, Loss: 1.7747, Val Acc: 0.1556, Test Acc: 0.2000\n",
            "Seed: 44, Epoch: 005, Loss: 1.7709, Val Acc: 0.1444, Test Acc: 0.2000\n",
            "Seed: 44, Epoch: 006, Loss: 1.7687, Val Acc: 0.1778, Test Acc: 0.1444\n",
            "Seed: 44, Epoch: 007, Loss: 1.7642, Val Acc: 0.1778, Test Acc: 0.1667\n",
            "Seed: 44, Epoch: 008, Loss: 1.7583, Val Acc: 0.1778, Test Acc: 0.1778\n",
            "Seed: 44, Epoch: 009, Loss: 1.7527, Val Acc: 0.1778, Test Acc: 0.2111\n",
            "Seed: 44, Epoch: 010, Loss: 1.7513, Val Acc: 0.1889, Test Acc: 0.2222\n",
            "Seed: 44, Epoch: 011, Loss: 1.7466, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 012, Loss: 1.7391, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 013, Loss: 1.7320, Val Acc: 0.2000, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 014, Loss: 1.7231, Val Acc: 0.2111, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 015, Loss: 1.7168, Val Acc: 0.1889, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 016, Loss: 1.7135, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 017, Loss: 1.7050, Val Acc: 0.2000, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 018, Loss: 1.7009, Val Acc: 0.2111, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 019, Loss: 1.6929, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 020, Loss: 1.6944, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 021, Loss: 1.6922, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 022, Loss: 1.6863, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 023, Loss: 1.6728, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 024, Loss: 1.6761, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 025, Loss: 1.6594, Val Acc: 0.2111, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 026, Loss: 1.6591, Val Acc: 0.2222, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 027, Loss: 1.6537, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 028, Loss: 1.6463, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 029, Loss: 1.6408, Val Acc: 0.2111, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 030, Loss: 1.6398, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 031, Loss: 1.6421, Val Acc: 0.2444, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 032, Loss: 1.6300, Val Acc: 0.2222, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 033, Loss: 1.6286, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 034, Loss: 1.6310, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 035, Loss: 1.6097, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 036, Loss: 1.6139, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 037, Loss: 1.6065, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 038, Loss: 1.6038, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 039, Loss: 1.5819, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 040, Loss: 1.5877, Val Acc: 0.3444, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 041, Loss: 1.5891, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 042, Loss: 1.5806, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 043, Loss: 1.5795, Val Acc: 0.3333, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 044, Loss: 1.5781, Val Acc: 0.2000, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 045, Loss: 1.5688, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 046, Loss: 1.5575, Val Acc: 0.3778, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 047, Loss: 1.5600, Val Acc: 0.3111, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 048, Loss: 1.5549, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 049, Loss: 1.5519, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 050, Loss: 1.5447, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 051, Loss: 1.5422, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 052, Loss: 1.5388, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 053, Loss: 1.5365, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 054, Loss: 1.5298, Val Acc: 0.3111, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 055, Loss: 1.5219, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 056, Loss: 1.5266, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 057, Loss: 1.5299, Val Acc: 0.2667, Test Acc: 0.2111\n",
            "Seed: 44, Epoch: 058, Loss: 1.5357, Val Acc: 0.2444, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 059, Loss: 1.5043, Val Acc: 0.3333, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 060, Loss: 1.5042, Val Acc: 0.2778, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 061, Loss: 1.5119, Val Acc: 0.2889, Test Acc: 0.2333\n",
            "Seed: 44, Epoch: 062, Loss: 1.5046, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 063, Loss: 1.4780, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 44, Epoch: 064, Loss: 1.5029, Val Acc: 0.3333, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 065, Loss: 1.4760, Val Acc: 0.3222, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 066, Loss: 1.4774, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 067, Loss: 1.4660, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 068, Loss: 1.4675, Val Acc: 0.3556, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 069, Loss: 1.4412, Val Acc: 0.3222, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 070, Loss: 1.4448, Val Acc: 0.3444, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 071, Loss: 1.4496, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 072, Loss: 1.4432, Val Acc: 0.3333, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 073, Loss: 1.4462, Val Acc: 0.4000, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 074, Loss: 1.4391, Val Acc: 0.2222, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 075, Loss: 1.4505, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 076, Loss: 1.4587, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 077, Loss: 1.4276, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 44, Epoch: 078, Loss: 1.4359, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 079, Loss: 1.4202, Val Acc: 0.3222, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 080, Loss: 1.4141, Val Acc: 0.3222, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 081, Loss: 1.4241, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 082, Loss: 1.4144, Val Acc: 0.3111, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 083, Loss: 1.3956, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 084, Loss: 1.3961, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 085, Loss: 1.3878, Val Acc: 0.3667, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 086, Loss: 1.3878, Val Acc: 0.3333, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 087, Loss: 1.3855, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 088, Loss: 1.3872, Val Acc: 0.3222, Test Acc: 0.2556\n",
            "Seed: 44, Epoch: 089, Loss: 1.3664, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 090, Loss: 1.3708, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 091, Loss: 1.3595, Val Acc: 0.3444, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 092, Loss: 1.3618, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 093, Loss: 1.3224, Val Acc: 0.3667, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 094, Loss: 1.3468, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 095, Loss: 1.3416, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 096, Loss: 1.3231, Val Acc: 0.3444, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 097, Loss: 1.3440, Val Acc: 0.3556, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 098, Loss: 1.3175, Val Acc: 0.3111, Test Acc: 0.3000\n",
            "Seed: 44, Epoch: 099, Loss: 1.3210, Val Acc: 0.3000, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 100, Loss: 1.3189, Val Acc: 0.3444, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 101, Loss: 1.2912, Val Acc: 0.3556, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 102, Loss: 1.2873, Val Acc: 0.3333, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 103, Loss: 1.3003, Val Acc: 0.3667, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 104, Loss: 1.2807, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 105, Loss: 1.2948, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 106, Loss: 1.2812, Val Acc: 0.3778, Test Acc: 0.3111\n",
            "Seed: 44, Epoch: 107, Loss: 1.2832, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 108, Loss: 1.3073, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 109, Loss: 1.2634, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 110, Loss: 1.2483, Val Acc: 0.3667, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 111, Loss: 1.2453, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 112, Loss: 1.2555, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 113, Loss: 1.2452, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 114, Loss: 1.2442, Val Acc: 0.3556, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 115, Loss: 1.2122, Val Acc: 0.3778, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 116, Loss: 1.2210, Val Acc: 0.3889, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 117, Loss: 1.2177, Val Acc: 0.3556, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 118, Loss: 1.2411, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 119, Loss: 1.2573, Val Acc: 0.3556, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 120, Loss: 1.2259, Val Acc: 0.3222, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 121, Loss: 1.2175, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 122, Loss: 1.2319, Val Acc: 0.3889, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 123, Loss: 1.2315, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 124, Loss: 1.2131, Val Acc: 0.3889, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 125, Loss: 1.1818, Val Acc: 0.3778, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 126, Loss: 1.2281, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 127, Loss: 1.3238, Val Acc: 0.2667, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 128, Loss: 1.4029, Val Acc: 0.2889, Test Acc: 0.2444\n",
            "Seed: 44, Epoch: 129, Loss: 1.3293, Val Acc: 0.3444, Test Acc: 0.2667\n",
            "Seed: 44, Epoch: 130, Loss: 1.4594, Val Acc: 0.3111, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 131, Loss: 1.3216, Val Acc: 0.2556, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 132, Loss: 1.2968, Val Acc: 0.3333, Test Acc: 0.3222\n",
            "Seed: 44, Epoch: 133, Loss: 1.2416, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 134, Loss: 1.2415, Val Acc: 0.3000, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 135, Loss: 1.2376, Val Acc: 0.3556, Test Acc: 0.3444\n",
            "Seed: 44, Epoch: 136, Loss: 1.2474, Val Acc: 0.3444, Test Acc: 0.3333\n",
            "Seed: 44, Epoch: 137, Loss: 1.2184, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 138, Loss: 1.2204, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 139, Loss: 1.1730, Val Acc: 0.3778, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 140, Loss: 1.1857, Val Acc: 0.3667, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 141, Loss: 1.1868, Val Acc: 0.3556, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 142, Loss: 1.1654, Val Acc: 0.3333, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 143, Loss: 1.1491, Val Acc: 0.3556, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 144, Loss: 1.1478, Val Acc: 0.3778, Test Acc: 0.3667\n",
            "Seed: 44, Epoch: 145, Loss: 1.1737, Val Acc: 0.3444, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 146, Loss: 1.1223, Val Acc: 0.3778, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 147, Loss: 1.1479, Val Acc: 0.3889, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 148, Loss: 1.1182, Val Acc: 0.3667, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 149, Loss: 1.0926, Val Acc: 0.3333, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 150, Loss: 1.1395, Val Acc: 0.3667, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 151, Loss: 1.1284, Val Acc: 0.3778, Test Acc: 0.3778\n",
            "Seed: 44, Epoch: 152, Loss: 1.1270, Val Acc: 0.3778, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 153, Loss: 1.1060, Val Acc: 0.3444, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 154, Loss: 1.0876, Val Acc: 0.3889, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 155, Loss: 1.1030, Val Acc: 0.3778, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 156, Loss: 1.1030, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 157, Loss: 1.0729, Val Acc: 0.3222, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 158, Loss: 1.0788, Val Acc: 0.4111, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 159, Loss: 1.0710, Val Acc: 0.3667, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 160, Loss: 1.0613, Val Acc: 0.3556, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 161, Loss: 1.0392, Val Acc: 0.3889, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 162, Loss: 1.0371, Val Acc: 0.3889, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 163, Loss: 1.0339, Val Acc: 0.3667, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 164, Loss: 1.0380, Val Acc: 0.4222, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 165, Loss: 1.0394, Val Acc: 0.3889, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 166, Loss: 1.0080, Val Acc: 0.3778, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 167, Loss: 0.9978, Val Acc: 0.3444, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 168, Loss: 1.0294, Val Acc: 0.3556, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 169, Loss: 1.0152, Val Acc: 0.3556, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 170, Loss: 1.0246, Val Acc: 0.3889, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 171, Loss: 1.0011, Val Acc: 0.4000, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 172, Loss: 1.0291, Val Acc: 0.3222, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 173, Loss: 1.0127, Val Acc: 0.3667, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 174, Loss: 1.0146, Val Acc: 0.3889, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 175, Loss: 0.9987, Val Acc: 0.3778, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 176, Loss: 0.9617, Val Acc: 0.3444, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 177, Loss: 0.9929, Val Acc: 0.4000, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 178, Loss: 0.9764, Val Acc: 0.3889, Test Acc: 0.4667\n",
            "Seed: 44, Epoch: 179, Loss: 0.9511, Val Acc: 0.3667, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 180, Loss: 0.9709, Val Acc: 0.4000, Test Acc: 0.4778\n",
            "Seed: 44, Epoch: 181, Loss: 0.9433, Val Acc: 0.4000, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 182, Loss: 0.9663, Val Acc: 0.3556, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 183, Loss: 0.9557, Val Acc: 0.3889, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 184, Loss: 0.9351, Val Acc: 0.3889, Test Acc: 0.4444\n",
            "Seed: 44, Epoch: 185, Loss: 0.9616, Val Acc: 0.4222, Test Acc: 0.4667\n",
            "Seed: 44, Epoch: 186, Loss: 0.9581, Val Acc: 0.4000, Test Acc: 0.4000\n",
            "Seed: 44, Epoch: 187, Loss: 0.9271, Val Acc: 0.3667, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 188, Loss: 0.9441, Val Acc: 0.3889, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 189, Loss: 0.9423, Val Acc: 0.3667, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 190, Loss: 0.9505, Val Acc: 0.3444, Test Acc: 0.3556\n",
            "Seed: 44, Epoch: 191, Loss: 0.9798, Val Acc: 0.4111, Test Acc: 0.4556\n",
            "Seed: 44, Epoch: 192, Loss: 0.9650, Val Acc: 0.4000, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 193, Loss: 0.9373, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 194, Loss: 0.9463, Val Acc: 0.3667, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 195, Loss: 0.9368, Val Acc: 0.3667, Test Acc: 0.3889\n",
            "Seed: 44, Epoch: 196, Loss: 0.9383, Val Acc: 0.3556, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 197, Loss: 0.9575, Val Acc: 0.4111, Test Acc: 0.4111\n",
            "Seed: 44, Epoch: 198, Loss: 0.8868, Val Acc: 0.3667, Test Acc: 0.4222\n",
            "Seed: 44, Epoch: 199, Loss: 0.9444, Val Acc: 0.3667, Test Acc: 0.4333\n",
            "Seed: 44, Epoch: 200, Loss: 0.9078, Val Acc: 0.4333, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 001, Loss: 1.7978, Val Acc: 0.1778, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 002, Loss: 1.7815, Val Acc: 0.1667, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 003, Loss: 1.7798, Val Acc: 0.1667, Test Acc: 0.2000\n",
            "Seed: 45, Epoch: 004, Loss: 1.7719, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 005, Loss: 1.7678, Val Acc: 0.2111, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 006, Loss: 1.7688, Val Acc: 0.2111, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 007, Loss: 1.7616, Val Acc: 0.2000, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 008, Loss: 1.7563, Val Acc: 0.2111, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 009, Loss: 1.7528, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 010, Loss: 1.7462, Val Acc: 0.2111, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 011, Loss: 1.7397, Val Acc: 0.2000, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 012, Loss: 1.7317, Val Acc: 0.1889, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 013, Loss: 1.7242, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 014, Loss: 1.7175, Val Acc: 0.2111, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 015, Loss: 1.7061, Val Acc: 0.2000, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 016, Loss: 1.7091, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 017, Loss: 1.7035, Val Acc: 0.2111, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 018, Loss: 1.7000, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 019, Loss: 1.6900, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 020, Loss: 1.6898, Val Acc: 0.1778, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 021, Loss: 1.6814, Val Acc: 0.2111, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 022, Loss: 1.6821, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 023, Loss: 1.6765, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 024, Loss: 1.6712, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 025, Loss: 1.6686, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 026, Loss: 1.6640, Val Acc: 0.2111, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 027, Loss: 1.6542, Val Acc: 0.3000, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 028, Loss: 1.6565, Val Acc: 0.2333, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 029, Loss: 1.6484, Val Acc: 0.2000, Test Acc: 0.1889\n",
            "Seed: 45, Epoch: 030, Loss: 1.6571, Val Acc: 0.2000, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 031, Loss: 1.6495, Val Acc: 0.2889, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 032, Loss: 1.6461, Val Acc: 0.2556, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 033, Loss: 1.6339, Val Acc: 0.2000, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 034, Loss: 1.6370, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 035, Loss: 1.6396, Val Acc: 0.2444, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 036, Loss: 1.6314, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 037, Loss: 1.6275, Val Acc: 0.2222, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 038, Loss: 1.6198, Val Acc: 0.2000, Test Acc: 0.2222\n",
            "Seed: 45, Epoch: 039, Loss: 1.6142, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 040, Loss: 1.6124, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 041, Loss: 1.6067, Val Acc: 0.2222, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 042, Loss: 1.6065, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 043, Loss: 1.6059, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 044, Loss: 1.5995, Val Acc: 0.2222, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 045, Loss: 1.5943, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 046, Loss: 1.5964, Val Acc: 0.3000, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 047, Loss: 1.5814, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 048, Loss: 1.5924, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 049, Loss: 1.5755, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 050, Loss: 1.5842, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 051, Loss: 1.5786, Val Acc: 0.2556, Test Acc: 0.2333\n",
            "Seed: 45, Epoch: 052, Loss: 1.5860, Val Acc: 0.2333, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 053, Loss: 1.5624, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 054, Loss: 1.5778, Val Acc: 0.3000, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 055, Loss: 1.5584, Val Acc: 0.2000, Test Acc: 0.2444\n",
            "Seed: 45, Epoch: 056, Loss: 1.5670, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 057, Loss: 1.5504, Val Acc: 0.3000, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 058, Loss: 1.5569, Val Acc: 0.3000, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 059, Loss: 1.5321, Val Acc: 0.2556, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 060, Loss: 1.5473, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 061, Loss: 1.5291, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 062, Loss: 1.5468, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 063, Loss: 1.5203, Val Acc: 0.2111, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 064, Loss: 1.5414, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 45, Epoch: 065, Loss: 1.5224, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 066, Loss: 1.5274, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 067, Loss: 1.4955, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 068, Loss: 1.5284, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 45, Epoch: 069, Loss: 1.5023, Val Acc: 0.3333, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 070, Loss: 1.5124, Val Acc: 0.3333, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 071, Loss: 1.4987, Val Acc: 0.2333, Test Acc: 0.2889\n",
            "Seed: 45, Epoch: 072, Loss: 1.5034, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 073, Loss: 1.4966, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 074, Loss: 1.4890, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 075, Loss: 1.4856, Val Acc: 0.3111, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 076, Loss: 1.4772, Val Acc: 0.3000, Test Acc: 0.2667\n",
            "Seed: 45, Epoch: 077, Loss: 1.4561, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 078, Loss: 1.4811, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 079, Loss: 1.4672, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 080, Loss: 1.4825, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 081, Loss: 1.4527, Val Acc: 0.3667, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 082, Loss: 1.4552, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 083, Loss: 1.4554, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 45, Epoch: 084, Loss: 1.4426, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 085, Loss: 1.4456, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 086, Loss: 1.4397, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 087, Loss: 1.4510, Val Acc: 0.2333, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 088, Loss: 1.4251, Val Acc: 0.3222, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 089, Loss: 1.4495, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 090, Loss: 1.4150, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 091, Loss: 1.4266, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 092, Loss: 1.4085, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 093, Loss: 1.4084, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 094, Loss: 1.3984, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 095, Loss: 1.4152, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 45, Epoch: 096, Loss: 1.3867, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 097, Loss: 1.4195, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 098, Loss: 1.3766, Val Acc: 0.3333, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 099, Loss: 1.4097, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 100, Loss: 1.3805, Val Acc: 0.2333, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 101, Loss: 1.3731, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 102, Loss: 1.3786, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 103, Loss: 1.3714, Val Acc: 0.2667, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 104, Loss: 1.3652, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 105, Loss: 1.3760, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 106, Loss: 1.3825, Val Acc: 0.2444, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 107, Loss: 1.3822, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 108, Loss: 1.3915, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 109, Loss: 1.3515, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 110, Loss: 1.3608, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 111, Loss: 1.3437, Val Acc: 0.2667, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 112, Loss: 1.3382, Val Acc: 0.3000, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 113, Loss: 1.3101, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 114, Loss: 1.3463, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 115, Loss: 1.3117, Val Acc: 0.2556, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 116, Loss: 1.3176, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 117, Loss: 1.3074, Val Acc: 0.3000, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 118, Loss: 1.2893, Val Acc: 0.3667, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 119, Loss: 1.3016, Val Acc: 0.3111, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 120, Loss: 1.3177, Val Acc: 0.3556, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 121, Loss: 1.3101, Val Acc: 0.2778, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 122, Loss: 1.2962, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 123, Loss: 1.2897, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 124, Loss: 1.2611, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 125, Loss: 1.2665, Val Acc: 0.3778, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 126, Loss: 1.2701, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 127, Loss: 1.2591, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 128, Loss: 1.2418, Val Acc: 0.3444, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 129, Loss: 1.2422, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 130, Loss: 1.2609, Val Acc: 0.2889, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 131, Loss: 1.2589, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 132, Loss: 1.2203, Val Acc: 0.3444, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 133, Loss: 1.2539, Val Acc: 0.3000, Test Acc: 0.4222\n",
            "Seed: 45, Epoch: 134, Loss: 1.2553, Val Acc: 0.2556, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 135, Loss: 1.2291, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 136, Loss: 1.2123, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 137, Loss: 1.1969, Val Acc: 0.2444, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 138, Loss: 1.1954, Val Acc: 0.3444, Test Acc: 0.4333\n",
            "Seed: 45, Epoch: 139, Loss: 1.2032, Val Acc: 0.2667, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 140, Loss: 1.1969, Val Acc: 0.3111, Test Acc: 0.4667\n",
            "Seed: 45, Epoch: 141, Loss: 1.1533, Val Acc: 0.3333, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 142, Loss: 1.1732, Val Acc: 0.3222, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 143, Loss: 1.1761, Val Acc: 0.2889, Test Acc: 0.4222\n",
            "Seed: 45, Epoch: 144, Loss: 1.1508, Val Acc: 0.2667, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 145, Loss: 1.1599, Val Acc: 0.3667, Test Acc: 0.4222\n",
            "Seed: 45, Epoch: 146, Loss: 1.1661, Val Acc: 0.2333, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 147, Loss: 1.1703, Val Acc: 0.3222, Test Acc: 0.4444\n",
            "Seed: 45, Epoch: 148, Loss: 1.1519, Val Acc: 0.3222, Test Acc: 0.4556\n",
            "Seed: 45, Epoch: 149, Loss: 1.1429, Val Acc: 0.2444, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 150, Loss: 1.1214, Val Acc: 0.3333, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 151, Loss: 1.1915, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 152, Loss: 1.2378, Val Acc: 0.2778, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 153, Loss: 1.1919, Val Acc: 0.3444, Test Acc: 0.4333\n",
            "Seed: 45, Epoch: 154, Loss: 1.1209, Val Acc: 0.2778, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 155, Loss: 1.1742, Val Acc: 0.3556, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 156, Loss: 1.1995, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 157, Loss: 1.1937, Val Acc: 0.2444, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 158, Loss: 1.1577, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 45, Epoch: 159, Loss: 1.1962, Val Acc: 0.3000, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 160, Loss: 1.1869, Val Acc: 0.2556, Test Acc: 0.3222\n",
            "Seed: 45, Epoch: 161, Loss: 1.2210, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 162, Loss: 1.1842, Val Acc: 0.3556, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 163, Loss: 1.1499, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 164, Loss: 1.1619, Val Acc: 0.2889, Test Acc: 0.4333\n",
            "Seed: 45, Epoch: 165, Loss: 1.1430, Val Acc: 0.2667, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 166, Loss: 1.1419, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 45, Epoch: 167, Loss: 1.1197, Val Acc: 0.2667, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 168, Loss: 1.1265, Val Acc: 0.3111, Test Acc: 0.4333\n",
            "Seed: 45, Epoch: 169, Loss: 1.0979, Val Acc: 0.2556, Test Acc: 0.4444\n",
            "Seed: 45, Epoch: 170, Loss: 1.0913, Val Acc: 0.3556, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 171, Loss: 1.1058, Val Acc: 0.4000, Test Acc: 0.4222\n",
            "Seed: 45, Epoch: 172, Loss: 1.1117, Val Acc: 0.2556, Test Acc: 0.4778\n",
            "Seed: 45, Epoch: 173, Loss: 1.0884, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 174, Loss: 1.1129, Val Acc: 0.2889, Test Acc: 0.4222\n",
            "Seed: 45, Epoch: 175, Loss: 1.1837, Val Acc: 0.3778, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 176, Loss: 1.2193, Val Acc: 0.3667, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 177, Loss: 1.0981, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 178, Loss: 1.1570, Val Acc: 0.3111, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 179, Loss: 1.0639, Val Acc: 0.3444, Test Acc: 0.4222\n",
            "Seed: 45, Epoch: 180, Loss: 1.0418, Val Acc: 0.2667, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 181, Loss: 1.0708, Val Acc: 0.2889, Test Acc: 0.4444\n",
            "Seed: 45, Epoch: 182, Loss: 1.0448, Val Acc: 0.3444, Test Acc: 0.3889\n",
            "Seed: 45, Epoch: 183, Loss: 1.0821, Val Acc: 0.2778, Test Acc: 0.4556\n",
            "Seed: 45, Epoch: 184, Loss: 1.0237, Val Acc: 0.2556, Test Acc: 0.4000\n",
            "Seed: 45, Epoch: 185, Loss: 1.0367, Val Acc: 0.3667, Test Acc: 0.4333\n",
            "Seed: 45, Epoch: 186, Loss: 1.0787, Val Acc: 0.3000, Test Acc: 0.4333\n",
            "Seed: 45, Epoch: 187, Loss: 1.0123, Val Acc: 0.2444, Test Acc: 0.3667\n",
            "Seed: 45, Epoch: 188, Loss: 1.0523, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 45, Epoch: 189, Loss: 1.0433, Val Acc: 0.3222, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 190, Loss: 1.0169, Val Acc: 0.2333, Test Acc: 0.4222\n",
            "Seed: 45, Epoch: 191, Loss: 1.0168, Val Acc: 0.3333, Test Acc: 0.4222\n",
            "Seed: 45, Epoch: 192, Loss: 0.9988, Val Acc: 0.3778, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 193, Loss: 1.0084, Val Acc: 0.2444, Test Acc: 0.4222\n",
            "Seed: 45, Epoch: 194, Loss: 1.0353, Val Acc: 0.2778, Test Acc: 0.4333\n",
            "Seed: 45, Epoch: 195, Loss: 0.9743, Val Acc: 0.3778, Test Acc: 0.3556\n",
            "Seed: 45, Epoch: 196, Loss: 1.0597, Val Acc: 0.3444, Test Acc: 0.4222\n",
            "Seed: 45, Epoch: 197, Loss: 1.0225, Val Acc: 0.2444, Test Acc: 0.4111\n",
            "Seed: 45, Epoch: 198, Loss: 1.0603, Val Acc: 0.3778, Test Acc: 0.4444\n",
            "Seed: 45, Epoch: 199, Loss: 1.0443, Val Acc: 0.3000, Test Acc: 0.3778\n",
            "Seed: 45, Epoch: 200, Loss: 1.0134, Val Acc: 0.2667, Test Acc: 0.4444\n",
            "Seed: 46, Epoch: 001, Loss: 1.8200, Val Acc: 0.1222, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 002, Loss: 1.7874, Val Acc: 0.2111, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 003, Loss: 1.7835, Val Acc: 0.2222, Test Acc: 0.2111\n",
            "Seed: 46, Epoch: 004, Loss: 1.7782, Val Acc: 0.1667, Test Acc: 0.2222\n",
            "Seed: 46, Epoch: 005, Loss: 1.7730, Val Acc: 0.1667, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 006, Loss: 1.7749, Val Acc: 0.2111, Test Acc: 0.2222\n",
            "Seed: 46, Epoch: 007, Loss: 1.7628, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 008, Loss: 1.7662, Val Acc: 0.2111, Test Acc: 0.2111\n",
            "Seed: 46, Epoch: 009, Loss: 1.7583, Val Acc: 0.2111, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 010, Loss: 1.7514, Val Acc: 0.2111, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 011, Loss: 1.7469, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 012, Loss: 1.7380, Val Acc: 0.2222, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 013, Loss: 1.7304, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 014, Loss: 1.7282, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 015, Loss: 1.7175, Val Acc: 0.2000, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 016, Loss: 1.7139, Val Acc: 0.2000, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 017, Loss: 1.6963, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 018, Loss: 1.6976, Val Acc: 0.2333, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 019, Loss: 1.6915, Val Acc: 0.2000, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 020, Loss: 1.6638, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 021, Loss: 1.6729, Val Acc: 0.2889, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 022, Loss: 1.6879, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 023, Loss: 1.6753, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 024, Loss: 1.6592, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 025, Loss: 1.6432, Val Acc: 0.1889, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 026, Loss: 1.6642, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 027, Loss: 1.6353, Val Acc: 0.2889, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 028, Loss: 1.6399, Val Acc: 0.2889, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 029, Loss: 1.6453, Val Acc: 0.2778, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 030, Loss: 1.6277, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 031, Loss: 1.6229, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 032, Loss: 1.6174, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 033, Loss: 1.6212, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 034, Loss: 1.6221, Val Acc: 0.2444, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 035, Loss: 1.6128, Val Acc: 0.2556, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 036, Loss: 1.6041, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 037, Loss: 1.6051, Val Acc: 0.2333, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 038, Loss: 1.5820, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 039, Loss: 1.5890, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 040, Loss: 1.5917, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 041, Loss: 1.5779, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 042, Loss: 1.5712, Val Acc: 0.2333, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 043, Loss: 1.5585, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 044, Loss: 1.5610, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 045, Loss: 1.5597, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 046, Loss: 1.5552, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 047, Loss: 1.5491, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 048, Loss: 1.5366, Val Acc: 0.2222, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 049, Loss: 1.5382, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 050, Loss: 1.5299, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 051, Loss: 1.5266, Val Acc: 0.2556, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 052, Loss: 1.5264, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 053, Loss: 1.5137, Val Acc: 0.2667, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 054, Loss: 1.5185, Val Acc: 0.2778, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 055, Loss: 1.5267, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 056, Loss: 1.5132, Val Acc: 0.2333, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 057, Loss: 1.4890, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 058, Loss: 1.4923, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 059, Loss: 1.4750, Val Acc: 0.2444, Test Acc: 0.2333\n",
            "Seed: 46, Epoch: 060, Loss: 1.4795, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 061, Loss: 1.4751, Val Acc: 0.2778, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 062, Loss: 1.4610, Val Acc: 0.2889, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 063, Loss: 1.4442, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 064, Loss: 1.4719, Val Acc: 0.2778, Test Acc: 0.2667\n",
            "Seed: 46, Epoch: 065, Loss: 1.4449, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 066, Loss: 1.4538, Val Acc: 0.2667, Test Acc: 0.2444\n",
            "Seed: 46, Epoch: 067, Loss: 1.4605, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 068, Loss: 1.4520, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 069, Loss: 1.4348, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 070, Loss: 1.4489, Val Acc: 0.2889, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 071, Loss: 1.4367, Val Acc: 0.2778, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 072, Loss: 1.4441, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 073, Loss: 1.4293, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 074, Loss: 1.4262, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 075, Loss: 1.4141, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 076, Loss: 1.4201, Val Acc: 0.2444, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 077, Loss: 1.4312, Val Acc: 0.2667, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 078, Loss: 1.4432, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 079, Loss: 1.4412, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 080, Loss: 1.4042, Val Acc: 0.3111, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 081, Loss: 1.4047, Val Acc: 0.2333, Test Acc: 0.2556\n",
            "Seed: 46, Epoch: 082, Loss: 1.4335, Val Acc: 0.3000, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 083, Loss: 1.4158, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 084, Loss: 1.4215, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 085, Loss: 1.3816, Val Acc: 0.2333, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 086, Loss: 1.3997, Val Acc: 0.2556, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 087, Loss: 1.3717, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 088, Loss: 1.3912, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 089, Loss: 1.3722, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 090, Loss: 1.3657, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 091, Loss: 1.3531, Val Acc: 0.3111, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 092, Loss: 1.3857, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 093, Loss: 1.3835, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 094, Loss: 1.3665, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 095, Loss: 1.3845, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 096, Loss: 1.3493, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 097, Loss: 1.3502, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 098, Loss: 1.3403, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 099, Loss: 1.3451, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 100, Loss: 1.3310, Val Acc: 0.2667, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 101, Loss: 1.3140, Val Acc: 0.3222, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 102, Loss: 1.3360, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 103, Loss: 1.3446, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 104, Loss: 1.3435, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 105, Loss: 1.3301, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 106, Loss: 1.3170, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 107, Loss: 1.3592, Val Acc: 0.3333, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 108, Loss: 1.3436, Val Acc: 0.2889, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 109, Loss: 1.3160, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 110, Loss: 1.3130, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 111, Loss: 1.2898, Val Acc: 0.3111, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 112, Loss: 1.3044, Val Acc: 0.3111, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 113, Loss: 1.2972, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 114, Loss: 1.2980, Val Acc: 0.2778, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 115, Loss: 1.2811, Val Acc: 0.3000, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 116, Loss: 1.2967, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 117, Loss: 1.3107, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 118, Loss: 1.2894, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 119, Loss: 1.2962, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 120, Loss: 1.2685, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 121, Loss: 1.2819, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 122, Loss: 1.3006, Val Acc: 0.3111, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 123, Loss: 1.3080, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 124, Loss: 1.2924, Val Acc: 0.2778, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 125, Loss: 1.2880, Val Acc: 0.3111, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 126, Loss: 1.2496, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 127, Loss: 1.2390, Val Acc: 0.2556, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 128, Loss: 1.2528, Val Acc: 0.2667, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 129, Loss: 1.2311, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 130, Loss: 1.2580, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 131, Loss: 1.2438, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 132, Loss: 1.2407, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 133, Loss: 1.2304, Val Acc: 0.3111, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 134, Loss: 1.2479, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 135, Loss: 1.2671, Val Acc: 0.2778, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 136, Loss: 1.2359, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 137, Loss: 1.2313, Val Acc: 0.3333, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 138, Loss: 1.2329, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 139, Loss: 1.1931, Val Acc: 0.2667, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 140, Loss: 1.2093, Val Acc: 0.3000, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 141, Loss: 1.2260, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 142, Loss: 1.2076, Val Acc: 0.2889, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 143, Loss: 1.2136, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 144, Loss: 1.1981, Val Acc: 0.2444, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 145, Loss: 1.2067, Val Acc: 0.2778, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 146, Loss: 1.2239, Val Acc: 0.3333, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 147, Loss: 1.1793, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 148, Loss: 1.1733, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 149, Loss: 1.1473, Val Acc: 0.2444, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 150, Loss: 1.1828, Val Acc: 0.2444, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 151, Loss: 1.2093, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 152, Loss: 1.1902, Val Acc: 0.2778, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 153, Loss: 1.1705, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 154, Loss: 1.2191, Val Acc: 0.2556, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 155, Loss: 1.1598, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 156, Loss: 1.1619, Val Acc: 0.3444, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 157, Loss: 1.1407, Val Acc: 0.3333, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 158, Loss: 1.1340, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 159, Loss: 1.1575, Val Acc: 0.2889, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 160, Loss: 1.1472, Val Acc: 0.3444, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 161, Loss: 1.1541, Val Acc: 0.3000, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 162, Loss: 1.1308, Val Acc: 0.2889, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 163, Loss: 1.1150, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 164, Loss: 1.1130, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 165, Loss: 1.1035, Val Acc: 0.3111, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 166, Loss: 1.1065, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 167, Loss: 1.1195, Val Acc: 0.3111, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 168, Loss: 1.1134, Val Acc: 0.3000, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 169, Loss: 1.1229, Val Acc: 0.3222, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 170, Loss: 1.0972, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 171, Loss: 1.1368, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 172, Loss: 1.1274, Val Acc: 0.2889, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 173, Loss: 1.1157, Val Acc: 0.3111, Test Acc: 0.3000\n",
            "Seed: 46, Epoch: 174, Loss: 1.1278, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 175, Loss: 1.1032, Val Acc: 0.2667, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 176, Loss: 1.1052, Val Acc: 0.3333, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 177, Loss: 1.0962, Val Acc: 0.3444, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 178, Loss: 1.1073, Val Acc: 0.3000, Test Acc: 0.3222\n",
            "Seed: 46, Epoch: 179, Loss: 1.0882, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 180, Loss: 1.1144, Val Acc: 0.3111, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 181, Loss: 1.1024, Val Acc: 0.2556, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 182, Loss: 1.1048, Val Acc: 0.2889, Test Acc: 0.4111\n",
            "Seed: 46, Epoch: 183, Loss: 1.0798, Val Acc: 0.3556, Test Acc: 0.4000\n",
            "Seed: 46, Epoch: 184, Loss: 1.0831, Val Acc: 0.3222, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 185, Loss: 1.0533, Val Acc: 0.3333, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 186, Loss: 1.0513, Val Acc: 0.3444, Test Acc: 0.4333\n",
            "Seed: 46, Epoch: 187, Loss: 1.0653, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 188, Loss: 1.0608, Val Acc: 0.2778, Test Acc: 0.3111\n",
            "Seed: 46, Epoch: 189, Loss: 1.0669, Val Acc: 0.3111, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 190, Loss: 1.0748, Val Acc: 0.2667, Test Acc: 0.2778\n",
            "Seed: 46, Epoch: 191, Loss: 1.2883, Val Acc: 0.2889, Test Acc: 0.3444\n",
            "Seed: 46, Epoch: 192, Loss: 1.1603, Val Acc: 0.3222, Test Acc: 0.3778\n",
            "Seed: 46, Epoch: 193, Loss: 1.0809, Val Acc: 0.3000, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 194, Loss: 1.0838, Val Acc: 0.3000, Test Acc: 0.3667\n",
            "Seed: 46, Epoch: 195, Loss: 1.1162, Val Acc: 0.2667, Test Acc: 0.3556\n",
            "Seed: 46, Epoch: 196, Loss: 1.0902, Val Acc: 0.3222, Test Acc: 0.3889\n",
            "Seed: 46, Epoch: 197, Loss: 1.0366, Val Acc: 0.3000, Test Acc: 0.2889\n",
            "Seed: 46, Epoch: 198, Loss: 1.0620, Val Acc: 0.3111, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 199, Loss: 1.0330, Val Acc: 0.3222, Test Acc: 0.3333\n",
            "Seed: 46, Epoch: 200, Loss: 1.0264, Val Acc: 0.2889, Test Acc: 0.3556\n",
            "Average Time: 30.82 seconds\n",
            "Var Time: 0.01 seconds\n",
            "Average Memory: 75.60 MB\n",
            "Average Best Val Acc: 0.4022\n",
            "Std Best Test Acc: 0.0191\n",
            "Average Test Acc: 0.4133\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, EdgePooling\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.transforms import ToUndirected\n",
        "from torch.nn import Linear\n",
        "import torch.optim as optim\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_geometric.utils import to_dense_batch\n",
        "from torch_geometric.nn import BatchNorm\n",
        "\n",
        "class HierarchicalGCN_HGPSL(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes):\n",
        "        super(HierarchicalGCN_HGPSL, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, out_channels)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.lin1 = torch.nn.Linear(out_channels, 32)\n",
        "        self.lin2 = torch.nn.Linear(32, num_classes)\n",
        "\n",
        "        self.pool1 = HGPSLPool(hidden_channels, ratio=0.5, sample=False, sparse=False, sl=True, lamb=1.0, negative_slop=0.2)\n",
        "        self.pool2 = HGPSLPool(hidden_channels, ratio=0.5, sample=False, sparse=False, sl=True, lamb=1.0, negative_slop=0.2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr=None\n",
        "        batch = data.batch\n",
        "\n",
        "        # First GCN and pooling layer\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn1(x)\n",
        "        x, edge_index, _, batch = self.pool1(x, edge_index, edge_attr, batch)\n",
        "\n",
        "        # Second GCN and pooling layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn2(x)\n",
        "        x, edge_index, _, batch = self.pool1(x, edge_index, edge_attr, batch)\n",
        "\n",
        "        # Third GCN layer\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = self.bn3(x)\n",
        "\n",
        "        # Mean pooling over the nodes\n",
        "        x, mask = to_dense_batch(x, batch)\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.lin1(x).relu()\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "\n",
        "num_classes = dataset_sparse.num_classes\n",
        "in_channels = dataset_sparse.num_features\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = HierarchicalGCN_HGPSL(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == data.y).sum().item()\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seeds = [42, 43, 44, 45, 46]\n",
        "times = []\n",
        "memories = []\n",
        "best_val_accs = []\n",
        "best_test_accs = []\n",
        "\n",
        "early_stop_patience = 150\n",
        "tolerance = 0.0001\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    model = HierarchicalGCN_HGPSL(in_channels=dataset_sparse.num_features, hidden_channels=64,out_channels=64, num_classes=dataset_sparse.num_classes).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        val_acc = test(valid_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        if val_acc > best_val_acc + tolerance:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "        if epochs_no_improve >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
        "\n",
        "    times.append(total_time)\n",
        "    memories.append(memory_allocated)\n",
        "    best_val_accs.append(best_val_acc)\n",
        "    best_test_accs.append(best_test_acc)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
        "print(f'Var Time: {np.var(times):.2f} seconds')\n",
        "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
        "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
        "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
        "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmhaQv7-XGGP"
      },
      "source": [
        "## Dense AsymCheegerCutPooling with HierarchicalGCN (2023)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moSPw4mABJyP",
        "outputId": "1d06960a-e7de-4a7e-e2e6-b18e4f426aa8"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.data import DenseDataLoader\n",
        "max_nodes = 100\n",
        "data_path = \"/data/zeyu/Pooling/2\"\n",
        "def process_adj(data):\n",
        "    edge_index = data.adj[:, :, 0]\n",
        "    edge_index[edge_index != 0] = 1\n",
        "    data.adj = edge_index\n",
        "    return data\n",
        "\n",
        "dataset_ENZYMES = TUDataset(root=\"/data/zeyu/Pooling/\", name='COLORS-3', use_node_attr=True, transform=T.Compose([T.ToDense(max_nodes), T.Constant()]), pre_filter=lambda data: data.num_nodes <= max_nodes)\n",
        "\n",
        "dataset_ENZYMES = dataset_ENZYMES.shuffle()\n",
        "dataset_size = len(dataset_ENZYMES)\n",
        "train_size = int(dataset_size * 0.7)\n",
        "val_size = int(dataset_size * 0.15)\n",
        "test_size = dataset_size - train_size - val_size\n",
        "\n",
        "train_dataset = dataset_ENZYMES[:train_size]\n",
        "val_dataset = dataset_ENZYMES[train_size:train_size+val_size]\n",
        "test_dataset = dataset_ENZYMES[train_size+val_size:]\n",
        "\n",
        "train_loader = DenseDataLoader(train_dataset, batch_size=2048, shuffle=True)\n",
        "valid_loader = DenseDataLoader(val_dataset, batch_size=2048, shuffle=False)\n",
        "test_loader = DenseDataLoader(test_dataset, batch_size=2048, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9Asy9U0S98ag"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional, Tuple, Union\n",
        "import math\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch_geometric.nn.models.mlp import Linear\n",
        "from torch_geometric.nn.resolver import activation_resolver\n",
        "from torch_geometric.nn import BatchNorm\n",
        "\n",
        "class AsymCheegerCutPool(torch.nn.Module):\n",
        "    r\"\"\"\n",
        "    The asymmetric cheeger cut pooling layer from the `\"Total Variation Graph Neural Networks\"\n",
        "    <https://arxiv.org/abs/2211.06218>`_ paper.\n",
        "\n",
        "    Args:\n",
        "        k (int):\n",
        "            Number of clusters or output nodes\n",
        "        mlp_channels (int, list of int):\n",
        "            Number of hidden units for each hidden layer in the MLP used to\n",
        "            compute cluster assignments. First integer must match the number\n",
        "            of input channels.\n",
        "        mlp_activation (any):\n",
        "            Activation function between hidden layers of the MLP.\n",
        "            Must be compatible with `torch_geometric.nn.resolver`.\n",
        "        return_selection (bool):\n",
        "            Whether to return selection matrix. Cannot not  be False\n",
        "            if `return_pooled_graph` is False. (default: :obj:`False`)\n",
        "        return_pooled_graph (bool):\n",
        "            Whether to return pooled node features and adjacency.\n",
        "            Cannot be False if `return_selection` is False. (default: :obj:`True`)\n",
        "        bias (bool):\n",
        "            whether to add a bias term to the MLP layers. (default: :obj:`True`)\n",
        "        totvar_coeff (float):\n",
        "            Coefficient for graph total variation loss component. (default: :obj:`1.0`)\n",
        "        balance_coeff (float):\n",
        "            Coefficient for asymmetric norm loss component. (default: :obj:`1.0`)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 k: int,\n",
        "                 mlp_channels: Union[int, List[int]],\n",
        "                 mlp_activation=\"relu\",\n",
        "                 return_selection: bool = False,\n",
        "                 return_pooled_graph: bool = True,\n",
        "                 bias: bool = True,\n",
        "                 totvar_coeff: float = 1.0,\n",
        "                 balance_coeff: float = 1.0,\n",
        "                 ):\n",
        "        super().__init__()\n",
        "\n",
        "        if not return_selection and not return_pooled_graph:\n",
        "            raise ValueError(\"return_selection and return_pooled_graph can not both be False\")\n",
        "\n",
        "        if isinstance(mlp_channels, int):\n",
        "            mlp_channels = [mlp_channels]\n",
        "\n",
        "        act = activation_resolver(mlp_activation)\n",
        "        in_channels = mlp_channels[0]\n",
        "        self.mlp = torch.nn.Sequential()\n",
        "        for channels in mlp_channels[1:]:\n",
        "            self.mlp.append(Linear(in_channels, channels, bias=bias))\n",
        "            in_channels = channels\n",
        "            self.mlp.append(act)\n",
        "\n",
        "\n",
        "        self.mlp.append(Linear(in_channels, k))\n",
        "        self.k = k\n",
        "        self.return_selection = return_selection\n",
        "        self.return_pooled_graph = return_pooled_graph\n",
        "        self.totvar_coeff = totvar_coeff\n",
        "        self.balance_coeff = balance_coeff\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for layer in self.mlp:\n",
        "            if isinstance(layer, Linear):\n",
        "                torch.nn.init.xavier_uniform(layer.weight)\n",
        "                torch.nn.init.zeros_(layer.bias)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: Tensor,\n",
        "        adj: Tensor,\n",
        "        mask: Optional[Tensor] = None,\n",
        "    ) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
        "        r\"\"\"\n",
        "        Args:\n",
        "            x (Tensor):\n",
        "                Node feature tensor :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times N \\times F}`\n",
        "                with batch-size :math:`B`, (maximum) number of nodes :math:`N` for each graph,\n",
        "                and feature dimension :math:`F`. Note that the cluster assignment matrix\n",
        "                :math:`\\mathbf{S} \\in \\mathbb{R}^{B \\times N \\times C}` is\n",
        "                being created within this method.\n",
        "            adj (Tensor):\n",
        "                Adjacency tensor :math:`\\mathbf{A} \\in \\mathbb{R}^{B \\times N \\times N}`.\n",
        "            mask (BoolTensor, optional):\n",
        "                Mask matrix :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}`\n",
        "                indicating the valid nodes for each graph. (default: :obj:`None`)\n",
        "\n",
        "        :rtype: (:class:`Tensor`, :class:`Tensor`, :class:`Tensor`,\n",
        "            :class:`Tensor`, :class:`Tensor`, :class:`Tensor`)\n",
        "        \"\"\"\n",
        "        x = x.unsqueeze(0) if x.dim() == 2 else x\n",
        "        adj = adj.unsqueeze(0) if adj.dim() == 2 else adj\n",
        "\n",
        "        s = self.mlp(x)\n",
        "        s = torch.softmax(s, dim=-1)\n",
        "\n",
        "        batch_size, n_nodes, _ = x.size()\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = mask.view(batch_size, n_nodes, 1).to(x.dtype)\n",
        "            x, s = x * mask, s * mask\n",
        "\n",
        "        # Pooled features and adjacency\n",
        "        if self.return_pooled_graph:\n",
        "            x_pool = torch.matmul(s.transpose(1, 2), x)\n",
        "            adj_pool = torch.matmul(torch.matmul(s.transpose(1, 2), adj), s)\n",
        "\n",
        "        # Total variation loss\n",
        "        tv_loss = self.totvar_coeff*torch.mean(self.totvar_loss(adj, s))\n",
        "\n",
        "        # Balance loss\n",
        "        bal_loss = self.balance_coeff*torch.mean(self.balance_loss(s))\n",
        "\n",
        "        if self.return_selection and self.return_pooled_graph:\n",
        "            return s, x_pool, adj_pool, tv_loss, bal_loss\n",
        "        elif self.return_selection and not self.return_pooled_graph:\n",
        "            return s, tv_loss, bal_loss\n",
        "        else:\n",
        "            return x_pool, adj_pool, tv_loss, bal_loss\n",
        "\n",
        "    def totvar_loss(self, adj, s):\n",
        "        l1_norm = torch.sum(torch.abs(s[..., None, :] - s[:, None, ...]), dim=-1)\n",
        "\n",
        "        loss = torch.sum(adj * l1_norm, dim=(-1, -2))\n",
        "\n",
        "        # Normalize loss\n",
        "        n_edges = torch.count_nonzero(adj, dim=(-1, -2))\n",
        "        loss *= 1 / (2 * n_edges)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def balance_loss(self, s):\n",
        "        n_nodes = s.size()[-2]\n",
        "\n",
        "        # k-quantile\n",
        "        idx = int(math.floor(n_nodes / self.k))\n",
        "        quant = torch.sort(s, dim=-2, descending=True)[0][:, idx, :] # shape [B, K]\n",
        "\n",
        "        # Asymmetric l1-norm\n",
        "        loss = s - torch.unsqueeze(quant, dim=1)\n",
        "        loss = (loss >= 0) * (self.k - 1) * loss + (loss < 0) * loss * -1\n",
        "        loss = torch.sum(loss, dim=(-1, -2)) # shape [B]\n",
        "        loss = 1 / (n_nodes * (self.k - 1)) * (n_nodes * (self.k - 1) - loss)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H1gKijVC_Fzj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 001, Loss: 2.4107, Val Acc: 0.1124, Test Acc: 0.0949\n",
            "Seed: 42, Epoch: 002, Loss: 2.4075, Val Acc: 0.1141, Test Acc: 0.0966\n",
            "Seed: 42, Epoch: 003, Loss: 2.4047, Val Acc: 0.1150, Test Acc: 0.1027\n",
            "Seed: 42, Epoch: 004, Loss: 2.4016, Val Acc: 0.1333, Test Acc: 0.1184\n",
            "Seed: 42, Epoch: 005, Loss: 2.3976, Val Acc: 0.1551, Test Acc: 0.1332\n",
            "Seed: 42, Epoch: 006, Loss: 2.3914, Val Acc: 0.1690, Test Acc: 0.1540\n",
            "Seed: 42, Epoch: 007, Loss: 2.3813, Val Acc: 0.1551, Test Acc: 0.1462\n",
            "Seed: 42, Epoch: 008, Loss: 2.3605, Val Acc: 0.1472, Test Acc: 0.1349\n",
            "Seed: 42, Epoch: 009, Loss: 2.3132, Val Acc: 0.1681, Test Acc: 0.1741\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 194\u001b[0m\n\u001b[1;32m    191\u001b[0m epochs_no_improve \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m201\u001b[39m):\n\u001b[0;32m--> 194\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m test(valid_loader)\n\u001b[1;32m    196\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m test(test_loader)\n",
            "Cell \u001b[0;32mIn[9], line 142\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    141\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    143\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    144\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch_geometric/data/dataset.py:198\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[1;32m    197\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices()[idx])\n\u001b[0;32m--> 198\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch_geometric/transforms/compose.py:21\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     19\u001b[0m         data \u001b[38;5;241m=\u001b[39m [transform(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch_geometric/transforms/to_dense.py:36\u001b[0m, in \u001b[0;36mToDense.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     34\u001b[0m size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize([num_nodes, num_nodes] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(edge_attr\u001b[38;5;241m.\u001b[39msize())[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m     35\u001b[0m adj \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_coo_tensor(data\u001b[38;5;241m.\u001b[39medge_index, edge_attr, size)\n\u001b[0;32m---> 36\u001b[0m data\u001b[38;5;241m.\u001b[39madj \u001b[38;5;241m=\u001b[39m \u001b[43madj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m data\u001b[38;5;241m.\u001b[39medge_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     38\u001b[0m data\u001b[38;5;241m.\u001b[39medge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "from torch_geometric.nn import SAGEConv\n",
        "\n",
        "import os.path as osp\n",
        "import time\n",
        "from math import ceil\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DenseDataLoader\n",
        "from torch_geometric.nn import DenseSAGEConv, dense_diff_pool\n",
        "\n",
        "dataset = dataset_ENZYMES\n",
        "dataset = dataset.shuffle()\n",
        "N = 150\n",
        "mp_layers = 1\n",
        "mp_channels = 64\n",
        "mp_activation = \"relu\"\n",
        "delta_coeff = 2.0\n",
        "\n",
        "mlp_hidden_layers = 1\n",
        "mlp_hidden_channels = 64\n",
        "mlp_activation = \"relu\"\n",
        "totvar_coeff = 0.5\n",
        "balance_coeff = 0.5\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 16\n",
        "learning_rate = 5e-4\n",
        "l2_reg_val = 0\n",
        "patience = 10\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = DenseSAGEConv(in_channels, hidden_channels, normalize)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv2 = DenseSAGEConv(hidden_channels, hidden_channels, normalize)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv3 = DenseSAGEConv(hidden_channels, out_channels, normalize)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        if lin:\n",
        "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
        "        else:\n",
        "            self.lin = None\n",
        "\n",
        "    def bn(self, i, x):\n",
        "        batch_size, num_nodes, num_channels = x.size()\n",
        "        x = x.view(-1, num_channels)\n",
        "        x = getattr(self, f'bn{i}')(x)\n",
        "        x = x.view(batch_size, num_nodes, num_channels)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, adj, mask=None):\n",
        "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
        "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
        "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
        "\n",
        "        if self.lin is not None:\n",
        "            x = self.lin(x).relu()\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Net_AsymCheegerCut(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        num_nodes = 64\n",
        "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
        "        self.gnn1_embed = DenseSAGEConv(dataset.num_features, 64)\n",
        "\n",
        "        num_nodes = 64\n",
        "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
        "        self.gnn2_embed = DenseSAGEConv(64, 64)\n",
        "\n",
        "        self.gnn3_embed = DenseSAGEConv(64, 64)\n",
        "\n",
        "        self.lin1 = torch.nn.Linear(64, 32)\n",
        "        self.lin2 = torch.nn.Linear(32, dataset.num_classes)\n",
        "\n",
        "        self.pool1 = AsymCheegerCutPool(int(N//2),\n",
        "                           mlp_channels=[mp_channels] +\n",
        "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
        "                           mlp_activation=mlp_activation,\n",
        "                           totvar_coeff=totvar_coeff,\n",
        "                           balance_coeff=balance_coeff,\n",
        "                           return_selection=False,\n",
        "                           return_pooled_graph=True)\n",
        "        self.pool2 = AsymCheegerCutPool(int(N//2),\n",
        "                           mlp_channels=[mp_channels] +\n",
        "                                [mlp_hidden_channels for _ in range(mlp_hidden_layers)],\n",
        "                           mlp_activation=mlp_activation,\n",
        "                           totvar_coeff=totvar_coeff,\n",
        "                           balance_coeff=balance_coeff,\n",
        "                           return_selection=False,\n",
        "                           return_pooled_graph=True)\n",
        "\n",
        "\n",
        "    def forward(self, x, adj, mask=None):\n",
        "        s = self.gnn1_pool(x, adj, mask)\n",
        "        x = self.gnn1_embed(x, adj, mask)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x, adj, tv1, bal1 = self.pool1(x, adj, mask=None)\n",
        "        #x = pool_output1.x_pool\n",
        "        #adj = pool_output1.adj_pool\n",
        "\n",
        "        s = self.gnn2_pool(x, adj)\n",
        "        x = self.gnn2_embed(x, adj)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x, adj, tv1, bal1 = self.pool2(x, adj, mask=None)\n",
        "        #x = pool_output1.x_pool\n",
        "        #adj = pool_output1.adj_pool\n",
        "\n",
        "        x = self.gnn3_embed(x, adj)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.lin1(x).relu()\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "model = Net_AsymCheegerCut().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.x, data.adj, data.mask)\n",
        "        data.y = data.y.to(torch.long)\n",
        "        loss = F.nll_loss(output, data.y.view(-1))\n",
        "        loss.backward()\n",
        "        total_loss += data.y.size(0) * float(loss)\n",
        "        optimizer.step()\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        output = model(data.x, data.adj, data.mask)\n",
        "        pred = output.max(dim=1)[1]\n",
        "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seeds = [42, 43, 44, 45, 46]\n",
        "times = []\n",
        "memories = []\n",
        "best_val_accs = []\n",
        "best_test_accs = []\n",
        "\n",
        "early_stop_patience = 150\n",
        "tolerance = 0.0001\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    model = Net_AsymCheegerCut().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        val_acc = test(valid_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        if val_acc > best_val_acc + tolerance:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "        if epochs_no_improve >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
        "\n",
        "    times.append(total_time)\n",
        "    memories.append(memory_allocated)\n",
        "    best_val_accs.append(best_val_acc)\n",
        "    best_test_accs.append(best_test_acc)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
        "print(f'Var Time: {np.var(times):.2f} seconds')\n",
        "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
        "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
        "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
        "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTIyKKSR-duB"
      },
      "source": [
        "## Dense DifferencePooling with HierarchicalGCN (2018)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_rMvQc0qWXBv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 001, Loss: 2.4107, Val Acc: 0.1098, Test Acc: 0.0914\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 153\u001b[0m\n\u001b[1;32m    150\u001b[0m epochs_no_improve \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m201\u001b[39m):\n\u001b[0;32m--> 153\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m test(valid_loader)\n\u001b[1;32m    155\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m test(test_loader)\n",
            "Cell \u001b[0;32mIn[10], line 101\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    100\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    102\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    103\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch_geometric/data/dataset.py:198\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[1;32m    197\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices()[idx])\n\u001b[0;32m--> 198\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch_geometric/transforms/compose.py:21\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     19\u001b[0m         data \u001b[38;5;241m=\u001b[39m [transform(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch_geometric/transforms/to_dense.py:36\u001b[0m, in \u001b[0;36mToDense.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     34\u001b[0m size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize([num_nodes, num_nodes] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(edge_attr\u001b[38;5;241m.\u001b[39msize())[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m     35\u001b[0m adj \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_coo_tensor(data\u001b[38;5;241m.\u001b[39medge_index, edge_attr, size)\n\u001b[0;32m---> 36\u001b[0m data\u001b[38;5;241m.\u001b[39madj \u001b[38;5;241m=\u001b[39m \u001b[43madj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m data\u001b[38;5;241m.\u001b[39medge_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     38\u001b[0m data\u001b[38;5;241m.\u001b[39medge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os.path as osp\n",
        "import time\n",
        "from math import ceil\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DenseDataLoader\n",
        "from torch_geometric.nn import DenseSAGEConv, dense_diff_pool\n",
        "max_nodes = 1500\n",
        "dataset = dataset_ENZYMES\n",
        "dataset = dataset.shuffle()\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = DenseSAGEConv(in_channels, hidden_channels, normalize)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv2 = DenseSAGEConv(hidden_channels, hidden_channels, normalize)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv3 = DenseSAGEConv(hidden_channels, out_channels, normalize)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        if lin:\n",
        "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
        "        else:\n",
        "            self.lin = None\n",
        "\n",
        "    def bn(self, i, x):\n",
        "        batch_size, num_nodes, num_channels = x.size()\n",
        "        x = x.view(-1, num_channels)\n",
        "        x = getattr(self, f'bn{i}')(x)\n",
        "        x = x.view(batch_size, num_nodes, num_channels)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, adj, mask=None):\n",
        "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
        "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
        "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
        "\n",
        "        if self.lin is not None:\n",
        "            x = self.lin(x).relu()\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Net_Diff(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        num_nodes = 64\n",
        "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
        "        self.gnn1_embed = DenseSAGEConv(dataset.num_features, 64)\n",
        "\n",
        "        num_nodes = 64\n",
        "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
        "        self.gnn2_embed = DenseSAGEConv(64, 64)\n",
        "\n",
        "        self.gnn3_embed = DenseSAGEConv(64, 64)\n",
        "\n",
        "        self.lin1 = torch.nn.Linear(64, 32)\n",
        "        self.lin2 = torch.nn.Linear(32, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, adj, mask=None):\n",
        "        s = self.gnn1_pool(x, adj, mask)\n",
        "        x = self.gnn1_embed(x, adj, mask)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x, adj, l1, e1 = dense_diff_pool(x, adj, s, mask)\n",
        "\n",
        "        s = self.gnn2_pool(x, adj)\n",
        "        x = self.gnn2_embed(x, adj)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x, adj, l2, e2 = dense_diff_pool(x, adj, s)\n",
        "\n",
        "        x = self.gnn3_embed(x, adj)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.lin1(x).relu()\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1), l1 + l2, e1 + e2\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "model = Net_Diff().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, _, _ = model(data.x, data.adj, data.mask)\n",
        "        data.y = data.y.to(torch.long)\n",
        "        loss = F.nll_loss(output, data.y.view(-1))\n",
        "        loss.backward()\n",
        "        total_loss += data.y.size(0) * float(loss)\n",
        "        optimizer.step()\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        output, _, _ = model(data.x, data.adj, data.mask)\n",
        "        pred = output.max(dim=1)[1]\n",
        "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seeds = [42, 43, 44, 45, 46]\n",
        "times = []\n",
        "memories = []\n",
        "best_val_accs = []\n",
        "best_test_accs = []\n",
        "\n",
        "early_stop_patience = 150\n",
        "tolerance = 0.0001\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    model = Net_Diff().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        val_acc = test(valid_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        if val_acc > best_val_acc + tolerance:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "        if epochs_no_improve >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
        "\n",
        "    times.append(total_time)\n",
        "    memories.append(memory_allocated)\n",
        "    best_val_accs.append(best_val_acc)\n",
        "    best_test_accs.append(best_test_acc)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
        "print(f'Var Time: {np.var(times):.2f} seconds')\n",
        "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
        "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
        "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
        "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC52hb019Kac"
      },
      "source": [
        "## Dense Mincutpooling with HierarchicalGCN (2020)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "55LL4Qqf9f3u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 001, Loss: 2.4104, Val Acc: 0.1124, Test Acc: 0.0931\n",
            "Seed: 42, Epoch: 002, Loss: 2.4047, Val Acc: 0.1150, Test Acc: 0.1018\n",
            "Seed: 42, Epoch: 003, Loss: 2.3979, Val Acc: 0.1411, Test Acc: 0.1184\n",
            "Seed: 42, Epoch: 004, Loss: 2.3877, Val Acc: 0.1742, Test Acc: 0.1584\n",
            "Seed: 42, Epoch: 005, Loss: 2.3701, Val Acc: 0.1777, Test Acc: 0.1636\n",
            "Seed: 42, Epoch: 006, Loss: 2.3413, Val Acc: 0.1760, Test Acc: 0.1610\n",
            "Seed: 42, Epoch: 007, Loss: 2.3029, Val Acc: 0.1777, Test Acc: 0.1619\n",
            "Seed: 42, Epoch: 008, Loss: 2.2583, Val Acc: 0.1777, Test Acc: 0.1636\n",
            "Seed: 42, Epoch: 009, Loss: 2.2087, Val Acc: 0.1821, Test Acc: 0.1715\n",
            "Seed: 42, Epoch: 010, Loss: 2.1681, Val Acc: 0.2047, Test Acc: 0.1897\n",
            "Seed: 42, Epoch: 011, Loss: 2.1231, Val Acc: 0.2221, Test Acc: 0.2115\n",
            "Seed: 42, Epoch: 012, Loss: 2.0769, Val Acc: 0.2308, Test Acc: 0.2237\n",
            "Seed: 42, Epoch: 013, Loss: 2.0263, Val Acc: 0.2404, Test Acc: 0.2480\n",
            "Seed: 42, Epoch: 014, Loss: 1.9740, Val Acc: 0.2317, Test Acc: 0.2272\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 150\u001b[0m\n\u001b[1;32m    147\u001b[0m epochs_no_improve \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m201\u001b[39m):\n\u001b[0;32m--> 150\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m test(valid_loader)\n\u001b[1;32m    152\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m test(test_loader)\n",
            "Cell \u001b[0;32mIn[11], line 98\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     97\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     99\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    100\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch_geometric/data/dataset.py:198\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[1;32m    197\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices()[idx])\n\u001b[0;32m--> 198\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch_geometric/transforms/compose.py:21\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     19\u001b[0m         data \u001b[38;5;241m=\u001b[39m [transform(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch_geometric/transforms/to_dense.py:36\u001b[0m, in \u001b[0;36mToDense.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     34\u001b[0m size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize([num_nodes, num_nodes] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(edge_attr\u001b[38;5;241m.\u001b[39msize())[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m     35\u001b[0m adj \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_coo_tensor(data\u001b[38;5;241m.\u001b[39medge_index, edge_attr, size)\n\u001b[0;32m---> 36\u001b[0m data\u001b[38;5;241m.\u001b[39madj \u001b[38;5;241m=\u001b[39m \u001b[43madj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m data\u001b[38;5;241m.\u001b[39medge_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     38\u001b[0m data\u001b[38;5;241m.\u001b[39medge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os.path as osp\n",
        "import time\n",
        "from math import ceil\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DenseDataLoader\n",
        "from torch_geometric.nn import DenseSAGEConv, dense_mincut_pool\n",
        "dataset = dataset_ENZYMES\n",
        "dataset = dataset.shuffle()\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = DenseSAGEConv(in_channels, hidden_channels, normalize)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv2 = DenseSAGEConv(hidden_channels, hidden_channels, normalize)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv3 = DenseSAGEConv(hidden_channels, out_channels, normalize)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        if lin:\n",
        "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
        "        else:\n",
        "            self.lin = None\n",
        "\n",
        "    def bn(self, i, x):\n",
        "        batch_size, num_nodes, num_channels = x.size()\n",
        "        x = x.view(-1, num_channels)\n",
        "        x = getattr(self, f'bn{i}')(x)\n",
        "        x = x.view(batch_size, num_nodes, num_channels)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, adj, mask=None):\n",
        "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
        "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
        "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Net_mincut(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        num_nodes = 64\n",
        "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
        "        self.gnn1_embed = DenseSAGEConv(dataset.num_features, 64)\n",
        "\n",
        "        num_nodes = 64\n",
        "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
        "        self.gnn2_embed = DenseSAGEConv(64, 64)\n",
        "\n",
        "        self.gnn3_embed = DenseSAGEConv(64, 64)\n",
        "\n",
        "        self.lin1 = torch.nn.Linear(64, 32)\n",
        "        self.lin2 = torch.nn.Linear(32, dataset.num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x, adj, mask=None):\n",
        "        s = self.gnn1_pool(x, adj, mask)\n",
        "        x = self.gnn1_embed(x, adj, mask)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x, adj, l1, e1 = dense_mincut_pool(x, adj, s, mask)\n",
        "\n",
        "        s = self.gnn2_pool(x, adj)\n",
        "        x = self.gnn2_embed(x, adj)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x, adj, l2, e2 = dense_mincut_pool(x, adj, s)\n",
        "\n",
        "        x = self.gnn3_embed(x, adj)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.lin1(x).relu()\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1), l1 + l2, e1 + e2\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "model = Net_mincut().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, _, _ = model(data.x, data.adj, data.mask)\n",
        "        data.y = data.y.to(torch.long)\n",
        "        loss = F.nll_loss(output, data.y.view(-1))\n",
        "        loss.backward()\n",
        "        total_loss += data.y.size(0) * float(loss)\n",
        "        optimizer.step()\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        output, _, _ = model(data.x, data.adj, data.mask)\n",
        "        pred = output.max(dim=1)[1]\n",
        "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seeds = [42, 43, 44, 45, 46]\n",
        "times = []\n",
        "memories = []\n",
        "best_val_accs = []\n",
        "best_test_accs = []\n",
        "\n",
        "early_stop_patience = 150\n",
        "tolerance = 0.0001\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    model = Net_mincut().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        val_acc = test(valid_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        if val_acc > best_val_acc + tolerance:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "        if epochs_no_improve >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
        "\n",
        "    times.append(total_time)\n",
        "    memories.append(memory_allocated)\n",
        "    best_val_accs.append(best_val_acc)\n",
        "    best_test_accs.append(best_test_acc)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
        "print(f'Var Time: {np.var(times):.2f} seconds')\n",
        "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
        "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
        "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
        "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wR5zL9d_DXT"
      },
      "source": [
        "## Dense DMoNPooling with HierarchicalGCN (2023)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WSJT58iz_RWM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 001, Loss: 2.3986, Val Acc: 0.0949, Test Acc: 0.0896\n",
            "Seed: 42, Epoch: 002, Loss: 2.3963, Val Acc: 0.0976, Test Acc: 0.0914\n",
            "Seed: 42, Epoch: 003, Loss: 2.3941, Val Acc: 0.0976, Test Acc: 0.0914\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 155\u001b[0m\n\u001b[1;32m    152\u001b[0m epochs_no_improve \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m201\u001b[39m):\n\u001b[0;32m--> 155\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m test(valid_loader)\n\u001b[1;32m    157\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m test(test_loader)\n",
            "Cell \u001b[0;32mIn[12], line 103\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    102\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    104\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    105\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch_geometric/data/dataset.py:198\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[1;32m    197\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices()[idx])\n\u001b[0;32m--> 198\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch_geometric/transforms/compose.py:21\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     19\u001b[0m         data \u001b[38;5;241m=\u001b[39m [transform(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch_geometric/transforms/to_dense.py:36\u001b[0m, in \u001b[0;36mToDense.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     34\u001b[0m size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize([num_nodes, num_nodes] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(edge_attr\u001b[38;5;241m.\u001b[39msize())[\u001b[38;5;241m1\u001b[39m:])\n\u001b[1;32m     35\u001b[0m adj \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_coo_tensor(data\u001b[38;5;241m.\u001b[39medge_index, edge_attr, size)\n\u001b[0;32m---> 36\u001b[0m data\u001b[38;5;241m.\u001b[39madj \u001b[38;5;241m=\u001b[39m \u001b[43madj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m data\u001b[38;5;241m.\u001b[39medge_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     38\u001b[0m data\u001b[38;5;241m.\u001b[39medge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os.path as osp\n",
        "import time\n",
        "from math import ceil\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DenseDataLoader\n",
        "from torch_geometric.nn import DenseSAGEConv, DMoNPooling\n",
        "\n",
        "dataset = dataset_ENZYMES\n",
        "dataset = dataset.shuffle()\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = DenseSAGEConv(in_channels, hidden_channels, normalize)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv2 = DenseSAGEConv(hidden_channels, hidden_channels, normalize)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv3 = DenseSAGEConv(hidden_channels, out_channels, normalize)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        if lin:\n",
        "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
        "        else:\n",
        "            self.lin = None\n",
        "\n",
        "    def bn(self, i, x):\n",
        "        batch_size, num_nodes, num_channels = x.size()\n",
        "        x = x.view(-1, num_channels)\n",
        "        x = getattr(self, f'bn{i}')(x)\n",
        "        x = x.view(batch_size, num_nodes, num_channels)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, adj, mask=None):\n",
        "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
        "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
        "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
        "\n",
        "        if self.lin is not None:\n",
        "            x = self.lin(x).relu()\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Net_DMoN(torch.nn.Module):\n",
        "    def __init__(self, in_channels=dataset.num_features, out_channels=64, hidden_channels=64):\n",
        "        super().__init__()\n",
        "\n",
        "        num_nodes = 64\n",
        "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
        "        self.pool1 = DMoNPooling([hidden_channels, hidden_channels], num_nodes)\n",
        "\n",
        "        num_nodes = 64\n",
        "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
        "        self.pool2 = DMoNPooling([hidden_channels, hidden_channels], num_nodes)\n",
        "\n",
        "        self.gnn1_embed = DenseSAGEConv(dataset.num_features, 64)\n",
        "        self.gnn2_embed = DenseSAGEConv(64, 64)\n",
        "        self.gnn3_embed = DenseSAGEConv(64, 64)\n",
        "\n",
        "        self.lin1 = torch.nn.Linear(64, 32)\n",
        "        self.lin2 = torch.nn.Linear(32, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, adj, mask=None):\n",
        "        s = self.gnn1_pool(x, adj, mask)\n",
        "        x = self.gnn1_embed(x, adj, mask)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        _, x, adj, sp1, o1, c1 = self.pool1(x, adj, mask)\n",
        "\n",
        "        s = self.gnn2_pool(x, adj)\n",
        "        x = self.gnn2_embed(x, adj)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        _, x, adj, sp2, o2, c2 = self.pool2(x, adj)\n",
        "\n",
        "        x = self.gnn3_embed(x, adj)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.lin1(x).relu()\n",
        "        x = self.lin2(x)\n",
        "        return F.log_softmax(x, dim=-1), sp1 + sp2 + o1 + o2 + c1 + c2\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "model = Net_DMoN().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output, _ = model(data.x, data.adj, data.mask)\n",
        "        data.y = data.y.to(torch.long)\n",
        "        loss = F.nll_loss(output, data.y.view(-1))\n",
        "        loss.backward()\n",
        "        total_loss += data.y.size(0) * float(loss)\n",
        "        optimizer.step()\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        output, _ = model(data.x, data.adj, data.mask)\n",
        "        pred = output.max(dim=1)[1]\n",
        "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seeds = [42, 43, 44, 45, 46]\n",
        "times = []\n",
        "memories = []\n",
        "best_val_accs = []\n",
        "best_test_accs = []\n",
        "\n",
        "early_stop_patience = 150\n",
        "tolerance = 0.0001\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    model = Net_DMoN().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        val_acc = test(valid_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        if val_acc > best_val_acc + tolerance:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "        if epochs_no_improve >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
        "\n",
        "    times.append(total_time)\n",
        "    memories.append(memory_allocated)\n",
        "    best_val_accs.append(best_val_acc)\n",
        "    best_test_accs.append(best_test_acc)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
        "print(f'Var Time: {np.var(times):.2f} seconds')\n",
        "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
        "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
        "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
        "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHh_t_QXnhA8"
      },
      "source": [
        "## Dense HoscPooling with HierarchicalGCN (2022)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Pf2WWOQenfKx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "EPS = 1e-15\n",
        "\n",
        "\n",
        "def dense_hoscpool(\n",
        "    x,\n",
        "    adj,\n",
        "    s,\n",
        "    mu=0.1,\n",
        "    alpha=0.5,\n",
        "    new_ortho=False,\n",
        "    mask=None,\n",
        "):\n",
        "    r\"\"\"The highe-order pooling operator (HoscPool) from the paper\n",
        "    `\"Higher-order clustering and pooling for Graph Neural Networks\"\n",
        "    <http://arxiv.org/abs/2209.03473>`_. Based on motif spectral clustering,\n",
        "    it captures and combines different levels of higher-order connectivity\n",
        "    patterns when coarsening the graph.\n",
        "    .. math::\n",
        "        \\mathbf{X}^{\\prime} &= {\\mathrm{softmax}(\\mathbf{S})}^{\\top} \\cdot\n",
        "        \\mathbf{X}\n",
        "        \\mathbf{A}^{\\prime} &= {\\mathrm{softmax}(\\mathbf{S})}^{\\top} \\cdot\n",
        "        \\mathbf{A} \\cdot \\mathrm{softmax}(\\mathbf{S})\n",
        "    based on the learned cluster assignment matrix :math:`\\mathbf{S} \\in \\mathbb{R}^{B\n",
        "    \\times N \\times K}`. This function returns the pooled feature matrix, the coarsened\n",
        "    symmetrically normalised adjacency matrix, the motif spectral clustering loss :math:`\\mathcal{L}_{mc}`\n",
        "    and the orthogonality loss :math:`\\mathcal{L}_{o}`.\n",
        "    .. math::\n",
        "        \\mathcal{L}_{mc} &= - \\frac{\\alpha_1}{K} \\cdot \\text{Tr}\\bigg(\\frac{\\mathbf{S}^\\top \\mathbf{A} \\mathbf{S}}\n",
        "            {\\mathbf{S}^\\top\\mathbf{D}\\mathbf{S}}\\bigg) - \\frac{\\alpha_2}{K} \\cdot \\text{Tr}\\bigg(\n",
        "                \\frac{\\mathbf{S}^\\top\\mathbf{A}_{M}\\mathbf{S}}{\\mathbf{S}^\\top\\mathbf{D}_{M}\\mathbf{S}}\\bigg).\n",
        "        \\mathcal{L}_o &= \\frac{1}{\\sqrt{K}-1} \\bigg( \\sqrt{K} - \\frac{1}{\\sqrt{N}}\\sum_{j=1}^K ||S_{*j}||_F\\bigg)\n",
        "    Args:\n",
        "        x (Tensor): Node feature tensor :math:`\\mathbf{X} \\in \\mathbb{R}^{B\n",
        "            \\times N \\times F}` with batch-size :math:`B`, (maximum)\n",
        "            number of nodes :math:`N` for each graph, and feature dimension\n",
        "            :math:`F`.\n",
        "        adj (Tensor): adjacency matrix :math:`\\mathbf{A} \\in \\mathbb{R}^{B \\times N \\times N}`.\n",
        "        s (Tensor): the learnable cluster assignment matrix :math:`\\mathbf{S} \\in \\mathbb{R}^{B\n",
        "            \\times N \\times K}` with number of clusters :math:`K`. The softmax\n",
        "            does not have to be applied beforehand, since it is executed\n",
        "            within this method.\n",
        "        mu (Tensor, optional): scalar that controls the importance given to regularization loss\n",
        "        alpha (Tensor, optional): scalar in [0,1] controlling the importance granted\n",
        "            to higher-order information (in loss function).\n",
        "        new_ortho (BoolTensor, optional): either to use new proposed loss or old one\n",
        "        mask (BoolTensor, optional): Mask matrix\n",
        "            :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}` indicating\n",
        "            the valid nodes for each graph. (default: :obj:`None`)\n",
        "    :rtype: (:class:`Tensor`, :class:`Tensor`, :class:`Tensor`,\n",
        "        :class:`Tensor`)\n",
        "    \"\"\"\n",
        "    x = x.unsqueeze(0) if x.dim() == 2 else x\n",
        "    adj = adj.unsqueeze(0) if adj.dim() == 2 else adj\n",
        "    s = s.unsqueeze(0) if s.dim() == 2 else s\n",
        "\n",
        "    (batch_size, num_nodes, _), k = x.size(), s.size(-1)\n",
        "\n",
        "    s = torch.softmax(s, dim=-1)\n",
        "\n",
        "    if mask is not None:\n",
        "        mask = mask.view(batch_size, num_nodes, 1).to(x.dtype)\n",
        "        x, s = x * mask, s * mask\n",
        "\n",
        "    # Output adjacency and feature matrices\n",
        "    out = torch.matmul(s.transpose(1, 2), x)\n",
        "    out_adj = torch.matmul(torch.matmul(s.transpose(1, 2), adj), s)\n",
        "\n",
        "    # Motif adj matrix - not sym. normalised\n",
        "    motif_adj = torch.mul(torch.matmul(adj, adj), adj)\n",
        "    motif_out_adj = torch.matmul(torch.matmul(s.transpose(1, 2), motif_adj), s)\n",
        "\n",
        "    mincut_loss = ho_mincut_loss = 0\n",
        "    # 1st order MinCUT loss\n",
        "    if alpha < 1:\n",
        "        diag_SAS = torch.einsum(\"ijj->ij\", out_adj.clone())\n",
        "        d_flat = torch.einsum(\"ijk->ij\", adj.clone())\n",
        "        d = _rank3_diag(d_flat)\n",
        "        sds = torch.matmul(torch.matmul(s.transpose(1, 2), d), s)\n",
        "        diag_SDS = torch.einsum(\"ijk->ij\", sds) + EPS\n",
        "        mincut_loss = -torch.sum(diag_SAS / diag_SDS, axis=1)\n",
        "        mincut_loss = 1 / k * torch.mean(mincut_loss)\n",
        "\n",
        "    # Higher order cut\n",
        "    if alpha > 0:\n",
        "        diag_SAS = torch.einsum(\"ijj->ij\", motif_out_adj)\n",
        "        d_flat = torch.einsum(\"ijk->ij\", motif_adj)\n",
        "        d = _rank3_diag(d_flat)\n",
        "        diag_SDS = (torch.einsum(\n",
        "            \"ijk->ij\", torch.matmul(torch.matmul(s.transpose(1, 2), d), s)) +\n",
        "                    EPS)\n",
        "        ho_mincut_loss = -torch.sum(diag_SAS / diag_SDS, axis=1)\n",
        "        ho_mincut_loss = 1 / k * torch.mean(ho_mincut_loss)\n",
        "\n",
        "    # Combine ho and fo mincut loss.\n",
        "    # We do not learn these coefficients yet\n",
        "    hosc_loss = (1 - alpha) * mincut_loss + alpha * ho_mincut_loss\n",
        "\n",
        "    # Orthogonality loss\n",
        "    if mu == 0:\n",
        "        ortho_loss = torch.tensor(0)\n",
        "    else:\n",
        "        if new_ortho:\n",
        "            if s.shape[0] == 1:\n",
        "                ortho_loss = ((-torch.sum(torch.norm(s, p=\"fro\", dim=-2)) /\n",
        "                               (num_nodes**0.5)) + k**0.5) / (k**0.5 - 1)\n",
        "            elif mask != None:\n",
        "                ortho_loss = sum([((-torch.sum(\n",
        "                    torch.norm(\n",
        "                        s[i][:mask[i].nonzero().shape[0]],\n",
        "                        p=\"fro\",\n",
        "                        dim=-2,\n",
        "                    )) / (mask[i].nonzero().shape[0]**0.5) + k**0.5) /\n",
        "                                   (k**0.5 - 1)) for i in range(batch_size)\n",
        "                                  ]) / float(batch_size)\n",
        "            else:\n",
        "                ortho_loss = sum(\n",
        "                    [((-torch.sum(torch.norm(s[i], p=\"fro\", dim=-2)) /\n",
        "                       (num_nodes**0.5) + k**0.5) / (k**0.5 - 1))\n",
        "                     for i in range(batch_size)]) / float(batch_size)\n",
        "        else:\n",
        "            # Orthogonality regularization.\n",
        "            ss = torch.matmul(s.transpose(1, 2), s)\n",
        "            i_s = torch.eye(k).type_as(ss)\n",
        "            ortho_loss = torch.norm(\n",
        "                ss / torch.norm(ss, dim=(-1, -2), keepdim=True) -\n",
        "                i_s / torch.norm(i_s),\n",
        "                dim=(-1, -2),\n",
        "            )\n",
        "            ortho_loss = torch.mean(ortho_loss)\n",
        "\n",
        "    # Fix and normalize coarsened adjacency matrix.\n",
        "    ind = torch.arange(k, device=out_adj.device)\n",
        "    out_adj[:, ind, ind] = 0\n",
        "    d = torch.einsum(\"ijk->ij\", out_adj)\n",
        "    d = torch.sqrt(d + EPS)[:, None]\n",
        "    out_adj = (out_adj / d) / d.transpose(1, 2)\n",
        "\n",
        "    return out, out_adj, hosc_loss, mu * ortho_loss\n",
        "\n",
        "\n",
        "def _rank3_diag(x):\n",
        "    eye = torch.eye(x.size(1)).type_as(x)\n",
        "    out = eye * x.unsqueeze(2).expand(*x.size(), x.size(1))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "46BZT1skoA3U"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seed: 42, Epoch: 001, Loss: 2.4105, Val Acc: 0.1115, Test Acc: 0.0914\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 155\u001b[0m\n\u001b[1;32m    152\u001b[0m epochs_no_improve \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m201\u001b[39m):\n\u001b[0;32m--> 155\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m test(valid_loader)\n\u001b[1;32m    157\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m test(test_loader)\n",
            "Cell \u001b[0;32mIn[14], line 103\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    102\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    104\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    105\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch_geometric/data/dataset.py:198\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[1;32m    197\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices()[idx])\n\u001b[0;32m--> 198\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch_geometric/transforms/compose.py:21\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     19\u001b[0m         data \u001b[38;5;241m=\u001b[39m [transform(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch_geometric/transforms/to_dense.py:35\u001b[0m, in \u001b[0;36mToDense.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     32\u001b[0m     edge_attr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39medge_attr\n\u001b[1;32m     34\u001b[0m size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize([num_nodes, num_nodes] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(edge_attr\u001b[38;5;241m.\u001b[39msize())[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m---> 35\u001b[0m adj \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_coo_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m data\u001b[38;5;241m.\u001b[39madj \u001b[38;5;241m=\u001b[39m adj\u001b[38;5;241m.\u001b[39mto_dense()\n\u001b[1;32m     37\u001b[0m data\u001b[38;5;241m.\u001b[39medge_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os.path as osp\n",
        "import time\n",
        "from math import ceil\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DenseDataLoader\n",
        "from torch_geometric.nn import DenseSAGEConv, dense_diff_pool\n",
        "max_nodes = 1500\n",
        "dataset = dataset_ENZYMES\n",
        "dataset = dataset.shuffle()\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = DenseSAGEConv(in_channels, hidden_channels, normalize)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv2 = DenseSAGEConv(hidden_channels, hidden_channels, normalize)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv3 = DenseSAGEConv(hidden_channels, out_channels, normalize)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        if lin:\n",
        "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
        "        else:\n",
        "            self.lin = None\n",
        "\n",
        "    def bn(self, i, x):\n",
        "        batch_size, num_nodes, num_channels = x.size()\n",
        "        x = x.view(-1, num_channels)\n",
        "        x = getattr(self, f'bn{i}')(x)\n",
        "        x = x.view(batch_size, num_nodes, num_channels)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, adj, mask=None):\n",
        "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
        "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
        "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
        "\n",
        "        if self.lin is not None:\n",
        "            x = self.lin(x).relu()\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Net_Hosc(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        num_nodes = 64\n",
        "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
        "\n",
        "        num_nodes = 64\n",
        "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
        "\n",
        "        self.gnn1_embed = DenseSAGEConv(dataset.num_features, 64)\n",
        "        self.gnn2_embed = DenseSAGEConv(64, 64)\n",
        "        self.gnn3_embed = DenseSAGEConv(64, 64)\n",
        "\n",
        "        self.lin1 = torch.nn.Linear(64, 32)\n",
        "        self.lin2 = torch.nn.Linear(32, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, adj, mask=None):\n",
        "        s = self.gnn1_pool(x, adj, mask)\n",
        "        x = self.gnn1_embed(x, adj, mask)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x, adj, mc, o = dense_hoscpool(x, adj, s, mu=0.1, alpha=0.5, new_ortho=False, mask=mask)\n",
        "\n",
        "        s = self.gnn2_pool(x, adj)\n",
        "        x = self.gnn2_embed(x, adj)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x, adj, mc_aux, o_aux = dense_hoscpool(x, adj, s, mu=0.1, alpha=0.5, new_ortho=False)\n",
        "\n",
        "        x = self.gnn3_embed(x, adj)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.lin1(x).relu()\n",
        "        x = self.lin2(x)\n",
        "        output = F.log_softmax(x, dim=-1)\n",
        "        #print(f\"Model output shape: {output.shape}\")\n",
        "        return output\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "model = Net_Hosc().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.x, data.adj, data.mask)\n",
        "        data.y = data.y.to(torch.long)\n",
        "        loss = F.nll_loss(output, data.y.view(-1))\n",
        "        loss.backward()\n",
        "        total_loss += data.y.size(0) * float(loss)\n",
        "        optimizer.step()\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        output = model(data.x, data.adj, data.mask)\n",
        "        pred = output.max(dim=1)[1]\n",
        "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seeds = [42, 43, 44, 45, 46]\n",
        "times = []\n",
        "memories = []\n",
        "best_val_accs = []\n",
        "best_test_accs = []\n",
        "\n",
        "early_stop_patience = 150\n",
        "tolerance = 0.0001\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    model = Net_Hosc().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        val_acc = test(valid_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        if val_acc > best_val_acc + tolerance:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "        if epochs_no_improve >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
        "\n",
        "    times.append(total_time)\n",
        "    memories.append(memory_allocated)\n",
        "    best_val_accs.append(best_val_acc)\n",
        "    best_test_accs.append(best_test_acc)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
        "print(f'Var Time: {np.var(times):.2f} seconds')\n",
        "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
        "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
        "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
        "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYPVvPvdT1B3"
      },
      "source": [
        "## Dense JustBalancePooling with HierarchicalGCN (2023)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "F57JezxfU1W_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "EPS = 1e-15\n",
        "\n",
        "\n",
        "def just_balance_pool(x, adj, s, mask=None, normalize=True):\n",
        "    r\"\"\"The Just Balance pooling operator from the `\"Simplifying Clustering with\n",
        "    Graph Neural Networks\" <https://arxiv.org/abs/2207.08779>`_ paper\n",
        "\n",
        "    .. math::\n",
        "        \\mathbf{X}^{\\prime} &= {\\mathrm{softmax}(\\mathbf{S})}^{\\top} \\cdot\n",
        "        \\mathbf{X}\n",
        "\n",
        "        \\mathbf{A}^{\\prime} &= {\\mathrm{softmax}(\\mathbf{S})}^{\\top} \\cdot\n",
        "        \\mathbf{A} \\cdot \\mathrm{softmax}(\\mathbf{S})\n",
        "\n",
        "    based on dense learned assignments :math:`\\mathbf{S} \\in \\mathbb{R}^{B\n",
        "    \\times N \\times C}`.\n",
        "    Returns the pooled node feature matrix, the coarsened and symmetrically\n",
        "    normalized adjacency matrix and the following auxiliary objective:\n",
        "\n",
        "    .. math::\n",
        "        \\mathcal{L} = - {\\mathrm{Tr}(\\sqrt{\\mathbf{S}^{\\top} \\mathbf{S}})}\n",
        "\n",
        "    Args:\n",
        "        x (Tensor): Node feature tensor :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times N \\times F}`\n",
        "            with batch-size :math:`B`, (maximum) number of nodes :math:`N`\n",
        "            for each graph, and feature dimension :math:`F`.\n",
        "        adj (Tensor): Symmetrically normalized adjacency tensor\n",
        "            :math:`\\mathbf{A} \\in \\mathbb{R}^{B \\times N \\times N}`.\n",
        "        s (Tensor): Assignment tensor :math:`\\mathbf{S} \\in \\mathbb{R}^{B \\times N \\times C}`\n",
        "            with number of clusters :math:`C`. The softmax does not have to be\n",
        "            applied beforehand, since it is executed within this method.\n",
        "        mask (BoolTensor, optional): Mask matrix\n",
        "            :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}` indicating\n",
        "            the valid nodes for each graph. (default: :obj:`None`)\n",
        "\n",
        "    :rtype: (:class:`Tensor`, :class:`Tensor`, :class:`Tensor`,\n",
        "        :class:`Tensor`)\n",
        "    \"\"\"\n",
        "\n",
        "    x = x.unsqueeze(0) if x.dim() == 2 else x\n",
        "    adj = adj.unsqueeze(0) if adj.dim() == 2 else adj\n",
        "    s = s.unsqueeze(0) if s.dim() == 2 else s\n",
        "\n",
        "    (batch_size, num_nodes, _), k = x.size(), s.size(-1)\n",
        "\n",
        "    s = torch.softmax(s, dim=-1)\n",
        "\n",
        "    if mask is not None:\n",
        "        mask = mask.view(batch_size, num_nodes, 1).to(x.dtype)\n",
        "        x, s = x * mask, s * mask\n",
        "\n",
        "    out = torch.matmul(s.transpose(1, 2), x)\n",
        "    out_adj = torch.matmul(torch.matmul(s.transpose(1, 2), adj), s)\n",
        "\n",
        "    # Loss\n",
        "    ss = torch.matmul(s.transpose(1, 2), s)\n",
        "    ss_sqrt = torch.sqrt(ss + EPS)\n",
        "    loss = torch.mean(-_rank3_trace(ss_sqrt))\n",
        "    if normalize:\n",
        "        loss = loss / torch.sqrt(torch.tensor(num_nodes * k))\n",
        "\n",
        "    # Fix and normalize coarsened adjacency matrix.\n",
        "    ind = torch.arange(k, device=out_adj.device)\n",
        "    out_adj[:, ind, ind] = 0\n",
        "    d = torch.einsum('ijk->ij', out_adj)\n",
        "    d = torch.sqrt(d)[:, None] + EPS\n",
        "    out_adj = (out_adj / d) / d.transpose(1, 2)\n",
        "\n",
        "    return out, out_adj, loss\n",
        "\n",
        "\n",
        "def _rank3_trace(x):\n",
        "    return torch.einsum('ijj->i', x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VIgmBDN4Vu-X"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "\"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 155\u001b[0m\n\u001b[1;32m    152\u001b[0m epochs_no_improve \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m201\u001b[39m):\n\u001b[0;32m--> 155\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     val_acc \u001b[38;5;241m=\u001b[39m test(valid_loader)\n\u001b[1;32m    157\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m test(test_loader)\n",
            "Cell \u001b[0;32mIn[16], line 107\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    106\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39madj, data\u001b[38;5;241m.\u001b[39mmask)\n\u001b[0;32m--> 107\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    109\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mfloat\u001b[39m(loss)\n",
            "File \u001b[0;32m~/anaconda3/envs/CG-ODE/lib/python3.9/site-packages/torch/nn/functional.py:2671\u001b[0m, in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2670\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnll_loss_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: \"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'"
          ]
        }
      ],
      "source": [
        "import os.path as osp\n",
        "import time\n",
        "from math import ceil\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DenseDataLoader\n",
        "from torch_geometric.nn import DenseSAGEConv, dense_diff_pool\n",
        "\n",
        "dataset = dataset_ENZYMES\n",
        "dataset = dataset.shuffle()\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = DenseSAGEConv(in_channels, hidden_channels, normalize)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv2 = DenseSAGEConv(hidden_channels, hidden_channels, normalize)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
        "        self.conv3 = DenseSAGEConv(hidden_channels, out_channels, normalize)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        if lin:\n",
        "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
        "        else:\n",
        "            self.lin = None\n",
        "\n",
        "    def bn(self, i, x):\n",
        "        batch_size, num_nodes, num_channels = x.size()\n",
        "        x = x.view(-1, num_channels)\n",
        "        x = getattr(self, f'bn{i}')(x)\n",
        "        x = x.view(batch_size, num_nodes, num_channels)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, adj, mask=None):\n",
        "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
        "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
        "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
        "\n",
        "        if self.lin is not None:\n",
        "            x = self.lin(x).relu()\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Net_JustBalance(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        num_nodes = 64\n",
        "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
        "\n",
        "        num_nodes = 64\n",
        "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
        "\n",
        "        self.gnn1_embed = DenseSAGEConv(dataset.num_features, 64)\n",
        "        self.gnn2_embed = DenseSAGEConv(64, 64)\n",
        "        self.gnn3_embed = DenseSAGEConv(64, 64)\n",
        "\n",
        "        self.lin1 = torch.nn.Linear(64, 32)\n",
        "        self.lin2 = torch.nn.Linear(32, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, adj, mask=None):\n",
        "        s = self.gnn1_pool(x, adj, mask)\n",
        "        x = self.gnn1_embed(x, adj, mask)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
        "\n",
        "        s = self.gnn2_pool(x, adj)\n",
        "        x = self.gnn2_embed(x, adj)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x, adj, b_loss = just_balance_pool(x, adj, s)\n",
        "\n",
        "        x = self.gnn3_embed(x, adj)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.lin1(x).relu()\n",
        "        x = self.lin2(x)\n",
        "        output = F.log_softmax(x, dim=-1)\n",
        "        #print(f\"Model output shape: {output.shape}\")\n",
        "        return output\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "model = Net_JustBalance().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data.x, data.adj, data.mask)\n",
        "        loss = F.nll_loss(output, data.y.view(-1))\n",
        "        loss.backward()\n",
        "        total_loss += data.y.size(0) * float(loss)\n",
        "        optimizer.step()\n",
        "    return total_loss / len(train_loader.dataset)\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        data.y = data.y.to(torch.long)\n",
        "        output = model(data.x, data.adj, data.mask)\n",
        "        pred = output.max(dim=1)[1]\n",
        "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seeds = [42, 43, 44, 45, 46]\n",
        "times = []\n",
        "memories = []\n",
        "best_val_accs = []\n",
        "best_test_accs = []\n",
        "\n",
        "early_stop_patience = 150\n",
        "tolerance = 0.0001\n",
        "\n",
        "for seed in seeds:\n",
        "    set_seed(seed)\n",
        "    model = Net_JustBalance().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    best_val_acc = 0\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, 201):\n",
        "        loss = train()\n",
        "        val_acc = test(valid_loader)\n",
        "        test_acc = test(test_loader)\n",
        "        if val_acc > best_val_acc + tolerance:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "        if epochs_no_improve >= early_stop_patience:\n",
        "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
        "\n",
        "    times.append(total_time)\n",
        "    memories.append(memory_allocated)\n",
        "    best_val_accs.append(best_val_acc)\n",
        "    best_test_accs.append(best_test_acc)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
        "print(f'Var Time: {np.var(times):.2f} seconds')\n",
        "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
        "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
        "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
        "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
