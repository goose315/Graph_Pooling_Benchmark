{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boot/anaconda3/envs/XXX1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import sys\n",
    "import torch\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from typing import Optional\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data.datapipes import functional_transform\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.datasets import WebKB\n",
    "from torch_geometric.datasets import Actor\n",
    "from torch_geometric.datasets import GNNBenchmarkDataset\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from sklearn.metrics import r2_score\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch.nn import Linear\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "from torch_sparse import spspmm\n",
    "from torch_sparse import coalesce\n",
    "from torch_sparse import eye\n",
    "from torch.nn import Parameter\n",
    "from torch_scatter import scatter_add\n",
    "from torch_scatter import scatter_max\n",
    "\n",
    "from torch_scatter import scatter_add, scatter\n",
    "from torch_geometric.nn.inits import uniform\n",
    "from torch_geometric.nn.resolver import activation_resolver\n",
    "from torch_geometric.nn import GCNConv, GATConv, LEConv, SAGEConv, GraphConv\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.utils import add_remaining_self_loops, to_dense_adj, add_self_loops\n",
    "from typing import Callable, Optional, Union\n",
    "from torch_sparse import coalesce, transpose\n",
    "from torch_scatter import scatter\n",
    "from torch import Tensor\n",
    "\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import math\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch_geometric.nn.models.mlp import Linear\n",
    "from torch_geometric.nn.resolver import activation_resolver\n",
    "from torch_geometric.nn import BatchNorm\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_mincut_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "EPS = 1e-15\n",
    "\n",
    "\n",
    "def dense_hoscpool(\n",
    "    x,\n",
    "    adj,\n",
    "    s,\n",
    "    mu=0.1,\n",
    "    alpha=0.5,\n",
    "    new_ortho=False,\n",
    "    mask=None,\n",
    "):\n",
    "    r\"\"\"The highe-order pooling operator (HoscPool) from the paper\n",
    "    `\"Higher-order clustering and pooling for Graph Neural Networks\"\n",
    "    <http://arxiv.org/abs/2209.03473>`_. Based on motif spectral clustering,\n",
    "    it captures and combines different levels of higher-order connectivity\n",
    "    patterns when coarsening the graph.\n",
    "    .. math::\n",
    "        \\mathbf{X}^{\\prime} &= {\\mathrm{softmax}(\\mathbf{S})}^{\\top} \\cdot\n",
    "        \\mathbf{X}\n",
    "        \\mathbf{A}^{\\prime} &= {\\mathrm{softmax}(\\mathbf{S})}^{\\top} \\cdot\n",
    "        \\mathbf{A} \\cdot \\mathrm{softmax}(\\mathbf{S})\n",
    "    based on the learned cluster assignment matrix :math:`\\mathbf{S} \\in \\mathbb{R}^{B\n",
    "    \\times N \\times K}`. This function returns the pooled feature matrix, the coarsened\n",
    "    symmetrically normalised adjacency matrix, the motif spectral clustering loss :math:`\\mathcal{L}_{mc}`\n",
    "    and the orthogonality loss :math:`\\mathcal{L}_{o}`.\n",
    "    .. math::\n",
    "        \\mathcal{L}_{mc} &= - \\frac{\\alpha_1}{K} \\cdot \\text{Tr}\\bigg(\\frac{\\mathbf{S}^\\top \\mathbf{A} \\mathbf{S}}\n",
    "            {\\mathbf{S}^\\top\\mathbf{D}\\mathbf{S}}\\bigg) - \\frac{\\alpha_2}{K} \\cdot \\text{Tr}\\bigg(\n",
    "                \\frac{\\mathbf{S}^\\top\\mathbf{A}_{M}\\mathbf{S}}{\\mathbf{S}^\\top\\mathbf{D}_{M}\\mathbf{S}}\\bigg).\n",
    "        \\mathcal{L}_o &= \\frac{1}{\\sqrt{K}-1} \\bigg( \\sqrt{K} - \\frac{1}{\\sqrt{N}}\\sum_{j=1}^K ||S_{*j}||_F\\bigg)\n",
    "    Args:\n",
    "        x (Tensor): Node feature tensor :math:`\\mathbf{X} \\in \\mathbb{R}^{B\n",
    "            \\times N \\times F}` with batch-size :math:`B`, (maximum)\n",
    "            number of nodes :math:`N` for each graph, and feature dimension\n",
    "            :math:`F`.\n",
    "        adj (Tensor): adjacency matrix :math:`\\mathbf{A} \\in \\mathbb{R}^{B \\times N \\times N}`.\n",
    "        s (Tensor): the learnable cluster assignment matrix :math:`\\mathbf{S} \\in \\mathbb{R}^{B\n",
    "            \\times N \\times K}` with number of clusters :math:`K`. The softmax\n",
    "            does not have to be applied beforehand, since it is executed\n",
    "            within this method.\n",
    "        mu (Tensor, optional): scalar that controls the importance given to regularization loss\n",
    "        alpha (Tensor, optional): scalar in [0,1] controlling the importance granted\n",
    "            to higher-order information (in loss function).\n",
    "        new_ortho (BoolTensor, optional): either to use new proposed loss or old one\n",
    "        mask (BoolTensor, optional): Mask matrix\n",
    "            :math:`\\mathbf{M} \\in {\\{ 0, 1 \\}}^{B \\times N}` indicating\n",
    "            the valid nodes for each graph. (default: :obj:`None`)\n",
    "    :rtype: (:class:`Tensor`, :class:`Tensor`, :class:`Tensor`,\n",
    "        :class:`Tensor`)\n",
    "    \"\"\"\n",
    "    x = x.unsqueeze(0) if x.dim() == 2 else x\n",
    "    adj = adj.unsqueeze(0) if adj.dim() == 2 else adj\n",
    "    s = s.unsqueeze(0) if s.dim() == 2 else s\n",
    "\n",
    "    (batch_size, num_nodes, _), k = x.size(), s.size(-1)\n",
    "\n",
    "    s = torch.softmax(s, dim=-1)\n",
    "\n",
    "    if mask is not None:\n",
    "        mask = mask.view(batch_size, num_nodes, 1).to(x.dtype)\n",
    "        x, s = x * mask, s * mask\n",
    "\n",
    "    # Output adjacency and feature matrices\n",
    "    out = torch.matmul(s.transpose(1, 2), x)\n",
    "    out_adj = torch.matmul(torch.matmul(s.transpose(1, 2), adj), s)\n",
    "\n",
    "    # Motif adj matrix - not sym. normalised\n",
    "    motif_adj = torch.mul(torch.matmul(adj, adj), adj)\n",
    "    motif_out_adj = torch.matmul(torch.matmul(s.transpose(1, 2), motif_adj), s)\n",
    "\n",
    "    mincut_loss = ho_mincut_loss = 0\n",
    "    # 1st order MinCUT loss\n",
    "    if alpha < 1:\n",
    "        diag_SAS = torch.einsum(\"ijj->ij\", out_adj.clone())\n",
    "        d_flat = torch.einsum(\"ijk->ij\", adj.clone())\n",
    "        d = _rank3_diag(d_flat)\n",
    "        sds = torch.matmul(torch.matmul(s.transpose(1, 2), d), s)\n",
    "        diag_SDS = torch.einsum(\"ijk->ij\", sds) + EPS\n",
    "        mincut_loss = -torch.sum(diag_SAS / diag_SDS, axis=1)\n",
    "        mincut_loss = 1 / k * torch.mean(mincut_loss)\n",
    "\n",
    "    # Higher order cut\n",
    "    if alpha > 0:\n",
    "        diag_SAS = torch.einsum(\"ijj->ij\", motif_out_adj)\n",
    "        d_flat = torch.einsum(\"ijk->ij\", motif_adj)\n",
    "        d = _rank3_diag(d_flat)\n",
    "        diag_SDS = (torch.einsum(\n",
    "            \"ijk->ij\", torch.matmul(torch.matmul(s.transpose(1, 2), d), s)) +\n",
    "                    EPS)\n",
    "        ho_mincut_loss = -torch.sum(diag_SAS / diag_SDS, axis=1)\n",
    "        ho_mincut_loss = 1 / k * torch.mean(ho_mincut_loss)\n",
    "\n",
    "    # Combine ho and fo mincut loss.\n",
    "    # We do not learn these coefficients yet\n",
    "    hosc_loss = (1 - alpha) * mincut_loss + alpha * ho_mincut_loss\n",
    "\n",
    "    # Orthogonality loss\n",
    "    if mu == 0:\n",
    "        ortho_loss = torch.tensor(0)\n",
    "    else:\n",
    "        if new_ortho:\n",
    "            if s.shape[0] == 1:\n",
    "                ortho_loss = ((-torch.sum(torch.norm(s, p=\"fro\", dim=-2)) /\n",
    "                               (num_nodes**0.5)) + k**0.5) / (k**0.5 - 1)\n",
    "            elif mask != None:\n",
    "                ortho_loss = sum([((-torch.sum(\n",
    "                    torch.norm(\n",
    "                        s[i][:mask[i].nonzero().shape[0]],\n",
    "                        p=\"fro\",\n",
    "                        dim=-2,\n",
    "                    )) / (mask[i].nonzero().shape[0]**0.5) + k**0.5) /\n",
    "                                   (k**0.5 - 1)) for i in range(batch_size)\n",
    "                                  ]) / float(batch_size)\n",
    "            else:\n",
    "                ortho_loss = sum(\n",
    "                    [((-torch.sum(torch.norm(s[i], p=\"fro\", dim=-2)) /\n",
    "                       (num_nodes**0.5) + k**0.5) / (k**0.5 - 1))\n",
    "                     for i in range(batch_size)]) / float(batch_size)\n",
    "        else:\n",
    "            # Orthogonality regularization.\n",
    "            ss = torch.matmul(s.transpose(1, 2), s)\n",
    "            i_s = torch.eye(k).type_as(ss)\n",
    "            ortho_loss = torch.norm(\n",
    "                ss / torch.norm(ss, dim=(-1, -2), keepdim=True) -\n",
    "                i_s / torch.norm(i_s),\n",
    "                dim=(-1, -2),\n",
    "            )\n",
    "            ortho_loss = torch.mean(ortho_loss)\n",
    "\n",
    "    # Fix and normalize coarsened adjacency matrix.\n",
    "    ind = torch.arange(k, device=out_adj.device)\n",
    "    out_adj[:, ind, ind] = 0\n",
    "    d = torch.einsum(\"ijk->ij\", out_adj)\n",
    "    d = torch.sqrt(d + EPS)[:, None]\n",
    "    out_adj = (out_adj / d) / d.transpose(1, 2)\n",
    "\n",
    "    return out, out_adj, hosc_loss, mu * ortho_loss\n",
    "\n",
    "\n",
    "def _rank3_diag(x):\n",
    "    eye = torch.eye(x.size(1)).type_as(x)\n",
    "    out = eye * x.unsqueeze(2).expand(*x.size(), x.size(1))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROTEINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6825, Val Acc: 0.6988, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 002, Loss: 0.6411, Val Acc: 0.6687, Test Acc: 0.7143\n",
      "Seed: 42, Epoch: 003, Loss: 0.6301, Val Acc: 0.6325, Test Acc: 0.6905\n",
      "Seed: 42, Epoch: 004, Loss: 0.6293, Val Acc: 0.6325, Test Acc: 0.6964\n",
      "Seed: 42, Epoch: 005, Loss: 0.6218, Val Acc: 0.6687, Test Acc: 0.7143\n",
      "Seed: 42, Epoch: 006, Loss: 0.6206, Val Acc: 0.6807, Test Acc: 0.7202\n",
      "Seed: 42, Epoch: 007, Loss: 0.6173, Val Acc: 0.6747, Test Acc: 0.7202\n",
      "Seed: 42, Epoch: 008, Loss: 0.6145, Val Acc: 0.6566, Test Acc: 0.7143\n",
      "Seed: 42, Epoch: 009, Loss: 0.6099, Val Acc: 0.6506, Test Acc: 0.7024\n",
      "Seed: 42, Epoch: 010, Loss: 0.6068, Val Acc: 0.6566, Test Acc: 0.7024\n",
      "Seed: 42, Epoch: 011, Loss: 0.6039, Val Acc: 0.6627, Test Acc: 0.7143\n",
      "Seed: 42, Epoch: 012, Loss: 0.6014, Val Acc: 0.6928, Test Acc: 0.7083\n",
      "Seed: 42, Epoch: 013, Loss: 0.5967, Val Acc: 0.6627, Test Acc: 0.7083\n",
      "Seed: 42, Epoch: 014, Loss: 0.5941, Val Acc: 0.6506, Test Acc: 0.7143\n",
      "Seed: 42, Epoch: 015, Loss: 0.5903, Val Acc: 0.6747, Test Acc: 0.7024\n",
      "Seed: 42, Epoch: 016, Loss: 0.5875, Val Acc: 0.7229, Test Acc: 0.7262\n",
      "Seed: 42, Epoch: 017, Loss: 0.5836, Val Acc: 0.6988, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 018, Loss: 0.5804, Val Acc: 0.7169, Test Acc: 0.7262\n",
      "Seed: 42, Epoch: 019, Loss: 0.5755, Val Acc: 0.7108, Test Acc: 0.7321\n",
      "Seed: 42, Epoch: 020, Loss: 0.5760, Val Acc: 0.7169, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 021, Loss: 0.5729, Val Acc: 0.7289, Test Acc: 0.7202\n",
      "Seed: 42, Epoch: 022, Loss: 0.5766, Val Acc: 0.7349, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 023, Loss: 0.5744, Val Acc: 0.6747, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 024, Loss: 0.5720, Val Acc: 0.6988, Test Acc: 0.7024\n",
      "Seed: 42, Epoch: 025, Loss: 0.5645, Val Acc: 0.7229, Test Acc: 0.7262\n",
      "Seed: 42, Epoch: 026, Loss: 0.5580, Val Acc: 0.7229, Test Acc: 0.7321\n",
      "Seed: 42, Epoch: 027, Loss: 0.5567, Val Acc: 0.7108, Test Acc: 0.7262\n",
      "Seed: 42, Epoch: 028, Loss: 0.5581, Val Acc: 0.6928, Test Acc: 0.7262\n",
      "Seed: 42, Epoch: 029, Loss: 0.5557, Val Acc: 0.7048, Test Acc: 0.7381\n",
      "Seed: 42, Epoch: 030, Loss: 0.5519, Val Acc: 0.7229, Test Acc: 0.7381\n",
      "Seed: 42, Epoch: 031, Loss: 0.5542, Val Acc: 0.6928, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 032, Loss: 0.5517, Val Acc: 0.7108, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 033, Loss: 0.5531, Val Acc: 0.7048, Test Acc: 0.7381\n",
      "Seed: 42, Epoch: 034, Loss: 0.5607, Val Acc: 0.7711, Test Acc: 0.7143\n",
      "Seed: 42, Epoch: 035, Loss: 0.5598, Val Acc: 0.7349, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 036, Loss: 0.5539, Val Acc: 0.7349, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 037, Loss: 0.5505, Val Acc: 0.7048, Test Acc: 0.7381\n",
      "Seed: 42, Epoch: 038, Loss: 0.5498, Val Acc: 0.6928, Test Acc: 0.7321\n",
      "Seed: 42, Epoch: 039, Loss: 0.5436, Val Acc: 0.7048, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 040, Loss: 0.5465, Val Acc: 0.7048, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 041, Loss: 0.5453, Val Acc: 0.7048, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 042, Loss: 0.5383, Val Acc: 0.7410, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 043, Loss: 0.5455, Val Acc: 0.6867, Test Acc: 0.7381\n",
      "Seed: 42, Epoch: 044, Loss: 0.5438, Val Acc: 0.6988, Test Acc: 0.7143\n",
      "Seed: 42, Epoch: 045, Loss: 0.5475, Val Acc: 0.7108, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 046, Loss: 0.5361, Val Acc: 0.7108, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 047, Loss: 0.5472, Val Acc: 0.7169, Test Acc: 0.7917\n",
      "Seed: 42, Epoch: 048, Loss: 0.5353, Val Acc: 0.7169, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 049, Loss: 0.5366, Val Acc: 0.7229, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 050, Loss: 0.5355, Val Acc: 0.7108, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 051, Loss: 0.5330, Val Acc: 0.6988, Test Acc: 0.7381\n",
      "Seed: 42, Epoch: 052, Loss: 0.5419, Val Acc: 0.6988, Test Acc: 0.7024\n",
      "Seed: 42, Epoch: 053, Loss: 0.5297, Val Acc: 0.7289, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 054, Loss: 0.5360, Val Acc: 0.7108, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 055, Loss: 0.5341, Val Acc: 0.7048, Test Acc: 0.7143\n",
      "Seed: 42, Epoch: 056, Loss: 0.5523, Val Acc: 0.7048, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 057, Loss: 0.5404, Val Acc: 0.6807, Test Acc: 0.7321\n",
      "Seed: 42, Epoch: 058, Loss: 0.5451, Val Acc: 0.6988, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 059, Loss: 0.5448, Val Acc: 0.7229, Test Acc: 0.8036\n",
      "Seed: 42, Epoch: 060, Loss: 0.5362, Val Acc: 0.7169, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 061, Loss: 0.5350, Val Acc: 0.7229, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 062, Loss: 0.5326, Val Acc: 0.6988, Test Acc: 0.7381\n",
      "Seed: 42, Epoch: 063, Loss: 0.5314, Val Acc: 0.7048, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 064, Loss: 0.5245, Val Acc: 0.6988, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 065, Loss: 0.5217, Val Acc: 0.7048, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 066, Loss: 0.5245, Val Acc: 0.7289, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 067, Loss: 0.5211, Val Acc: 0.7169, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 068, Loss: 0.5224, Val Acc: 0.7229, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 069, Loss: 0.5182, Val Acc: 0.7108, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 070, Loss: 0.5289, Val Acc: 0.7410, Test Acc: 0.7262\n",
      "Seed: 42, Epoch: 071, Loss: 0.5324, Val Acc: 0.7169, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 072, Loss: 0.5194, Val Acc: 0.7349, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 073, Loss: 0.5229, Val Acc: 0.7289, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 074, Loss: 0.5146, Val Acc: 0.7349, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 075, Loss: 0.5159, Val Acc: 0.7229, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 076, Loss: 0.5267, Val Acc: 0.7108, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 077, Loss: 0.5229, Val Acc: 0.7169, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 078, Loss: 0.5476, Val Acc: 0.7169, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 079, Loss: 0.5474, Val Acc: 0.7169, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 080, Loss: 0.5281, Val Acc: 0.7169, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 081, Loss: 0.5345, Val Acc: 0.7229, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 082, Loss: 0.5229, Val Acc: 0.6988, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 083, Loss: 0.5280, Val Acc: 0.7048, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 084, Loss: 0.5290, Val Acc: 0.6928, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 085, Loss: 0.5259, Val Acc: 0.7229, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 086, Loss: 0.5184, Val Acc: 0.7229, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 087, Loss: 0.5299, Val Acc: 0.7349, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 088, Loss: 0.5132, Val Acc: 0.7229, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 089, Loss: 0.5137, Val Acc: 0.7470, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 090, Loss: 0.5143, Val Acc: 0.7229, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 091, Loss: 0.5061, Val Acc: 0.7289, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 092, Loss: 0.5039, Val Acc: 0.7108, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 093, Loss: 0.5092, Val Acc: 0.6988, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 094, Loss: 0.5023, Val Acc: 0.6988, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 095, Loss: 0.5093, Val Acc: 0.6988, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 096, Loss: 0.5147, Val Acc: 0.7108, Test Acc: 0.7321\n",
      "Seed: 42, Epoch: 097, Loss: 0.5241, Val Acc: 0.7169, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 098, Loss: 0.5192, Val Acc: 0.7349, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 099, Loss: 0.5140, Val Acc: 0.7229, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 100, Loss: 0.5073, Val Acc: 0.7289, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 101, Loss: 0.5128, Val Acc: 0.7108, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 102, Loss: 0.5037, Val Acc: 0.7108, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 103, Loss: 0.5030, Val Acc: 0.7108, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 104, Loss: 0.5161, Val Acc: 0.6867, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 105, Loss: 0.5038, Val Acc: 0.6928, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 106, Loss: 0.5034, Val Acc: 0.6867, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 107, Loss: 0.5023, Val Acc: 0.6988, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 108, Loss: 0.5031, Val Acc: 0.7108, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 109, Loss: 0.5129, Val Acc: 0.7229, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 110, Loss: 0.5094, Val Acc: 0.7169, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 111, Loss: 0.5130, Val Acc: 0.7169, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 112, Loss: 0.5148, Val Acc: 0.7048, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 113, Loss: 0.5104, Val Acc: 0.6988, Test Acc: 0.7917\n",
      "Seed: 42, Epoch: 114, Loss: 0.5021, Val Acc: 0.6928, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 115, Loss: 0.5022, Val Acc: 0.6867, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 116, Loss: 0.5168, Val Acc: 0.6867, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 117, Loss: 0.5054, Val Acc: 0.6988, Test Acc: 0.7381\n",
      "Seed: 42, Epoch: 118, Loss: 0.5051, Val Acc: 0.7470, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 119, Loss: 0.5107, Val Acc: 0.7108, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 120, Loss: 0.5018, Val Acc: 0.6928, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 121, Loss: 0.4993, Val Acc: 0.7349, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 122, Loss: 0.5020, Val Acc: 0.7349, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 123, Loss: 0.5055, Val Acc: 0.7470, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 124, Loss: 0.5004, Val Acc: 0.7349, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 125, Loss: 0.4913, Val Acc: 0.7169, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 126, Loss: 0.4909, Val Acc: 0.6928, Test Acc: 0.7381\n",
      "Seed: 42, Epoch: 127, Loss: 0.4911, Val Acc: 0.7048, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 128, Loss: 0.4969, Val Acc: 0.6988, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 129, Loss: 0.4869, Val Acc: 0.7048, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 130, Loss: 0.4931, Val Acc: 0.7048, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 131, Loss: 0.4965, Val Acc: 0.7169, Test Acc: 0.7917\n",
      "Seed: 42, Epoch: 132, Loss: 0.5119, Val Acc: 0.7108, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 133, Loss: 0.4950, Val Acc: 0.7108, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 134, Loss: 0.4938, Val Acc: 0.7169, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 135, Loss: 0.4926, Val Acc: 0.7169, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 136, Loss: 0.4926, Val Acc: 0.7289, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 137, Loss: 0.5436, Val Acc: 0.6988, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 138, Loss: 0.5346, Val Acc: 0.6988, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 139, Loss: 0.5257, Val Acc: 0.7289, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 140, Loss: 0.5209, Val Acc: 0.7229, Test Acc: 0.7917\n",
      "Seed: 42, Epoch: 141, Loss: 0.5129, Val Acc: 0.6988, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 142, Loss: 0.5097, Val Acc: 0.6928, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 143, Loss: 0.5031, Val Acc: 0.6928, Test Acc: 0.7917\n",
      "Seed: 42, Epoch: 144, Loss: 0.4951, Val Acc: 0.7108, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 145, Loss: 0.4916, Val Acc: 0.7048, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 146, Loss: 0.4918, Val Acc: 0.7229, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 147, Loss: 0.4827, Val Acc: 0.6988, Test Acc: 0.7917\n",
      "Seed: 42, Epoch: 148, Loss: 0.4901, Val Acc: 0.7229, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 149, Loss: 0.4910, Val Acc: 0.7229, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 150, Loss: 0.4895, Val Acc: 0.7651, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 151, Loss: 0.5028, Val Acc: 0.7410, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 152, Loss: 0.4924, Val Acc: 0.7349, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 153, Loss: 0.4897, Val Acc: 0.7048, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 154, Loss: 0.4946, Val Acc: 0.7169, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 155, Loss: 0.5022, Val Acc: 0.6807, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 156, Loss: 0.5426, Val Acc: 0.6265, Test Acc: 0.6845\n",
      "Seed: 42, Epoch: 157, Loss: 0.5655, Val Acc: 0.6928, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 158, Loss: 0.5327, Val Acc: 0.7229, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 159, Loss: 0.5529, Val Acc: 0.7349, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 160, Loss: 0.5352, Val Acc: 0.7289, Test Acc: 0.7917\n",
      "Seed: 42, Epoch: 161, Loss: 0.5261, Val Acc: 0.7289, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 162, Loss: 0.5246, Val Acc: 0.7108, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 163, Loss: 0.5235, Val Acc: 0.6988, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 164, Loss: 0.5158, Val Acc: 0.6928, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 165, Loss: 0.5126, Val Acc: 0.6867, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 166, Loss: 0.5191, Val Acc: 0.7048, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 167, Loss: 0.5119, Val Acc: 0.6928, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 168, Loss: 0.5113, Val Acc: 0.7108, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 169, Loss: 0.5059, Val Acc: 0.7108, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 170, Loss: 0.5037, Val Acc: 0.7289, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 171, Loss: 0.5058, Val Acc: 0.7108, Test Acc: 0.7619\n",
      "Seed: 42, Epoch: 172, Loss: 0.5050, Val Acc: 0.7229, Test Acc: 0.7381\n",
      "Seed: 42, Epoch: 173, Loss: 0.4972, Val Acc: 0.7651, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 174, Loss: 0.5012, Val Acc: 0.7470, Test Acc: 0.7679\n",
      "Seed: 42, Epoch: 175, Loss: 0.4974, Val Acc: 0.7108, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 176, Loss: 0.4907, Val Acc: 0.7048, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 177, Loss: 0.4983, Val Acc: 0.7289, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 178, Loss: 0.4989, Val Acc: 0.7229, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 179, Loss: 0.4990, Val Acc: 0.7530, Test Acc: 0.7917\n",
      "Seed: 42, Epoch: 180, Loss: 0.5047, Val Acc: 0.7349, Test Acc: 0.7857\n",
      "Seed: 42, Epoch: 181, Loss: 0.5234, Val Acc: 0.7229, Test Acc: 0.7738\n",
      "Seed: 42, Epoch: 182, Loss: 0.5079, Val Acc: 0.7108, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 183, Loss: 0.5115, Val Acc: 0.7410, Test Acc: 0.7798\n",
      "Seed: 42, Epoch: 184, Loss: 0.4976, Val Acc: 0.7349, Test Acc: 0.7440\n",
      "Early stopping at epoch 184 for seed 42\n",
      "Seed: 43, Epoch: 001, Loss: 0.6759, Val Acc: 0.6807, Test Acc: 0.6488\n",
      "Seed: 43, Epoch: 002, Loss: 0.6286, Val Acc: 0.6807, Test Acc: 0.6548\n",
      "Seed: 43, Epoch: 003, Loss: 0.6197, Val Acc: 0.6386, Test Acc: 0.6369\n",
      "Seed: 43, Epoch: 004, Loss: 0.6164, Val Acc: 0.6084, Test Acc: 0.6250\n",
      "Seed: 43, Epoch: 005, Loss: 0.6110, Val Acc: 0.6687, Test Acc: 0.6548\n",
      "Seed: 43, Epoch: 006, Loss: 0.6087, Val Acc: 0.6747, Test Acc: 0.6726\n",
      "Seed: 43, Epoch: 007, Loss: 0.6030, Val Acc: 0.6747, Test Acc: 0.6429\n",
      "Seed: 43, Epoch: 008, Loss: 0.5981, Val Acc: 0.6566, Test Acc: 0.6369\n",
      "Seed: 43, Epoch: 009, Loss: 0.5950, Val Acc: 0.7169, Test Acc: 0.6786\n",
      "Seed: 43, Epoch: 010, Loss: 0.5892, Val Acc: 0.7169, Test Acc: 0.6845\n",
      "Seed: 43, Epoch: 011, Loss: 0.5878, Val Acc: 0.7349, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 012, Loss: 0.5823, Val Acc: 0.7470, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 013, Loss: 0.5788, Val Acc: 0.7410, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 014, Loss: 0.5760, Val Acc: 0.7349, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 015, Loss: 0.5716, Val Acc: 0.7470, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 016, Loss: 0.5683, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 017, Loss: 0.5676, Val Acc: 0.7229, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 018, Loss: 0.5633, Val Acc: 0.7349, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 019, Loss: 0.5595, Val Acc: 0.7410, Test Acc: 0.7024\n",
      "Seed: 43, Epoch: 020, Loss: 0.5585, Val Acc: 0.7349, Test Acc: 0.6964\n",
      "Seed: 43, Epoch: 021, Loss: 0.5574, Val Acc: 0.7349, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 022, Loss: 0.5520, Val Acc: 0.7410, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 023, Loss: 0.5474, Val Acc: 0.7651, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 024, Loss: 0.5432, Val Acc: 0.7410, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 025, Loss: 0.5462, Val Acc: 0.7349, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 026, Loss: 0.5580, Val Acc: 0.7108, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 027, Loss: 0.5496, Val Acc: 0.7530, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 028, Loss: 0.5490, Val Acc: 0.7590, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 029, Loss: 0.5507, Val Acc: 0.7711, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 030, Loss: 0.5406, Val Acc: 0.7470, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 031, Loss: 0.5381, Val Acc: 0.7410, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 032, Loss: 0.5365, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 033, Loss: 0.5368, Val Acc: 0.7289, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 034, Loss: 0.5328, Val Acc: 0.7410, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 035, Loss: 0.5345, Val Acc: 0.7349, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 036, Loss: 0.5434, Val Acc: 0.7470, Test Acc: 0.7440\n",
      "Seed: 43, Epoch: 037, Loss: 0.5288, Val Acc: 0.7169, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 038, Loss: 0.5238, Val Acc: 0.7229, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 039, Loss: 0.5201, Val Acc: 0.7169, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 040, Loss: 0.5215, Val Acc: 0.7108, Test Acc: 0.7024\n",
      "Seed: 43, Epoch: 041, Loss: 0.5234, Val Acc: 0.7470, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 042, Loss: 0.5237, Val Acc: 0.7169, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 043, Loss: 0.5136, Val Acc: 0.7229, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 044, Loss: 0.5213, Val Acc: 0.7470, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 045, Loss: 0.5186, Val Acc: 0.7410, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 046, Loss: 0.5316, Val Acc: 0.7349, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 047, Loss: 0.5166, Val Acc: 0.7289, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 048, Loss: 0.5222, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 049, Loss: 0.5187, Val Acc: 0.7410, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 050, Loss: 0.5108, Val Acc: 0.7470, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 051, Loss: 0.5161, Val Acc: 0.7410, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 052, Loss: 0.5107, Val Acc: 0.7530, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 053, Loss: 0.5104, Val Acc: 0.7410, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 054, Loss: 0.5164, Val Acc: 0.7169, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 055, Loss: 0.5163, Val Acc: 0.7470, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 056, Loss: 0.5131, Val Acc: 0.7410, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 057, Loss: 0.5140, Val Acc: 0.7530, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 058, Loss: 0.5199, Val Acc: 0.7530, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 059, Loss: 0.5106, Val Acc: 0.7530, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 060, Loss: 0.5130, Val Acc: 0.7289, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 061, Loss: 0.5052, Val Acc: 0.7410, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 062, Loss: 0.5134, Val Acc: 0.7410, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 063, Loss: 0.5133, Val Acc: 0.7651, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 064, Loss: 0.5059, Val Acc: 0.7590, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 065, Loss: 0.5084, Val Acc: 0.7410, Test Acc: 0.6905\n",
      "Seed: 43, Epoch: 066, Loss: 0.4985, Val Acc: 0.7530, Test Acc: 0.7024\n",
      "Seed: 43, Epoch: 067, Loss: 0.4997, Val Acc: 0.7470, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 068, Loss: 0.5064, Val Acc: 0.7651, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 069, Loss: 0.4881, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 070, Loss: 0.4906, Val Acc: 0.7590, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 071, Loss: 0.4923, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 072, Loss: 0.5029, Val Acc: 0.7530, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 073, Loss: 0.4932, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 074, Loss: 0.4905, Val Acc: 0.7470, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 075, Loss: 0.5051, Val Acc: 0.7410, Test Acc: 0.6964\n",
      "Seed: 43, Epoch: 076, Loss: 0.4948, Val Acc: 0.7349, Test Acc: 0.6964\n",
      "Seed: 43, Epoch: 077, Loss: 0.4935, Val Acc: 0.7530, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 078, Loss: 0.4945, Val Acc: 0.7470, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 079, Loss: 0.4841, Val Acc: 0.7470, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 080, Loss: 0.4918, Val Acc: 0.7410, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 081, Loss: 0.4891, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 082, Loss: 0.4924, Val Acc: 0.7410, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 083, Loss: 0.5009, Val Acc: 0.7651, Test Acc: 0.7024\n",
      "Seed: 43, Epoch: 084, Loss: 0.4848, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 085, Loss: 0.4854, Val Acc: 0.7651, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 086, Loss: 0.4770, Val Acc: 0.7711, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 087, Loss: 0.4829, Val Acc: 0.7590, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 088, Loss: 0.4837, Val Acc: 0.7590, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 089, Loss: 0.4792, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 090, Loss: 0.4783, Val Acc: 0.7530, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 091, Loss: 0.4821, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 092, Loss: 0.4836, Val Acc: 0.7410, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 093, Loss: 0.4890, Val Acc: 0.7530, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 094, Loss: 0.4872, Val Acc: 0.7651, Test Acc: 0.7024\n",
      "Seed: 43, Epoch: 095, Loss: 0.4811, Val Acc: 0.7530, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 096, Loss: 0.5118, Val Acc: 0.7410, Test Acc: 0.7024\n",
      "Seed: 43, Epoch: 097, Loss: 0.5266, Val Acc: 0.7470, Test Acc: 0.7024\n",
      "Seed: 43, Epoch: 098, Loss: 0.5004, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 099, Loss: 0.4980, Val Acc: 0.7410, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 100, Loss: 0.4814, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 101, Loss: 0.4820, Val Acc: 0.7410, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 102, Loss: 0.4841, Val Acc: 0.7410, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 103, Loss: 0.4844, Val Acc: 0.7349, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 104, Loss: 0.4851, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 105, Loss: 0.4934, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 106, Loss: 0.4832, Val Acc: 0.7470, Test Acc: 0.7024\n",
      "Seed: 43, Epoch: 107, Loss: 0.4825, Val Acc: 0.7590, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 108, Loss: 0.4860, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 109, Loss: 0.5028, Val Acc: 0.7590, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 110, Loss: 0.4903, Val Acc: 0.7470, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 111, Loss: 0.4892, Val Acc: 0.7651, Test Acc: 0.6964\n",
      "Seed: 43, Epoch: 112, Loss: 0.4864, Val Acc: 0.7590, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 113, Loss: 0.4925, Val Acc: 0.7711, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 114, Loss: 0.4970, Val Acc: 0.7530, Test Acc: 0.7024\n",
      "Seed: 43, Epoch: 115, Loss: 0.4901, Val Acc: 0.7711, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 116, Loss: 0.4862, Val Acc: 0.7771, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 117, Loss: 0.4792, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 118, Loss: 0.4836, Val Acc: 0.7711, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 119, Loss: 0.4785, Val Acc: 0.7590, Test Acc: 0.7440\n",
      "Seed: 43, Epoch: 120, Loss: 0.4815, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 121, Loss: 0.4769, Val Acc: 0.7590, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 122, Loss: 0.4725, Val Acc: 0.7470, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 123, Loss: 0.4833, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 124, Loss: 0.5191, Val Acc: 0.7470, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 125, Loss: 0.5105, Val Acc: 0.7590, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 126, Loss: 0.4835, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 127, Loss: 0.4866, Val Acc: 0.7711, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 128, Loss: 0.4798, Val Acc: 0.7470, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 129, Loss: 0.4873, Val Acc: 0.7470, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 130, Loss: 0.4919, Val Acc: 0.7711, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 131, Loss: 0.4764, Val Acc: 0.7530, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 132, Loss: 0.4782, Val Acc: 0.7530, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 133, Loss: 0.4763, Val Acc: 0.7590, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 134, Loss: 0.4788, Val Acc: 0.7410, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 135, Loss: 0.4729, Val Acc: 0.7530, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 136, Loss: 0.4721, Val Acc: 0.7711, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 137, Loss: 0.4837, Val Acc: 0.7530, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 138, Loss: 0.4763, Val Acc: 0.7651, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 139, Loss: 0.4769, Val Acc: 0.7711, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 140, Loss: 0.4742, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 141, Loss: 0.4735, Val Acc: 0.7590, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 142, Loss: 0.4758, Val Acc: 0.7771, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 143, Loss: 0.4767, Val Acc: 0.7771, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 144, Loss: 0.4731, Val Acc: 0.7590, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 145, Loss: 0.4824, Val Acc: 0.7530, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 146, Loss: 0.4676, Val Acc: 0.7590, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 147, Loss: 0.4684, Val Acc: 0.7711, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 148, Loss: 0.4670, Val Acc: 0.7470, Test Acc: 0.7024\n",
      "Seed: 43, Epoch: 149, Loss: 0.4708, Val Acc: 0.7410, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 150, Loss: 0.4790, Val Acc: 0.7711, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 151, Loss: 0.4780, Val Acc: 0.7470, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 152, Loss: 0.4608, Val Acc: 0.7349, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 153, Loss: 0.4685, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 154, Loss: 0.4688, Val Acc: 0.7651, Test Acc: 0.7024\n",
      "Seed: 43, Epoch: 155, Loss: 0.4736, Val Acc: 0.7590, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 156, Loss: 0.4734, Val Acc: 0.7651, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 157, Loss: 0.4722, Val Acc: 0.7590, Test Acc: 0.7440\n",
      "Seed: 43, Epoch: 158, Loss: 0.4704, Val Acc: 0.7590, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 159, Loss: 0.4740, Val Acc: 0.7530, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 160, Loss: 0.4704, Val Acc: 0.7410, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 161, Loss: 0.4643, Val Acc: 0.7711, Test Acc: 0.6964\n",
      "Seed: 43, Epoch: 162, Loss: 0.4690, Val Acc: 0.7651, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 163, Loss: 0.4602, Val Acc: 0.7590, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 164, Loss: 0.4662, Val Acc: 0.7590, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 165, Loss: 0.4734, Val Acc: 0.7410, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 166, Loss: 0.4588, Val Acc: 0.7530, Test Acc: 0.6964\n",
      "Seed: 43, Epoch: 167, Loss: 0.4663, Val Acc: 0.7590, Test Acc: 0.6964\n",
      "Seed: 43, Epoch: 168, Loss: 0.4667, Val Acc: 0.7651, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 169, Loss: 0.4621, Val Acc: 0.7651, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 170, Loss: 0.4638, Val Acc: 0.7711, Test Acc: 0.7381\n",
      "Seed: 43, Epoch: 171, Loss: 0.4791, Val Acc: 0.7771, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 172, Loss: 0.5001, Val Acc: 0.7590, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 173, Loss: 0.4737, Val Acc: 0.7410, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 174, Loss: 0.4714, Val Acc: 0.7771, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 175, Loss: 0.4714, Val Acc: 0.7771, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 176, Loss: 0.4646, Val Acc: 0.7530, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 177, Loss: 0.4629, Val Acc: 0.7530, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 178, Loss: 0.4693, Val Acc: 0.7711, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 179, Loss: 0.4579, Val Acc: 0.7711, Test Acc: 0.6964\n",
      "Seed: 43, Epoch: 180, Loss: 0.4599, Val Acc: 0.7651, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 181, Loss: 0.4571, Val Acc: 0.7771, Test Acc: 0.7321\n",
      "Seed: 43, Epoch: 182, Loss: 0.4570, Val Acc: 0.7651, Test Acc: 0.7024\n",
      "Seed: 43, Epoch: 183, Loss: 0.4688, Val Acc: 0.7711, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 184, Loss: 0.4739, Val Acc: 0.7289, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 185, Loss: 0.4659, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 186, Loss: 0.4745, Val Acc: 0.7530, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 187, Loss: 0.4666, Val Acc: 0.7349, Test Acc: 0.7440\n",
      "Seed: 43, Epoch: 188, Loss: 0.4581, Val Acc: 0.7590, Test Acc: 0.6964\n",
      "Seed: 43, Epoch: 189, Loss: 0.4673, Val Acc: 0.7651, Test Acc: 0.7440\n",
      "Seed: 43, Epoch: 190, Loss: 0.4684, Val Acc: 0.7651, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 191, Loss: 0.4575, Val Acc: 0.7590, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 192, Loss: 0.4576, Val Acc: 0.7530, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 193, Loss: 0.4597, Val Acc: 0.7530, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 194, Loss: 0.4694, Val Acc: 0.7651, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 195, Loss: 0.4803, Val Acc: 0.7590, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 196, Loss: 0.4753, Val Acc: 0.7711, Test Acc: 0.7143\n",
      "Seed: 43, Epoch: 197, Loss: 0.4690, Val Acc: 0.7771, Test Acc: 0.7262\n",
      "Seed: 43, Epoch: 198, Loss: 0.4749, Val Acc: 0.7651, Test Acc: 0.7440\n",
      "Seed: 43, Epoch: 199, Loss: 0.4735, Val Acc: 0.7711, Test Acc: 0.7202\n",
      "Seed: 43, Epoch: 200, Loss: 0.4697, Val Acc: 0.7651, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 001, Loss: 0.6793, Val Acc: 0.7169, Test Acc: 0.6786\n",
      "Seed: 44, Epoch: 002, Loss: 0.6355, Val Acc: 0.6084, Test Acc: 0.5952\n",
      "Seed: 44, Epoch: 003, Loss: 0.6178, Val Acc: 0.6084, Test Acc: 0.6012\n",
      "Seed: 44, Epoch: 004, Loss: 0.6141, Val Acc: 0.6205, Test Acc: 0.5952\n",
      "Seed: 44, Epoch: 005, Loss: 0.6095, Val Acc: 0.6627, Test Acc: 0.5952\n",
      "Seed: 44, Epoch: 006, Loss: 0.6082, Val Acc: 0.6988, Test Acc: 0.6310\n",
      "Seed: 44, Epoch: 007, Loss: 0.6107, Val Acc: 0.6928, Test Acc: 0.6548\n",
      "Seed: 44, Epoch: 008, Loss: 0.6042, Val Acc: 0.6807, Test Acc: 0.6131\n",
      "Seed: 44, Epoch: 009, Loss: 0.5997, Val Acc: 0.6807, Test Acc: 0.6071\n",
      "Seed: 44, Epoch: 010, Loss: 0.5981, Val Acc: 0.7048, Test Acc: 0.6548\n",
      "Seed: 44, Epoch: 011, Loss: 0.5972, Val Acc: 0.7108, Test Acc: 0.6667\n",
      "Seed: 44, Epoch: 012, Loss: 0.5968, Val Acc: 0.6867, Test Acc: 0.6607\n",
      "Seed: 44, Epoch: 013, Loss: 0.5900, Val Acc: 0.7289, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 014, Loss: 0.5870, Val Acc: 0.7169, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 015, Loss: 0.5817, Val Acc: 0.7048, Test Acc: 0.6786\n",
      "Seed: 44, Epoch: 016, Loss: 0.5777, Val Acc: 0.6807, Test Acc: 0.6905\n",
      "Seed: 44, Epoch: 017, Loss: 0.5734, Val Acc: 0.7229, Test Acc: 0.6726\n",
      "Seed: 44, Epoch: 018, Loss: 0.5677, Val Acc: 0.7349, Test Acc: 0.6905\n",
      "Seed: 44, Epoch: 019, Loss: 0.5615, Val Acc: 0.6867, Test Acc: 0.6726\n",
      "Seed: 44, Epoch: 020, Loss: 0.5676, Val Acc: 0.6747, Test Acc: 0.6845\n",
      "Seed: 44, Epoch: 021, Loss: 0.5583, Val Acc: 0.6747, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 022, Loss: 0.5551, Val Acc: 0.6867, Test Acc: 0.6845\n",
      "Seed: 44, Epoch: 023, Loss: 0.5499, Val Acc: 0.6988, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 024, Loss: 0.5490, Val Acc: 0.7048, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 025, Loss: 0.5395, Val Acc: 0.7169, Test Acc: 0.6905\n",
      "Seed: 44, Epoch: 026, Loss: 0.5365, Val Acc: 0.7048, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 027, Loss: 0.5327, Val Acc: 0.7108, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 028, Loss: 0.5517, Val Acc: 0.6867, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 029, Loss: 0.5363, Val Acc: 0.7108, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 030, Loss: 0.5426, Val Acc: 0.7108, Test Acc: 0.6905\n",
      "Seed: 44, Epoch: 031, Loss: 0.5429, Val Acc: 0.7229, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 032, Loss: 0.5355, Val Acc: 0.7169, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 033, Loss: 0.5379, Val Acc: 0.7289, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 034, Loss: 0.5374, Val Acc: 0.7289, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 035, Loss: 0.5336, Val Acc: 0.7470, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 036, Loss: 0.5285, Val Acc: 0.7289, Test Acc: 0.6905\n",
      "Seed: 44, Epoch: 037, Loss: 0.5271, Val Acc: 0.7349, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 038, Loss: 0.5345, Val Acc: 0.7289, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 039, Loss: 0.5266, Val Acc: 0.7108, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 040, Loss: 0.5316, Val Acc: 0.7169, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 041, Loss: 0.5250, Val Acc: 0.7169, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 042, Loss: 0.5296, Val Acc: 0.7229, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 043, Loss: 0.5219, Val Acc: 0.6928, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 044, Loss: 0.5176, Val Acc: 0.6928, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 045, Loss: 0.5262, Val Acc: 0.6928, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 046, Loss: 0.5190, Val Acc: 0.7349, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 047, Loss: 0.5156, Val Acc: 0.7229, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 048, Loss: 0.5130, Val Acc: 0.6928, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 049, Loss: 0.5127, Val Acc: 0.6807, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 050, Loss: 0.5217, Val Acc: 0.7289, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 051, Loss: 0.5112, Val Acc: 0.7349, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 052, Loss: 0.5047, Val Acc: 0.7229, Test Acc: 0.6905\n",
      "Seed: 44, Epoch: 053, Loss: 0.5084, Val Acc: 0.7169, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 054, Loss: 0.5091, Val Acc: 0.7048, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 055, Loss: 0.5144, Val Acc: 0.7229, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 056, Loss: 0.5072, Val Acc: 0.7169, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 057, Loss: 0.5110, Val Acc: 0.7108, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 058, Loss: 0.5011, Val Acc: 0.7048, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 059, Loss: 0.5056, Val Acc: 0.7410, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 060, Loss: 0.4938, Val Acc: 0.7289, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 061, Loss: 0.4969, Val Acc: 0.7229, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 062, Loss: 0.4991, Val Acc: 0.6988, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 063, Loss: 0.5088, Val Acc: 0.6928, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 064, Loss: 0.5094, Val Acc: 0.6988, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 065, Loss: 0.5217, Val Acc: 0.7229, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 066, Loss: 0.5146, Val Acc: 0.7108, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 067, Loss: 0.4996, Val Acc: 0.7108, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 068, Loss: 0.5025, Val Acc: 0.7289, Test Acc: 0.6905\n",
      "Seed: 44, Epoch: 069, Loss: 0.4945, Val Acc: 0.7048, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 070, Loss: 0.5102, Val Acc: 0.6867, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 071, Loss: 0.4868, Val Acc: 0.7048, Test Acc: 0.6905\n",
      "Seed: 44, Epoch: 072, Loss: 0.4828, Val Acc: 0.6988, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 073, Loss: 0.4837, Val Acc: 0.7229, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 074, Loss: 0.4941, Val Acc: 0.7349, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 075, Loss: 0.4933, Val Acc: 0.7410, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 076, Loss: 0.4828, Val Acc: 0.7410, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 077, Loss: 0.4866, Val Acc: 0.7289, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 078, Loss: 0.4768, Val Acc: 0.7108, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 079, Loss: 0.4855, Val Acc: 0.7229, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 080, Loss: 0.4791, Val Acc: 0.7169, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 081, Loss: 0.4729, Val Acc: 0.7410, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 082, Loss: 0.4891, Val Acc: 0.7289, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 083, Loss: 0.4858, Val Acc: 0.7590, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 084, Loss: 0.4831, Val Acc: 0.7169, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 085, Loss: 0.4835, Val Acc: 0.7530, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 086, Loss: 0.4878, Val Acc: 0.6988, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 087, Loss: 0.4793, Val Acc: 0.7530, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 088, Loss: 0.4776, Val Acc: 0.7289, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 089, Loss: 0.5044, Val Acc: 0.7229, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 090, Loss: 0.4956, Val Acc: 0.7169, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 091, Loss: 0.4963, Val Acc: 0.6988, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 092, Loss: 0.4850, Val Acc: 0.7530, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 093, Loss: 0.4839, Val Acc: 0.7229, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 094, Loss: 0.4853, Val Acc: 0.7289, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 095, Loss: 0.4821, Val Acc: 0.7349, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 096, Loss: 0.4809, Val Acc: 0.7108, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 097, Loss: 0.4709, Val Acc: 0.7229, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 098, Loss: 0.4699, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 099, Loss: 0.4811, Val Acc: 0.7289, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 100, Loss: 0.4732, Val Acc: 0.7349, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 101, Loss: 0.4821, Val Acc: 0.7470, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 102, Loss: 0.4896, Val Acc: 0.7349, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 103, Loss: 0.4767, Val Acc: 0.7590, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 104, Loss: 0.4758, Val Acc: 0.7349, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 105, Loss: 0.4719, Val Acc: 0.7349, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 106, Loss: 0.4840, Val Acc: 0.7410, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 107, Loss: 0.4872, Val Acc: 0.7349, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 108, Loss: 0.4862, Val Acc: 0.7470, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 109, Loss: 0.4856, Val Acc: 0.7289, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 110, Loss: 0.4960, Val Acc: 0.7169, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 111, Loss: 0.4910, Val Acc: 0.7470, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 112, Loss: 0.4736, Val Acc: 0.7349, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 113, Loss: 0.4797, Val Acc: 0.7530, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 114, Loss: 0.4714, Val Acc: 0.7289, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 115, Loss: 0.4726, Val Acc: 0.7470, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 116, Loss: 0.4845, Val Acc: 0.7349, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 117, Loss: 0.4854, Val Acc: 0.7349, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 118, Loss: 0.4778, Val Acc: 0.7470, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 119, Loss: 0.4929, Val Acc: 0.7349, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 120, Loss: 0.4815, Val Acc: 0.7169, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 121, Loss: 0.4755, Val Acc: 0.7229, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 122, Loss: 0.4740, Val Acc: 0.7229, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 123, Loss: 0.4682, Val Acc: 0.7289, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 124, Loss: 0.4730, Val Acc: 0.7108, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 125, Loss: 0.4811, Val Acc: 0.7410, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 126, Loss: 0.4851, Val Acc: 0.6988, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 127, Loss: 0.4727, Val Acc: 0.7108, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 128, Loss: 0.4691, Val Acc: 0.7410, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 129, Loss: 0.4641, Val Acc: 0.6988, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 130, Loss: 0.4712, Val Acc: 0.7229, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 131, Loss: 0.4633, Val Acc: 0.7289, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 132, Loss: 0.4668, Val Acc: 0.7349, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 133, Loss: 0.4681, Val Acc: 0.7108, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 134, Loss: 0.4689, Val Acc: 0.7349, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 135, Loss: 0.4599, Val Acc: 0.7108, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 136, Loss: 0.4627, Val Acc: 0.7229, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 137, Loss: 0.4605, Val Acc: 0.7229, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 138, Loss: 0.4632, Val Acc: 0.7349, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 139, Loss: 0.4684, Val Acc: 0.7289, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 140, Loss: 0.4637, Val Acc: 0.7289, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 141, Loss: 0.4585, Val Acc: 0.7349, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 142, Loss: 0.4638, Val Acc: 0.7349, Test Acc: 0.7321\n",
      "Seed: 44, Epoch: 143, Loss: 0.4783, Val Acc: 0.7229, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 144, Loss: 0.4562, Val Acc: 0.7410, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 145, Loss: 0.4744, Val Acc: 0.7229, Test Acc: 0.7440\n",
      "Seed: 44, Epoch: 146, Loss: 0.4686, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 147, Loss: 0.4615, Val Acc: 0.7349, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 148, Loss: 0.4658, Val Acc: 0.7410, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 149, Loss: 0.4630, Val Acc: 0.7470, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 150, Loss: 0.4616, Val Acc: 0.7349, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 151, Loss: 0.4603, Val Acc: 0.7470, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 152, Loss: 0.4566, Val Acc: 0.7470, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 153, Loss: 0.4525, Val Acc: 0.7410, Test Acc: 0.6905\n",
      "Seed: 44, Epoch: 154, Loss: 0.4552, Val Acc: 0.7410, Test Acc: 0.6905\n",
      "Seed: 44, Epoch: 155, Loss: 0.4534, Val Acc: 0.7470, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 156, Loss: 0.4615, Val Acc: 0.7289, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 157, Loss: 0.4611, Val Acc: 0.7169, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 158, Loss: 0.4541, Val Acc: 0.7349, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 159, Loss: 0.4602, Val Acc: 0.7349, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 160, Loss: 0.4667, Val Acc: 0.7169, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 161, Loss: 0.4593, Val Acc: 0.7169, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 162, Loss: 0.4630, Val Acc: 0.7470, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 163, Loss: 0.4624, Val Acc: 0.7289, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 164, Loss: 0.4584, Val Acc: 0.7349, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 165, Loss: 0.4557, Val Acc: 0.7410, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 166, Loss: 0.4612, Val Acc: 0.7410, Test Acc: 0.7381\n",
      "Seed: 44, Epoch: 167, Loss: 0.4626, Val Acc: 0.7108, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 168, Loss: 0.4606, Val Acc: 0.7169, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 169, Loss: 0.4623, Val Acc: 0.7229, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 170, Loss: 0.4645, Val Acc: 0.7229, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 171, Loss: 0.4714, Val Acc: 0.7410, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 172, Loss: 0.4694, Val Acc: 0.7349, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 173, Loss: 0.4705, Val Acc: 0.7349, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 174, Loss: 0.4648, Val Acc: 0.7470, Test Acc: 0.6786\n",
      "Seed: 44, Epoch: 175, Loss: 0.4587, Val Acc: 0.7410, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 176, Loss: 0.4669, Val Acc: 0.7590, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 177, Loss: 0.4607, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 178, Loss: 0.4801, Val Acc: 0.7169, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 179, Loss: 0.4741, Val Acc: 0.7108, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 180, Loss: 0.4747, Val Acc: 0.7410, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 181, Loss: 0.4740, Val Acc: 0.7410, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 182, Loss: 0.4607, Val Acc: 0.7410, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 183, Loss: 0.4557, Val Acc: 0.7771, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 184, Loss: 0.4717, Val Acc: 0.7349, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 185, Loss: 0.4755, Val Acc: 0.7289, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 186, Loss: 0.4539, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 187, Loss: 0.4741, Val Acc: 0.7410, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 188, Loss: 0.4820, Val Acc: 0.7470, Test Acc: 0.7262\n",
      "Seed: 44, Epoch: 189, Loss: 0.4683, Val Acc: 0.7349, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 190, Loss: 0.4638, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 191, Loss: 0.4729, Val Acc: 0.7410, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 192, Loss: 0.4727, Val Acc: 0.7410, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 193, Loss: 0.4653, Val Acc: 0.7651, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 194, Loss: 0.4656, Val Acc: 0.7349, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 195, Loss: 0.4611, Val Acc: 0.7410, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 196, Loss: 0.4640, Val Acc: 0.7530, Test Acc: 0.6964\n",
      "Seed: 44, Epoch: 197, Loss: 0.4595, Val Acc: 0.7530, Test Acc: 0.7202\n",
      "Seed: 44, Epoch: 198, Loss: 0.4614, Val Acc: 0.7590, Test Acc: 0.7024\n",
      "Seed: 44, Epoch: 199, Loss: 0.4643, Val Acc: 0.7651, Test Acc: 0.7143\n",
      "Seed: 44, Epoch: 200, Loss: 0.4570, Val Acc: 0.7410, Test Acc: 0.7262\n",
      "Average Time: 361.96 seconds\n",
      "Var Time: 1152.64 seconds\n",
      "Average Memory: 2469.33 MB\n",
      "Average Best Val Acc: 0.7751\n",
      "Std Best Test Acc: 0.0074\n",
      "Average Test Acc: 0.7242\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "max_nodes = 700\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"PROTEINS\",\n",
    "    transform=T.Compose([T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_hosc(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc, o = dense_hoscpool(x, adj, s, mu=0.5, alpha=0.5, new_ortho=False, mask=mask)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc_aux, o_aux = dense_hoscpool(x, adj, s, mu=0.5, alpha=0.5, new_ortho=False)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_hosc().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = Net_hosc().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCI1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6875, Val Acc: 0.4838, Test Acc: 0.4619\n",
      "Seed: 42, Epoch: 002, Loss: 0.6634, Val Acc: 0.6266, Test Acc: 0.6224\n",
      "Seed: 42, Epoch: 003, Loss: 0.6345, Val Acc: 0.6526, Test Acc: 0.6126\n",
      "Seed: 42, Epoch: 004, Loss: 0.6105, Val Acc: 0.6331, Test Acc: 0.6321\n",
      "Seed: 42, Epoch: 005, Loss: 0.6011, Val Acc: 0.6705, Test Acc: 0.6467\n",
      "Seed: 42, Epoch: 006, Loss: 0.5928, Val Acc: 0.6169, Test Acc: 0.6434\n",
      "Seed: 42, Epoch: 007, Loss: 0.5823, Val Acc: 0.6818, Test Acc: 0.6548\n",
      "Seed: 42, Epoch: 008, Loss: 0.5669, Val Acc: 0.6851, Test Acc: 0.6840\n",
      "Seed: 42, Epoch: 009, Loss: 0.5692, Val Acc: 0.7029, Test Acc: 0.6904\n",
      "Seed: 42, Epoch: 010, Loss: 0.5673, Val Acc: 0.6705, Test Acc: 0.6791\n",
      "Seed: 42, Epoch: 011, Loss: 0.5584, Val Acc: 0.6883, Test Acc: 0.6759\n",
      "Seed: 42, Epoch: 012, Loss: 0.5503, Val Acc: 0.7208, Test Acc: 0.7245\n",
      "Seed: 42, Epoch: 013, Loss: 0.5423, Val Acc: 0.6899, Test Acc: 0.7099\n",
      "Seed: 42, Epoch: 014, Loss: 0.5395, Val Acc: 0.6786, Test Acc: 0.6807\n",
      "Seed: 42, Epoch: 015, Loss: 0.5365, Val Acc: 0.7240, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 016, Loss: 0.5216, Val Acc: 0.6802, Test Acc: 0.6694\n",
      "Seed: 42, Epoch: 017, Loss: 0.5247, Val Acc: 0.7321, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 018, Loss: 0.5180, Val Acc: 0.7110, Test Acc: 0.7310\n",
      "Seed: 42, Epoch: 019, Loss: 0.5050, Val Acc: 0.7110, Test Acc: 0.6661\n",
      "Seed: 42, Epoch: 020, Loss: 0.5054, Val Acc: 0.7468, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 021, Loss: 0.5014, Val Acc: 0.7484, Test Acc: 0.7326\n",
      "Seed: 42, Epoch: 022, Loss: 0.5003, Val Acc: 0.7435, Test Acc: 0.7034\n",
      "Seed: 42, Epoch: 023, Loss: 0.4872, Val Acc: 0.7127, Test Acc: 0.6969\n",
      "Seed: 42, Epoch: 024, Loss: 0.4912, Val Acc: 0.7143, Test Acc: 0.7229\n",
      "Seed: 42, Epoch: 025, Loss: 0.4919, Val Acc: 0.7500, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 026, Loss: 0.4855, Val Acc: 0.7338, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 027, Loss: 0.4905, Val Acc: 0.7419, Test Acc: 0.7585\n",
      "Seed: 42, Epoch: 028, Loss: 0.4801, Val Acc: 0.7127, Test Acc: 0.7066\n",
      "Seed: 42, Epoch: 029, Loss: 0.4674, Val Acc: 0.7386, Test Acc: 0.7196\n",
      "Seed: 42, Epoch: 030, Loss: 0.4655, Val Acc: 0.7305, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 031, Loss: 0.4898, Val Acc: 0.7110, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 032, Loss: 0.4710, Val Acc: 0.7581, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 033, Loss: 0.4693, Val Acc: 0.6899, Test Acc: 0.7002\n",
      "Seed: 42, Epoch: 034, Loss: 0.4659, Val Acc: 0.7468, Test Acc: 0.7196\n",
      "Seed: 42, Epoch: 035, Loss: 0.4543, Val Acc: 0.7192, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 036, Loss: 0.4669, Val Acc: 0.7516, Test Acc: 0.7585\n",
      "Seed: 42, Epoch: 037, Loss: 0.4445, Val Acc: 0.7240, Test Acc: 0.7034\n",
      "Seed: 42, Epoch: 038, Loss: 0.4593, Val Acc: 0.7500, Test Acc: 0.7277\n",
      "Seed: 42, Epoch: 039, Loss: 0.4414, Val Acc: 0.7451, Test Acc: 0.7229\n",
      "Seed: 42, Epoch: 040, Loss: 0.4344, Val Acc: 0.7500, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 041, Loss: 0.4477, Val Acc: 0.6802, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 042, Loss: 0.4483, Val Acc: 0.7127, Test Acc: 0.6888\n",
      "Seed: 42, Epoch: 043, Loss: 0.4468, Val Acc: 0.7744, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 044, Loss: 0.4268, Val Acc: 0.7078, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 045, Loss: 0.4415, Val Acc: 0.7159, Test Acc: 0.7245\n",
      "Seed: 42, Epoch: 046, Loss: 0.4390, Val Acc: 0.7711, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 047, Loss: 0.4291, Val Acc: 0.7500, Test Acc: 0.7115\n",
      "Seed: 42, Epoch: 048, Loss: 0.4290, Val Acc: 0.7516, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 049, Loss: 0.4075, Val Acc: 0.8019, Test Acc: 0.7601\n",
      "Seed: 42, Epoch: 050, Loss: 0.4155, Val Acc: 0.7305, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 051, Loss: 0.4039, Val Acc: 0.7662, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 052, Loss: 0.4119, Val Acc: 0.7662, Test Acc: 0.7310\n",
      "Seed: 42, Epoch: 053, Loss: 0.4075, Val Acc: 0.7500, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 054, Loss: 0.4056, Val Acc: 0.7630, Test Acc: 0.7050\n",
      "Seed: 42, Epoch: 055, Loss: 0.4135, Val Acc: 0.7581, Test Acc: 0.7261\n",
      "Seed: 42, Epoch: 056, Loss: 0.4069, Val Acc: 0.7873, Test Acc: 0.7618\n",
      "Seed: 42, Epoch: 057, Loss: 0.3998, Val Acc: 0.7516, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 058, Loss: 0.4147, Val Acc: 0.7500, Test Acc: 0.7180\n",
      "Seed: 42, Epoch: 059, Loss: 0.4112, Val Acc: 0.7614, Test Acc: 0.7585\n",
      "Seed: 42, Epoch: 060, Loss: 0.3892, Val Acc: 0.7435, Test Acc: 0.7229\n",
      "Seed: 42, Epoch: 061, Loss: 0.3867, Val Acc: 0.7565, Test Acc: 0.7666\n",
      "Seed: 42, Epoch: 062, Loss: 0.4014, Val Acc: 0.7581, Test Acc: 0.7180\n",
      "Seed: 42, Epoch: 063, Loss: 0.3942, Val Acc: 0.7614, Test Acc: 0.7553\n",
      "Seed: 42, Epoch: 064, Loss: 0.3862, Val Acc: 0.7662, Test Acc: 0.7553\n",
      "Seed: 42, Epoch: 065, Loss: 0.3805, Val Acc: 0.7581, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 066, Loss: 0.3891, Val Acc: 0.7354, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 067, Loss: 0.3974, Val Acc: 0.7500, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 068, Loss: 0.3848, Val Acc: 0.7808, Test Acc: 0.7569\n",
      "Seed: 42, Epoch: 069, Loss: 0.3606, Val Acc: 0.7630, Test Acc: 0.7715\n",
      "Seed: 42, Epoch: 070, Loss: 0.3713, Val Acc: 0.7516, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 071, Loss: 0.3771, Val Acc: 0.7273, Test Acc: 0.7407\n",
      "Seed: 42, Epoch: 072, Loss: 0.3747, Val Acc: 0.7321, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 073, Loss: 0.3737, Val Acc: 0.7468, Test Acc: 0.7277\n",
      "Seed: 42, Epoch: 074, Loss: 0.3729, Val Acc: 0.7159, Test Acc: 0.6969\n",
      "Seed: 42, Epoch: 075, Loss: 0.3827, Val Acc: 0.7679, Test Acc: 0.7536\n",
      "Seed: 42, Epoch: 076, Loss: 0.3753, Val Acc: 0.7744, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 077, Loss: 0.3599, Val Acc: 0.7419, Test Acc: 0.7180\n",
      "Seed: 42, Epoch: 078, Loss: 0.3509, Val Acc: 0.7549, Test Acc: 0.7569\n",
      "Seed: 42, Epoch: 079, Loss: 0.3657, Val Acc: 0.7532, Test Acc: 0.7261\n",
      "Seed: 42, Epoch: 080, Loss: 0.3644, Val Acc: 0.7565, Test Acc: 0.7472\n",
      "Seed: 42, Epoch: 081, Loss: 0.3451, Val Acc: 0.7662, Test Acc: 0.7342\n",
      "Seed: 42, Epoch: 082, Loss: 0.3531, Val Acc: 0.7289, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 083, Loss: 0.3651, Val Acc: 0.7614, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 084, Loss: 0.3475, Val Acc: 0.7305, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 085, Loss: 0.3683, Val Acc: 0.7305, Test Acc: 0.7326\n",
      "Seed: 42, Epoch: 086, Loss: 0.3698, Val Acc: 0.7890, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 087, Loss: 0.3567, Val Acc: 0.7711, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 088, Loss: 0.3476, Val Acc: 0.7662, Test Acc: 0.7342\n",
      "Seed: 42, Epoch: 089, Loss: 0.3457, Val Acc: 0.7386, Test Acc: 0.7147\n",
      "Seed: 42, Epoch: 090, Loss: 0.3476, Val Acc: 0.7614, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 091, Loss: 0.3524, Val Acc: 0.7565, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 092, Loss: 0.3543, Val Acc: 0.7224, Test Acc: 0.7326\n",
      "Seed: 42, Epoch: 093, Loss: 0.3458, Val Acc: 0.6981, Test Acc: 0.7050\n",
      "Seed: 42, Epoch: 094, Loss: 0.3475, Val Acc: 0.7614, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 095, Loss: 0.3389, Val Acc: 0.7516, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 096, Loss: 0.3340, Val Acc: 0.7727, Test Acc: 0.7553\n",
      "Seed: 42, Epoch: 097, Loss: 0.3285, Val Acc: 0.7500, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 098, Loss: 0.3295, Val Acc: 0.7727, Test Acc: 0.7536\n",
      "Seed: 42, Epoch: 099, Loss: 0.3258, Val Acc: 0.7516, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 100, Loss: 0.3310, Val Acc: 0.7451, Test Acc: 0.7310\n",
      "Seed: 42, Epoch: 101, Loss: 0.3193, Val Acc: 0.7646, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 102, Loss: 0.3201, Val Acc: 0.7630, Test Acc: 0.7472\n",
      "Seed: 42, Epoch: 103, Loss: 0.3139, Val Acc: 0.7744, Test Acc: 0.7618\n",
      "Seed: 42, Epoch: 104, Loss: 0.3014, Val Acc: 0.7321, Test Acc: 0.7472\n",
      "Seed: 42, Epoch: 105, Loss: 0.3195, Val Acc: 0.7468, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 106, Loss: 0.3124, Val Acc: 0.7646, Test Acc: 0.7472\n",
      "Seed: 42, Epoch: 107, Loss: 0.3106, Val Acc: 0.7500, Test Acc: 0.7618\n",
      "Seed: 42, Epoch: 108, Loss: 0.3054, Val Acc: 0.7679, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 109, Loss: 0.3149, Val Acc: 0.7662, Test Acc: 0.7569\n",
      "Seed: 42, Epoch: 110, Loss: 0.3213, Val Acc: 0.7808, Test Acc: 0.7618\n",
      "Seed: 42, Epoch: 111, Loss: 0.3065, Val Acc: 0.7711, Test Acc: 0.7569\n",
      "Seed: 42, Epoch: 112, Loss: 0.3081, Val Acc: 0.7873, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 113, Loss: 0.2877, Val Acc: 0.7695, Test Acc: 0.7180\n",
      "Seed: 42, Epoch: 114, Loss: 0.3017, Val Acc: 0.7614, Test Acc: 0.7472\n",
      "Seed: 42, Epoch: 115, Loss: 0.2873, Val Acc: 0.7760, Test Acc: 0.7472\n",
      "Seed: 42, Epoch: 116, Loss: 0.2960, Val Acc: 0.7468, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 117, Loss: 0.2874, Val Acc: 0.7776, Test Acc: 0.7553\n",
      "Seed: 42, Epoch: 118, Loss: 0.2998, Val Acc: 0.7516, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 119, Loss: 0.3058, Val Acc: 0.7565, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 120, Loss: 0.2873, Val Acc: 0.7614, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 121, Loss: 0.3150, Val Acc: 0.7630, Test Acc: 0.7245\n",
      "Seed: 42, Epoch: 122, Loss: 0.2977, Val Acc: 0.7825, Test Acc: 0.7796\n",
      "Seed: 42, Epoch: 123, Loss: 0.2809, Val Acc: 0.7532, Test Acc: 0.7131\n",
      "Seed: 42, Epoch: 124, Loss: 0.2884, Val Acc: 0.7435, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 125, Loss: 0.3015, Val Acc: 0.7630, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 126, Loss: 0.2775, Val Acc: 0.7808, Test Acc: 0.7666\n",
      "Seed: 42, Epoch: 127, Loss: 0.2781, Val Acc: 0.7646, Test Acc: 0.7536\n",
      "Seed: 42, Epoch: 128, Loss: 0.2886, Val Acc: 0.7419, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 129, Loss: 0.3088, Val Acc: 0.7013, Test Acc: 0.6840\n",
      "Seed: 42, Epoch: 130, Loss: 0.2916, Val Acc: 0.7451, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 131, Loss: 0.2854, Val Acc: 0.7273, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 132, Loss: 0.2983, Val Acc: 0.7630, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 133, Loss: 0.2855, Val Acc: 0.7403, Test Acc: 0.7585\n",
      "Seed: 42, Epoch: 134, Loss: 0.2927, Val Acc: 0.7354, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 135, Loss: 0.2873, Val Acc: 0.7549, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 136, Loss: 0.2779, Val Acc: 0.7435, Test Acc: 0.7293\n",
      "Seed: 42, Epoch: 137, Loss: 0.2717, Val Acc: 0.7549, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 138, Loss: 0.2929, Val Acc: 0.7143, Test Acc: 0.7342\n",
      "Seed: 42, Epoch: 139, Loss: 0.3029, Val Acc: 0.7451, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 140, Loss: 0.2698, Val Acc: 0.7776, Test Acc: 0.7472\n",
      "Seed: 42, Epoch: 141, Loss: 0.2667, Val Acc: 0.7256, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 142, Loss: 0.2731, Val Acc: 0.7614, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 143, Loss: 0.2688, Val Acc: 0.7532, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 144, Loss: 0.2640, Val Acc: 0.7403, Test Acc: 0.7407\n",
      "Seed: 42, Epoch: 145, Loss: 0.2781, Val Acc: 0.6964, Test Acc: 0.7245\n",
      "Seed: 42, Epoch: 146, Loss: 0.2672, Val Acc: 0.7435, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 147, Loss: 0.2660, Val Acc: 0.7776, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 148, Loss: 0.2678, Val Acc: 0.7127, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 149, Loss: 0.2717, Val Acc: 0.7289, Test Acc: 0.7261\n",
      "Seed: 42, Epoch: 150, Loss: 0.2738, Val Acc: 0.7532, Test Acc: 0.7115\n",
      "Seed: 42, Epoch: 151, Loss: 0.2723, Val Acc: 0.7062, Test Acc: 0.6807\n",
      "Seed: 42, Epoch: 152, Loss: 0.2599, Val Acc: 0.7695, Test Acc: 0.7569\n",
      "Seed: 42, Epoch: 153, Loss: 0.2440, Val Acc: 0.7289, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 154, Loss: 0.2592, Val Acc: 0.7662, Test Acc: 0.7682\n",
      "Seed: 42, Epoch: 155, Loss: 0.2460, Val Acc: 0.7419, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 156, Loss: 0.2711, Val Acc: 0.7256, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 157, Loss: 0.2529, Val Acc: 0.7792, Test Acc: 0.7569\n",
      "Seed: 42, Epoch: 158, Loss: 0.2720, Val Acc: 0.7873, Test Acc: 0.7634\n",
      "Seed: 42, Epoch: 159, Loss: 0.2475, Val Acc: 0.7289, Test Acc: 0.7423\n",
      "Seed: 42, Epoch: 160, Loss: 0.2455, Val Acc: 0.7679, Test Acc: 0.7715\n",
      "Seed: 42, Epoch: 161, Loss: 0.2477, Val Acc: 0.7825, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 162, Loss: 0.2425, Val Acc: 0.7532, Test Acc: 0.7666\n",
      "Seed: 42, Epoch: 163, Loss: 0.2465, Val Acc: 0.7127, Test Acc: 0.7212\n",
      "Seed: 42, Epoch: 164, Loss: 0.2617, Val Acc: 0.7224, Test Acc: 0.7245\n",
      "Seed: 42, Epoch: 165, Loss: 0.2601, Val Acc: 0.7532, Test Acc: 0.7650\n",
      "Seed: 42, Epoch: 166, Loss: 0.2405, Val Acc: 0.7516, Test Acc: 0.7650\n",
      "Seed: 42, Epoch: 167, Loss: 0.2480, Val Acc: 0.7727, Test Acc: 0.7585\n",
      "Seed: 42, Epoch: 168, Loss: 0.2489, Val Acc: 0.7532, Test Acc: 0.7472\n",
      "Seed: 42, Epoch: 169, Loss: 0.2633, Val Acc: 0.7532, Test Acc: 0.7164\n",
      "Seed: 42, Epoch: 170, Loss: 0.2555, Val Acc: 0.7289, Test Acc: 0.7358\n",
      "Seed: 42, Epoch: 171, Loss: 0.2389, Val Acc: 0.7549, Test Acc: 0.7180\n",
      "Seed: 42, Epoch: 172, Loss: 0.2433, Val Acc: 0.7614, Test Acc: 0.7618\n",
      "Seed: 42, Epoch: 173, Loss: 0.2503, Val Acc: 0.7744, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 174, Loss: 0.2598, Val Acc: 0.7338, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 175, Loss: 0.2575, Val Acc: 0.7614, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 176, Loss: 0.2444, Val Acc: 0.7468, Test Acc: 0.7455\n",
      "Seed: 42, Epoch: 177, Loss: 0.2378, Val Acc: 0.7662, Test Acc: 0.7682\n",
      "Seed: 42, Epoch: 178, Loss: 0.2663, Val Acc: 0.7597, Test Acc: 0.7618\n",
      "Seed: 42, Epoch: 179, Loss: 0.2490, Val Acc: 0.7532, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 180, Loss: 0.2403, Val Acc: 0.7614, Test Acc: 0.7536\n",
      "Seed: 42, Epoch: 181, Loss: 0.2402, Val Acc: 0.7597, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 182, Loss: 0.2432, Val Acc: 0.7403, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 183, Loss: 0.2374, Val Acc: 0.7532, Test Acc: 0.7650\n",
      "Seed: 42, Epoch: 184, Loss: 0.2259, Val Acc: 0.7354, Test Acc: 0.7229\n",
      "Seed: 42, Epoch: 185, Loss: 0.2419, Val Acc: 0.7484, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 186, Loss: 0.2474, Val Acc: 0.7516, Test Acc: 0.7391\n",
      "Seed: 42, Epoch: 187, Loss: 0.2353, Val Acc: 0.7500, Test Acc: 0.7553\n",
      "Seed: 42, Epoch: 188, Loss: 0.2505, Val Acc: 0.7419, Test Acc: 0.7326\n",
      "Seed: 42, Epoch: 189, Loss: 0.2464, Val Acc: 0.7679, Test Acc: 0.7828\n",
      "Seed: 42, Epoch: 190, Loss: 0.2634, Val Acc: 0.7289, Test Acc: 0.7666\n",
      "Seed: 42, Epoch: 191, Loss: 0.2331, Val Acc: 0.7662, Test Acc: 0.7585\n",
      "Seed: 42, Epoch: 192, Loss: 0.2204, Val Acc: 0.7289, Test Acc: 0.7374\n",
      "Seed: 42, Epoch: 193, Loss: 0.2399, Val Acc: 0.7614, Test Acc: 0.7650\n",
      "Seed: 42, Epoch: 194, Loss: 0.2334, Val Acc: 0.7321, Test Acc: 0.7439\n",
      "Seed: 42, Epoch: 195, Loss: 0.2074, Val Acc: 0.7386, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 196, Loss: 0.2148, Val Acc: 0.7516, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 197, Loss: 0.2133, Val Acc: 0.7484, Test Acc: 0.7488\n",
      "Seed: 42, Epoch: 198, Loss: 0.2301, Val Acc: 0.7419, Test Acc: 0.7504\n",
      "Seed: 42, Epoch: 199, Loss: 0.2306, Val Acc: 0.7614, Test Acc: 0.7293\n",
      "Early stopping at epoch 199 for seed 42\n",
      "Seed: 43, Epoch: 001, Loss: 0.6869, Val Acc: 0.5666, Test Acc: 0.5267\n",
      "Seed: 43, Epoch: 002, Loss: 0.6564, Val Acc: 0.5893, Test Acc: 0.5900\n",
      "Seed: 43, Epoch: 003, Loss: 0.6237, Val Acc: 0.6169, Test Acc: 0.6921\n",
      "Seed: 43, Epoch: 004, Loss: 0.6088, Val Acc: 0.6542, Test Acc: 0.6775\n",
      "Seed: 43, Epoch: 005, Loss: 0.6036, Val Acc: 0.6461, Test Acc: 0.6742\n",
      "Seed: 43, Epoch: 006, Loss: 0.5897, Val Acc: 0.6737, Test Acc: 0.6953\n",
      "Seed: 43, Epoch: 007, Loss: 0.5791, Val Acc: 0.6640, Test Acc: 0.6823\n",
      "Seed: 43, Epoch: 008, Loss: 0.5732, Val Acc: 0.6445, Test Acc: 0.6921\n",
      "Seed: 43, Epoch: 009, Loss: 0.5707, Val Acc: 0.6607, Test Acc: 0.7212\n",
      "Seed: 43, Epoch: 010, Loss: 0.5720, Val Acc: 0.6656, Test Acc: 0.7034\n",
      "Seed: 43, Epoch: 011, Loss: 0.5551, Val Acc: 0.7159, Test Acc: 0.7374\n",
      "Seed: 43, Epoch: 012, Loss: 0.5495, Val Acc: 0.7013, Test Acc: 0.7358\n",
      "Seed: 43, Epoch: 013, Loss: 0.5573, Val Acc: 0.6299, Test Acc: 0.6126\n",
      "Seed: 43, Epoch: 014, Loss: 0.5513, Val Acc: 0.6786, Test Acc: 0.7147\n",
      "Seed: 43, Epoch: 015, Loss: 0.5423, Val Acc: 0.7192, Test Acc: 0.7407\n",
      "Seed: 43, Epoch: 016, Loss: 0.5336, Val Acc: 0.7143, Test Acc: 0.7569\n",
      "Seed: 43, Epoch: 017, Loss: 0.5319, Val Acc: 0.7175, Test Acc: 0.7293\n",
      "Seed: 43, Epoch: 018, Loss: 0.5206, Val Acc: 0.7062, Test Acc: 0.7423\n",
      "Seed: 43, Epoch: 019, Loss: 0.5272, Val Acc: 0.7256, Test Acc: 0.7326\n",
      "Seed: 43, Epoch: 020, Loss: 0.5299, Val Acc: 0.6818, Test Acc: 0.7018\n",
      "Seed: 43, Epoch: 021, Loss: 0.5196, Val Acc: 0.7273, Test Acc: 0.7439\n",
      "Seed: 43, Epoch: 022, Loss: 0.5219, Val Acc: 0.6899, Test Acc: 0.6953\n",
      "Seed: 43, Epoch: 023, Loss: 0.5087, Val Acc: 0.7516, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 024, Loss: 0.5032, Val Acc: 0.7468, Test Acc: 0.7666\n",
      "Seed: 43, Epoch: 025, Loss: 0.4959, Val Acc: 0.7127, Test Acc: 0.7423\n",
      "Seed: 43, Epoch: 026, Loss: 0.4882, Val Acc: 0.6981, Test Acc: 0.7277\n",
      "Seed: 43, Epoch: 027, Loss: 0.5010, Val Acc: 0.6964, Test Acc: 0.7212\n",
      "Seed: 43, Epoch: 028, Loss: 0.4919, Val Acc: 0.7175, Test Acc: 0.7423\n",
      "Seed: 43, Epoch: 029, Loss: 0.4798, Val Acc: 0.7289, Test Acc: 0.7310\n",
      "Seed: 43, Epoch: 030, Loss: 0.4731, Val Acc: 0.6786, Test Acc: 0.7293\n",
      "Seed: 43, Epoch: 031, Loss: 0.4787, Val Acc: 0.7386, Test Acc: 0.7585\n",
      "Seed: 43, Epoch: 032, Loss: 0.4733, Val Acc: 0.7484, Test Acc: 0.7796\n",
      "Seed: 43, Epoch: 033, Loss: 0.4761, Val Acc: 0.7273, Test Acc: 0.7407\n",
      "Seed: 43, Epoch: 034, Loss: 0.4724, Val Acc: 0.7370, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 035, Loss: 0.4663, Val Acc: 0.7646, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 036, Loss: 0.4633, Val Acc: 0.6737, Test Acc: 0.6483\n",
      "Seed: 43, Epoch: 037, Loss: 0.4661, Val Acc: 0.7208, Test Acc: 0.7293\n",
      "Seed: 43, Epoch: 038, Loss: 0.4686, Val Acc: 0.6932, Test Acc: 0.6921\n",
      "Seed: 43, Epoch: 039, Loss: 0.4578, Val Acc: 0.7419, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 040, Loss: 0.4466, Val Acc: 0.7695, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 041, Loss: 0.4546, Val Acc: 0.6867, Test Acc: 0.7293\n",
      "Seed: 43, Epoch: 042, Loss: 0.4554, Val Acc: 0.7094, Test Acc: 0.7569\n",
      "Seed: 43, Epoch: 043, Loss: 0.4406, Val Acc: 0.7338, Test Acc: 0.6985\n",
      "Seed: 43, Epoch: 044, Loss: 0.4616, Val Acc: 0.7045, Test Acc: 0.6985\n",
      "Seed: 43, Epoch: 045, Loss: 0.4734, Val Acc: 0.7679, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 046, Loss: 0.4454, Val Acc: 0.7597, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 047, Loss: 0.4335, Val Acc: 0.7744, Test Acc: 0.7585\n",
      "Seed: 43, Epoch: 048, Loss: 0.4451, Val Acc: 0.7403, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 049, Loss: 0.4393, Val Acc: 0.7354, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 050, Loss: 0.4314, Val Acc: 0.7841, Test Acc: 0.7553\n",
      "Seed: 43, Epoch: 051, Loss: 0.4369, Val Acc: 0.7305, Test Acc: 0.7277\n",
      "Seed: 43, Epoch: 052, Loss: 0.4317, Val Acc: 0.7565, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 053, Loss: 0.4180, Val Acc: 0.7240, Test Acc: 0.7553\n",
      "Seed: 43, Epoch: 054, Loss: 0.4327, Val Acc: 0.7403, Test Acc: 0.7326\n",
      "Seed: 43, Epoch: 055, Loss: 0.4329, Val Acc: 0.7256, Test Acc: 0.7488\n",
      "Seed: 43, Epoch: 056, Loss: 0.4264, Val Acc: 0.7256, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 057, Loss: 0.4153, Val Acc: 0.7695, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 058, Loss: 0.4096, Val Acc: 0.7338, Test Acc: 0.7358\n",
      "Seed: 43, Epoch: 059, Loss: 0.4199, Val Acc: 0.7354, Test Acc: 0.7131\n",
      "Seed: 43, Epoch: 060, Loss: 0.4146, Val Acc: 0.7289, Test Acc: 0.7504\n",
      "Seed: 43, Epoch: 061, Loss: 0.4124, Val Acc: 0.6672, Test Acc: 0.6726\n",
      "Seed: 43, Epoch: 062, Loss: 0.4043, Val Acc: 0.7760, Test Acc: 0.7212\n",
      "Seed: 43, Epoch: 063, Loss: 0.4105, Val Acc: 0.7500, Test Acc: 0.7391\n",
      "Seed: 43, Epoch: 064, Loss: 0.3941, Val Acc: 0.7386, Test Acc: 0.7488\n",
      "Seed: 43, Epoch: 065, Loss: 0.4158, Val Acc: 0.7695, Test Acc: 0.7666\n",
      "Seed: 43, Epoch: 066, Loss: 0.4046, Val Acc: 0.7744, Test Acc: 0.7861\n",
      "Seed: 43, Epoch: 067, Loss: 0.3965, Val Acc: 0.7370, Test Acc: 0.7261\n",
      "Seed: 43, Epoch: 068, Loss: 0.3885, Val Acc: 0.7451, Test Acc: 0.7277\n",
      "Seed: 43, Epoch: 069, Loss: 0.3966, Val Acc: 0.7711, Test Acc: 0.7407\n",
      "Seed: 43, Epoch: 070, Loss: 0.3971, Val Acc: 0.7532, Test Acc: 0.7277\n",
      "Seed: 43, Epoch: 071, Loss: 0.3940, Val Acc: 0.7175, Test Acc: 0.6888\n",
      "Seed: 43, Epoch: 072, Loss: 0.3899, Val Acc: 0.7662, Test Acc: 0.7196\n",
      "Seed: 43, Epoch: 073, Loss: 0.4008, Val Acc: 0.6883, Test Acc: 0.6985\n",
      "Seed: 43, Epoch: 074, Loss: 0.4032, Val Acc: 0.7175, Test Acc: 0.7342\n",
      "Seed: 43, Epoch: 075, Loss: 0.3942, Val Acc: 0.7825, Test Acc: 0.7326\n",
      "Seed: 43, Epoch: 076, Loss: 0.3825, Val Acc: 0.7711, Test Acc: 0.7293\n",
      "Seed: 43, Epoch: 077, Loss: 0.3864, Val Acc: 0.7451, Test Acc: 0.7277\n",
      "Seed: 43, Epoch: 078, Loss: 0.3962, Val Acc: 0.7127, Test Acc: 0.7099\n",
      "Seed: 43, Epoch: 079, Loss: 0.3772, Val Acc: 0.7403, Test Acc: 0.7131\n",
      "Seed: 43, Epoch: 080, Loss: 0.3806, Val Acc: 0.8019, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 081, Loss: 0.3756, Val Acc: 0.7273, Test Acc: 0.7245\n",
      "Seed: 43, Epoch: 082, Loss: 0.3740, Val Acc: 0.7516, Test Acc: 0.7326\n",
      "Seed: 43, Epoch: 083, Loss: 0.3668, Val Acc: 0.7792, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 084, Loss: 0.3677, Val Acc: 0.7662, Test Acc: 0.7472\n",
      "Seed: 43, Epoch: 085, Loss: 0.3691, Val Acc: 0.7532, Test Acc: 0.7488\n",
      "Seed: 43, Epoch: 086, Loss: 0.3630, Val Acc: 0.7630, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 087, Loss: 0.3729, Val Acc: 0.7013, Test Acc: 0.7277\n",
      "Seed: 43, Epoch: 088, Loss: 0.3625, Val Acc: 0.7646, Test Acc: 0.7423\n",
      "Seed: 43, Epoch: 089, Loss: 0.3548, Val Acc: 0.7873, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 090, Loss: 0.3530, Val Acc: 0.7808, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 091, Loss: 0.3640, Val Acc: 0.7468, Test Acc: 0.7472\n",
      "Seed: 43, Epoch: 092, Loss: 0.3595, Val Acc: 0.7451, Test Acc: 0.7083\n",
      "Seed: 43, Epoch: 093, Loss: 0.3464, Val Acc: 0.7549, Test Acc: 0.7358\n",
      "Seed: 43, Epoch: 094, Loss: 0.3614, Val Acc: 0.7646, Test Acc: 0.7293\n",
      "Seed: 43, Epoch: 095, Loss: 0.3643, Val Acc: 0.7938, Test Acc: 0.7553\n",
      "Seed: 43, Epoch: 096, Loss: 0.3550, Val Acc: 0.7110, Test Acc: 0.7115\n",
      "Seed: 43, Epoch: 097, Loss: 0.3633, Val Acc: 0.7808, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 098, Loss: 0.3429, Val Acc: 0.7695, Test Acc: 0.7164\n",
      "Seed: 43, Epoch: 099, Loss: 0.3484, Val Acc: 0.7273, Test Acc: 0.7099\n",
      "Seed: 43, Epoch: 100, Loss: 0.3342, Val Acc: 0.7597, Test Acc: 0.7569\n",
      "Seed: 43, Epoch: 101, Loss: 0.3453, Val Acc: 0.7403, Test Acc: 0.7261\n",
      "Seed: 43, Epoch: 102, Loss: 0.3248, Val Acc: 0.7825, Test Acc: 0.7731\n",
      "Seed: 43, Epoch: 103, Loss: 0.3444, Val Acc: 0.7468, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 104, Loss: 0.3357, Val Acc: 0.7825, Test Acc: 0.7261\n",
      "Seed: 43, Epoch: 105, Loss: 0.3280, Val Acc: 0.7662, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 106, Loss: 0.3493, Val Acc: 0.7614, Test Acc: 0.7342\n",
      "Seed: 43, Epoch: 107, Loss: 0.3310, Val Acc: 0.7451, Test Acc: 0.7342\n",
      "Seed: 43, Epoch: 108, Loss: 0.3323, Val Acc: 0.7435, Test Acc: 0.7196\n",
      "Seed: 43, Epoch: 109, Loss: 0.3298, Val Acc: 0.7484, Test Acc: 0.7358\n",
      "Seed: 43, Epoch: 110, Loss: 0.3343, Val Acc: 0.6997, Test Acc: 0.7099\n",
      "Seed: 43, Epoch: 111, Loss: 0.3594, Val Acc: 0.7630, Test Acc: 0.7245\n",
      "Seed: 43, Epoch: 112, Loss: 0.3391, Val Acc: 0.7792, Test Acc: 0.7455\n",
      "Seed: 43, Epoch: 113, Loss: 0.3189, Val Acc: 0.7873, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 114, Loss: 0.3205, Val Acc: 0.7857, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 115, Loss: 0.3139, Val Acc: 0.7808, Test Acc: 0.7569\n",
      "Seed: 43, Epoch: 116, Loss: 0.3311, Val Acc: 0.7516, Test Acc: 0.7310\n",
      "Seed: 43, Epoch: 117, Loss: 0.3266, Val Acc: 0.7792, Test Acc: 0.7504\n",
      "Seed: 43, Epoch: 118, Loss: 0.3203, Val Acc: 0.7695, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 119, Loss: 0.3325, Val Acc: 0.7370, Test Acc: 0.7066\n",
      "Seed: 43, Epoch: 120, Loss: 0.3120, Val Acc: 0.7662, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 121, Loss: 0.3213, Val Acc: 0.7679, Test Acc: 0.7715\n",
      "Seed: 43, Epoch: 122, Loss: 0.3243, Val Acc: 0.7792, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 123, Loss: 0.3134, Val Acc: 0.7906, Test Acc: 0.7844\n",
      "Seed: 43, Epoch: 124, Loss: 0.3085, Val Acc: 0.7906, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 125, Loss: 0.3248, Val Acc: 0.7289, Test Acc: 0.7147\n",
      "Seed: 43, Epoch: 126, Loss: 0.3227, Val Acc: 0.7760, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 127, Loss: 0.3068, Val Acc: 0.7597, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 128, Loss: 0.3090, Val Acc: 0.7403, Test Acc: 0.7277\n",
      "Seed: 43, Epoch: 129, Loss: 0.3089, Val Acc: 0.7581, Test Acc: 0.7164\n",
      "Seed: 43, Epoch: 130, Loss: 0.3057, Val Acc: 0.7597, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 131, Loss: 0.3266, Val Acc: 0.7662, Test Acc: 0.7147\n",
      "Seed: 43, Epoch: 132, Loss: 0.3174, Val Acc: 0.7987, Test Acc: 0.7861\n",
      "Seed: 43, Epoch: 133, Loss: 0.2986, Val Acc: 0.7354, Test Acc: 0.7147\n",
      "Seed: 43, Epoch: 134, Loss: 0.2918, Val Acc: 0.7321, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 135, Loss: 0.2781, Val Acc: 0.7938, Test Acc: 0.7763\n",
      "Seed: 43, Epoch: 136, Loss: 0.3112, Val Acc: 0.7938, Test Acc: 0.7439\n",
      "Seed: 43, Epoch: 137, Loss: 0.3045, Val Acc: 0.7776, Test Acc: 0.7666\n",
      "Seed: 43, Epoch: 138, Loss: 0.2868, Val Acc: 0.7565, Test Acc: 0.7358\n",
      "Seed: 43, Epoch: 139, Loss: 0.2883, Val Acc: 0.7695, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 140, Loss: 0.2922, Val Acc: 0.7386, Test Acc: 0.6904\n",
      "Seed: 43, Epoch: 141, Loss: 0.2924, Val Acc: 0.7906, Test Acc: 0.7682\n",
      "Seed: 43, Epoch: 142, Loss: 0.2801, Val Acc: 0.7808, Test Acc: 0.7796\n",
      "Seed: 43, Epoch: 143, Loss: 0.2986, Val Acc: 0.7354, Test Acc: 0.7212\n",
      "Seed: 43, Epoch: 144, Loss: 0.2936, Val Acc: 0.7321, Test Acc: 0.7180\n",
      "Seed: 43, Epoch: 145, Loss: 0.3052, Val Acc: 0.7419, Test Acc: 0.6661\n",
      "Seed: 43, Epoch: 146, Loss: 0.3089, Val Acc: 0.7727, Test Acc: 0.7391\n",
      "Seed: 43, Epoch: 147, Loss: 0.2976, Val Acc: 0.7468, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 148, Loss: 0.2860, Val Acc: 0.7971, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 149, Loss: 0.2804, Val Acc: 0.7662, Test Acc: 0.7391\n",
      "Seed: 43, Epoch: 150, Loss: 0.3064, Val Acc: 0.7419, Test Acc: 0.7504\n",
      "Seed: 43, Epoch: 151, Loss: 0.2916, Val Acc: 0.7776, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 152, Loss: 0.2912, Val Acc: 0.7873, Test Acc: 0.7472\n",
      "Seed: 43, Epoch: 153, Loss: 0.2809, Val Acc: 0.7922, Test Acc: 0.7553\n",
      "Seed: 43, Epoch: 154, Loss: 0.2880, Val Acc: 0.7565, Test Acc: 0.7715\n",
      "Seed: 43, Epoch: 155, Loss: 0.2752, Val Acc: 0.7500, Test Acc: 0.7293\n",
      "Seed: 43, Epoch: 156, Loss: 0.2704, Val Acc: 0.7695, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 157, Loss: 0.2902, Val Acc: 0.7662, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 158, Loss: 0.2889, Val Acc: 0.7029, Test Acc: 0.7326\n",
      "Seed: 43, Epoch: 159, Loss: 0.2757, Val Acc: 0.7646, Test Acc: 0.7828\n",
      "Seed: 43, Epoch: 160, Loss: 0.2774, Val Acc: 0.7516, Test Acc: 0.7180\n",
      "Seed: 43, Epoch: 161, Loss: 0.2779, Val Acc: 0.7711, Test Acc: 0.7828\n",
      "Seed: 43, Epoch: 162, Loss: 0.2641, Val Acc: 0.7727, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 163, Loss: 0.2641, Val Acc: 0.7808, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 164, Loss: 0.2644, Val Acc: 0.7776, Test Acc: 0.7520\n",
      "Seed: 43, Epoch: 165, Loss: 0.2684, Val Acc: 0.7662, Test Acc: 0.7925\n",
      "Seed: 43, Epoch: 166, Loss: 0.2591, Val Acc: 0.7630, Test Acc: 0.7715\n",
      "Seed: 43, Epoch: 167, Loss: 0.2654, Val Acc: 0.7435, Test Acc: 0.7131\n",
      "Seed: 43, Epoch: 168, Loss: 0.2769, Val Acc: 0.7614, Test Acc: 0.7553\n",
      "Seed: 43, Epoch: 169, Loss: 0.2623, Val Acc: 0.7581, Test Acc: 0.7796\n",
      "Seed: 43, Epoch: 170, Loss: 0.2679, Val Acc: 0.7581, Test Acc: 0.7407\n",
      "Seed: 43, Epoch: 171, Loss: 0.2631, Val Acc: 0.7906, Test Acc: 0.7780\n",
      "Seed: 43, Epoch: 172, Loss: 0.2709, Val Acc: 0.7646, Test Acc: 0.7861\n",
      "Seed: 43, Epoch: 173, Loss: 0.2753, Val Acc: 0.7419, Test Acc: 0.7293\n",
      "Seed: 43, Epoch: 174, Loss: 0.2616, Val Acc: 0.7922, Test Acc: 0.7796\n",
      "Seed: 43, Epoch: 175, Loss: 0.2669, Val Acc: 0.7760, Test Acc: 0.7634\n",
      "Seed: 43, Epoch: 176, Loss: 0.2796, Val Acc: 0.7662, Test Acc: 0.7715\n",
      "Seed: 43, Epoch: 177, Loss: 0.2526, Val Acc: 0.7808, Test Acc: 0.7666\n",
      "Seed: 43, Epoch: 178, Loss: 0.2638, Val Acc: 0.7906, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 179, Loss: 0.2560, Val Acc: 0.7808, Test Acc: 0.7618\n",
      "Seed: 43, Epoch: 180, Loss: 0.2513, Val Acc: 0.7435, Test Acc: 0.7763\n",
      "Seed: 43, Epoch: 181, Loss: 0.2510, Val Acc: 0.7435, Test Acc: 0.7293\n",
      "Seed: 43, Epoch: 182, Loss: 0.2678, Val Acc: 0.7468, Test Acc: 0.7472\n",
      "Seed: 43, Epoch: 183, Loss: 0.2533, Val Acc: 0.7679, Test Acc: 0.7407\n",
      "Seed: 43, Epoch: 184, Loss: 0.2547, Val Acc: 0.7386, Test Acc: 0.7180\n",
      "Seed: 43, Epoch: 185, Loss: 0.2650, Val Acc: 0.7841, Test Acc: 0.7909\n",
      "Seed: 43, Epoch: 186, Loss: 0.2388, Val Acc: 0.7679, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 187, Loss: 0.2460, Val Acc: 0.7727, Test Acc: 0.7844\n",
      "Seed: 43, Epoch: 188, Loss: 0.2508, Val Acc: 0.7662, Test Acc: 0.7958\n",
      "Seed: 43, Epoch: 189, Loss: 0.2556, Val Acc: 0.7435, Test Acc: 0.7812\n",
      "Seed: 43, Epoch: 190, Loss: 0.2448, Val Acc: 0.7565, Test Acc: 0.7439\n",
      "Seed: 43, Epoch: 191, Loss: 0.2417, Val Acc: 0.7711, Test Acc: 0.7666\n",
      "Seed: 43, Epoch: 192, Loss: 0.2392, Val Acc: 0.7321, Test Acc: 0.7391\n",
      "Seed: 43, Epoch: 193, Loss: 0.2441, Val Acc: 0.7532, Test Acc: 0.7504\n",
      "Seed: 43, Epoch: 194, Loss: 0.2362, Val Acc: 0.7695, Test Acc: 0.7601\n",
      "Seed: 43, Epoch: 195, Loss: 0.2305, Val Acc: 0.7776, Test Acc: 0.7585\n",
      "Seed: 43, Epoch: 196, Loss: 0.2422, Val Acc: 0.7857, Test Acc: 0.7391\n",
      "Seed: 43, Epoch: 197, Loss: 0.2313, Val Acc: 0.7597, Test Acc: 0.7650\n",
      "Seed: 43, Epoch: 198, Loss: 0.2492, Val Acc: 0.7825, Test Acc: 0.7504\n",
      "Seed: 43, Epoch: 199, Loss: 0.2506, Val Acc: 0.7873, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 200, Loss: 0.2516, Val Acc: 0.7354, Test Acc: 0.7229\n",
      "Seed: 44, Epoch: 001, Loss: 0.6971, Val Acc: 0.4919, Test Acc: 0.4895\n",
      "Seed: 44, Epoch: 002, Loss: 0.6742, Val Acc: 0.5860, Test Acc: 0.5640\n",
      "Seed: 44, Epoch: 003, Loss: 0.6343, Val Acc: 0.6201, Test Acc: 0.6110\n",
      "Seed: 44, Epoch: 004, Loss: 0.6199, Val Acc: 0.6672, Test Acc: 0.6467\n",
      "Seed: 44, Epoch: 005, Loss: 0.6071, Val Acc: 0.6510, Test Acc: 0.6191\n",
      "Seed: 44, Epoch: 006, Loss: 0.5965, Val Acc: 0.6786, Test Acc: 0.6467\n",
      "Seed: 44, Epoch: 007, Loss: 0.5909, Val Acc: 0.6786, Test Acc: 0.6710\n",
      "Seed: 44, Epoch: 008, Loss: 0.5843, Val Acc: 0.6688, Test Acc: 0.6613\n",
      "Seed: 44, Epoch: 009, Loss: 0.5732, Val Acc: 0.6851, Test Acc: 0.6823\n",
      "Seed: 44, Epoch: 010, Loss: 0.5693, Val Acc: 0.6753, Test Acc: 0.6499\n",
      "Seed: 44, Epoch: 011, Loss: 0.5628, Val Acc: 0.6721, Test Acc: 0.6726\n",
      "Seed: 44, Epoch: 012, Loss: 0.5590, Val Acc: 0.7045, Test Acc: 0.7099\n",
      "Seed: 44, Epoch: 013, Loss: 0.5428, Val Acc: 0.6964, Test Acc: 0.6904\n",
      "Seed: 44, Epoch: 014, Loss: 0.5424, Val Acc: 0.6786, Test Acc: 0.6791\n",
      "Seed: 44, Epoch: 015, Loss: 0.5343, Val Acc: 0.7062, Test Acc: 0.7245\n",
      "Seed: 44, Epoch: 016, Loss: 0.5336, Val Acc: 0.7143, Test Acc: 0.7196\n",
      "Seed: 44, Epoch: 017, Loss: 0.5277, Val Acc: 0.7175, Test Acc: 0.7131\n",
      "Seed: 44, Epoch: 018, Loss: 0.5164, Val Acc: 0.7159, Test Acc: 0.7212\n",
      "Seed: 44, Epoch: 019, Loss: 0.5236, Val Acc: 0.6981, Test Acc: 0.7002\n",
      "Seed: 44, Epoch: 020, Loss: 0.5140, Val Acc: 0.7208, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 021, Loss: 0.5144, Val Acc: 0.7273, Test Acc: 0.7164\n",
      "Seed: 44, Epoch: 022, Loss: 0.5124, Val Acc: 0.6802, Test Acc: 0.6953\n",
      "Seed: 44, Epoch: 023, Loss: 0.5081, Val Acc: 0.7370, Test Acc: 0.7050\n",
      "Seed: 44, Epoch: 024, Loss: 0.4987, Val Acc: 0.7208, Test Acc: 0.7066\n",
      "Seed: 44, Epoch: 025, Loss: 0.4921, Val Acc: 0.7208, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 026, Loss: 0.5016, Val Acc: 0.7029, Test Acc: 0.7099\n",
      "Seed: 44, Epoch: 027, Loss: 0.5102, Val Acc: 0.7029, Test Acc: 0.7034\n",
      "Seed: 44, Epoch: 028, Loss: 0.4875, Val Acc: 0.7403, Test Acc: 0.7391\n",
      "Seed: 44, Epoch: 029, Loss: 0.4799, Val Acc: 0.7127, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 030, Loss: 0.5037, Val Acc: 0.7468, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 031, Loss: 0.4838, Val Acc: 0.6834, Test Acc: 0.6840\n",
      "Seed: 44, Epoch: 032, Loss: 0.4668, Val Acc: 0.7386, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 033, Loss: 0.4695, Val Acc: 0.7256, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 034, Loss: 0.4715, Val Acc: 0.7208, Test Acc: 0.7391\n",
      "Seed: 44, Epoch: 035, Loss: 0.4619, Val Acc: 0.7289, Test Acc: 0.7002\n",
      "Seed: 44, Epoch: 036, Loss: 0.4620, Val Acc: 0.7386, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 037, Loss: 0.4543, Val Acc: 0.7175, Test Acc: 0.7196\n",
      "Seed: 44, Epoch: 038, Loss: 0.4464, Val Acc: 0.6948, Test Acc: 0.6856\n",
      "Seed: 44, Epoch: 039, Loss: 0.4530, Val Acc: 0.7305, Test Acc: 0.7083\n",
      "Seed: 44, Epoch: 040, Loss: 0.4552, Val Acc: 0.7532, Test Acc: 0.7391\n",
      "Seed: 44, Epoch: 041, Loss: 0.4570, Val Acc: 0.7208, Test Acc: 0.7229\n",
      "Seed: 44, Epoch: 042, Loss: 0.4540, Val Acc: 0.7338, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 043, Loss: 0.4518, Val Acc: 0.7256, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 044, Loss: 0.4613, Val Acc: 0.7386, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 045, Loss: 0.4399, Val Acc: 0.7500, Test Acc: 0.7699\n",
      "Seed: 44, Epoch: 046, Loss: 0.4415, Val Acc: 0.7484, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 047, Loss: 0.4378, Val Acc: 0.7029, Test Acc: 0.7229\n",
      "Seed: 44, Epoch: 048, Loss: 0.4452, Val Acc: 0.6981, Test Acc: 0.6921\n",
      "Seed: 44, Epoch: 049, Loss: 0.4364, Val Acc: 0.7305, Test Acc: 0.7423\n",
      "Seed: 44, Epoch: 050, Loss: 0.4304, Val Acc: 0.7646, Test Acc: 0.7472\n",
      "Seed: 44, Epoch: 051, Loss: 0.4224, Val Acc: 0.7581, Test Acc: 0.7374\n",
      "Seed: 44, Epoch: 052, Loss: 0.4242, Val Acc: 0.7159, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 053, Loss: 0.4244, Val Acc: 0.7289, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 054, Loss: 0.4140, Val Acc: 0.7468, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 055, Loss: 0.4179, Val Acc: 0.7386, Test Acc: 0.7618\n",
      "Seed: 44, Epoch: 056, Loss: 0.4080, Val Acc: 0.7435, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 057, Loss: 0.4228, Val Acc: 0.7451, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 058, Loss: 0.4247, Val Acc: 0.7305, Test Acc: 0.7326\n",
      "Seed: 44, Epoch: 059, Loss: 0.4174, Val Acc: 0.7273, Test Acc: 0.7002\n",
      "Seed: 44, Epoch: 060, Loss: 0.4102, Val Acc: 0.7062, Test Acc: 0.7245\n",
      "Seed: 44, Epoch: 061, Loss: 0.4013, Val Acc: 0.7159, Test Acc: 0.7212\n",
      "Seed: 44, Epoch: 062, Loss: 0.4088, Val Acc: 0.6786, Test Acc: 0.6937\n",
      "Seed: 44, Epoch: 063, Loss: 0.4178, Val Acc: 0.7419, Test Acc: 0.7455\n",
      "Seed: 44, Epoch: 064, Loss: 0.4012, Val Acc: 0.6932, Test Acc: 0.6953\n",
      "Seed: 44, Epoch: 065, Loss: 0.4048, Val Acc: 0.7192, Test Acc: 0.7374\n",
      "Seed: 44, Epoch: 066, Loss: 0.4112, Val Acc: 0.7078, Test Acc: 0.6759\n",
      "Seed: 44, Epoch: 067, Loss: 0.3900, Val Acc: 0.7321, Test Acc: 0.7618\n",
      "Seed: 44, Epoch: 068, Loss: 0.3916, Val Acc: 0.7289, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 069, Loss: 0.3828, Val Acc: 0.7581, Test Acc: 0.7634\n",
      "Seed: 44, Epoch: 070, Loss: 0.3852, Val Acc: 0.7597, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 071, Loss: 0.3806, Val Acc: 0.7208, Test Acc: 0.7050\n",
      "Seed: 44, Epoch: 072, Loss: 0.3730, Val Acc: 0.7289, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 073, Loss: 0.3733, Val Acc: 0.7289, Test Acc: 0.7066\n",
      "Seed: 44, Epoch: 074, Loss: 0.3879, Val Acc: 0.6981, Test Acc: 0.7180\n",
      "Seed: 44, Epoch: 075, Loss: 0.3713, Val Acc: 0.6883, Test Acc: 0.6856\n",
      "Seed: 44, Epoch: 076, Loss: 0.3777, Val Acc: 0.7451, Test Acc: 0.7585\n",
      "Seed: 44, Epoch: 077, Loss: 0.3768, Val Acc: 0.7273, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 078, Loss: 0.3690, Val Acc: 0.7159, Test Acc: 0.7212\n",
      "Seed: 44, Epoch: 079, Loss: 0.3649, Val Acc: 0.7500, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 080, Loss: 0.3666, Val Acc: 0.7321, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 081, Loss: 0.3603, Val Acc: 0.7192, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 082, Loss: 0.3640, Val Acc: 0.7224, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 083, Loss: 0.3573, Val Acc: 0.7354, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 084, Loss: 0.3674, Val Acc: 0.7630, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 085, Loss: 0.3572, Val Acc: 0.7240, Test Acc: 0.7229\n",
      "Seed: 44, Epoch: 086, Loss: 0.3553, Val Acc: 0.7565, Test Acc: 0.7455\n",
      "Seed: 44, Epoch: 087, Loss: 0.3563, Val Acc: 0.7240, Test Acc: 0.7455\n",
      "Seed: 44, Epoch: 088, Loss: 0.3409, Val Acc: 0.7484, Test Acc: 0.7553\n",
      "Seed: 44, Epoch: 089, Loss: 0.3621, Val Acc: 0.7484, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 090, Loss: 0.3465, Val Acc: 0.6916, Test Acc: 0.7147\n",
      "Seed: 44, Epoch: 091, Loss: 0.3513, Val Acc: 0.7305, Test Acc: 0.7147\n",
      "Seed: 44, Epoch: 092, Loss: 0.3426, Val Acc: 0.7435, Test Acc: 0.7618\n",
      "Seed: 44, Epoch: 093, Loss: 0.3530, Val Acc: 0.6818, Test Acc: 0.7066\n",
      "Seed: 44, Epoch: 094, Loss: 0.3565, Val Acc: 0.6997, Test Acc: 0.7115\n",
      "Seed: 44, Epoch: 095, Loss: 0.3449, Val Acc: 0.7370, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 096, Loss: 0.3343, Val Acc: 0.7289, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 097, Loss: 0.3361, Val Acc: 0.7500, Test Acc: 0.7423\n",
      "Seed: 44, Epoch: 098, Loss: 0.3379, Val Acc: 0.7516, Test Acc: 0.7358\n",
      "Seed: 44, Epoch: 099, Loss: 0.3470, Val Acc: 0.7127, Test Acc: 0.7034\n",
      "Seed: 44, Epoch: 100, Loss: 0.3425, Val Acc: 0.7159, Test Acc: 0.7196\n",
      "Seed: 44, Epoch: 101, Loss: 0.3326, Val Acc: 0.7500, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 102, Loss: 0.3376, Val Acc: 0.7175, Test Acc: 0.7472\n",
      "Seed: 44, Epoch: 103, Loss: 0.3424, Val Acc: 0.7549, Test Acc: 0.7682\n",
      "Seed: 44, Epoch: 104, Loss: 0.3241, Val Acc: 0.7549, Test Acc: 0.7261\n",
      "Seed: 44, Epoch: 105, Loss: 0.3472, Val Acc: 0.7435, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 106, Loss: 0.3340, Val Acc: 0.7110, Test Acc: 0.7196\n",
      "Seed: 44, Epoch: 107, Loss: 0.3329, Val Acc: 0.7435, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 108, Loss: 0.3112, Val Acc: 0.7435, Test Acc: 0.7472\n",
      "Seed: 44, Epoch: 109, Loss: 0.3350, Val Acc: 0.7143, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 110, Loss: 0.3258, Val Acc: 0.6623, Test Acc: 0.6677\n",
      "Seed: 44, Epoch: 111, Loss: 0.3319, Val Acc: 0.7695, Test Acc: 0.7763\n",
      "Seed: 44, Epoch: 112, Loss: 0.3086, Val Acc: 0.7370, Test Acc: 0.7147\n",
      "Seed: 44, Epoch: 113, Loss: 0.3317, Val Acc: 0.7273, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 114, Loss: 0.3441, Val Acc: 0.7549, Test Acc: 0.7342\n",
      "Seed: 44, Epoch: 115, Loss: 0.3351, Val Acc: 0.7565, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 116, Loss: 0.3246, Val Acc: 0.7484, Test Acc: 0.7245\n",
      "Seed: 44, Epoch: 117, Loss: 0.3169, Val Acc: 0.7338, Test Acc: 0.7245\n",
      "Seed: 44, Epoch: 118, Loss: 0.3062, Val Acc: 0.7484, Test Acc: 0.7407\n",
      "Seed: 44, Epoch: 119, Loss: 0.3093, Val Acc: 0.7549, Test Acc: 0.7569\n",
      "Seed: 44, Epoch: 120, Loss: 0.3210, Val Acc: 0.7305, Test Acc: 0.7374\n",
      "Seed: 44, Epoch: 121, Loss: 0.3233, Val Acc: 0.7468, Test Acc: 0.7666\n",
      "Seed: 44, Epoch: 122, Loss: 0.3178, Val Acc: 0.7711, Test Acc: 0.7715\n",
      "Seed: 44, Epoch: 123, Loss: 0.3006, Val Acc: 0.7597, Test Acc: 0.7763\n",
      "Seed: 44, Epoch: 124, Loss: 0.3002, Val Acc: 0.7451, Test Acc: 0.7358\n",
      "Seed: 44, Epoch: 125, Loss: 0.3076, Val Acc: 0.7597, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 126, Loss: 0.2960, Val Acc: 0.7273, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 127, Loss: 0.2899, Val Acc: 0.7403, Test Acc: 0.7634\n",
      "Seed: 44, Epoch: 128, Loss: 0.2941, Val Acc: 0.7386, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 129, Loss: 0.3044, Val Acc: 0.7646, Test Acc: 0.7763\n",
      "Seed: 44, Epoch: 130, Loss: 0.3006, Val Acc: 0.7403, Test Acc: 0.7650\n",
      "Seed: 44, Epoch: 131, Loss: 0.2833, Val Acc: 0.7159, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 132, Loss: 0.3151, Val Acc: 0.7532, Test Acc: 0.7763\n",
      "Seed: 44, Epoch: 133, Loss: 0.2982, Val Acc: 0.7256, Test Acc: 0.7277\n",
      "Seed: 44, Epoch: 134, Loss: 0.3085, Val Acc: 0.7419, Test Acc: 0.7310\n",
      "Seed: 44, Epoch: 135, Loss: 0.2979, Val Acc: 0.7419, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 136, Loss: 0.2913, Val Acc: 0.7451, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 137, Loss: 0.3024, Val Acc: 0.6851, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 138, Loss: 0.3027, Val Acc: 0.7662, Test Acc: 0.7942\n",
      "Seed: 44, Epoch: 139, Loss: 0.2908, Val Acc: 0.7597, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 140, Loss: 0.2986, Val Acc: 0.7500, Test Acc: 0.7682\n",
      "Seed: 44, Epoch: 141, Loss: 0.3035, Val Acc: 0.7451, Test Acc: 0.7634\n",
      "Seed: 44, Epoch: 142, Loss: 0.2813, Val Acc: 0.7159, Test Acc: 0.7423\n",
      "Seed: 44, Epoch: 143, Loss: 0.2825, Val Acc: 0.7727, Test Acc: 0.7731\n",
      "Seed: 44, Epoch: 144, Loss: 0.2720, Val Acc: 0.7484, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 145, Loss: 0.2911, Val Acc: 0.7338, Test Acc: 0.7455\n",
      "Seed: 44, Epoch: 146, Loss: 0.2990, Val Acc: 0.6867, Test Acc: 0.6791\n",
      "Seed: 44, Epoch: 147, Loss: 0.3028, Val Acc: 0.7484, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 148, Loss: 0.2929, Val Acc: 0.7338, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 149, Loss: 0.2733, Val Acc: 0.7679, Test Acc: 0.7569\n",
      "Seed: 44, Epoch: 150, Loss: 0.2693, Val Acc: 0.7695, Test Acc: 0.7844\n",
      "Seed: 44, Epoch: 151, Loss: 0.2823, Val Acc: 0.7630, Test Acc: 0.7828\n",
      "Seed: 44, Epoch: 152, Loss: 0.2835, Val Acc: 0.7370, Test Acc: 0.7699\n",
      "Seed: 44, Epoch: 153, Loss: 0.2701, Val Acc: 0.7630, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 154, Loss: 0.2750, Val Acc: 0.7256, Test Acc: 0.7682\n",
      "Seed: 44, Epoch: 155, Loss: 0.2790, Val Acc: 0.7500, Test Acc: 0.7731\n",
      "Seed: 44, Epoch: 156, Loss: 0.2784, Val Acc: 0.7354, Test Acc: 0.7569\n",
      "Seed: 44, Epoch: 157, Loss: 0.2800, Val Acc: 0.7597, Test Acc: 0.7877\n",
      "Seed: 44, Epoch: 158, Loss: 0.2812, Val Acc: 0.7419, Test Acc: 0.7472\n",
      "Seed: 44, Epoch: 159, Loss: 0.2716, Val Acc: 0.7354, Test Acc: 0.7715\n",
      "Seed: 44, Epoch: 160, Loss: 0.2669, Val Acc: 0.7208, Test Acc: 0.7585\n",
      "Seed: 44, Epoch: 161, Loss: 0.2610, Val Acc: 0.7516, Test Acc: 0.7618\n",
      "Seed: 44, Epoch: 162, Loss: 0.2711, Val Acc: 0.7143, Test Acc: 0.7034\n",
      "Seed: 44, Epoch: 163, Loss: 0.2604, Val Acc: 0.7143, Test Acc: 0.7374\n",
      "Seed: 44, Epoch: 164, Loss: 0.2826, Val Acc: 0.7630, Test Acc: 0.7812\n",
      "Seed: 44, Epoch: 165, Loss: 0.2623, Val Acc: 0.7484, Test Acc: 0.7618\n",
      "Seed: 44, Epoch: 166, Loss: 0.2688, Val Acc: 0.7484, Test Acc: 0.7715\n",
      "Seed: 44, Epoch: 167, Loss: 0.2764, Val Acc: 0.7581, Test Acc: 0.7812\n",
      "Seed: 44, Epoch: 168, Loss: 0.2575, Val Acc: 0.7175, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 169, Loss: 0.2591, Val Acc: 0.7208, Test Acc: 0.7034\n",
      "Seed: 44, Epoch: 170, Loss: 0.2612, Val Acc: 0.7159, Test Acc: 0.7391\n",
      "Seed: 44, Epoch: 171, Loss: 0.2647, Val Acc: 0.7516, Test Acc: 0.7666\n",
      "Seed: 44, Epoch: 172, Loss: 0.2712, Val Acc: 0.7792, Test Acc: 0.7731\n",
      "Seed: 44, Epoch: 173, Loss: 0.2464, Val Acc: 0.7159, Test Acc: 0.7455\n",
      "Seed: 44, Epoch: 174, Loss: 0.2496, Val Acc: 0.7500, Test Acc: 0.7682\n",
      "Seed: 44, Epoch: 175, Loss: 0.2663, Val Acc: 0.7256, Test Acc: 0.7536\n",
      "Seed: 44, Epoch: 176, Loss: 0.2663, Val Acc: 0.7662, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 177, Loss: 0.2504, Val Acc: 0.7321, Test Acc: 0.7245\n",
      "Seed: 44, Epoch: 178, Loss: 0.2679, Val Acc: 0.7338, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 179, Loss: 0.2575, Val Acc: 0.7581, Test Acc: 0.7780\n",
      "Seed: 44, Epoch: 180, Loss: 0.2451, Val Acc: 0.7354, Test Acc: 0.7844\n",
      "Seed: 44, Epoch: 181, Loss: 0.2586, Val Acc: 0.7597, Test Acc: 0.7731\n",
      "Seed: 44, Epoch: 182, Loss: 0.2579, Val Acc: 0.7500, Test Acc: 0.7634\n",
      "Seed: 44, Epoch: 183, Loss: 0.2701, Val Acc: 0.7646, Test Acc: 0.7942\n",
      "Seed: 44, Epoch: 184, Loss: 0.2457, Val Acc: 0.7305, Test Acc: 0.7504\n",
      "Seed: 44, Epoch: 185, Loss: 0.2532, Val Acc: 0.7760, Test Acc: 0.7974\n",
      "Seed: 44, Epoch: 186, Loss: 0.2478, Val Acc: 0.7484, Test Acc: 0.7553\n",
      "Seed: 44, Epoch: 187, Loss: 0.2549, Val Acc: 0.7727, Test Acc: 0.7731\n",
      "Seed: 44, Epoch: 188, Loss: 0.2434, Val Acc: 0.7192, Test Acc: 0.7634\n",
      "Seed: 44, Epoch: 189, Loss: 0.2458, Val Acc: 0.7695, Test Acc: 0.7439\n",
      "Seed: 44, Epoch: 190, Loss: 0.2353, Val Acc: 0.7208, Test Acc: 0.7715\n",
      "Seed: 44, Epoch: 191, Loss: 0.2509, Val Acc: 0.7451, Test Acc: 0.7877\n",
      "Seed: 44, Epoch: 192, Loss: 0.2549, Val Acc: 0.7695, Test Acc: 0.8039\n",
      "Seed: 44, Epoch: 193, Loss: 0.2502, Val Acc: 0.7192, Test Acc: 0.7780\n",
      "Seed: 44, Epoch: 194, Loss: 0.2434, Val Acc: 0.7403, Test Acc: 0.7488\n",
      "Seed: 44, Epoch: 195, Loss: 0.2610, Val Acc: 0.7305, Test Acc: 0.7585\n",
      "Seed: 44, Epoch: 196, Loss: 0.2506, Val Acc: 0.7792, Test Acc: 0.7877\n",
      "Seed: 44, Epoch: 197, Loss: 0.2512, Val Acc: 0.7451, Test Acc: 0.7455\n",
      "Seed: 44, Epoch: 198, Loss: 0.2537, Val Acc: 0.7289, Test Acc: 0.7472\n",
      "Seed: 44, Epoch: 199, Loss: 0.2509, Val Acc: 0.7386, Test Acc: 0.7618\n",
      "Seed: 44, Epoch: 200, Loss: 0.2416, Val Acc: 0.7419, Test Acc: 0.7731\n",
      "Average Time: 348.59 seconds\n",
      "Var Time: 63.72 seconds\n",
      "Average Memory: 536.00 MB\n",
      "Average Best Val Acc: 0.7944\n",
      "Std Best Test Acc: 0.0061\n",
      "Average Test Acc: 0.7688\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "max_nodes = 150\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"NCI1\",\n",
    "    transform=T.Compose([T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_hosc(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc, o = dense_hoscpool(x, adj, s, mu=0.3, alpha=0.3, new_ortho=False, mask=mask)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc_aux, o_aux = dense_hoscpool(x, adj, s, mu=0.3, alpha=0.3, new_ortho=False)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_hosc().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = Net_hosc().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCI109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6878, Val Acc: 0.4879, Test Acc: 0.5081\n",
      "Seed: 42, Epoch: 002, Loss: 0.6681, Val Acc: 0.6171, Test Acc: 0.5887\n",
      "Seed: 42, Epoch: 003, Loss: 0.6427, Val Acc: 0.6414, Test Acc: 0.6113\n",
      "Seed: 42, Epoch: 004, Loss: 0.6275, Val Acc: 0.6914, Test Acc: 0.6548\n",
      "Seed: 42, Epoch: 005, Loss: 0.6128, Val Acc: 0.6979, Test Acc: 0.6403\n",
      "Seed: 42, Epoch: 006, Loss: 0.5982, Val Acc: 0.7141, Test Acc: 0.6790\n",
      "Seed: 42, Epoch: 007, Loss: 0.5881, Val Acc: 0.6898, Test Acc: 0.6710\n",
      "Seed: 42, Epoch: 008, Loss: 0.5887, Val Acc: 0.6801, Test Acc: 0.6468\n",
      "Seed: 42, Epoch: 009, Loss: 0.5875, Val Acc: 0.6834, Test Acc: 0.6274\n",
      "Seed: 42, Epoch: 010, Loss: 0.5803, Val Acc: 0.6866, Test Acc: 0.6726\n",
      "Seed: 42, Epoch: 011, Loss: 0.5765, Val Acc: 0.7286, Test Acc: 0.6677\n",
      "Seed: 42, Epoch: 012, Loss: 0.5673, Val Acc: 0.7141, Test Acc: 0.6742\n",
      "Seed: 42, Epoch: 013, Loss: 0.5635, Val Acc: 0.7011, Test Acc: 0.6823\n",
      "Seed: 42, Epoch: 014, Loss: 0.5655, Val Acc: 0.7173, Test Acc: 0.6839\n",
      "Seed: 42, Epoch: 015, Loss: 0.5585, Val Acc: 0.7076, Test Acc: 0.7032\n",
      "Seed: 42, Epoch: 016, Loss: 0.5464, Val Acc: 0.6769, Test Acc: 0.6871\n",
      "Seed: 42, Epoch: 017, Loss: 0.5476, Val Acc: 0.6850, Test Acc: 0.6452\n",
      "Seed: 42, Epoch: 018, Loss: 0.5488, Val Acc: 0.7027, Test Acc: 0.6774\n",
      "Seed: 42, Epoch: 019, Loss: 0.5422, Val Acc: 0.7108, Test Acc: 0.6742\n",
      "Seed: 42, Epoch: 020, Loss: 0.5387, Val Acc: 0.7447, Test Acc: 0.7065\n",
      "Seed: 42, Epoch: 021, Loss: 0.5386, Val Acc: 0.7221, Test Acc: 0.6935\n",
      "Seed: 42, Epoch: 022, Loss: 0.5311, Val Acc: 0.7189, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 023, Loss: 0.5206, Val Acc: 0.6979, Test Acc: 0.6823\n",
      "Seed: 42, Epoch: 024, Loss: 0.5193, Val Acc: 0.7302, Test Acc: 0.7177\n",
      "Seed: 42, Epoch: 025, Loss: 0.5118, Val Acc: 0.7351, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 026, Loss: 0.5060, Val Acc: 0.7286, Test Acc: 0.6968\n",
      "Seed: 42, Epoch: 027, Loss: 0.5028, Val Acc: 0.7108, Test Acc: 0.6774\n",
      "Seed: 42, Epoch: 028, Loss: 0.5098, Val Acc: 0.7561, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 029, Loss: 0.4994, Val Acc: 0.7221, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 030, Loss: 0.5036, Val Acc: 0.7302, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 031, Loss: 0.4997, Val Acc: 0.7141, Test Acc: 0.6952\n",
      "Seed: 42, Epoch: 032, Loss: 0.5009, Val Acc: 0.7480, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 033, Loss: 0.4969, Val Acc: 0.7431, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 034, Loss: 0.4822, Val Acc: 0.7561, Test Acc: 0.7129\n",
      "Seed: 42, Epoch: 035, Loss: 0.4840, Val Acc: 0.7674, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 036, Loss: 0.4816, Val Acc: 0.7480, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 037, Loss: 0.4701, Val Acc: 0.7561, Test Acc: 0.7258\n",
      "Seed: 42, Epoch: 038, Loss: 0.4734, Val Acc: 0.7205, Test Acc: 0.7065\n",
      "Seed: 42, Epoch: 039, Loss: 0.4927, Val Acc: 0.7108, Test Acc: 0.6694\n",
      "Seed: 42, Epoch: 040, Loss: 0.4782, Val Acc: 0.7593, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 041, Loss: 0.4631, Val Acc: 0.7173, Test Acc: 0.6790\n",
      "Seed: 42, Epoch: 042, Loss: 0.4696, Val Acc: 0.7512, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 043, Loss: 0.4649, Val Acc: 0.7480, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 044, Loss: 0.4607, Val Acc: 0.7561, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 045, Loss: 0.4598, Val Acc: 0.7641, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 046, Loss: 0.4517, Val Acc: 0.7334, Test Acc: 0.6952\n",
      "Seed: 42, Epoch: 047, Loss: 0.4623, Val Acc: 0.7415, Test Acc: 0.7097\n",
      "Seed: 42, Epoch: 048, Loss: 0.4454, Val Acc: 0.7334, Test Acc: 0.7016\n",
      "Seed: 42, Epoch: 049, Loss: 0.4374, Val Acc: 0.7415, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 050, Loss: 0.4545, Val Acc: 0.7318, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 051, Loss: 0.4491, Val Acc: 0.7593, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 052, Loss: 0.4412, Val Acc: 0.7496, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 053, Loss: 0.4467, Val Acc: 0.7173, Test Acc: 0.6903\n",
      "Seed: 42, Epoch: 054, Loss: 0.4460, Val Acc: 0.7270, Test Acc: 0.7290\n",
      "Seed: 42, Epoch: 055, Loss: 0.4455, Val Acc: 0.7060, Test Acc: 0.6742\n",
      "Seed: 42, Epoch: 056, Loss: 0.4381, Val Acc: 0.7270, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 057, Loss: 0.4378, Val Acc: 0.7544, Test Acc: 0.7258\n",
      "Seed: 42, Epoch: 058, Loss: 0.4257, Val Acc: 0.7771, Test Acc: 0.7290\n",
      "Seed: 42, Epoch: 059, Loss: 0.4268, Val Acc: 0.7593, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 060, Loss: 0.4365, Val Acc: 0.7076, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 061, Loss: 0.4320, Val Acc: 0.7544, Test Acc: 0.7484\n",
      "Seed: 42, Epoch: 062, Loss: 0.4158, Val Acc: 0.7593, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 063, Loss: 0.4180, Val Acc: 0.7528, Test Acc: 0.7484\n",
      "Seed: 42, Epoch: 064, Loss: 0.4236, Val Acc: 0.7544, Test Acc: 0.7258\n",
      "Seed: 42, Epoch: 065, Loss: 0.4148, Val Acc: 0.7480, Test Acc: 0.7323\n",
      "Seed: 42, Epoch: 066, Loss: 0.4088, Val Acc: 0.7690, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 067, Loss: 0.4168, Val Acc: 0.7367, Test Acc: 0.7306\n",
      "Seed: 42, Epoch: 068, Loss: 0.4118, Val Acc: 0.7415, Test Acc: 0.7306\n",
      "Seed: 42, Epoch: 069, Loss: 0.4019, Val Acc: 0.7561, Test Acc: 0.6984\n",
      "Seed: 42, Epoch: 070, Loss: 0.4034, Val Acc: 0.7447, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 071, Loss: 0.3963, Val Acc: 0.7367, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 072, Loss: 0.3917, Val Acc: 0.7447, Test Acc: 0.7532\n",
      "Seed: 42, Epoch: 073, Loss: 0.3943, Val Acc: 0.7593, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 074, Loss: 0.3989, Val Acc: 0.7658, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 075, Loss: 0.3832, Val Acc: 0.7399, Test Acc: 0.7629\n",
      "Seed: 42, Epoch: 076, Loss: 0.4045, Val Acc: 0.7334, Test Acc: 0.7081\n",
      "Seed: 42, Epoch: 077, Loss: 0.4053, Val Acc: 0.7431, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 078, Loss: 0.3829, Val Acc: 0.7528, Test Acc: 0.7323\n",
      "Seed: 42, Epoch: 079, Loss: 0.3931, Val Acc: 0.7496, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 080, Loss: 0.3859, Val Acc: 0.7286, Test Acc: 0.7290\n",
      "Seed: 42, Epoch: 081, Loss: 0.3762, Val Acc: 0.7577, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 082, Loss: 0.3824, Val Acc: 0.7722, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 083, Loss: 0.3657, Val Acc: 0.7690, Test Acc: 0.7484\n",
      "Seed: 42, Epoch: 084, Loss: 0.3816, Val Acc: 0.7722, Test Acc: 0.7694\n",
      "Seed: 42, Epoch: 085, Loss: 0.3699, Val Acc: 0.7496, Test Acc: 0.7290\n",
      "Seed: 42, Epoch: 086, Loss: 0.3961, Val Acc: 0.7528, Test Acc: 0.7516\n",
      "Seed: 42, Epoch: 087, Loss: 0.3938, Val Acc: 0.7593, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 088, Loss: 0.3721, Val Acc: 0.7367, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 089, Loss: 0.3857, Val Acc: 0.7641, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 090, Loss: 0.3704, Val Acc: 0.7561, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 091, Loss: 0.3720, Val Acc: 0.7544, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 092, Loss: 0.3670, Val Acc: 0.7577, Test Acc: 0.7177\n",
      "Seed: 42, Epoch: 093, Loss: 0.3595, Val Acc: 0.7609, Test Acc: 0.7629\n",
      "Seed: 42, Epoch: 094, Loss: 0.3582, Val Acc: 0.7447, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 095, Loss: 0.3628, Val Acc: 0.7399, Test Acc: 0.7403\n",
      "Seed: 42, Epoch: 096, Loss: 0.3637, Val Acc: 0.7658, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 097, Loss: 0.3578, Val Acc: 0.7625, Test Acc: 0.7548\n",
      "Seed: 42, Epoch: 098, Loss: 0.3675, Val Acc: 0.7674, Test Acc: 0.7516\n",
      "Seed: 42, Epoch: 099, Loss: 0.3624, Val Acc: 0.7367, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 100, Loss: 0.3528, Val Acc: 0.7464, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 101, Loss: 0.3514, Val Acc: 0.7415, Test Acc: 0.7597\n",
      "Seed: 42, Epoch: 102, Loss: 0.3499, Val Acc: 0.7609, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 103, Loss: 0.3451, Val Acc: 0.7674, Test Acc: 0.7597\n",
      "Seed: 42, Epoch: 104, Loss: 0.3428, Val Acc: 0.7464, Test Acc: 0.7516\n",
      "Seed: 42, Epoch: 105, Loss: 0.3513, Val Acc: 0.7464, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 106, Loss: 0.3624, Val Acc: 0.7722, Test Acc: 0.7468\n",
      "Seed: 42, Epoch: 107, Loss: 0.3453, Val Acc: 0.7286, Test Acc: 0.7258\n",
      "Seed: 42, Epoch: 108, Loss: 0.3508, Val Acc: 0.7351, Test Acc: 0.7258\n",
      "Seed: 42, Epoch: 109, Loss: 0.3553, Val Acc: 0.7577, Test Acc: 0.7516\n",
      "Seed: 42, Epoch: 110, Loss: 0.3443, Val Acc: 0.7609, Test Acc: 0.7516\n",
      "Seed: 42, Epoch: 111, Loss: 0.3416, Val Acc: 0.7674, Test Acc: 0.7468\n",
      "Seed: 42, Epoch: 112, Loss: 0.3490, Val Acc: 0.7480, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 113, Loss: 0.3366, Val Acc: 0.7512, Test Acc: 0.7532\n",
      "Seed: 42, Epoch: 114, Loss: 0.3324, Val Acc: 0.7544, Test Acc: 0.7694\n",
      "Seed: 42, Epoch: 115, Loss: 0.3509, Val Acc: 0.7141, Test Acc: 0.6839\n",
      "Seed: 42, Epoch: 116, Loss: 0.3548, Val Acc: 0.7351, Test Acc: 0.7258\n",
      "Seed: 42, Epoch: 117, Loss: 0.3466, Val Acc: 0.7674, Test Acc: 0.7274\n",
      "Seed: 42, Epoch: 118, Loss: 0.3284, Val Acc: 0.7237, Test Acc: 0.7145\n",
      "Seed: 42, Epoch: 119, Loss: 0.3289, Val Acc: 0.7932, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 120, Loss: 0.3333, Val Acc: 0.7415, Test Acc: 0.7629\n",
      "Seed: 42, Epoch: 121, Loss: 0.3336, Val Acc: 0.7480, Test Acc: 0.7516\n",
      "Seed: 42, Epoch: 122, Loss: 0.3438, Val Acc: 0.7496, Test Acc: 0.7177\n",
      "Seed: 42, Epoch: 123, Loss: 0.3376, Val Acc: 0.7399, Test Acc: 0.7468\n",
      "Seed: 42, Epoch: 124, Loss: 0.3182, Val Acc: 0.7754, Test Acc: 0.7548\n",
      "Seed: 42, Epoch: 125, Loss: 0.3102, Val Acc: 0.7706, Test Acc: 0.7274\n",
      "Seed: 42, Epoch: 126, Loss: 0.3351, Val Acc: 0.7722, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 127, Loss: 0.3292, Val Acc: 0.7528, Test Acc: 0.7516\n",
      "Seed: 42, Epoch: 128, Loss: 0.3197, Val Acc: 0.7609, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 129, Loss: 0.3329, Val Acc: 0.7577, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 130, Loss: 0.3135, Val Acc: 0.7609, Test Acc: 0.7468\n",
      "Seed: 42, Epoch: 131, Loss: 0.3225, Val Acc: 0.7593, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 132, Loss: 0.3149, Val Acc: 0.7787, Test Acc: 0.7403\n",
      "Seed: 42, Epoch: 133, Loss: 0.3133, Val Acc: 0.7496, Test Acc: 0.7290\n",
      "Seed: 42, Epoch: 134, Loss: 0.3256, Val Acc: 0.7157, Test Acc: 0.7274\n",
      "Seed: 42, Epoch: 135, Loss: 0.3153, Val Acc: 0.7754, Test Acc: 0.7548\n",
      "Seed: 42, Epoch: 136, Loss: 0.3155, Val Acc: 0.7496, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 137, Loss: 0.3133, Val Acc: 0.7561, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 138, Loss: 0.3136, Val Acc: 0.7609, Test Acc: 0.7258\n",
      "Seed: 42, Epoch: 139, Loss: 0.3228, Val Acc: 0.7367, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 140, Loss: 0.3146, Val Acc: 0.7658, Test Acc: 0.7597\n",
      "Seed: 42, Epoch: 141, Loss: 0.3058, Val Acc: 0.7641, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 142, Loss: 0.3007, Val Acc: 0.7561, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 143, Loss: 0.2994, Val Acc: 0.7544, Test Acc: 0.7113\n",
      "Seed: 42, Epoch: 144, Loss: 0.3170, Val Acc: 0.7399, Test Acc: 0.7355\n",
      "Seed: 42, Epoch: 145, Loss: 0.3064, Val Acc: 0.7431, Test Acc: 0.7290\n",
      "Seed: 42, Epoch: 146, Loss: 0.3118, Val Acc: 0.7690, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 147, Loss: 0.3041, Val Acc: 0.7609, Test Acc: 0.7581\n",
      "Seed: 42, Epoch: 148, Loss: 0.2879, Val Acc: 0.7480, Test Acc: 0.7323\n",
      "Seed: 42, Epoch: 149, Loss: 0.2942, Val Acc: 0.7367, Test Acc: 0.7177\n",
      "Seed: 42, Epoch: 150, Loss: 0.2926, Val Acc: 0.7690, Test Acc: 0.7306\n",
      "Seed: 42, Epoch: 151, Loss: 0.3082, Val Acc: 0.7480, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 152, Loss: 0.3025, Val Acc: 0.7318, Test Acc: 0.7032\n",
      "Seed: 42, Epoch: 153, Loss: 0.3053, Val Acc: 0.7577, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 154, Loss: 0.2917, Val Acc: 0.7464, Test Acc: 0.6887\n",
      "Seed: 42, Epoch: 155, Loss: 0.2804, Val Acc: 0.7738, Test Acc: 0.7548\n",
      "Seed: 42, Epoch: 156, Loss: 0.2831, Val Acc: 0.7641, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 157, Loss: 0.2893, Val Acc: 0.7351, Test Acc: 0.7323\n",
      "Seed: 42, Epoch: 158, Loss: 0.2916, Val Acc: 0.7431, Test Acc: 0.7242\n",
      "Seed: 42, Epoch: 159, Loss: 0.3014, Val Acc: 0.7641, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 160, Loss: 0.2838, Val Acc: 0.7076, Test Acc: 0.6758\n",
      "Seed: 42, Epoch: 161, Loss: 0.2835, Val Acc: 0.7334, Test Acc: 0.7032\n",
      "Seed: 42, Epoch: 162, Loss: 0.2718, Val Acc: 0.7706, Test Acc: 0.7548\n",
      "Seed: 42, Epoch: 163, Loss: 0.2797, Val Acc: 0.7431, Test Acc: 0.7290\n",
      "Seed: 42, Epoch: 164, Loss: 0.2848, Val Acc: 0.7706, Test Acc: 0.7355\n",
      "Seed: 42, Epoch: 165, Loss: 0.2912, Val Acc: 0.7577, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 166, Loss: 0.2787, Val Acc: 0.7593, Test Acc: 0.7484\n",
      "Seed: 42, Epoch: 167, Loss: 0.2750, Val Acc: 0.7658, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 168, Loss: 0.2709, Val Acc: 0.7964, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 169, Loss: 0.2781, Val Acc: 0.7367, Test Acc: 0.7177\n",
      "Seed: 42, Epoch: 170, Loss: 0.2766, Val Acc: 0.7528, Test Acc: 0.7323\n",
      "Seed: 42, Epoch: 171, Loss: 0.2672, Val Acc: 0.7803, Test Acc: 0.7435\n",
      "Seed: 42, Epoch: 172, Loss: 0.2820, Val Acc: 0.7787, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 173, Loss: 0.2730, Val Acc: 0.7318, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 174, Loss: 0.2798, Val Acc: 0.7674, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 175, Loss: 0.2620, Val Acc: 0.7480, Test Acc: 0.7500\n",
      "Seed: 42, Epoch: 176, Loss: 0.2791, Val Acc: 0.7641, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 177, Loss: 0.2637, Val Acc: 0.7334, Test Acc: 0.7323\n",
      "Seed: 42, Epoch: 178, Loss: 0.2937, Val Acc: 0.7690, Test Acc: 0.7452\n",
      "Seed: 42, Epoch: 179, Loss: 0.2696, Val Acc: 0.7415, Test Acc: 0.7355\n",
      "Seed: 42, Epoch: 180, Loss: 0.2778, Val Acc: 0.7334, Test Acc: 0.7016\n",
      "Seed: 42, Epoch: 181, Loss: 0.2694, Val Acc: 0.7593, Test Acc: 0.7210\n",
      "Seed: 42, Epoch: 182, Loss: 0.2765, Val Acc: 0.7658, Test Acc: 0.7290\n",
      "Seed: 42, Epoch: 183, Loss: 0.2734, Val Acc: 0.7447, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 184, Loss: 0.2738, Val Acc: 0.7399, Test Acc: 0.7161\n",
      "Seed: 42, Epoch: 185, Loss: 0.2887, Val Acc: 0.7609, Test Acc: 0.7468\n",
      "Seed: 42, Epoch: 186, Loss: 0.2731, Val Acc: 0.7674, Test Acc: 0.7758\n",
      "Seed: 42, Epoch: 187, Loss: 0.2663, Val Acc: 0.7835, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 188, Loss: 0.2579, Val Acc: 0.7512, Test Acc: 0.7403\n",
      "Seed: 42, Epoch: 189, Loss: 0.2624, Val Acc: 0.7415, Test Acc: 0.7194\n",
      "Seed: 42, Epoch: 190, Loss: 0.2732, Val Acc: 0.7609, Test Acc: 0.7629\n",
      "Seed: 42, Epoch: 191, Loss: 0.2654, Val Acc: 0.7868, Test Acc: 0.7403\n",
      "Seed: 42, Epoch: 192, Loss: 0.2576, Val Acc: 0.7722, Test Acc: 0.7597\n",
      "Seed: 42, Epoch: 193, Loss: 0.2547, Val Acc: 0.7641, Test Acc: 0.7548\n",
      "Seed: 42, Epoch: 194, Loss: 0.2583, Val Acc: 0.7690, Test Acc: 0.7419\n",
      "Seed: 42, Epoch: 195, Loss: 0.2666, Val Acc: 0.7738, Test Acc: 0.7532\n",
      "Seed: 42, Epoch: 196, Loss: 0.2460, Val Acc: 0.7383, Test Acc: 0.7339\n",
      "Seed: 42, Epoch: 197, Loss: 0.2601, Val Acc: 0.7318, Test Acc: 0.7177\n",
      "Seed: 42, Epoch: 198, Loss: 0.2461, Val Acc: 0.7528, Test Acc: 0.7371\n",
      "Seed: 42, Epoch: 199, Loss: 0.2525, Val Acc: 0.7415, Test Acc: 0.7226\n",
      "Seed: 42, Epoch: 200, Loss: 0.2665, Val Acc: 0.7480, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 001, Loss: 0.6907, Val Acc: 0.5202, Test Acc: 0.5048\n",
      "Seed: 43, Epoch: 002, Loss: 0.6708, Val Acc: 0.6349, Test Acc: 0.6435\n",
      "Seed: 43, Epoch: 003, Loss: 0.6370, Val Acc: 0.6478, Test Acc: 0.6548\n",
      "Seed: 43, Epoch: 004, Loss: 0.6187, Val Acc: 0.6656, Test Acc: 0.6742\n",
      "Seed: 43, Epoch: 005, Loss: 0.6104, Val Acc: 0.6672, Test Acc: 0.6919\n",
      "Seed: 43, Epoch: 006, Loss: 0.5979, Val Acc: 0.6979, Test Acc: 0.7081\n",
      "Seed: 43, Epoch: 007, Loss: 0.5890, Val Acc: 0.6478, Test Acc: 0.6645\n",
      "Seed: 43, Epoch: 008, Loss: 0.5881, Val Acc: 0.6559, Test Acc: 0.6952\n",
      "Seed: 43, Epoch: 009, Loss: 0.5807, Val Acc: 0.6801, Test Acc: 0.6806\n",
      "Seed: 43, Epoch: 010, Loss: 0.5772, Val Acc: 0.6672, Test Acc: 0.6565\n",
      "Seed: 43, Epoch: 011, Loss: 0.5723, Val Acc: 0.6914, Test Acc: 0.6855\n",
      "Seed: 43, Epoch: 012, Loss: 0.5660, Val Acc: 0.6430, Test Acc: 0.6726\n",
      "Seed: 43, Epoch: 013, Loss: 0.5628, Val Acc: 0.6979, Test Acc: 0.7210\n",
      "Seed: 43, Epoch: 014, Loss: 0.5555, Val Acc: 0.6947, Test Acc: 0.7129\n",
      "Seed: 43, Epoch: 015, Loss: 0.5555, Val Acc: 0.6737, Test Acc: 0.7097\n",
      "Seed: 43, Epoch: 016, Loss: 0.5511, Val Acc: 0.7060, Test Acc: 0.7258\n",
      "Seed: 43, Epoch: 017, Loss: 0.5424, Val Acc: 0.6931, Test Acc: 0.7129\n",
      "Seed: 43, Epoch: 018, Loss: 0.5437, Val Acc: 0.6624, Test Acc: 0.6823\n",
      "Seed: 43, Epoch: 019, Loss: 0.5517, Val Acc: 0.6834, Test Acc: 0.6790\n",
      "Seed: 43, Epoch: 020, Loss: 0.5369, Val Acc: 0.6947, Test Acc: 0.6952\n",
      "Seed: 43, Epoch: 021, Loss: 0.5322, Val Acc: 0.6591, Test Acc: 0.6790\n",
      "Seed: 43, Epoch: 022, Loss: 0.5356, Val Acc: 0.7027, Test Acc: 0.6968\n",
      "Seed: 43, Epoch: 023, Loss: 0.5424, Val Acc: 0.6898, Test Acc: 0.6839\n",
      "Seed: 43, Epoch: 024, Loss: 0.5317, Val Acc: 0.7060, Test Acc: 0.7274\n",
      "Seed: 43, Epoch: 025, Loss: 0.5113, Val Acc: 0.6898, Test Acc: 0.7081\n",
      "Seed: 43, Epoch: 026, Loss: 0.5057, Val Acc: 0.6721, Test Acc: 0.7210\n",
      "Seed: 43, Epoch: 027, Loss: 0.5034, Val Acc: 0.7076, Test Acc: 0.7484\n",
      "Seed: 43, Epoch: 028, Loss: 0.5011, Val Acc: 0.7124, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 029, Loss: 0.4984, Val Acc: 0.6850, Test Acc: 0.6968\n",
      "Seed: 43, Epoch: 030, Loss: 0.4894, Val Acc: 0.6834, Test Acc: 0.6903\n",
      "Seed: 43, Epoch: 031, Loss: 0.4854, Val Acc: 0.7334, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 032, Loss: 0.4981, Val Acc: 0.6947, Test Acc: 0.7145\n",
      "Seed: 43, Epoch: 033, Loss: 0.4988, Val Acc: 0.7011, Test Acc: 0.7129\n",
      "Seed: 43, Epoch: 034, Loss: 0.4899, Val Acc: 0.7011, Test Acc: 0.7226\n",
      "Seed: 43, Epoch: 035, Loss: 0.4843, Val Acc: 0.7237, Test Acc: 0.7403\n",
      "Seed: 43, Epoch: 036, Loss: 0.4755, Val Acc: 0.7270, Test Acc: 0.7081\n",
      "Seed: 43, Epoch: 037, Loss: 0.4753, Val Acc: 0.6834, Test Acc: 0.6839\n",
      "Seed: 43, Epoch: 038, Loss: 0.4860, Val Acc: 0.7254, Test Acc: 0.7210\n",
      "Seed: 43, Epoch: 039, Loss: 0.4780, Val Acc: 0.7237, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 040, Loss: 0.4551, Val Acc: 0.7270, Test Acc: 0.7452\n",
      "Seed: 43, Epoch: 041, Loss: 0.4766, Val Acc: 0.7044, Test Acc: 0.7113\n",
      "Seed: 43, Epoch: 042, Loss: 0.4853, Val Acc: 0.7173, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 043, Loss: 0.4678, Val Acc: 0.7270, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 044, Loss: 0.4732, Val Acc: 0.7124, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 045, Loss: 0.4736, Val Acc: 0.6317, Test Acc: 0.7016\n",
      "Seed: 43, Epoch: 046, Loss: 0.4702, Val Acc: 0.7286, Test Acc: 0.7452\n",
      "Seed: 43, Epoch: 047, Loss: 0.4558, Val Acc: 0.7141, Test Acc: 0.7452\n",
      "Seed: 43, Epoch: 048, Loss: 0.4589, Val Acc: 0.7383, Test Acc: 0.7258\n",
      "Seed: 43, Epoch: 049, Loss: 0.4428, Val Acc: 0.6931, Test Acc: 0.7065\n",
      "Seed: 43, Epoch: 050, Loss: 0.4424, Val Acc: 0.7189, Test Acc: 0.7129\n",
      "Seed: 43, Epoch: 051, Loss: 0.4489, Val Acc: 0.7270, Test Acc: 0.7274\n",
      "Seed: 43, Epoch: 052, Loss: 0.4432, Val Acc: 0.7254, Test Acc: 0.7177\n",
      "Seed: 43, Epoch: 053, Loss: 0.4449, Val Acc: 0.6931, Test Acc: 0.7113\n",
      "Seed: 43, Epoch: 054, Loss: 0.4411, Val Acc: 0.7060, Test Acc: 0.7194\n",
      "Seed: 43, Epoch: 055, Loss: 0.4517, Val Acc: 0.6866, Test Acc: 0.7194\n",
      "Seed: 43, Epoch: 056, Loss: 0.4441, Val Acc: 0.7254, Test Acc: 0.7177\n",
      "Seed: 43, Epoch: 057, Loss: 0.4508, Val Acc: 0.7270, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 058, Loss: 0.4375, Val Acc: 0.7173, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 059, Loss: 0.4330, Val Acc: 0.7108, Test Acc: 0.7226\n",
      "Seed: 43, Epoch: 060, Loss: 0.4315, Val Acc: 0.7318, Test Acc: 0.7339\n",
      "Seed: 43, Epoch: 061, Loss: 0.4223, Val Acc: 0.7577, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 062, Loss: 0.4214, Val Acc: 0.6979, Test Acc: 0.7226\n",
      "Seed: 43, Epoch: 063, Loss: 0.4213, Val Acc: 0.7254, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 064, Loss: 0.4276, Val Acc: 0.6817, Test Acc: 0.7048\n",
      "Seed: 43, Epoch: 065, Loss: 0.4175, Val Acc: 0.7351, Test Acc: 0.7452\n",
      "Seed: 43, Epoch: 066, Loss: 0.4063, Val Acc: 0.6817, Test Acc: 0.7097\n",
      "Seed: 43, Epoch: 067, Loss: 0.4083, Val Acc: 0.7609, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 068, Loss: 0.3977, Val Acc: 0.6963, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 069, Loss: 0.4127, Val Acc: 0.6914, Test Acc: 0.7000\n",
      "Seed: 43, Epoch: 070, Loss: 0.4088, Val Acc: 0.7124, Test Acc: 0.6935\n",
      "Seed: 43, Epoch: 071, Loss: 0.4055, Val Acc: 0.7318, Test Acc: 0.7581\n",
      "Seed: 43, Epoch: 072, Loss: 0.3963, Val Acc: 0.6963, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 073, Loss: 0.3904, Val Acc: 0.7076, Test Acc: 0.7145\n",
      "Seed: 43, Epoch: 074, Loss: 0.4049, Val Acc: 0.7464, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 075, Loss: 0.3884, Val Acc: 0.7124, Test Acc: 0.7565\n",
      "Seed: 43, Epoch: 076, Loss: 0.3913, Val Acc: 0.7447, Test Acc: 0.7726\n",
      "Seed: 43, Epoch: 077, Loss: 0.3719, Val Acc: 0.6591, Test Acc: 0.6839\n",
      "Seed: 43, Epoch: 078, Loss: 0.3874, Val Acc: 0.7334, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 079, Loss: 0.3780, Val Acc: 0.7221, Test Acc: 0.7145\n",
      "Seed: 43, Epoch: 080, Loss: 0.3894, Val Acc: 0.7076, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 081, Loss: 0.3849, Val Acc: 0.7173, Test Acc: 0.7435\n",
      "Seed: 43, Epoch: 082, Loss: 0.3755, Val Acc: 0.7108, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 083, Loss: 0.3769, Val Acc: 0.7302, Test Acc: 0.7597\n",
      "Seed: 43, Epoch: 084, Loss: 0.3795, Val Acc: 0.7173, Test Acc: 0.7226\n",
      "Seed: 43, Epoch: 085, Loss: 0.3746, Val Acc: 0.7173, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 086, Loss: 0.3843, Val Acc: 0.6785, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 087, Loss: 0.3781, Val Acc: 0.7528, Test Acc: 0.7468\n",
      "Seed: 43, Epoch: 088, Loss: 0.3662, Val Acc: 0.7447, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 089, Loss: 0.3626, Val Acc: 0.6737, Test Acc: 0.6806\n",
      "Seed: 43, Epoch: 090, Loss: 0.3639, Val Acc: 0.6284, Test Acc: 0.6629\n",
      "Seed: 43, Epoch: 091, Loss: 0.3613, Val Acc: 0.7173, Test Acc: 0.7129\n",
      "Seed: 43, Epoch: 092, Loss: 0.3619, Val Acc: 0.7351, Test Acc: 0.7452\n",
      "Seed: 43, Epoch: 093, Loss: 0.3709, Val Acc: 0.7221, Test Acc: 0.7468\n",
      "Seed: 43, Epoch: 094, Loss: 0.3777, Val Acc: 0.7480, Test Acc: 0.7645\n",
      "Seed: 43, Epoch: 095, Loss: 0.3633, Val Acc: 0.7108, Test Acc: 0.7484\n",
      "Seed: 43, Epoch: 096, Loss: 0.3548, Val Acc: 0.7189, Test Acc: 0.7581\n",
      "Seed: 43, Epoch: 097, Loss: 0.3481, Val Acc: 0.7237, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 098, Loss: 0.3566, Val Acc: 0.7334, Test Acc: 0.7226\n",
      "Seed: 43, Epoch: 099, Loss: 0.3577, Val Acc: 0.7141, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 100, Loss: 0.3529, Val Acc: 0.7334, Test Acc: 0.7645\n",
      "Seed: 43, Epoch: 101, Loss: 0.3582, Val Acc: 0.6995, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 102, Loss: 0.3483, Val Acc: 0.7512, Test Acc: 0.7742\n",
      "Seed: 43, Epoch: 103, Loss: 0.3491, Val Acc: 0.7011, Test Acc: 0.6887\n",
      "Seed: 43, Epoch: 104, Loss: 0.3486, Val Acc: 0.7221, Test Acc: 0.7210\n",
      "Seed: 43, Epoch: 105, Loss: 0.3545, Val Acc: 0.6898, Test Acc: 0.7194\n",
      "Seed: 43, Epoch: 106, Loss: 0.3515, Val Acc: 0.7173, Test Acc: 0.7565\n",
      "Seed: 43, Epoch: 107, Loss: 0.3366, Val Acc: 0.6931, Test Acc: 0.7435\n",
      "Seed: 43, Epoch: 108, Loss: 0.3344, Val Acc: 0.7480, Test Acc: 0.7661\n",
      "Seed: 43, Epoch: 109, Loss: 0.3446, Val Acc: 0.7205, Test Acc: 0.7661\n",
      "Seed: 43, Epoch: 110, Loss: 0.3388, Val Acc: 0.7512, Test Acc: 0.7419\n",
      "Seed: 43, Epoch: 111, Loss: 0.3340, Val Acc: 0.7205, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 112, Loss: 0.3320, Val Acc: 0.7011, Test Acc: 0.7435\n",
      "Seed: 43, Epoch: 113, Loss: 0.3377, Val Acc: 0.7108, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 114, Loss: 0.3262, Val Acc: 0.7302, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 115, Loss: 0.3460, Val Acc: 0.7205, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 116, Loss: 0.3277, Val Acc: 0.7447, Test Acc: 0.7468\n",
      "Seed: 43, Epoch: 117, Loss: 0.3166, Val Acc: 0.7076, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 118, Loss: 0.3471, Val Acc: 0.7044, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 119, Loss: 0.3337, Val Acc: 0.7431, Test Acc: 0.7645\n",
      "Seed: 43, Epoch: 120, Loss: 0.3227, Val Acc: 0.7270, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 121, Loss: 0.3075, Val Acc: 0.7334, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 122, Loss: 0.3212, Val Acc: 0.6963, Test Acc: 0.7468\n",
      "Seed: 43, Epoch: 123, Loss: 0.3180, Val Acc: 0.7480, Test Acc: 0.7258\n",
      "Seed: 43, Epoch: 124, Loss: 0.3105, Val Acc: 0.7706, Test Acc: 0.7790\n",
      "Seed: 43, Epoch: 125, Loss: 0.3108, Val Acc: 0.7189, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 126, Loss: 0.3206, Val Acc: 0.6963, Test Acc: 0.7323\n",
      "Seed: 43, Epoch: 127, Loss: 0.3153, Val Acc: 0.7173, Test Acc: 0.7629\n",
      "Seed: 43, Epoch: 128, Loss: 0.3206, Val Acc: 0.7141, Test Acc: 0.7532\n",
      "Seed: 43, Epoch: 129, Loss: 0.3184, Val Acc: 0.7431, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 130, Loss: 0.3238, Val Acc: 0.7254, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 131, Loss: 0.3147, Val Acc: 0.7108, Test Acc: 0.7258\n",
      "Seed: 43, Epoch: 132, Loss: 0.3112, Val Acc: 0.7237, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 133, Loss: 0.3070, Val Acc: 0.7399, Test Acc: 0.7774\n",
      "Seed: 43, Epoch: 134, Loss: 0.2916, Val Acc: 0.7334, Test Acc: 0.7774\n",
      "Seed: 43, Epoch: 135, Loss: 0.2890, Val Acc: 0.7318, Test Acc: 0.7532\n",
      "Seed: 43, Epoch: 136, Loss: 0.2844, Val Acc: 0.7141, Test Acc: 0.7435\n",
      "Seed: 43, Epoch: 137, Loss: 0.3170, Val Acc: 0.7221, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 138, Loss: 0.3040, Val Acc: 0.7270, Test Acc: 0.7581\n",
      "Seed: 43, Epoch: 139, Loss: 0.2904, Val Acc: 0.7318, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 140, Loss: 0.2991, Val Acc: 0.7480, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 141, Loss: 0.3169, Val Acc: 0.7334, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 142, Loss: 0.3139, Val Acc: 0.7351, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 143, Loss: 0.3117, Val Acc: 0.6640, Test Acc: 0.7129\n",
      "Seed: 43, Epoch: 144, Loss: 0.2960, Val Acc: 0.7076, Test Acc: 0.7484\n",
      "Seed: 43, Epoch: 145, Loss: 0.2958, Val Acc: 0.7173, Test Acc: 0.7371\n",
      "Seed: 43, Epoch: 146, Loss: 0.3059, Val Acc: 0.6898, Test Acc: 0.7194\n",
      "Seed: 43, Epoch: 147, Loss: 0.2930, Val Acc: 0.7124, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 148, Loss: 0.3023, Val Acc: 0.7237, Test Acc: 0.7452\n",
      "Seed: 43, Epoch: 149, Loss: 0.3076, Val Acc: 0.6769, Test Acc: 0.7065\n",
      "Seed: 43, Epoch: 150, Loss: 0.3128, Val Acc: 0.7254, Test Acc: 0.7435\n",
      "Seed: 43, Epoch: 151, Loss: 0.3037, Val Acc: 0.7205, Test Acc: 0.7677\n",
      "Seed: 43, Epoch: 152, Loss: 0.2898, Val Acc: 0.6979, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 153, Loss: 0.2869, Val Acc: 0.7141, Test Acc: 0.7710\n",
      "Seed: 43, Epoch: 154, Loss: 0.2921, Val Acc: 0.7399, Test Acc: 0.7710\n",
      "Seed: 43, Epoch: 155, Loss: 0.2797, Val Acc: 0.7302, Test Acc: 0.7274\n",
      "Seed: 43, Epoch: 156, Loss: 0.2970, Val Acc: 0.7254, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 157, Loss: 0.2919, Val Acc: 0.7254, Test Acc: 0.7597\n",
      "Seed: 43, Epoch: 158, Loss: 0.2909, Val Acc: 0.7254, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 159, Loss: 0.2867, Val Acc: 0.7189, Test Acc: 0.7242\n",
      "Seed: 43, Epoch: 160, Loss: 0.3052, Val Acc: 0.7157, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 161, Loss: 0.2805, Val Acc: 0.7254, Test Acc: 0.7468\n",
      "Seed: 43, Epoch: 162, Loss: 0.2865, Val Acc: 0.7141, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 163, Loss: 0.2972, Val Acc: 0.7383, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 164, Loss: 0.2857, Val Acc: 0.7205, Test Acc: 0.7290\n",
      "Seed: 43, Epoch: 165, Loss: 0.2857, Val Acc: 0.7254, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 166, Loss: 0.2733, Val Acc: 0.7254, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 167, Loss: 0.2822, Val Acc: 0.7076, Test Acc: 0.7532\n",
      "Seed: 43, Epoch: 168, Loss: 0.2737, Val Acc: 0.7189, Test Acc: 0.7468\n",
      "Seed: 43, Epoch: 169, Loss: 0.2593, Val Acc: 0.7157, Test Acc: 0.7306\n",
      "Seed: 43, Epoch: 170, Loss: 0.3032, Val Acc: 0.7302, Test Acc: 0.7597\n",
      "Seed: 43, Epoch: 171, Loss: 0.2652, Val Acc: 0.7076, Test Acc: 0.7371\n",
      "Seed: 43, Epoch: 172, Loss: 0.2720, Val Acc: 0.7011, Test Acc: 0.7403\n",
      "Seed: 43, Epoch: 173, Loss: 0.2911, Val Acc: 0.7221, Test Acc: 0.7532\n",
      "Seed: 43, Epoch: 174, Loss: 0.2761, Val Acc: 0.7593, Test Acc: 0.7629\n",
      "Seed: 43, Epoch: 175, Loss: 0.2700, Val Acc: 0.6882, Test Acc: 0.7339\n",
      "Seed: 43, Epoch: 176, Loss: 0.2785, Val Acc: 0.7318, Test Acc: 0.7403\n",
      "Seed: 43, Epoch: 177, Loss: 0.2633, Val Acc: 0.7157, Test Acc: 0.7435\n",
      "Seed: 43, Epoch: 178, Loss: 0.2747, Val Acc: 0.7254, Test Acc: 0.7177\n",
      "Seed: 43, Epoch: 179, Loss: 0.2793, Val Acc: 0.7367, Test Acc: 0.7694\n",
      "Seed: 43, Epoch: 180, Loss: 0.2500, Val Acc: 0.7060, Test Acc: 0.7371\n",
      "Seed: 43, Epoch: 181, Loss: 0.2670, Val Acc: 0.7512, Test Acc: 0.7742\n",
      "Seed: 43, Epoch: 182, Loss: 0.2750, Val Acc: 0.7237, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 183, Loss: 0.2679, Val Acc: 0.7302, Test Acc: 0.7516\n",
      "Seed: 43, Epoch: 184, Loss: 0.2510, Val Acc: 0.7092, Test Acc: 0.7339\n",
      "Seed: 43, Epoch: 185, Loss: 0.2602, Val Acc: 0.7302, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 186, Loss: 0.2621, Val Acc: 0.7237, Test Acc: 0.7371\n",
      "Seed: 43, Epoch: 187, Loss: 0.2580, Val Acc: 0.7464, Test Acc: 0.7468\n",
      "Seed: 43, Epoch: 188, Loss: 0.2612, Val Acc: 0.7286, Test Acc: 0.7677\n",
      "Seed: 43, Epoch: 189, Loss: 0.2573, Val Acc: 0.7351, Test Acc: 0.7403\n",
      "Seed: 43, Epoch: 190, Loss: 0.2522, Val Acc: 0.7044, Test Acc: 0.7548\n",
      "Seed: 43, Epoch: 191, Loss: 0.2592, Val Acc: 0.7544, Test Acc: 0.7613\n",
      "Seed: 43, Epoch: 192, Loss: 0.2668, Val Acc: 0.6640, Test Acc: 0.6952\n",
      "Seed: 43, Epoch: 193, Loss: 0.2874, Val Acc: 0.7318, Test Acc: 0.7500\n",
      "Seed: 43, Epoch: 194, Loss: 0.2735, Val Acc: 0.7351, Test Acc: 0.7565\n",
      "Seed: 43, Epoch: 195, Loss: 0.2533, Val Acc: 0.7399, Test Acc: 0.7661\n",
      "Seed: 43, Epoch: 196, Loss: 0.2453, Val Acc: 0.7060, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 197, Loss: 0.2444, Val Acc: 0.7447, Test Acc: 0.7758\n",
      "Seed: 43, Epoch: 198, Loss: 0.2417, Val Acc: 0.7512, Test Acc: 0.7694\n",
      "Seed: 43, Epoch: 199, Loss: 0.2447, Val Acc: 0.7108, Test Acc: 0.7355\n",
      "Seed: 43, Epoch: 200, Loss: 0.2565, Val Acc: 0.7076, Test Acc: 0.7468\n",
      "Seed: 44, Epoch: 001, Loss: 0.6878, Val Acc: 0.4863, Test Acc: 0.5097\n",
      "Seed: 44, Epoch: 002, Loss: 0.6677, Val Acc: 0.6139, Test Acc: 0.6290\n",
      "Seed: 44, Epoch: 003, Loss: 0.6411, Val Acc: 0.6074, Test Acc: 0.6484\n",
      "Seed: 44, Epoch: 004, Loss: 0.6199, Val Acc: 0.6414, Test Acc: 0.6790\n",
      "Seed: 44, Epoch: 005, Loss: 0.6050, Val Acc: 0.6656, Test Acc: 0.6984\n",
      "Seed: 44, Epoch: 006, Loss: 0.5951, Val Acc: 0.6527, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 007, Loss: 0.5859, Val Acc: 0.6785, Test Acc: 0.6935\n",
      "Seed: 44, Epoch: 008, Loss: 0.5767, Val Acc: 0.6575, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 009, Loss: 0.5694, Val Acc: 0.6898, Test Acc: 0.7306\n",
      "Seed: 44, Epoch: 010, Loss: 0.5633, Val Acc: 0.6721, Test Acc: 0.7032\n",
      "Seed: 44, Epoch: 011, Loss: 0.5561, Val Acc: 0.6381, Test Acc: 0.6613\n",
      "Seed: 44, Epoch: 012, Loss: 0.5572, Val Acc: 0.7124, Test Acc: 0.7468\n",
      "Seed: 44, Epoch: 013, Loss: 0.5465, Val Acc: 0.6914, Test Acc: 0.6903\n",
      "Seed: 44, Epoch: 014, Loss: 0.5528, Val Acc: 0.6866, Test Acc: 0.6984\n",
      "Seed: 44, Epoch: 015, Loss: 0.5379, Val Acc: 0.6640, Test Acc: 0.7113\n",
      "Seed: 44, Epoch: 016, Loss: 0.5328, Val Acc: 0.6204, Test Acc: 0.6629\n",
      "Seed: 44, Epoch: 017, Loss: 0.5342, Val Acc: 0.6979, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 018, Loss: 0.5339, Val Acc: 0.7108, Test Acc: 0.7226\n",
      "Seed: 44, Epoch: 019, Loss: 0.5207, Val Acc: 0.7189, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 020, Loss: 0.5183, Val Acc: 0.7302, Test Acc: 0.7710\n",
      "Seed: 44, Epoch: 021, Loss: 0.5102, Val Acc: 0.6817, Test Acc: 0.6935\n",
      "Seed: 44, Epoch: 022, Loss: 0.5125, Val Acc: 0.7044, Test Acc: 0.7194\n",
      "Seed: 44, Epoch: 023, Loss: 0.5162, Val Acc: 0.7124, Test Acc: 0.7258\n",
      "Seed: 44, Epoch: 024, Loss: 0.5059, Val Acc: 0.6704, Test Acc: 0.7242\n",
      "Seed: 44, Epoch: 025, Loss: 0.5071, Val Acc: 0.7044, Test Acc: 0.7161\n",
      "Seed: 44, Epoch: 026, Loss: 0.5057, Val Acc: 0.7270, Test Acc: 0.7419\n",
      "Seed: 44, Epoch: 027, Loss: 0.4833, Val Acc: 0.7124, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 028, Loss: 0.4829, Val Acc: 0.6866, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 029, Loss: 0.4792, Val Acc: 0.7286, Test Acc: 0.7339\n",
      "Seed: 44, Epoch: 030, Loss: 0.4779, Val Acc: 0.6914, Test Acc: 0.7242\n",
      "Seed: 44, Epoch: 031, Loss: 0.4712, Val Acc: 0.7318, Test Acc: 0.7226\n",
      "Seed: 44, Epoch: 032, Loss: 0.4767, Val Acc: 0.7108, Test Acc: 0.7306\n",
      "Seed: 44, Epoch: 033, Loss: 0.4774, Val Acc: 0.7108, Test Acc: 0.7210\n",
      "Seed: 44, Epoch: 034, Loss: 0.4644, Val Acc: 0.6931, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 035, Loss: 0.4663, Val Acc: 0.7011, Test Acc: 0.7258\n",
      "Seed: 44, Epoch: 036, Loss: 0.4527, Val Acc: 0.6753, Test Acc: 0.7306\n",
      "Seed: 44, Epoch: 037, Loss: 0.4701, Val Acc: 0.6995, Test Acc: 0.6919\n",
      "Seed: 44, Epoch: 038, Loss: 0.4608, Val Acc: 0.7141, Test Acc: 0.7323\n",
      "Seed: 44, Epoch: 039, Loss: 0.4530, Val Acc: 0.6898, Test Acc: 0.6952\n",
      "Seed: 44, Epoch: 040, Loss: 0.4672, Val Acc: 0.6931, Test Acc: 0.7177\n",
      "Seed: 44, Epoch: 041, Loss: 0.4697, Val Acc: 0.7480, Test Acc: 0.7290\n",
      "Seed: 44, Epoch: 042, Loss: 0.4419, Val Acc: 0.7496, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 043, Loss: 0.4384, Val Acc: 0.7334, Test Acc: 0.7242\n",
      "Seed: 44, Epoch: 044, Loss: 0.4390, Val Acc: 0.7367, Test Acc: 0.7581\n",
      "Seed: 44, Epoch: 045, Loss: 0.4404, Val Acc: 0.7399, Test Acc: 0.7355\n",
      "Seed: 44, Epoch: 046, Loss: 0.4410, Val Acc: 0.7092, Test Acc: 0.7339\n",
      "Seed: 44, Epoch: 047, Loss: 0.4394, Val Acc: 0.7609, Test Acc: 0.7645\n",
      "Seed: 44, Epoch: 048, Loss: 0.4324, Val Acc: 0.7076, Test Acc: 0.7048\n",
      "Seed: 44, Epoch: 049, Loss: 0.4255, Val Acc: 0.7141, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 050, Loss: 0.4193, Val Acc: 0.7173, Test Acc: 0.7242\n",
      "Seed: 44, Epoch: 051, Loss: 0.4220, Val Acc: 0.7189, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 052, Loss: 0.4189, Val Acc: 0.7512, Test Acc: 0.7548\n",
      "Seed: 44, Epoch: 053, Loss: 0.4144, Val Acc: 0.6672, Test Acc: 0.7032\n",
      "Seed: 44, Epoch: 054, Loss: 0.4248, Val Acc: 0.7141, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 055, Loss: 0.4100, Val Acc: 0.7270, Test Acc: 0.7323\n",
      "Seed: 44, Epoch: 056, Loss: 0.4171, Val Acc: 0.7302, Test Acc: 0.7548\n",
      "Seed: 44, Epoch: 057, Loss: 0.4177, Val Acc: 0.7205, Test Acc: 0.7419\n",
      "Seed: 44, Epoch: 058, Loss: 0.4181, Val Acc: 0.7318, Test Acc: 0.7419\n",
      "Seed: 44, Epoch: 059, Loss: 0.3995, Val Acc: 0.6834, Test Acc: 0.7048\n",
      "Seed: 44, Epoch: 060, Loss: 0.3956, Val Acc: 0.7464, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 061, Loss: 0.4034, Val Acc: 0.7464, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 062, Loss: 0.3979, Val Acc: 0.7011, Test Acc: 0.7419\n",
      "Seed: 44, Epoch: 063, Loss: 0.4009, Val Acc: 0.7464, Test Acc: 0.7210\n",
      "Seed: 44, Epoch: 064, Loss: 0.3996, Val Acc: 0.7141, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 065, Loss: 0.3900, Val Acc: 0.7027, Test Acc: 0.7032\n",
      "Seed: 44, Epoch: 066, Loss: 0.3936, Val Acc: 0.7221, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 067, Loss: 0.4059, Val Acc: 0.7415, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 068, Loss: 0.4030, Val Acc: 0.7286, Test Acc: 0.7758\n",
      "Seed: 44, Epoch: 069, Loss: 0.3883, Val Acc: 0.7027, Test Acc: 0.7355\n",
      "Seed: 44, Epoch: 070, Loss: 0.3907, Val Acc: 0.7464, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 071, Loss: 0.3961, Val Acc: 0.7480, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 072, Loss: 0.3945, Val Acc: 0.7609, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 073, Loss: 0.3784, Val Acc: 0.7480, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 074, Loss: 0.3683, Val Acc: 0.7367, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 075, Loss: 0.3766, Val Acc: 0.7431, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 076, Loss: 0.3812, Val Acc: 0.7254, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 077, Loss: 0.3851, Val Acc: 0.6785, Test Acc: 0.7097\n",
      "Seed: 44, Epoch: 078, Loss: 0.3757, Val Acc: 0.7593, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 079, Loss: 0.3726, Val Acc: 0.7011, Test Acc: 0.7403\n",
      "Seed: 44, Epoch: 080, Loss: 0.3660, Val Acc: 0.7108, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 081, Loss: 0.3646, Val Acc: 0.7302, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 082, Loss: 0.3591, Val Acc: 0.7221, Test Acc: 0.7323\n",
      "Seed: 44, Epoch: 083, Loss: 0.3589, Val Acc: 0.7383, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 084, Loss: 0.3623, Val Acc: 0.7108, Test Acc: 0.7242\n",
      "Seed: 44, Epoch: 085, Loss: 0.3596, Val Acc: 0.7286, Test Acc: 0.7129\n",
      "Seed: 44, Epoch: 086, Loss: 0.3635, Val Acc: 0.7480, Test Acc: 0.7290\n",
      "Seed: 44, Epoch: 087, Loss: 0.3529, Val Acc: 0.7577, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 088, Loss: 0.3642, Val Acc: 0.6882, Test Acc: 0.7290\n",
      "Seed: 44, Epoch: 089, Loss: 0.3516, Val Acc: 0.7060, Test Acc: 0.7306\n",
      "Seed: 44, Epoch: 090, Loss: 0.3678, Val Acc: 0.7561, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 091, Loss: 0.3735, Val Acc: 0.7415, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 092, Loss: 0.3654, Val Acc: 0.7124, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 093, Loss: 0.3457, Val Acc: 0.7415, Test Acc: 0.7581\n",
      "Seed: 44, Epoch: 094, Loss: 0.3645, Val Acc: 0.7415, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 095, Loss: 0.3491, Val Acc: 0.7415, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 096, Loss: 0.3546, Val Acc: 0.7060, Test Acc: 0.7290\n",
      "Seed: 44, Epoch: 097, Loss: 0.3495, Val Acc: 0.7609, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 098, Loss: 0.3476, Val Acc: 0.7464, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 099, Loss: 0.3452, Val Acc: 0.7464, Test Acc: 0.7710\n",
      "Seed: 44, Epoch: 100, Loss: 0.3385, Val Acc: 0.7383, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 101, Loss: 0.3318, Val Acc: 0.7367, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 102, Loss: 0.3375, Val Acc: 0.7270, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 103, Loss: 0.3519, Val Acc: 0.7076, Test Acc: 0.7129\n",
      "Seed: 44, Epoch: 104, Loss: 0.3469, Val Acc: 0.7399, Test Acc: 0.7694\n",
      "Seed: 44, Epoch: 105, Loss: 0.3258, Val Acc: 0.7383, Test Acc: 0.7661\n",
      "Seed: 44, Epoch: 106, Loss: 0.3429, Val Acc: 0.7351, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 107, Loss: 0.3373, Val Acc: 0.7124, Test Acc: 0.7548\n",
      "Seed: 44, Epoch: 108, Loss: 0.3341, Val Acc: 0.7399, Test Acc: 0.7371\n",
      "Seed: 44, Epoch: 109, Loss: 0.3345, Val Acc: 0.7399, Test Acc: 0.7871\n",
      "Seed: 44, Epoch: 110, Loss: 0.3397, Val Acc: 0.7431, Test Acc: 0.7710\n",
      "Seed: 44, Epoch: 111, Loss: 0.3327, Val Acc: 0.7480, Test Acc: 0.7823\n",
      "Seed: 44, Epoch: 112, Loss: 0.3266, Val Acc: 0.7141, Test Acc: 0.7403\n",
      "Seed: 44, Epoch: 113, Loss: 0.3242, Val Acc: 0.7237, Test Acc: 0.7677\n",
      "Seed: 44, Epoch: 114, Loss: 0.3120, Val Acc: 0.7141, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 115, Loss: 0.3273, Val Acc: 0.7157, Test Acc: 0.7419\n",
      "Seed: 44, Epoch: 116, Loss: 0.3197, Val Acc: 0.7157, Test Acc: 0.7403\n",
      "Seed: 44, Epoch: 117, Loss: 0.3233, Val Acc: 0.7334, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 118, Loss: 0.3055, Val Acc: 0.7464, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 119, Loss: 0.3430, Val Acc: 0.7092, Test Acc: 0.7290\n",
      "Seed: 44, Epoch: 120, Loss: 0.3449, Val Acc: 0.7415, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 121, Loss: 0.3170, Val Acc: 0.7431, Test Acc: 0.7839\n",
      "Seed: 44, Epoch: 122, Loss: 0.3069, Val Acc: 0.7092, Test Acc: 0.7226\n",
      "Seed: 44, Epoch: 123, Loss: 0.3168, Val Acc: 0.7334, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 124, Loss: 0.3015, Val Acc: 0.7141, Test Acc: 0.7484\n",
      "Seed: 44, Epoch: 125, Loss: 0.3020, Val Acc: 0.7399, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 126, Loss: 0.3000, Val Acc: 0.7076, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 127, Loss: 0.3107, Val Acc: 0.7561, Test Acc: 0.7774\n",
      "Seed: 44, Epoch: 128, Loss: 0.3054, Val Acc: 0.7480, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 129, Loss: 0.3140, Val Acc: 0.7754, Test Acc: 0.7710\n",
      "Seed: 44, Epoch: 130, Loss: 0.2897, Val Acc: 0.7302, Test Acc: 0.7306\n",
      "Seed: 44, Epoch: 131, Loss: 0.2918, Val Acc: 0.6914, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 132, Loss: 0.3112, Val Acc: 0.6898, Test Acc: 0.7129\n",
      "Seed: 44, Epoch: 133, Loss: 0.3053, Val Acc: 0.7221, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 134, Loss: 0.2961, Val Acc: 0.7141, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 135, Loss: 0.3034, Val Acc: 0.7254, Test Acc: 0.7661\n",
      "Seed: 44, Epoch: 136, Loss: 0.2848, Val Acc: 0.7254, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 137, Loss: 0.2813, Val Acc: 0.7205, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 138, Loss: 0.2911, Val Acc: 0.7205, Test Acc: 0.7226\n",
      "Seed: 44, Epoch: 139, Loss: 0.2722, Val Acc: 0.7237, Test Acc: 0.7323\n",
      "Seed: 44, Epoch: 140, Loss: 0.2998, Val Acc: 0.7415, Test Acc: 0.7758\n",
      "Seed: 44, Epoch: 141, Loss: 0.2783, Val Acc: 0.7415, Test Acc: 0.7887\n",
      "Seed: 44, Epoch: 142, Loss: 0.2878, Val Acc: 0.7399, Test Acc: 0.7694\n",
      "Seed: 44, Epoch: 143, Loss: 0.2991, Val Acc: 0.7351, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 144, Loss: 0.3067, Val Acc: 0.7302, Test Acc: 0.7468\n",
      "Seed: 44, Epoch: 145, Loss: 0.2839, Val Acc: 0.7318, Test Acc: 0.7758\n",
      "Seed: 44, Epoch: 146, Loss: 0.2897, Val Acc: 0.6995, Test Acc: 0.7339\n",
      "Seed: 44, Epoch: 147, Loss: 0.2842, Val Acc: 0.7270, Test Acc: 0.7145\n",
      "Seed: 44, Epoch: 148, Loss: 0.2856, Val Acc: 0.7302, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 149, Loss: 0.2919, Val Acc: 0.7124, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 150, Loss: 0.2791, Val Acc: 0.7157, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 151, Loss: 0.2758, Val Acc: 0.7512, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 152, Loss: 0.2760, Val Acc: 0.7270, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 153, Loss: 0.2686, Val Acc: 0.7221, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 154, Loss: 0.2657, Val Acc: 0.7157, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 155, Loss: 0.2875, Val Acc: 0.6963, Test Acc: 0.7097\n",
      "Seed: 44, Epoch: 156, Loss: 0.2789, Val Acc: 0.7221, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 157, Loss: 0.2656, Val Acc: 0.7011, Test Acc: 0.7306\n",
      "Seed: 44, Epoch: 158, Loss: 0.2772, Val Acc: 0.7480, Test Acc: 0.7548\n",
      "Seed: 44, Epoch: 159, Loss: 0.2799, Val Acc: 0.7141, Test Acc: 0.7581\n",
      "Seed: 44, Epoch: 160, Loss: 0.2672, Val Acc: 0.7464, Test Acc: 0.7339\n",
      "Seed: 44, Epoch: 161, Loss: 0.2636, Val Acc: 0.7205, Test Acc: 0.7677\n",
      "Seed: 44, Epoch: 162, Loss: 0.2752, Val Acc: 0.7286, Test Acc: 0.7774\n",
      "Seed: 44, Epoch: 163, Loss: 0.2699, Val Acc: 0.7060, Test Acc: 0.7306\n",
      "Seed: 44, Epoch: 164, Loss: 0.2743, Val Acc: 0.7512, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 165, Loss: 0.2800, Val Acc: 0.7237, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 166, Loss: 0.2667, Val Acc: 0.7286, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 167, Loss: 0.2856, Val Acc: 0.7318, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 168, Loss: 0.2588, Val Acc: 0.7108, Test Acc: 0.7323\n",
      "Seed: 44, Epoch: 169, Loss: 0.2457, Val Acc: 0.7415, Test Acc: 0.7645\n",
      "Seed: 44, Epoch: 170, Loss: 0.2531, Val Acc: 0.7027, Test Acc: 0.7339\n",
      "Seed: 44, Epoch: 171, Loss: 0.2550, Val Acc: 0.7367, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 172, Loss: 0.2717, Val Acc: 0.7205, Test Acc: 0.7419\n",
      "Seed: 44, Epoch: 173, Loss: 0.2473, Val Acc: 0.7431, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 174, Loss: 0.2419, Val Acc: 0.7399, Test Acc: 0.7452\n",
      "Seed: 44, Epoch: 175, Loss: 0.2684, Val Acc: 0.7447, Test Acc: 0.7323\n",
      "Seed: 44, Epoch: 176, Loss: 0.2494, Val Acc: 0.7108, Test Acc: 0.7161\n",
      "Seed: 44, Epoch: 177, Loss: 0.2495, Val Acc: 0.7302, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 178, Loss: 0.2735, Val Acc: 0.7464, Test Acc: 0.7403\n",
      "Seed: 44, Epoch: 179, Loss: 0.2539, Val Acc: 0.7367, Test Acc: 0.7468\n",
      "Seed: 44, Epoch: 180, Loss: 0.2512, Val Acc: 0.7173, Test Acc: 0.7435\n",
      "Seed: 44, Epoch: 181, Loss: 0.2573, Val Acc: 0.6947, Test Acc: 0.7419\n",
      "Seed: 44, Epoch: 182, Loss: 0.2683, Val Acc: 0.7044, Test Acc: 0.7355\n",
      "Seed: 44, Epoch: 183, Loss: 0.2468, Val Acc: 0.7124, Test Acc: 0.7629\n",
      "Seed: 44, Epoch: 184, Loss: 0.2662, Val Acc: 0.7544, Test Acc: 0.7516\n",
      "Seed: 44, Epoch: 185, Loss: 0.2648, Val Acc: 0.7383, Test Acc: 0.7597\n",
      "Seed: 44, Epoch: 186, Loss: 0.2432, Val Acc: 0.7189, Test Acc: 0.7661\n",
      "Seed: 44, Epoch: 187, Loss: 0.2462, Val Acc: 0.7528, Test Acc: 0.7790\n",
      "Seed: 44, Epoch: 188, Loss: 0.2707, Val Acc: 0.7351, Test Acc: 0.7726\n",
      "Seed: 44, Epoch: 189, Loss: 0.2576, Val Acc: 0.7270, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 190, Loss: 0.2478, Val Acc: 0.7383, Test Acc: 0.7581\n",
      "Seed: 44, Epoch: 191, Loss: 0.2537, Val Acc: 0.7496, Test Acc: 0.7710\n",
      "Seed: 44, Epoch: 192, Loss: 0.2509, Val Acc: 0.7060, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 193, Loss: 0.2632, Val Acc: 0.7480, Test Acc: 0.7548\n",
      "Seed: 44, Epoch: 194, Loss: 0.2356, Val Acc: 0.7496, Test Acc: 0.7532\n",
      "Seed: 44, Epoch: 195, Loss: 0.2565, Val Acc: 0.7157, Test Acc: 0.7339\n",
      "Seed: 44, Epoch: 196, Loss: 0.2474, Val Acc: 0.7447, Test Acc: 0.7290\n",
      "Seed: 44, Epoch: 197, Loss: 0.2344, Val Acc: 0.7367, Test Acc: 0.7500\n",
      "Seed: 44, Epoch: 198, Loss: 0.2413, Val Acc: 0.7060, Test Acc: 0.7565\n",
      "Seed: 44, Epoch: 199, Loss: 0.2392, Val Acc: 0.7334, Test Acc: 0.7419\n",
      "Seed: 44, Epoch: 200, Loss: 0.2382, Val Acc: 0.7173, Test Acc: 0.7484\n",
      "Average Time: 346.03 seconds\n",
      "Var Time: 67.75 seconds\n",
      "Average Memory: 484.67 MB\n",
      "Average Best Val Acc: 0.7808\n",
      "Std Best Test Acc: 0.0197\n",
      "Average Test Acc: 0.7613\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "max_nodes = 150\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"NCI109\",\n",
    "    transform=T.Compose([T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_hosc(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc, o = dense_hoscpool(x, adj, s, mu=0.3, alpha=0.3, new_ortho=False, mask=mask)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc_aux, o_aux = dense_hoscpool(x, adj, s, mu=0.3, alpha=0.3, new_ortho=False)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_hosc().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    model = Net_hosc().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MUTAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[150, 7], y=[1], adj=[150, 150], mask=[150])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.transforms import BaseTransform\n",
    "\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "max_nodes = 150\n",
    "class ConvertToDenseAdj(BaseTransform):\n",
    "    def __call__(self, data):\n",
    "        # 确保 data.adj 存在且为三维\n",
    "        if hasattr(data, 'adj') and data.adj.dim() == 3:\n",
    "            # 对第三维进行合并操作，这里以求和为例\n",
    "            data.adj = data.adj.sum(dim=-1)\n",
    "            # 你可以选择其他方式，如取最大值：\n",
    "            # data.adj = data.adj.max(dim=-1)[0]\n",
    "\n",
    "        return data\n",
    "\n",
    "# 在加载数据时应用这个变换\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"MUTAG\",\n",
    "    transform=T.Compose([T.ToDense(max_nodes), ConvertToDenseAdj()]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "dataset_dense[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Time: 34.75 seconds\n",
      "Var Time: 73.19 seconds\n",
      "Average Memory: 428.67 MB\n",
      "Average Best Val Acc: 0.9048\n",
      "Std Best Test Acc: 0.0163\n",
      "Average Test Acc: 0.8506\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_hosc(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc, o = dense_hoscpool(x, adj, s, mu=0.3, alpha=0.5, new_ortho=False, mask=mask)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc_aux, o_aux = dense_hoscpool(x, adj, s, mu=0.3, alpha=0.5, new_ortho=False)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_hosc().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=512, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "    model = Net_hosc().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        #print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6906, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 002, Loss: 0.6889, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 003, Loss: 0.6877, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 004, Loss: 0.6868, Val Acc: 0.5495, Test Acc: 0.5676\n",
      "Seed: 42, Epoch: 005, Loss: 0.6861, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 006, Loss: 0.6854, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 007, Loss: 0.6847, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 008, Loss: 0.6840, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 009, Loss: 0.6831, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 010, Loss: 0.6820, Val Acc: 0.5495, Test Acc: 0.5586\n",
      "Seed: 42, Epoch: 011, Loss: 0.6808, Val Acc: 0.5766, Test Acc: 0.5766\n",
      "Seed: 42, Epoch: 012, Loss: 0.6793, Val Acc: 0.6937, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 013, Loss: 0.6775, Val Acc: 0.7297, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 014, Loss: 0.6752, Val Acc: 0.7748, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 015, Loss: 0.6723, Val Acc: 0.7748, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 016, Loss: 0.6689, Val Acc: 0.7027, Test Acc: 0.6486\n",
      "Seed: 42, Epoch: 017, Loss: 0.6659, Val Acc: 0.7117, Test Acc: 0.6126\n",
      "Seed: 42, Epoch: 018, Loss: 0.6617, Val Acc: 0.6757, Test Acc: 0.6036\n",
      "Seed: 42, Epoch: 019, Loss: 0.6583, Val Acc: 0.6577, Test Acc: 0.5856\n",
      "Seed: 42, Epoch: 020, Loss: 0.6547, Val Acc: 0.6667, Test Acc: 0.6036\n",
      "Seed: 42, Epoch: 021, Loss: 0.6497, Val Acc: 0.6847, Test Acc: 0.5946\n",
      "Seed: 42, Epoch: 022, Loss: 0.6446, Val Acc: 0.7207, Test Acc: 0.6216\n",
      "Seed: 42, Epoch: 023, Loss: 0.6387, Val Acc: 0.7297, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 024, Loss: 0.6346, Val Acc: 0.7928, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 025, Loss: 0.6322, Val Acc: 0.7928, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 026, Loss: 0.6245, Val Acc: 0.7568, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 027, Loss: 0.6138, Val Acc: 0.7117, Test Acc: 0.6306\n",
      "Seed: 42, Epoch: 028, Loss: 0.6070, Val Acc: 0.6667, Test Acc: 0.5946\n",
      "Seed: 42, Epoch: 029, Loss: 0.6070, Val Acc: 0.6486, Test Acc: 0.5766\n",
      "Seed: 42, Epoch: 030, Loss: 0.6080, Val Acc: 0.6667, Test Acc: 0.6036\n",
      "Seed: 42, Epoch: 031, Loss: 0.5982, Val Acc: 0.7117, Test Acc: 0.6396\n",
      "Seed: 42, Epoch: 032, Loss: 0.5837, Val Acc: 0.7748, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 033, Loss: 0.5720, Val Acc: 0.7928, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 034, Loss: 0.5757, Val Acc: 0.7297, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 035, Loss: 0.5830, Val Acc: 0.7748, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 036, Loss: 0.5648, Val Acc: 0.7748, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 037, Loss: 0.5505, Val Acc: 0.7658, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 038, Loss: 0.5414, Val Acc: 0.7568, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 039, Loss: 0.5332, Val Acc: 0.7477, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 040, Loss: 0.5296, Val Acc: 0.7027, Test Acc: 0.6486\n",
      "Seed: 42, Epoch: 041, Loss: 0.5318, Val Acc: 0.6937, Test Acc: 0.6396\n",
      "Seed: 42, Epoch: 042, Loss: 0.5341, Val Acc: 0.7027, Test Acc: 0.6486\n",
      "Seed: 42, Epoch: 043, Loss: 0.5260, Val Acc: 0.6937, Test Acc: 0.6577\n",
      "Seed: 42, Epoch: 044, Loss: 0.5204, Val Acc: 0.7027, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 045, Loss: 0.5137, Val Acc: 0.7117, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 046, Loss: 0.5046, Val Acc: 0.7207, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 047, Loss: 0.4966, Val Acc: 0.7387, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 048, Loss: 0.4784, Val Acc: 0.7748, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 049, Loss: 0.4743, Val Acc: 0.7568, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 050, Loss: 0.4870, Val Acc: 0.7568, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 051, Loss: 0.4874, Val Acc: 0.7568, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 052, Loss: 0.4792, Val Acc: 0.7748, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 053, Loss: 0.4611, Val Acc: 0.7748, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 054, Loss: 0.4508, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 055, Loss: 0.4522, Val Acc: 0.7568, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 056, Loss: 0.4795, Val Acc: 0.6757, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 057, Loss: 0.5150, Val Acc: 0.6216, Test Acc: 0.6216\n",
      "Seed: 42, Epoch: 058, Loss: 0.5592, Val Acc: 0.7117, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 059, Loss: 0.5154, Val Acc: 0.7838, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 060, Loss: 0.4428, Val Acc: 0.8018, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 061, Loss: 0.4281, Val Acc: 0.7838, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 062, Loss: 0.4291, Val Acc: 0.7568, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 063, Loss: 0.4279, Val Acc: 0.7207, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 064, Loss: 0.4392, Val Acc: 0.7477, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 065, Loss: 0.4423, Val Acc: 0.7568, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 066, Loss: 0.4225, Val Acc: 0.7928, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 067, Loss: 0.4191, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 068, Loss: 0.4803, Val Acc: 0.7027, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 069, Loss: 0.4906, Val Acc: 0.7117, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 070, Loss: 0.4523, Val Acc: 0.7387, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 071, Loss: 0.4212, Val Acc: 0.7928, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 072, Loss: 0.3983, Val Acc: 0.8378, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 073, Loss: 0.4023, Val Acc: 0.7838, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 074, Loss: 0.4141, Val Acc: 0.7748, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 075, Loss: 0.4203, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 076, Loss: 0.4177, Val Acc: 0.7928, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 077, Loss: 0.3968, Val Acc: 0.7477, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 078, Loss: 0.4123, Val Acc: 0.7117, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 079, Loss: 0.4530, Val Acc: 0.7838, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 080, Loss: 0.4039, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 081, Loss: 0.4037, Val Acc: 0.7387, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 082, Loss: 0.4516, Val Acc: 0.7117, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 083, Loss: 0.4636, Val Acc: 0.7387, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 084, Loss: 0.4541, Val Acc: 0.7477, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 085, Loss: 0.4391, Val Acc: 0.7928, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 086, Loss: 0.4223, Val Acc: 0.7838, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 087, Loss: 0.4176, Val Acc: 0.7838, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 088, Loss: 0.4142, Val Acc: 0.7838, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 089, Loss: 0.4012, Val Acc: 0.8108, Test Acc: 0.7928\n",
      "Seed: 42, Epoch: 090, Loss: 0.3876, Val Acc: 0.7928, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 091, Loss: 0.3808, Val Acc: 0.7748, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 092, Loss: 0.3820, Val Acc: 0.7748, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 093, Loss: 0.3815, Val Acc: 0.7748, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 094, Loss: 0.3723, Val Acc: 0.7928, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 095, Loss: 0.3668, Val Acc: 0.8018, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 096, Loss: 0.3911, Val Acc: 0.7748, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 097, Loss: 0.4048, Val Acc: 0.8018, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 098, Loss: 0.4045, Val Acc: 0.8018, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 099, Loss: 0.3868, Val Acc: 0.7838, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 100, Loss: 0.3690, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 101, Loss: 0.3606, Val Acc: 0.8198, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 102, Loss: 0.3538, Val Acc: 0.8378, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 103, Loss: 0.3528, Val Acc: 0.8108, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 104, Loss: 0.3519, Val Acc: 0.7928, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 105, Loss: 0.3528, Val Acc: 0.8018, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 106, Loss: 0.3478, Val Acc: 0.8108, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 107, Loss: 0.3441, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 108, Loss: 0.3443, Val Acc: 0.8198, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 109, Loss: 0.3458, Val Acc: 0.7928, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 110, Loss: 0.3661, Val Acc: 0.8198, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 111, Loss: 0.3470, Val Acc: 0.7838, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 112, Loss: 0.3432, Val Acc: 0.7658, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 113, Loss: 0.3519, Val Acc: 0.7928, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 114, Loss: 0.3479, Val Acc: 0.7838, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 115, Loss: 0.3481, Val Acc: 0.8288, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 116, Loss: 0.3612, Val Acc: 0.8108, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 117, Loss: 0.3667, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 118, Loss: 0.3536, Val Acc: 0.7838, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 119, Loss: 0.3441, Val Acc: 0.8018, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 120, Loss: 0.3418, Val Acc: 0.8108, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 121, Loss: 0.3483, Val Acc: 0.7928, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 122, Loss: 0.3437, Val Acc: 0.8198, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 123, Loss: 0.3350, Val Acc: 0.7928, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 124, Loss: 0.3651, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 125, Loss: 0.4088, Val Acc: 0.7207, Test Acc: 0.6577\n",
      "Seed: 42, Epoch: 126, Loss: 0.4297, Val Acc: 0.7477, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 127, Loss: 0.4312, Val Acc: 0.7477, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 128, Loss: 0.4221, Val Acc: 0.7658, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 129, Loss: 0.3893, Val Acc: 0.8378, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 130, Loss: 0.3514, Val Acc: 0.8198, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 131, Loss: 0.3351, Val Acc: 0.8018, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 132, Loss: 0.3307, Val Acc: 0.7838, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 133, Loss: 0.3314, Val Acc: 0.8288, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 134, Loss: 0.3324, Val Acc: 0.8288, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 135, Loss: 0.3418, Val Acc: 0.8378, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 136, Loss: 0.3392, Val Acc: 0.8559, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 137, Loss: 0.3386, Val Acc: 0.8559, Test Acc: 0.6757\n",
      "Seed: 42, Epoch: 138, Loss: 0.3369, Val Acc: 0.8468, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 139, Loss: 0.3391, Val Acc: 0.8288, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 140, Loss: 0.3349, Val Acc: 0.8108, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 141, Loss: 0.3309, Val Acc: 0.8198, Test Acc: 0.7838\n",
      "Seed: 42, Epoch: 142, Loss: 0.3239, Val Acc: 0.8108, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 143, Loss: 0.3210, Val Acc: 0.8198, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 144, Loss: 0.3198, Val Acc: 0.8108, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 145, Loss: 0.3197, Val Acc: 0.8108, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 146, Loss: 0.3237, Val Acc: 0.8378, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 147, Loss: 0.3370, Val Acc: 0.8018, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 148, Loss: 0.3533, Val Acc: 0.7748, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 149, Loss: 0.3642, Val Acc: 0.7297, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 150, Loss: 0.3722, Val Acc: 0.7207, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 151, Loss: 0.3526, Val Acc: 0.7477, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 152, Loss: 0.3354, Val Acc: 0.7928, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 153, Loss: 0.3590, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 154, Loss: 0.3506, Val Acc: 0.7477, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 155, Loss: 0.3254, Val Acc: 0.7658, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 156, Loss: 0.3379, Val Acc: 0.7117, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 157, Loss: 0.3608, Val Acc: 0.7477, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 158, Loss: 0.3683, Val Acc: 0.7658, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 159, Loss: 0.3548, Val Acc: 0.8018, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 160, Loss: 0.3400, Val Acc: 0.8198, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 161, Loss: 0.3395, Val Acc: 0.8198, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 162, Loss: 0.3427, Val Acc: 0.7748, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 163, Loss: 0.3447, Val Acc: 0.7568, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 164, Loss: 0.3390, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 165, Loss: 0.3182, Val Acc: 0.8108, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 166, Loss: 0.3112, Val Acc: 0.8018, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 167, Loss: 0.3269, Val Acc: 0.7928, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 168, Loss: 0.3431, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 169, Loss: 0.3340, Val Acc: 0.8198, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 170, Loss: 0.3145, Val Acc: 0.8108, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 171, Loss: 0.3027, Val Acc: 0.8198, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 172, Loss: 0.2904, Val Acc: 0.7928, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 173, Loss: 0.2901, Val Acc: 0.7748, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 174, Loss: 0.2811, Val Acc: 0.8198, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 175, Loss: 0.2884, Val Acc: 0.8108, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 176, Loss: 0.3251, Val Acc: 0.8108, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 177, Loss: 0.3468, Val Acc: 0.8198, Test Acc: 0.6847\n",
      "Seed: 42, Epoch: 178, Loss: 0.3442, Val Acc: 0.7748, Test Acc: 0.6937\n",
      "Seed: 42, Epoch: 179, Loss: 0.3332, Val Acc: 0.7658, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 180, Loss: 0.3177, Val Acc: 0.8018, Test Acc: 0.7658\n",
      "Seed: 42, Epoch: 181, Loss: 0.2972, Val Acc: 0.7748, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 182, Loss: 0.2955, Val Acc: 0.7568, Test Acc: 0.7117\n",
      "Seed: 42, Epoch: 183, Loss: 0.3050, Val Acc: 0.8018, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 184, Loss: 0.2979, Val Acc: 0.7658, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 185, Loss: 0.2941, Val Acc: 0.7658, Test Acc: 0.7748\n",
      "Seed: 42, Epoch: 186, Loss: 0.2933, Val Acc: 0.7477, Test Acc: 0.7838\n",
      "Seed: 42, Epoch: 187, Loss: 0.2920, Val Acc: 0.7568, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 188, Loss: 0.2920, Val Acc: 0.8018, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 189, Loss: 0.3060, Val Acc: 0.7387, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 190, Loss: 0.3506, Val Acc: 0.7387, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 191, Loss: 0.3877, Val Acc: 0.7658, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 192, Loss: 0.3634, Val Acc: 0.8288, Test Acc: 0.7477\n",
      "Seed: 42, Epoch: 193, Loss: 0.3093, Val Acc: 0.8378, Test Acc: 0.7568\n",
      "Seed: 42, Epoch: 194, Loss: 0.2792, Val Acc: 0.7207, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 195, Loss: 0.3432, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 42, Epoch: 196, Loss: 0.3983, Val Acc: 0.7477, Test Acc: 0.7387\n",
      "Seed: 42, Epoch: 197, Loss: 0.3250, Val Acc: 0.8198, Test Acc: 0.7928\n",
      "Seed: 42, Epoch: 198, Loss: 0.3021, Val Acc: 0.8018, Test Acc: 0.7297\n",
      "Seed: 42, Epoch: 199, Loss: 0.3444, Val Acc: 0.7748, Test Acc: 0.7027\n",
      "Seed: 42, Epoch: 200, Loss: 0.3883, Val Acc: 0.7748, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 001, Loss: 0.6913, Val Acc: 0.5405, Test Acc: 0.6126\n",
      "Seed: 43, Epoch: 002, Loss: 0.6902, Val Acc: 0.5405, Test Acc: 0.6126\n",
      "Seed: 43, Epoch: 003, Loss: 0.6897, Val Acc: 0.5405, Test Acc: 0.6216\n",
      "Seed: 43, Epoch: 004, Loss: 0.6890, Val Acc: 0.5495, Test Acc: 0.6396\n",
      "Seed: 43, Epoch: 005, Loss: 0.6882, Val Acc: 0.6126, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 006, Loss: 0.6871, Val Acc: 0.7117, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 007, Loss: 0.6860, Val Acc: 0.7297, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 008, Loss: 0.6846, Val Acc: 0.7207, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 009, Loss: 0.6831, Val Acc: 0.7117, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 010, Loss: 0.6811, Val Acc: 0.6757, Test Acc: 0.6486\n",
      "Seed: 43, Epoch: 011, Loss: 0.6789, Val Acc: 0.6306, Test Acc: 0.5856\n",
      "Seed: 43, Epoch: 012, Loss: 0.6761, Val Acc: 0.5946, Test Acc: 0.5766\n",
      "Seed: 43, Epoch: 013, Loss: 0.6725, Val Acc: 0.5495, Test Acc: 0.5405\n",
      "Seed: 43, Epoch: 014, Loss: 0.6688, Val Acc: 0.5315, Test Acc: 0.5405\n",
      "Seed: 43, Epoch: 015, Loss: 0.6646, Val Acc: 0.5315, Test Acc: 0.5315\n",
      "Seed: 43, Epoch: 016, Loss: 0.6599, Val Acc: 0.5225, Test Acc: 0.5135\n",
      "Seed: 43, Epoch: 017, Loss: 0.6553, Val Acc: 0.5315, Test Acc: 0.5135\n",
      "Seed: 43, Epoch: 018, Loss: 0.6502, Val Acc: 0.5225, Test Acc: 0.5225\n",
      "Seed: 43, Epoch: 019, Loss: 0.6438, Val Acc: 0.5315, Test Acc: 0.5405\n",
      "Seed: 43, Epoch: 020, Loss: 0.6366, Val Acc: 0.5856, Test Acc: 0.5586\n",
      "Seed: 43, Epoch: 021, Loss: 0.6296, Val Acc: 0.6036, Test Acc: 0.5856\n",
      "Seed: 43, Epoch: 022, Loss: 0.6229, Val Acc: 0.6486, Test Acc: 0.5766\n",
      "Seed: 43, Epoch: 023, Loss: 0.6168, Val Acc: 0.6847, Test Acc: 0.6396\n",
      "Seed: 43, Epoch: 024, Loss: 0.6158, Val Acc: 0.7387, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 025, Loss: 0.6144, Val Acc: 0.7207, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 026, Loss: 0.6114, Val Acc: 0.7207, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 027, Loss: 0.6032, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 028, Loss: 0.5887, Val Acc: 0.6757, Test Acc: 0.6396\n",
      "Seed: 43, Epoch: 029, Loss: 0.5770, Val Acc: 0.6667, Test Acc: 0.6216\n",
      "Seed: 43, Epoch: 030, Loss: 0.5689, Val Acc: 0.6937, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 031, Loss: 0.5628, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 032, Loss: 0.5566, Val Acc: 0.7207, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 033, Loss: 0.5538, Val Acc: 0.7297, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 034, Loss: 0.5481, Val Acc: 0.6937, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 035, Loss: 0.5358, Val Acc: 0.6667, Test Acc: 0.6036\n",
      "Seed: 43, Epoch: 036, Loss: 0.5355, Val Acc: 0.6577, Test Acc: 0.6036\n",
      "Seed: 43, Epoch: 037, Loss: 0.5338, Val Acc: 0.6577, Test Acc: 0.6126\n",
      "Seed: 43, Epoch: 038, Loss: 0.5266, Val Acc: 0.7027, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 039, Loss: 0.5175, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 040, Loss: 0.5129, Val Acc: 0.7027, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 041, Loss: 0.5105, Val Acc: 0.6757, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 042, Loss: 0.5091, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 043, Loss: 0.4967, Val Acc: 0.7297, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 044, Loss: 0.4862, Val Acc: 0.7117, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 045, Loss: 0.4898, Val Acc: 0.7027, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 046, Loss: 0.4881, Val Acc: 0.6937, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 047, Loss: 0.4747, Val Acc: 0.7387, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 048, Loss: 0.4637, Val Acc: 0.6847, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 049, Loss: 0.4783, Val Acc: 0.6667, Test Acc: 0.6126\n",
      "Seed: 43, Epoch: 050, Loss: 0.5070, Val Acc: 0.6847, Test Acc: 0.6486\n",
      "Seed: 43, Epoch: 051, Loss: 0.4917, Val Acc: 0.7387, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 052, Loss: 0.4509, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 053, Loss: 0.4715, Val Acc: 0.7027, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 054, Loss: 0.4795, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 055, Loss: 0.4478, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 056, Loss: 0.4484, Val Acc: 0.7207, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 057, Loss: 0.4457, Val Acc: 0.7387, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 058, Loss: 0.4458, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 059, Loss: 0.4433, Val Acc: 0.7297, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 060, Loss: 0.4370, Val Acc: 0.6937, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 061, Loss: 0.4418, Val Acc: 0.6937, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 062, Loss: 0.4393, Val Acc: 0.7117, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 063, Loss: 0.4329, Val Acc: 0.7207, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 064, Loss: 0.4257, Val Acc: 0.7207, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 065, Loss: 0.4197, Val Acc: 0.7387, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 066, Loss: 0.4152, Val Acc: 0.7477, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 067, Loss: 0.4077, Val Acc: 0.7387, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 068, Loss: 0.4051, Val Acc: 0.7568, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 069, Loss: 0.4003, Val Acc: 0.7477, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 070, Loss: 0.3968, Val Acc: 0.7477, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 071, Loss: 0.3924, Val Acc: 0.7387, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 072, Loss: 0.3886, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 073, Loss: 0.3945, Val Acc: 0.6937, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 074, Loss: 0.4055, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 075, Loss: 0.3857, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 076, Loss: 0.3922, Val Acc: 0.7387, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 077, Loss: 0.4102, Val Acc: 0.7387, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 078, Loss: 0.4004, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 079, Loss: 0.3954, Val Acc: 0.7117, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 080, Loss: 0.3772, Val Acc: 0.6847, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 081, Loss: 0.3938, Val Acc: 0.7117, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 082, Loss: 0.3841, Val Acc: 0.7117, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 083, Loss: 0.3788, Val Acc: 0.7387, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 084, Loss: 0.3888, Val Acc: 0.7297, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 085, Loss: 0.3903, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 086, Loss: 0.3765, Val Acc: 0.6937, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 087, Loss: 0.3749, Val Acc: 0.6486, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 088, Loss: 0.4534, Val Acc: 0.6396, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 089, Loss: 0.4937, Val Acc: 0.6847, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 090, Loss: 0.4176, Val Acc: 0.6847, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 091, Loss: 0.3646, Val Acc: 0.7027, Test Acc: 0.6577\n",
      "Seed: 43, Epoch: 092, Loss: 0.4067, Val Acc: 0.6667, Test Acc: 0.6036\n",
      "Seed: 43, Epoch: 093, Loss: 0.4401, Val Acc: 0.6937, Test Acc: 0.6306\n",
      "Seed: 43, Epoch: 094, Loss: 0.4351, Val Acc: 0.7207, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 095, Loss: 0.4085, Val Acc: 0.7207, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 096, Loss: 0.3783, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 097, Loss: 0.3653, Val Acc: 0.7117, Test Acc: 0.6577\n",
      "Seed: 43, Epoch: 098, Loss: 0.3657, Val Acc: 0.6847, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 099, Loss: 0.3674, Val Acc: 0.6667, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 100, Loss: 0.3623, Val Acc: 0.6937, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 101, Loss: 0.3537, Val Acc: 0.6577, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 102, Loss: 0.3561, Val Acc: 0.6667, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 103, Loss: 0.3623, Val Acc: 0.6937, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 104, Loss: 0.3650, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 105, Loss: 0.3568, Val Acc: 0.6847, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 106, Loss: 0.3510, Val Acc: 0.6757, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 107, Loss: 0.3417, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 108, Loss: 0.3414, Val Acc: 0.6847, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 109, Loss: 0.3614, Val Acc: 0.6577, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 110, Loss: 0.3689, Val Acc: 0.7117, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 111, Loss: 0.3525, Val Acc: 0.7117, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 112, Loss: 0.3292, Val Acc: 0.7117, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 113, Loss: 0.3503, Val Acc: 0.6847, Test Acc: 0.6486\n",
      "Seed: 43, Epoch: 114, Loss: 0.4034, Val Acc: 0.6847, Test Acc: 0.6036\n",
      "Seed: 43, Epoch: 115, Loss: 0.4340, Val Acc: 0.6937, Test Acc: 0.6126\n",
      "Seed: 43, Epoch: 116, Loss: 0.4382, Val Acc: 0.6847, Test Acc: 0.6126\n",
      "Seed: 43, Epoch: 117, Loss: 0.4243, Val Acc: 0.7117, Test Acc: 0.6486\n",
      "Seed: 43, Epoch: 118, Loss: 0.3894, Val Acc: 0.7477, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 119, Loss: 0.3551, Val Acc: 0.7207, Test Acc: 0.6486\n",
      "Seed: 43, Epoch: 120, Loss: 0.3444, Val Acc: 0.6937, Test Acc: 0.6577\n",
      "Seed: 43, Epoch: 121, Loss: 0.3426, Val Acc: 0.7387, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 122, Loss: 0.3396, Val Acc: 0.7297, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 123, Loss: 0.3348, Val Acc: 0.7297, Test Acc: 0.6577\n",
      "Seed: 43, Epoch: 124, Loss: 0.3303, Val Acc: 0.7117, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 125, Loss: 0.3279, Val Acc: 0.7207, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 126, Loss: 0.3264, Val Acc: 0.7207, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 127, Loss: 0.3235, Val Acc: 0.7117, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 128, Loss: 0.3219, Val Acc: 0.7117, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 129, Loss: 0.3228, Val Acc: 0.7207, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 130, Loss: 0.3279, Val Acc: 0.6847, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 131, Loss: 0.3316, Val Acc: 0.6847, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 132, Loss: 0.3289, Val Acc: 0.6847, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 133, Loss: 0.3282, Val Acc: 0.7027, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 134, Loss: 0.3323, Val Acc: 0.7297, Test Acc: 0.6577\n",
      "Seed: 43, Epoch: 135, Loss: 0.3224, Val Acc: 0.7387, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 136, Loss: 0.3213, Val Acc: 0.7297, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 137, Loss: 0.3221, Val Acc: 0.7387, Test Acc: 0.6577\n",
      "Seed: 43, Epoch: 138, Loss: 0.3166, Val Acc: 0.7658, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 139, Loss: 0.3126, Val Acc: 0.7658, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 140, Loss: 0.3151, Val Acc: 0.7477, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 141, Loss: 0.3166, Val Acc: 0.7297, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 142, Loss: 0.3256, Val Acc: 0.7207, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 143, Loss: 0.3325, Val Acc: 0.7297, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 144, Loss: 0.3360, Val Acc: 0.7387, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 145, Loss: 0.3253, Val Acc: 0.7477, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 146, Loss: 0.3183, Val Acc: 0.7568, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 147, Loss: 0.3106, Val Acc: 0.7387, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 148, Loss: 0.3017, Val Acc: 0.7477, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 149, Loss: 0.3001, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 150, Loss: 0.3181, Val Acc: 0.7027, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 151, Loss: 0.3154, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 152, Loss: 0.3003, Val Acc: 0.6847, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 153, Loss: 0.2934, Val Acc: 0.6757, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 154, Loss: 0.2898, Val Acc: 0.6757, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 155, Loss: 0.2891, Val Acc: 0.6757, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 156, Loss: 0.2889, Val Acc: 0.6577, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 157, Loss: 0.2897, Val Acc: 0.6757, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 158, Loss: 0.2975, Val Acc: 0.6847, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 159, Loss: 0.3132, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 160, Loss: 0.3313, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 161, Loss: 0.3340, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 162, Loss: 0.3309, Val Acc: 0.6847, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 163, Loss: 0.3261, Val Acc: 0.7117, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 164, Loss: 0.3086, Val Acc: 0.6847, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 165, Loss: 0.3039, Val Acc: 0.6847, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 166, Loss: 0.2932, Val Acc: 0.7027, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 167, Loss: 0.2874, Val Acc: 0.7117, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 168, Loss: 0.2847, Val Acc: 0.7207, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 169, Loss: 0.2810, Val Acc: 0.7117, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 170, Loss: 0.2780, Val Acc: 0.7117, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 171, Loss: 0.2767, Val Acc: 0.7297, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 172, Loss: 0.2795, Val Acc: 0.7477, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 173, Loss: 0.2780, Val Acc: 0.7207, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 174, Loss: 0.2730, Val Acc: 0.6937, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 175, Loss: 0.2816, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 176, Loss: 0.3116, Val Acc: 0.7027, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 177, Loss: 0.3052, Val Acc: 0.7207, Test Acc: 0.6847\n",
      "Seed: 43, Epoch: 178, Loss: 0.2992, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 179, Loss: 0.3280, Val Acc: 0.6847, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 180, Loss: 0.3668, Val Acc: 0.6847, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 181, Loss: 0.3516, Val Acc: 0.7027, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 182, Loss: 0.3201, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 183, Loss: 0.3280, Val Acc: 0.6937, Test Acc: 0.6577\n",
      "Seed: 43, Epoch: 184, Loss: 0.3593, Val Acc: 0.7027, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 185, Loss: 0.3837, Val Acc: 0.6847, Test Acc: 0.6757\n",
      "Seed: 43, Epoch: 186, Loss: 0.3797, Val Acc: 0.7027, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 187, Loss: 0.3550, Val Acc: 0.7207, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 188, Loss: 0.3149, Val Acc: 0.7207, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 189, Loss: 0.3003, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 43, Epoch: 190, Loss: 0.3215, Val Acc: 0.6667, Test Acc: 0.7387\n",
      "Seed: 43, Epoch: 191, Loss: 0.3357, Val Acc: 0.6667, Test Acc: 0.7117\n",
      "Seed: 43, Epoch: 192, Loss: 0.3292, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 193, Loss: 0.3017, Val Acc: 0.7207, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 194, Loss: 0.2810, Val Acc: 0.7387, Test Acc: 0.7207\n",
      "Seed: 43, Epoch: 195, Loss: 0.2795, Val Acc: 0.7117, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 196, Loss: 0.2912, Val Acc: 0.7477, Test Acc: 0.6937\n",
      "Seed: 43, Epoch: 197, Loss: 0.2889, Val Acc: 0.7387, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 198, Loss: 0.2800, Val Acc: 0.7297, Test Acc: 0.7027\n",
      "Seed: 43, Epoch: 199, Loss: 0.2740, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 43, Epoch: 200, Loss: 0.2678, Val Acc: 0.6306, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 001, Loss: 0.6945, Val Acc: 0.5045, Test Acc: 0.4234\n",
      "Seed: 44, Epoch: 002, Loss: 0.6937, Val Acc: 0.5045, Test Acc: 0.4234\n",
      "Seed: 44, Epoch: 003, Loss: 0.6938, Val Acc: 0.5045, Test Acc: 0.4234\n",
      "Seed: 44, Epoch: 004, Loss: 0.6936, Val Acc: 0.5045, Test Acc: 0.4234\n",
      "Seed: 44, Epoch: 005, Loss: 0.6929, Val Acc: 0.5045, Test Acc: 0.4685\n",
      "Seed: 44, Epoch: 006, Loss: 0.6922, Val Acc: 0.6577, Test Acc: 0.6126\n",
      "Seed: 44, Epoch: 007, Loss: 0.6915, Val Acc: 0.7207, Test Acc: 0.7838\n",
      "Seed: 44, Epoch: 008, Loss: 0.6906, Val Acc: 0.6306, Test Acc: 0.6757\n",
      "Seed: 44, Epoch: 009, Loss: 0.6896, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 010, Loss: 0.6887, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 011, Loss: 0.6881, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 012, Loss: 0.6879, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 013, Loss: 0.6873, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 014, Loss: 0.6865, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 015, Loss: 0.6857, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 016, Loss: 0.6844, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 017, Loss: 0.6830, Val Acc: 0.4955, Test Acc: 0.5766\n",
      "Seed: 44, Epoch: 018, Loss: 0.6813, Val Acc: 0.5676, Test Acc: 0.6486\n",
      "Seed: 44, Epoch: 019, Loss: 0.6795, Val Acc: 0.6486, Test Acc: 0.7027\n",
      "Seed: 44, Epoch: 020, Loss: 0.6774, Val Acc: 0.6847, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 021, Loss: 0.6748, Val Acc: 0.7207, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 022, Loss: 0.6714, Val Acc: 0.7027, Test Acc: 0.7117\n",
      "Seed: 44, Epoch: 023, Loss: 0.6673, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 024, Loss: 0.6635, Val Acc: 0.7297, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 025, Loss: 0.6584, Val Acc: 0.7477, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 026, Loss: 0.6538, Val Acc: 0.7207, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 027, Loss: 0.6482, Val Acc: 0.7207, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 028, Loss: 0.6420, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 029, Loss: 0.6358, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 030, Loss: 0.6293, Val Acc: 0.7387, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 031, Loss: 0.6229, Val Acc: 0.7297, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 032, Loss: 0.6142, Val Acc: 0.6757, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 033, Loss: 0.6059, Val Acc: 0.6757, Test Acc: 0.7027\n",
      "Seed: 44, Epoch: 034, Loss: 0.5981, Val Acc: 0.7207, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 035, Loss: 0.5875, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 036, Loss: 0.5839, Val Acc: 0.6847, Test Acc: 0.7027\n",
      "Seed: 44, Epoch: 037, Loss: 0.5884, Val Acc: 0.7027, Test Acc: 0.7117\n",
      "Seed: 44, Epoch: 038, Loss: 0.5671, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 039, Loss: 0.5650, Val Acc: 0.6847, Test Acc: 0.6847\n",
      "Seed: 44, Epoch: 040, Loss: 0.5696, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 041, Loss: 0.5553, Val Acc: 0.7207, Test Acc: 0.7117\n",
      "Seed: 44, Epoch: 042, Loss: 0.5433, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 043, Loss: 0.5378, Val Acc: 0.6937, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 044, Loss: 0.5310, Val Acc: 0.7027, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 045, Loss: 0.5256, Val Acc: 0.6847, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 046, Loss: 0.5205, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 047, Loss: 0.5165, Val Acc: 0.7207, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 048, Loss: 0.5132, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 049, Loss: 0.5205, Val Acc: 0.7117, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 050, Loss: 0.5223, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 051, Loss: 0.5022, Val Acc: 0.7027, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 052, Loss: 0.4900, Val Acc: 0.6216, Test Acc: 0.6847\n",
      "Seed: 44, Epoch: 053, Loss: 0.5282, Val Acc: 0.5676, Test Acc: 0.6306\n",
      "Seed: 44, Epoch: 054, Loss: 0.5856, Val Acc: 0.6216, Test Acc: 0.6847\n",
      "Seed: 44, Epoch: 055, Loss: 0.5387, Val Acc: 0.6757, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 056, Loss: 0.4833, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 057, Loss: 0.4761, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 058, Loss: 0.4755, Val Acc: 0.6757, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 059, Loss: 0.4739, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 060, Loss: 0.4683, Val Acc: 0.6937, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 061, Loss: 0.4660, Val Acc: 0.6486, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 062, Loss: 0.4740, Val Acc: 0.6577, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 063, Loss: 0.4670, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 064, Loss: 0.4517, Val Acc: 0.7207, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 065, Loss: 0.4636, Val Acc: 0.6847, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 066, Loss: 0.4907, Val Acc: 0.7027, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 067, Loss: 0.4945, Val Acc: 0.7207, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 068, Loss: 0.4663, Val Acc: 0.6937, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 069, Loss: 0.4389, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 070, Loss: 0.4397, Val Acc: 0.6757, Test Acc: 0.7027\n",
      "Seed: 44, Epoch: 071, Loss: 0.4523, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 072, Loss: 0.4399, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 073, Loss: 0.4330, Val Acc: 0.7027, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 074, Loss: 0.4646, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 075, Loss: 0.4910, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 076, Loss: 0.4842, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 077, Loss: 0.4589, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 078, Loss: 0.4237, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 079, Loss: 0.4098, Val Acc: 0.6396, Test Acc: 0.7117\n",
      "Seed: 44, Epoch: 080, Loss: 0.4368, Val Acc: 0.6126, Test Acc: 0.6847\n",
      "Seed: 44, Epoch: 081, Loss: 0.4555, Val Acc: 0.6306, Test Acc: 0.6757\n",
      "Seed: 44, Epoch: 082, Loss: 0.4273, Val Acc: 0.7027, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 083, Loss: 0.4002, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 084, Loss: 0.3920, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 085, Loss: 0.3863, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 086, Loss: 0.3830, Val Acc: 0.6937, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 087, Loss: 0.3820, Val Acc: 0.6847, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 088, Loss: 0.3846, Val Acc: 0.6757, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 089, Loss: 0.3849, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 090, Loss: 0.3874, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 091, Loss: 0.3825, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 092, Loss: 0.3850, Val Acc: 0.6757, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 093, Loss: 0.3927, Val Acc: 0.6667, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 094, Loss: 0.3856, Val Acc: 0.6847, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 095, Loss: 0.3876, Val Acc: 0.6757, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 096, Loss: 0.3840, Val Acc: 0.6757, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 097, Loss: 0.3792, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 098, Loss: 0.3809, Val Acc: 0.7297, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 099, Loss: 0.4045, Val Acc: 0.7387, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 100, Loss: 0.4260, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 101, Loss: 0.4190, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 102, Loss: 0.4019, Val Acc: 0.6847, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 103, Loss: 0.3823, Val Acc: 0.6757, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 104, Loss: 0.3660, Val Acc: 0.6847, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 105, Loss: 0.3592, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 106, Loss: 0.3546, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 107, Loss: 0.3510, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 108, Loss: 0.3522, Val Acc: 0.6937, Test Acc: 0.7117\n",
      "Seed: 44, Epoch: 109, Loss: 0.3617, Val Acc: 0.7027, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 110, Loss: 0.3394, Val Acc: 0.7297, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 111, Loss: 0.3586, Val Acc: 0.7207, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 112, Loss: 0.3708, Val Acc: 0.7297, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 113, Loss: 0.3438, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 114, Loss: 0.3413, Val Acc: 0.6757, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 115, Loss: 0.4042, Val Acc: 0.6577, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 116, Loss: 0.3968, Val Acc: 0.6667, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 117, Loss: 0.3397, Val Acc: 0.7027, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 118, Loss: 0.3451, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 119, Loss: 0.3773, Val Acc: 0.6847, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 120, Loss: 0.4057, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 121, Loss: 0.3950, Val Acc: 0.7297, Test Acc: 0.7838\n",
      "Seed: 44, Epoch: 122, Loss: 0.3545, Val Acc: 0.7027, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 123, Loss: 0.3351, Val Acc: 0.6396, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 124, Loss: 0.3442, Val Acc: 0.6486, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 125, Loss: 0.3403, Val Acc: 0.6577, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 126, Loss: 0.3296, Val Acc: 0.6667, Test Acc: 0.7928\n",
      "Seed: 44, Epoch: 127, Loss: 0.3227, Val Acc: 0.7117, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 128, Loss: 0.3187, Val Acc: 0.7207, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 129, Loss: 0.3223, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 130, Loss: 0.3227, Val Acc: 0.7117, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 131, Loss: 0.3213, Val Acc: 0.6937, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 132, Loss: 0.3157, Val Acc: 0.6757, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 133, Loss: 0.3244, Val Acc: 0.7207, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 134, Loss: 0.3338, Val Acc: 0.7297, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 135, Loss: 0.3367, Val Acc: 0.7297, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 136, Loss: 0.3505, Val Acc: 0.7297, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 137, Loss: 0.3453, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 138, Loss: 0.3186, Val Acc: 0.7297, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 139, Loss: 0.3024, Val Acc: 0.6757, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 140, Loss: 0.2989, Val Acc: 0.6757, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 141, Loss: 0.3027, Val Acc: 0.6937, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 142, Loss: 0.2968, Val Acc: 0.6937, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 143, Loss: 0.3086, Val Acc: 0.7027, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 144, Loss: 0.3261, Val Acc: 0.7117, Test Acc: 0.7297\n",
      "Seed: 44, Epoch: 145, Loss: 0.3477, Val Acc: 0.7117, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 146, Loss: 0.3686, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 147, Loss: 0.3661, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 148, Loss: 0.3286, Val Acc: 0.7117, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 149, Loss: 0.3073, Val Acc: 0.6847, Test Acc: 0.7387\n",
      "Seed: 44, Epoch: 150, Loss: 0.3127, Val Acc: 0.6757, Test Acc: 0.6847\n",
      "Seed: 44, Epoch: 151, Loss: 0.3461, Val Acc: 0.6757, Test Acc: 0.6937\n",
      "Seed: 44, Epoch: 152, Loss: 0.3291, Val Acc: 0.6937, Test Acc: 0.7207\n",
      "Seed: 44, Epoch: 153, Loss: 0.2911, Val Acc: 0.6937, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 154, Loss: 0.3066, Val Acc: 0.6937, Test Acc: 0.7838\n",
      "Seed: 44, Epoch: 155, Loss: 0.3685, Val Acc: 0.7207, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 156, Loss: 0.3775, Val Acc: 0.7117, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 157, Loss: 0.3859, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 158, Loss: 0.3575, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 159, Loss: 0.3179, Val Acc: 0.7027, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 160, Loss: 0.2959, Val Acc: 0.6847, Test Acc: 0.6667\n",
      "Seed: 44, Epoch: 161, Loss: 0.2986, Val Acc: 0.6486, Test Acc: 0.6757\n",
      "Seed: 44, Epoch: 162, Loss: 0.3256, Val Acc: 0.6667, Test Acc: 0.7027\n",
      "Seed: 44, Epoch: 163, Loss: 0.3079, Val Acc: 0.6667, Test Acc: 0.7027\n",
      "Seed: 44, Epoch: 164, Loss: 0.2867, Val Acc: 0.6847, Test Acc: 0.7928\n",
      "Seed: 44, Epoch: 165, Loss: 0.2801, Val Acc: 0.6847, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 166, Loss: 0.2927, Val Acc: 0.6937, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 167, Loss: 0.3018, Val Acc: 0.6937, Test Acc: 0.7568\n",
      "Seed: 44, Epoch: 168, Loss: 0.3001, Val Acc: 0.7117, Test Acc: 0.7748\n",
      "Seed: 44, Epoch: 169, Loss: 0.2939, Val Acc: 0.7027, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 170, Loss: 0.2816, Val Acc: 0.6577, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 171, Loss: 0.2739, Val Acc: 0.6577, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 172, Loss: 0.2764, Val Acc: 0.6847, Test Acc: 0.7477\n",
      "Seed: 44, Epoch: 173, Loss: 0.2701, Val Acc: 0.7027, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 174, Loss: 0.2610, Val Acc: 0.7117, Test Acc: 0.7658\n",
      "Seed: 44, Epoch: 175, Loss: 0.2714, Val Acc: 0.7207, Test Acc: 0.7387\n",
      "Early stopping at epoch 175 for seed 44\n",
      "Average Time: 229.18 seconds\n",
      "Var Time: 147.92 seconds\n",
      "Average Memory: 5478.00 MB\n",
      "Average Best Val Acc: 0.7898\n",
      "Std Best Test Acc: 0.0212\n",
      "Average Test Acc: 0.7177\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "max_nodes = 500\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"DD\",\n",
    "    transform=T.Compose([T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_hosc(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc, o = dense_hoscpool(x, adj, s, mu=0.1, alpha=0.5, new_ortho=False, mask=mask)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc_aux, o_aux = dense_hoscpool(x, adj, s, mu=0.3, alpha=0.5, new_ortho=False)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_hosc().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=512, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "    model = Net_hosc().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB-BINARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 0.6961, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 002, Loss: 0.6954, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 003, Loss: 0.6949, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 004, Loss: 0.6943, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 005, Loss: 0.6937, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 006, Loss: 0.6930, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 007, Loss: 0.6921, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 008, Loss: 0.6909, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 009, Loss: 0.6895, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 010, Loss: 0.6874, Val Acc: 0.5200, Test Acc: 0.5267\n",
      "Seed: 42, Epoch: 011, Loss: 0.6845, Val Acc: 0.5267, Test Acc: 0.5533\n",
      "Seed: 42, Epoch: 012, Loss: 0.6815, Val Acc: 0.5267, Test Acc: 0.5667\n",
      "Seed: 42, Epoch: 013, Loss: 0.6778, Val Acc: 0.5333, Test Acc: 0.6333\n",
      "Seed: 42, Epoch: 014, Loss: 0.6730, Val Acc: 0.5933, Test Acc: 0.6867\n",
      "Seed: 42, Epoch: 015, Loss: 0.6671, Val Acc: 0.7067, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 016, Loss: 0.6602, Val Acc: 0.7400, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 017, Loss: 0.6518, Val Acc: 0.7467, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 018, Loss: 0.6431, Val Acc: 0.7733, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 019, Loss: 0.6314, Val Acc: 0.7733, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 020, Loss: 0.6204, Val Acc: 0.7733, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 021, Loss: 0.6068, Val Acc: 0.7733, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 022, Loss: 0.5897, Val Acc: 0.7600, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 023, Loss: 0.5744, Val Acc: 0.7600, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 024, Loss: 0.5592, Val Acc: 0.7667, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 025, Loss: 0.5422, Val Acc: 0.7733, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 026, Loss: 0.5279, Val Acc: 0.7800, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 027, Loss: 0.5125, Val Acc: 0.7733, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 028, Loss: 0.5027, Val Acc: 0.7800, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 029, Loss: 0.4988, Val Acc: 0.7800, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 030, Loss: 0.4850, Val Acc: 0.7800, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 031, Loss: 0.4805, Val Acc: 0.7933, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 032, Loss: 0.4749, Val Acc: 0.7867, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 033, Loss: 0.4735, Val Acc: 0.7867, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 034, Loss: 0.4680, Val Acc: 0.8000, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 035, Loss: 0.4645, Val Acc: 0.8067, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 036, Loss: 0.4661, Val Acc: 0.7733, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 037, Loss: 0.4570, Val Acc: 0.7867, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 038, Loss: 0.4542, Val Acc: 0.7800, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 039, Loss: 0.4480, Val Acc: 0.7867, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 040, Loss: 0.4508, Val Acc: 0.7667, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 041, Loss: 0.4482, Val Acc: 0.7867, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 042, Loss: 0.4375, Val Acc: 0.8133, Test Acc: 0.8267\n",
      "Seed: 42, Epoch: 043, Loss: 0.4373, Val Acc: 0.8000, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 044, Loss: 0.4281, Val Acc: 0.7933, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 045, Loss: 0.4269, Val Acc: 0.7867, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 046, Loss: 0.4187, Val Acc: 0.7800, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 047, Loss: 0.4178, Val Acc: 0.7933, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 048, Loss: 0.4158, Val Acc: 0.7867, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 049, Loss: 0.4059, Val Acc: 0.7800, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 050, Loss: 0.4063, Val Acc: 0.7667, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 051, Loss: 0.4020, Val Acc: 0.7667, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 052, Loss: 0.4003, Val Acc: 0.7667, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 053, Loss: 0.3966, Val Acc: 0.7800, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 054, Loss: 0.3909, Val Acc: 0.7733, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 055, Loss: 0.3857, Val Acc: 0.7467, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 056, Loss: 0.3818, Val Acc: 0.7267, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 057, Loss: 0.3844, Val Acc: 0.7533, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 058, Loss: 0.3786, Val Acc: 0.7467, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 059, Loss: 0.3744, Val Acc: 0.7667, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 060, Loss: 0.3714, Val Acc: 0.8200, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 061, Loss: 0.3660, Val Acc: 0.8067, Test Acc: 0.8133\n",
      "Seed: 42, Epoch: 062, Loss: 0.3622, Val Acc: 0.8000, Test Acc: 0.8000\n",
      "Seed: 42, Epoch: 063, Loss: 0.3630, Val Acc: 0.8267, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 064, Loss: 0.3601, Val Acc: 0.7800, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 065, Loss: 0.3510, Val Acc: 0.7600, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 066, Loss: 0.3583, Val Acc: 0.7667, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 067, Loss: 0.3566, Val Acc: 0.7600, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 068, Loss: 0.3491, Val Acc: 0.7800, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 069, Loss: 0.3490, Val Acc: 0.7800, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 070, Loss: 0.3465, Val Acc: 0.7600, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 071, Loss: 0.3404, Val Acc: 0.6933, Test Acc: 0.6933\n",
      "Seed: 42, Epoch: 072, Loss: 0.3399, Val Acc: 0.7333, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 073, Loss: 0.3360, Val Acc: 0.7600, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 074, Loss: 0.3281, Val Acc: 0.7800, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 075, Loss: 0.3219, Val Acc: 0.7733, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 076, Loss: 0.3208, Val Acc: 0.7800, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 077, Loss: 0.3233, Val Acc: 0.7533, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 078, Loss: 0.3294, Val Acc: 0.7733, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 079, Loss: 0.3285, Val Acc: 0.7533, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 080, Loss: 0.3233, Val Acc: 0.7400, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 081, Loss: 0.3252, Val Acc: 0.7600, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 082, Loss: 0.3272, Val Acc: 0.7733, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 083, Loss: 0.3253, Val Acc: 0.7667, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 084, Loss: 0.3194, Val Acc: 0.7667, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 085, Loss: 0.3155, Val Acc: 0.7600, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 086, Loss: 0.3235, Val Acc: 0.7667, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 087, Loss: 0.3103, Val Acc: 0.8067, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 088, Loss: 0.3069, Val Acc: 0.7733, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 089, Loss: 0.3029, Val Acc: 0.7667, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 090, Loss: 0.3078, Val Acc: 0.7667, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 091, Loss: 0.2956, Val Acc: 0.7667, Test Acc: 0.7067\n",
      "Seed: 42, Epoch: 092, Loss: 0.2946, Val Acc: 0.7800, Test Acc: 0.7133\n",
      "Seed: 42, Epoch: 093, Loss: 0.2991, Val Acc: 0.7467, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 094, Loss: 0.3026, Val Acc: 0.7867, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 095, Loss: 0.3035, Val Acc: 0.7733, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 096, Loss: 0.2920, Val Acc: 0.7533, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 097, Loss: 0.2904, Val Acc: 0.7667, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 098, Loss: 0.2912, Val Acc: 0.7733, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 099, Loss: 0.2923, Val Acc: 0.7733, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 100, Loss: 0.2974, Val Acc: 0.7600, Test Acc: 0.6933\n",
      "Seed: 42, Epoch: 101, Loss: 0.2890, Val Acc: 0.7667, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 102, Loss: 0.2890, Val Acc: 0.7800, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 103, Loss: 0.2983, Val Acc: 0.7467, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 104, Loss: 0.2941, Val Acc: 0.7667, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 105, Loss: 0.2913, Val Acc: 0.7467, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 106, Loss: 0.2921, Val Acc: 0.7533, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 107, Loss: 0.3005, Val Acc: 0.7533, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 108, Loss: 0.2995, Val Acc: 0.7400, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 109, Loss: 0.3153, Val Acc: 0.7467, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 110, Loss: 0.3194, Val Acc: 0.7400, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 111, Loss: 0.3163, Val Acc: 0.7800, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 112, Loss: 0.3041, Val Acc: 0.7867, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 113, Loss: 0.3144, Val Acc: 0.7667, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 114, Loss: 0.3134, Val Acc: 0.7200, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 115, Loss: 0.3077, Val Acc: 0.7533, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 116, Loss: 0.3060, Val Acc: 0.7600, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 117, Loss: 0.3077, Val Acc: 0.7733, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 118, Loss: 0.3056, Val Acc: 0.7667, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 119, Loss: 0.2958, Val Acc: 0.7267, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 120, Loss: 0.2992, Val Acc: 0.7533, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 121, Loss: 0.2988, Val Acc: 0.7533, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 122, Loss: 0.2957, Val Acc: 0.7600, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 123, Loss: 0.2786, Val Acc: 0.7800, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 124, Loss: 0.3003, Val Acc: 0.7800, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 125, Loss: 0.2960, Val Acc: 0.7800, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 126, Loss: 0.2849, Val Acc: 0.7533, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 127, Loss: 0.2791, Val Acc: 0.7733, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 128, Loss: 0.2903, Val Acc: 0.7933, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 129, Loss: 0.2782, Val Acc: 0.7733, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 130, Loss: 0.2921, Val Acc: 0.7267, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 131, Loss: 0.2699, Val Acc: 0.7400, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 132, Loss: 0.2775, Val Acc: 0.7333, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 133, Loss: 0.2827, Val Acc: 0.7400, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 134, Loss: 0.2740, Val Acc: 0.7333, Test Acc: 0.7067\n",
      "Seed: 42, Epoch: 135, Loss: 0.2742, Val Acc: 0.7467, Test Acc: 0.6933\n",
      "Seed: 42, Epoch: 136, Loss: 0.2708, Val Acc: 0.7667, Test Acc: 0.6800\n",
      "Seed: 42, Epoch: 137, Loss: 0.2749, Val Acc: 0.7400, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 138, Loss: 0.2642, Val Acc: 0.7467, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 139, Loss: 0.2639, Val Acc: 0.7467, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 140, Loss: 0.2703, Val Acc: 0.7200, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 141, Loss: 0.2758, Val Acc: 0.7200, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 142, Loss: 0.2749, Val Acc: 0.7333, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 143, Loss: 0.2711, Val Acc: 0.7267, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 144, Loss: 0.2789, Val Acc: 0.7333, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 145, Loss: 0.2761, Val Acc: 0.7267, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 146, Loss: 0.2770, Val Acc: 0.7200, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 147, Loss: 0.2672, Val Acc: 0.7267, Test Acc: 0.8067\n",
      "Seed: 42, Epoch: 148, Loss: 0.2696, Val Acc: 0.7667, Test Acc: 0.7400\n",
      "Seed: 42, Epoch: 149, Loss: 0.2659, Val Acc: 0.7667, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 150, Loss: 0.2723, Val Acc: 0.7600, Test Acc: 0.7133\n",
      "Seed: 42, Epoch: 151, Loss: 0.2781, Val Acc: 0.7400, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 152, Loss: 0.2777, Val Acc: 0.7267, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 153, Loss: 0.2624, Val Acc: 0.7400, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 154, Loss: 0.2634, Val Acc: 0.7400, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 155, Loss: 0.2598, Val Acc: 0.7400, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 156, Loss: 0.2574, Val Acc: 0.7400, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 157, Loss: 0.2536, Val Acc: 0.7400, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 158, Loss: 0.2512, Val Acc: 0.7800, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 159, Loss: 0.2540, Val Acc: 0.7667, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 160, Loss: 0.2625, Val Acc: 0.7600, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 161, Loss: 0.2562, Val Acc: 0.7667, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 162, Loss: 0.2491, Val Acc: 0.7800, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 163, Loss: 0.2611, Val Acc: 0.7533, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 164, Loss: 0.2478, Val Acc: 0.7600, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 165, Loss: 0.2599, Val Acc: 0.7467, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 166, Loss: 0.2491, Val Acc: 0.7667, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 167, Loss: 0.2555, Val Acc: 0.7733, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 168, Loss: 0.2644, Val Acc: 0.7400, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 169, Loss: 0.2498, Val Acc: 0.7333, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 170, Loss: 0.2524, Val Acc: 0.7400, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 171, Loss: 0.2535, Val Acc: 0.7467, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 172, Loss: 0.2518, Val Acc: 0.7533, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 173, Loss: 0.2544, Val Acc: 0.7600, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 174, Loss: 0.2466, Val Acc: 0.7467, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 175, Loss: 0.2443, Val Acc: 0.7667, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 176, Loss: 0.2494, Val Acc: 0.7933, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 177, Loss: 0.2470, Val Acc: 0.8000, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 178, Loss: 0.2491, Val Acc: 0.7733, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 179, Loss: 0.2498, Val Acc: 0.7733, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 180, Loss: 0.2607, Val Acc: 0.7533, Test Acc: 0.7933\n",
      "Seed: 42, Epoch: 181, Loss: 0.2548, Val Acc: 0.7533, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 182, Loss: 0.2600, Val Acc: 0.7333, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 183, Loss: 0.2564, Val Acc: 0.7533, Test Acc: 0.7067\n",
      "Seed: 42, Epoch: 184, Loss: 0.2560, Val Acc: 0.7267, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 185, Loss: 0.2614, Val Acc: 0.7467, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 186, Loss: 0.2613, Val Acc: 0.7400, Test Acc: 0.6933\n",
      "Seed: 42, Epoch: 187, Loss: 0.2667, Val Acc: 0.7400, Test Acc: 0.6667\n",
      "Seed: 42, Epoch: 188, Loss: 0.2589, Val Acc: 0.7200, Test Acc: 0.6933\n",
      "Seed: 42, Epoch: 189, Loss: 0.2524, Val Acc: 0.6933, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 190, Loss: 0.2399, Val Acc: 0.7333, Test Acc: 0.7067\n",
      "Seed: 42, Epoch: 191, Loss: 0.2493, Val Acc: 0.7267, Test Acc: 0.7133\n",
      "Seed: 42, Epoch: 192, Loss: 0.2504, Val Acc: 0.7733, Test Acc: 0.6733\n",
      "Seed: 42, Epoch: 193, Loss: 0.2575, Val Acc: 0.7200, Test Acc: 0.6733\n",
      "Seed: 42, Epoch: 194, Loss: 0.2485, Val Acc: 0.7067, Test Acc: 0.6933\n",
      "Seed: 42, Epoch: 195, Loss: 0.2577, Val Acc: 0.7467, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 196, Loss: 0.2501, Val Acc: 0.7533, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 197, Loss: 0.2476, Val Acc: 0.7467, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 198, Loss: 0.2651, Val Acc: 0.7400, Test Acc: 0.7333\n",
      "Seed: 42, Epoch: 199, Loss: 0.2450, Val Acc: 0.7600, Test Acc: 0.7267\n",
      "Seed: 42, Epoch: 200, Loss: 0.2552, Val Acc: 0.7667, Test Acc: 0.7000\n",
      "Seed: 43, Epoch: 001, Loss: 0.6986, Val Acc: 0.5867, Test Acc: 0.5400\n",
      "Seed: 43, Epoch: 002, Loss: 0.6972, Val Acc: 0.5867, Test Acc: 0.5400\n",
      "Seed: 43, Epoch: 003, Loss: 0.6958, Val Acc: 0.5867, Test Acc: 0.5400\n",
      "Seed: 43, Epoch: 004, Loss: 0.6945, Val Acc: 0.5867, Test Acc: 0.5400\n",
      "Seed: 43, Epoch: 005, Loss: 0.6932, Val Acc: 0.5867, Test Acc: 0.5400\n",
      "Seed: 43, Epoch: 006, Loss: 0.6917, Val Acc: 0.5867, Test Acc: 0.5400\n",
      "Seed: 43, Epoch: 007, Loss: 0.6900, Val Acc: 0.6067, Test Acc: 0.5600\n",
      "Seed: 43, Epoch: 008, Loss: 0.6882, Val Acc: 0.6533, Test Acc: 0.6067\n",
      "Seed: 43, Epoch: 009, Loss: 0.6858, Val Acc: 0.6867, Test Acc: 0.6933\n",
      "Seed: 43, Epoch: 010, Loss: 0.6830, Val Acc: 0.6733, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 011, Loss: 0.6798, Val Acc: 0.6200, Test Acc: 0.7000\n",
      "Seed: 43, Epoch: 012, Loss: 0.6760, Val Acc: 0.6133, Test Acc: 0.6867\n",
      "Seed: 43, Epoch: 013, Loss: 0.6716, Val Acc: 0.6133, Test Acc: 0.6600\n",
      "Seed: 43, Epoch: 014, Loss: 0.6655, Val Acc: 0.6267, Test Acc: 0.6533\n",
      "Seed: 43, Epoch: 015, Loss: 0.6582, Val Acc: 0.6200, Test Acc: 0.6533\n",
      "Seed: 43, Epoch: 016, Loss: 0.6486, Val Acc: 0.6200, Test Acc: 0.6600\n",
      "Seed: 43, Epoch: 017, Loss: 0.6376, Val Acc: 0.6267, Test Acc: 0.6667\n",
      "Seed: 43, Epoch: 018, Loss: 0.6242, Val Acc: 0.6133, Test Acc: 0.6867\n",
      "Seed: 43, Epoch: 019, Loss: 0.6105, Val Acc: 0.6200, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 020, Loss: 0.5951, Val Acc: 0.6467, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 021, Loss: 0.5794, Val Acc: 0.6667, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 022, Loss: 0.5599, Val Acc: 0.6667, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 023, Loss: 0.5424, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 024, Loss: 0.5244, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 025, Loss: 0.5097, Val Acc: 0.6867, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 026, Loss: 0.4965, Val Acc: 0.6733, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 027, Loss: 0.4859, Val Acc: 0.7067, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 028, Loss: 0.4775, Val Acc: 0.7200, Test Acc: 0.7000\n",
      "Seed: 43, Epoch: 029, Loss: 0.4680, Val Acc: 0.7267, Test Acc: 0.7000\n",
      "Seed: 43, Epoch: 030, Loss: 0.4626, Val Acc: 0.6867, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 031, Loss: 0.4597, Val Acc: 0.7133, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 032, Loss: 0.4554, Val Acc: 0.7333, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 033, Loss: 0.4515, Val Acc: 0.7400, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 034, Loss: 0.4484, Val Acc: 0.7467, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 035, Loss: 0.4419, Val Acc: 0.7267, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 036, Loss: 0.4379, Val Acc: 0.7133, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 037, Loss: 0.4364, Val Acc: 0.7067, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 038, Loss: 0.4328, Val Acc: 0.7333, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 039, Loss: 0.4299, Val Acc: 0.7200, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 040, Loss: 0.4265, Val Acc: 0.7267, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 041, Loss: 0.4227, Val Acc: 0.7133, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 042, Loss: 0.4186, Val Acc: 0.7133, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 043, Loss: 0.4189, Val Acc: 0.7200, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 044, Loss: 0.4157, Val Acc: 0.7133, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 045, Loss: 0.4154, Val Acc: 0.7267, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 046, Loss: 0.4119, Val Acc: 0.7400, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 047, Loss: 0.4105, Val Acc: 0.6867, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 048, Loss: 0.4102, Val Acc: 0.7133, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 049, Loss: 0.4062, Val Acc: 0.7333, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 050, Loss: 0.4045, Val Acc: 0.7467, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 051, Loss: 0.4012, Val Acc: 0.7467, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 052, Loss: 0.3998, Val Acc: 0.7200, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 053, Loss: 0.3981, Val Acc: 0.7267, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 054, Loss: 0.3948, Val Acc: 0.7000, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 055, Loss: 0.3940, Val Acc: 0.7000, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 056, Loss: 0.3982, Val Acc: 0.7133, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 057, Loss: 0.3905, Val Acc: 0.7200, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 058, Loss: 0.3900, Val Acc: 0.7200, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 059, Loss: 0.3853, Val Acc: 0.7133, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 060, Loss: 0.3825, Val Acc: 0.7000, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 061, Loss: 0.3803, Val Acc: 0.7000, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 062, Loss: 0.3791, Val Acc: 0.6933, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 063, Loss: 0.3783, Val Acc: 0.7133, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 064, Loss: 0.3786, Val Acc: 0.7267, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 065, Loss: 0.3812, Val Acc: 0.7133, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 066, Loss: 0.3805, Val Acc: 0.7133, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 067, Loss: 0.3731, Val Acc: 0.7400, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 068, Loss: 0.3721, Val Acc: 0.7333, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 069, Loss: 0.3698, Val Acc: 0.7267, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 070, Loss: 0.3715, Val Acc: 0.7133, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 071, Loss: 0.3704, Val Acc: 0.6867, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 072, Loss: 0.3657, Val Acc: 0.6933, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 073, Loss: 0.3677, Val Acc: 0.6733, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 074, Loss: 0.3657, Val Acc: 0.6600, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 075, Loss: 0.3637, Val Acc: 0.6800, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 076, Loss: 0.3579, Val Acc: 0.7067, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 077, Loss: 0.3577, Val Acc: 0.7133, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 078, Loss: 0.3597, Val Acc: 0.7133, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 079, Loss: 0.3565, Val Acc: 0.7067, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 080, Loss: 0.3527, Val Acc: 0.6800, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 081, Loss: 0.3524, Val Acc: 0.6800, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 082, Loss: 0.3509, Val Acc: 0.7133, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 083, Loss: 0.3511, Val Acc: 0.6933, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 084, Loss: 0.3502, Val Acc: 0.6933, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 085, Loss: 0.3480, Val Acc: 0.6867, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 086, Loss: 0.3493, Val Acc: 0.7133, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 087, Loss: 0.3483, Val Acc: 0.7200, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 088, Loss: 0.3416, Val Acc: 0.7067, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 089, Loss: 0.3472, Val Acc: 0.7000, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 090, Loss: 0.3435, Val Acc: 0.7467, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 091, Loss: 0.3416, Val Acc: 0.7467, Test Acc: 0.6933\n",
      "Seed: 43, Epoch: 092, Loss: 0.3391, Val Acc: 0.7133, Test Acc: 0.7000\n",
      "Seed: 43, Epoch: 093, Loss: 0.3438, Val Acc: 0.6800, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 094, Loss: 0.3521, Val Acc: 0.7000, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 095, Loss: 0.3531, Val Acc: 0.7067, Test Acc: 0.6933\n",
      "Seed: 43, Epoch: 096, Loss: 0.3465, Val Acc: 0.7000, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 097, Loss: 0.3459, Val Acc: 0.7000, Test Acc: 0.7000\n",
      "Seed: 43, Epoch: 098, Loss: 0.3377, Val Acc: 0.7000, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 099, Loss: 0.3408, Val Acc: 0.6733, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 100, Loss: 0.3374, Val Acc: 0.6733, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 101, Loss: 0.3400, Val Acc: 0.6600, Test Acc: 0.6933\n",
      "Seed: 43, Epoch: 102, Loss: 0.3362, Val Acc: 0.6867, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 103, Loss: 0.3358, Val Acc: 0.7000, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 104, Loss: 0.3330, Val Acc: 0.6733, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 105, Loss: 0.3253, Val Acc: 0.6733, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 106, Loss: 0.3249, Val Acc: 0.6600, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 107, Loss: 0.3247, Val Acc: 0.6867, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 108, Loss: 0.3270, Val Acc: 0.6933, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 109, Loss: 0.3230, Val Acc: 0.6467, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 110, Loss: 0.3187, Val Acc: 0.6400, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 111, Loss: 0.3205, Val Acc: 0.6467, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 112, Loss: 0.3174, Val Acc: 0.6600, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 113, Loss: 0.3162, Val Acc: 0.6467, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 114, Loss: 0.3161, Val Acc: 0.6467, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 115, Loss: 0.3172, Val Acc: 0.6600, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 116, Loss: 0.3146, Val Acc: 0.6533, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 117, Loss: 0.3103, Val Acc: 0.6533, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 118, Loss: 0.3075, Val Acc: 0.6733, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 119, Loss: 0.3134, Val Acc: 0.7200, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 120, Loss: 0.3107, Val Acc: 0.6733, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 121, Loss: 0.3053, Val Acc: 0.6533, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 122, Loss: 0.3130, Val Acc: 0.6867, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 123, Loss: 0.3087, Val Acc: 0.7133, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 124, Loss: 0.3134, Val Acc: 0.6933, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 125, Loss: 0.3140, Val Acc: 0.6867, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 126, Loss: 0.3131, Val Acc: 0.6867, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 127, Loss: 0.3120, Val Acc: 0.7267, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 128, Loss: 0.3092, Val Acc: 0.7200, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 129, Loss: 0.3101, Val Acc: 0.6867, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 130, Loss: 0.3028, Val Acc: 0.6933, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 131, Loss: 0.3015, Val Acc: 0.7000, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 132, Loss: 0.3066, Val Acc: 0.7200, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 133, Loss: 0.3006, Val Acc: 0.6733, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 134, Loss: 0.3027, Val Acc: 0.6733, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 135, Loss: 0.3018, Val Acc: 0.6600, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 136, Loss: 0.2984, Val Acc: 0.6933, Test Acc: 0.6800\n",
      "Seed: 43, Epoch: 137, Loss: 0.3050, Val Acc: 0.6867, Test Acc: 0.6800\n",
      "Seed: 43, Epoch: 138, Loss: 0.3027, Val Acc: 0.6867, Test Acc: 0.6800\n",
      "Seed: 43, Epoch: 139, Loss: 0.3041, Val Acc: 0.6867, Test Acc: 0.6800\n",
      "Seed: 43, Epoch: 140, Loss: 0.3049, Val Acc: 0.7000, Test Acc: 0.6933\n",
      "Seed: 43, Epoch: 141, Loss: 0.3030, Val Acc: 0.6800, Test Acc: 0.6933\n",
      "Seed: 43, Epoch: 142, Loss: 0.3024, Val Acc: 0.6800, Test Acc: 0.7067\n",
      "Seed: 43, Epoch: 143, Loss: 0.3052, Val Acc: 0.6800, Test Acc: 0.6867\n",
      "Seed: 43, Epoch: 144, Loss: 0.3084, Val Acc: 0.6667, Test Acc: 0.6800\n",
      "Seed: 43, Epoch: 145, Loss: 0.2963, Val Acc: 0.6600, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 146, Loss: 0.2996, Val Acc: 0.6667, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 147, Loss: 0.2918, Val Acc: 0.6600, Test Acc: 0.7200\n",
      "Seed: 43, Epoch: 148, Loss: 0.2951, Val Acc: 0.6600, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 149, Loss: 0.2889, Val Acc: 0.6533, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 150, Loss: 0.2929, Val Acc: 0.6667, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 151, Loss: 0.2850, Val Acc: 0.7000, Test Acc: 0.7000\n",
      "Seed: 43, Epoch: 152, Loss: 0.2876, Val Acc: 0.7067, Test Acc: 0.7000\n",
      "Seed: 43, Epoch: 153, Loss: 0.2852, Val Acc: 0.6800, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 154, Loss: 0.2849, Val Acc: 0.6800, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 155, Loss: 0.2815, Val Acc: 0.6733, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 156, Loss: 0.2844, Val Acc: 0.6800, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 157, Loss: 0.2843, Val Acc: 0.6733, Test Acc: 0.7600\n",
      "Seed: 43, Epoch: 158, Loss: 0.2789, Val Acc: 0.7067, Test Acc: 0.7133\n",
      "Seed: 43, Epoch: 159, Loss: 0.2808, Val Acc: 0.6733, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 160, Loss: 0.2784, Val Acc: 0.6867, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 161, Loss: 0.2732, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 162, Loss: 0.2772, Val Acc: 0.6733, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 163, Loss: 0.2705, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 164, Loss: 0.2705, Val Acc: 0.6800, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 165, Loss: 0.2787, Val Acc: 0.7000, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 166, Loss: 0.2690, Val Acc: 0.6933, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 167, Loss: 0.2719, Val Acc: 0.6867, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 168, Loss: 0.2663, Val Acc: 0.6733, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 169, Loss: 0.2666, Val Acc: 0.6933, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 170, Loss: 0.2683, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 171, Loss: 0.2698, Val Acc: 0.6733, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 172, Loss: 0.2721, Val Acc: 0.6800, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 173, Loss: 0.2682, Val Acc: 0.6800, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 174, Loss: 0.2800, Val Acc: 0.6867, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 175, Loss: 0.2720, Val Acc: 0.6600, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 176, Loss: 0.2644, Val Acc: 0.6800, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 177, Loss: 0.2677, Val Acc: 0.6733, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 178, Loss: 0.2679, Val Acc: 0.6667, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 179, Loss: 0.2667, Val Acc: 0.6600, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 180, Loss: 0.2702, Val Acc: 0.6933, Test Acc: 0.7533\n",
      "Seed: 43, Epoch: 181, Loss: 0.2647, Val Acc: 0.6733, Test Acc: 0.7400\n",
      "Seed: 43, Epoch: 182, Loss: 0.2748, Val Acc: 0.6667, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 183, Loss: 0.2816, Val Acc: 0.6867, Test Acc: 0.7267\n",
      "Seed: 43, Epoch: 184, Loss: 0.2610, Val Acc: 0.6600, Test Acc: 0.7333\n",
      "Early stopping at epoch 184 for seed 43\n",
      "Seed: 44, Epoch: 001, Loss: 0.6938, Val Acc: 0.4600, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 002, Loss: 0.6931, Val Acc: 0.4600, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 003, Loss: 0.6920, Val Acc: 0.4600, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 004, Loss: 0.6911, Val Acc: 0.4600, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 005, Loss: 0.6897, Val Acc: 0.4600, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 006, Loss: 0.6882, Val Acc: 0.4600, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 007, Loss: 0.6863, Val Acc: 0.4667, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 008, Loss: 0.6837, Val Acc: 0.4667, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 009, Loss: 0.6807, Val Acc: 0.4933, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 010, Loss: 0.6775, Val Acc: 0.5200, Test Acc: 0.4867\n",
      "Seed: 44, Epoch: 011, Loss: 0.6730, Val Acc: 0.5467, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 012, Loss: 0.6678, Val Acc: 0.5600, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 013, Loss: 0.6612, Val Acc: 0.6000, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 014, Loss: 0.6535, Val Acc: 0.6067, Test Acc: 0.5733\n",
      "Seed: 44, Epoch: 015, Loss: 0.6455, Val Acc: 0.6133, Test Acc: 0.6000\n",
      "Seed: 44, Epoch: 016, Loss: 0.6351, Val Acc: 0.6200, Test Acc: 0.6467\n",
      "Seed: 44, Epoch: 017, Loss: 0.6227, Val Acc: 0.6267, Test Acc: 0.6467\n",
      "Seed: 44, Epoch: 018, Loss: 0.6080, Val Acc: 0.6267, Test Acc: 0.6467\n",
      "Seed: 44, Epoch: 019, Loss: 0.5921, Val Acc: 0.6333, Test Acc: 0.6533\n",
      "Seed: 44, Epoch: 020, Loss: 0.5778, Val Acc: 0.6333, Test Acc: 0.6533\n",
      "Seed: 44, Epoch: 021, Loss: 0.5575, Val Acc: 0.6333, Test Acc: 0.6600\n",
      "Seed: 44, Epoch: 022, Loss: 0.5391, Val Acc: 0.6400, Test Acc: 0.6733\n",
      "Seed: 44, Epoch: 023, Loss: 0.5218, Val Acc: 0.6467, Test Acc: 0.6800\n",
      "Seed: 44, Epoch: 024, Loss: 0.5035, Val Acc: 0.6400, Test Acc: 0.6800\n",
      "Seed: 44, Epoch: 025, Loss: 0.4866, Val Acc: 0.6400, Test Acc: 0.6867\n",
      "Seed: 44, Epoch: 026, Loss: 0.4714, Val Acc: 0.6400, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 027, Loss: 0.4585, Val Acc: 0.6267, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 028, Loss: 0.4498, Val Acc: 0.6400, Test Acc: 0.6733\n",
      "Seed: 44, Epoch: 029, Loss: 0.4429, Val Acc: 0.6667, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 030, Loss: 0.4380, Val Acc: 0.6867, Test Acc: 0.6800\n",
      "Seed: 44, Epoch: 031, Loss: 0.4359, Val Acc: 0.6867, Test Acc: 0.6800\n",
      "Seed: 44, Epoch: 032, Loss: 0.4295, Val Acc: 0.6933, Test Acc: 0.6733\n",
      "Seed: 44, Epoch: 033, Loss: 0.4239, Val Acc: 0.6933, Test Acc: 0.6667\n",
      "Seed: 44, Epoch: 034, Loss: 0.4203, Val Acc: 0.6867, Test Acc: 0.6667\n",
      "Seed: 44, Epoch: 035, Loss: 0.4155, Val Acc: 0.6867, Test Acc: 0.6600\n",
      "Seed: 44, Epoch: 036, Loss: 0.4113, Val Acc: 0.6933, Test Acc: 0.6600\n",
      "Seed: 44, Epoch: 037, Loss: 0.4068, Val Acc: 0.7133, Test Acc: 0.6667\n",
      "Seed: 44, Epoch: 038, Loss: 0.4131, Val Acc: 0.7333, Test Acc: 0.6467\n",
      "Seed: 44, Epoch: 039, Loss: 0.4140, Val Acc: 0.7400, Test Acc: 0.6667\n",
      "Seed: 44, Epoch: 040, Loss: 0.4092, Val Acc: 0.7200, Test Acc: 0.6867\n",
      "Seed: 44, Epoch: 041, Loss: 0.4097, Val Acc: 0.7400, Test Acc: 0.6867\n",
      "Seed: 44, Epoch: 042, Loss: 0.4013, Val Acc: 0.7467, Test Acc: 0.6733\n",
      "Seed: 44, Epoch: 043, Loss: 0.3991, Val Acc: 0.7467, Test Acc: 0.6867\n",
      "Seed: 44, Epoch: 044, Loss: 0.3964, Val Acc: 0.7333, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 045, Loss: 0.3940, Val Acc: 0.7400, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 046, Loss: 0.3917, Val Acc: 0.7467, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 047, Loss: 0.3839, Val Acc: 0.7467, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 048, Loss: 0.3771, Val Acc: 0.7533, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 049, Loss: 0.3725, Val Acc: 0.7400, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 050, Loss: 0.3659, Val Acc: 0.7267, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 051, Loss: 0.3652, Val Acc: 0.7267, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 052, Loss: 0.3656, Val Acc: 0.7333, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 053, Loss: 0.3615, Val Acc: 0.7333, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 054, Loss: 0.3566, Val Acc: 0.7600, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 055, Loss: 0.3609, Val Acc: 0.7467, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 056, Loss: 0.3641, Val Acc: 0.7467, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 057, Loss: 0.3474, Val Acc: 0.7267, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 058, Loss: 0.3480, Val Acc: 0.7400, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 059, Loss: 0.3481, Val Acc: 0.7333, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 060, Loss: 0.3382, Val Acc: 0.7133, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 061, Loss: 0.3385, Val Acc: 0.7000, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 062, Loss: 0.3316, Val Acc: 0.7333, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 063, Loss: 0.3343, Val Acc: 0.7333, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 064, Loss: 0.3304, Val Acc: 0.7267, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 065, Loss: 0.3251, Val Acc: 0.7333, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 066, Loss: 0.3305, Val Acc: 0.7200, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 067, Loss: 0.3315, Val Acc: 0.7267, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 068, Loss: 0.3271, Val Acc: 0.7200, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 069, Loss: 0.3385, Val Acc: 0.7133, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 070, Loss: 0.3330, Val Acc: 0.7067, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 071, Loss: 0.3214, Val Acc: 0.7067, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 072, Loss: 0.3298, Val Acc: 0.7400, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 073, Loss: 0.3200, Val Acc: 0.7333, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 074, Loss: 0.3265, Val Acc: 0.7333, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 075, Loss: 0.3251, Val Acc: 0.7400, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 076, Loss: 0.3135, Val Acc: 0.7267, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 077, Loss: 0.3061, Val Acc: 0.7267, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 078, Loss: 0.3189, Val Acc: 0.7133, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 079, Loss: 0.3064, Val Acc: 0.7200, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 080, Loss: 0.3023, Val Acc: 0.7200, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 081, Loss: 0.3058, Val Acc: 0.7133, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 082, Loss: 0.2997, Val Acc: 0.7267, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 083, Loss: 0.2911, Val Acc: 0.7200, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 084, Loss: 0.2894, Val Acc: 0.7067, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 085, Loss: 0.2824, Val Acc: 0.7067, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 086, Loss: 0.2823, Val Acc: 0.7000, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 087, Loss: 0.2838, Val Acc: 0.7333, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 088, Loss: 0.2861, Val Acc: 0.7200, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 089, Loss: 0.2767, Val Acc: 0.7133, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 090, Loss: 0.2708, Val Acc: 0.6933, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 091, Loss: 0.2733, Val Acc: 0.7267, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 092, Loss: 0.2713, Val Acc: 0.6933, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 093, Loss: 0.2720, Val Acc: 0.7000, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 094, Loss: 0.2748, Val Acc: 0.6800, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 095, Loss: 0.2606, Val Acc: 0.6867, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 096, Loss: 0.2623, Val Acc: 0.7000, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 097, Loss: 0.2652, Val Acc: 0.7067, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 098, Loss: 0.2617, Val Acc: 0.6867, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 099, Loss: 0.2636, Val Acc: 0.6867, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 100, Loss: 0.2642, Val Acc: 0.6933, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 101, Loss: 0.2589, Val Acc: 0.6733, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 102, Loss: 0.2573, Val Acc: 0.6867, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 103, Loss: 0.2552, Val Acc: 0.6733, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 104, Loss: 0.2607, Val Acc: 0.7133, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 105, Loss: 0.2644, Val Acc: 0.7133, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 106, Loss: 0.2608, Val Acc: 0.7267, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 107, Loss: 0.2696, Val Acc: 0.7400, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 108, Loss: 0.2536, Val Acc: 0.7467, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 109, Loss: 0.2626, Val Acc: 0.7400, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 110, Loss: 0.2595, Val Acc: 0.7400, Test Acc: 0.6867\n",
      "Seed: 44, Epoch: 111, Loss: 0.2613, Val Acc: 0.7333, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 112, Loss: 0.2939, Val Acc: 0.7200, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 113, Loss: 0.2561, Val Acc: 0.7400, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 114, Loss: 0.2614, Val Acc: 0.7400, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 115, Loss: 0.2720, Val Acc: 0.7200, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 116, Loss: 0.2699, Val Acc: 0.7200, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 117, Loss: 0.2645, Val Acc: 0.7133, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 118, Loss: 0.2549, Val Acc: 0.7067, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 119, Loss: 0.2566, Val Acc: 0.6933, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 120, Loss: 0.2629, Val Acc: 0.7000, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 121, Loss: 0.2637, Val Acc: 0.6667, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 122, Loss: 0.2626, Val Acc: 0.6733, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 123, Loss: 0.2600, Val Acc: 0.6600, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 124, Loss: 0.2486, Val Acc: 0.6733, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 125, Loss: 0.2488, Val Acc: 0.6867, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 126, Loss: 0.2673, Val Acc: 0.6733, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 127, Loss: 0.2561, Val Acc: 0.6733, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 128, Loss: 0.2622, Val Acc: 0.6867, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 129, Loss: 0.2635, Val Acc: 0.6800, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 130, Loss: 0.2680, Val Acc: 0.6667, Test Acc: 0.8067\n",
      "Seed: 44, Epoch: 131, Loss: 0.2626, Val Acc: 0.6600, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 132, Loss: 0.2564, Val Acc: 0.6867, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 133, Loss: 0.2561, Val Acc: 0.6800, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 134, Loss: 0.2537, Val Acc: 0.6933, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 135, Loss: 0.2393, Val Acc: 0.7000, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 136, Loss: 0.2453, Val Acc: 0.6867, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 137, Loss: 0.2415, Val Acc: 0.6533, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 138, Loss: 0.2414, Val Acc: 0.6733, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 139, Loss: 0.2372, Val Acc: 0.6733, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 140, Loss: 0.2436, Val Acc: 0.7000, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 141, Loss: 0.2414, Val Acc: 0.6933, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 142, Loss: 0.2395, Val Acc: 0.7000, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 143, Loss: 0.2374, Val Acc: 0.6800, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 144, Loss: 0.2317, Val Acc: 0.6733, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 145, Loss: 0.2488, Val Acc: 0.6733, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 146, Loss: 0.2351, Val Acc: 0.6800, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 147, Loss: 0.2423, Val Acc: 0.6733, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 148, Loss: 0.2457, Val Acc: 0.6733, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 149, Loss: 0.2417, Val Acc: 0.6533, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 150, Loss: 0.2370, Val Acc: 0.6600, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 151, Loss: 0.2422, Val Acc: 0.6600, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 152, Loss: 0.2453, Val Acc: 0.6667, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 153, Loss: 0.2348, Val Acc: 0.6933, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 154, Loss: 0.2498, Val Acc: 0.6733, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 155, Loss: 0.2501, Val Acc: 0.6667, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 156, Loss: 0.2396, Val Acc: 0.6867, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 157, Loss: 0.2427, Val Acc: 0.6933, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 158, Loss: 0.2545, Val Acc: 0.7000, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 159, Loss: 0.2568, Val Acc: 0.7067, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 160, Loss: 0.2678, Val Acc: 0.6933, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 161, Loss: 0.2583, Val Acc: 0.6867, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 162, Loss: 0.2464, Val Acc: 0.7000, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 163, Loss: 0.2585, Val Acc: 0.6867, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 164, Loss: 0.2522, Val Acc: 0.6667, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 165, Loss: 0.2394, Val Acc: 0.6467, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 166, Loss: 0.2396, Val Acc: 0.6533, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 167, Loss: 0.2363, Val Acc: 0.6533, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 168, Loss: 0.2432, Val Acc: 0.6533, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 169, Loss: 0.2343, Val Acc: 0.6533, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 170, Loss: 0.2377, Val Acc: 0.6533, Test Acc: 0.7000\n",
      "Seed: 44, Epoch: 171, Loss: 0.2347, Val Acc: 0.6600, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 172, Loss: 0.2327, Val Acc: 0.6800, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 173, Loss: 0.2322, Val Acc: 0.6867, Test Acc: 0.6933\n",
      "Seed: 44, Epoch: 174, Loss: 0.2268, Val Acc: 0.6867, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 175, Loss: 0.2341, Val Acc: 0.7000, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 176, Loss: 0.2351, Val Acc: 0.6867, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 177, Loss: 0.2233, Val Acc: 0.7067, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 178, Loss: 0.2229, Val Acc: 0.7067, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 179, Loss: 0.2243, Val Acc: 0.7000, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 180, Loss: 0.2342, Val Acc: 0.7133, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 181, Loss: 0.2246, Val Acc: 0.6933, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 182, Loss: 0.2312, Val Acc: 0.7267, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 183, Loss: 0.2330, Val Acc: 0.7333, Test Acc: 0.7267\n",
      "Seed: 44, Epoch: 184, Loss: 0.2401, Val Acc: 0.7333, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 185, Loss: 0.2370, Val Acc: 0.7000, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 186, Loss: 0.2374, Val Acc: 0.6933, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 187, Loss: 0.2225, Val Acc: 0.6600, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 188, Loss: 0.2400, Val Acc: 0.6667, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 189, Loss: 0.2223, Val Acc: 0.6933, Test Acc: 0.7400\n",
      "Seed: 44, Epoch: 190, Loss: 0.2358, Val Acc: 0.7133, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 191, Loss: 0.2300, Val Acc: 0.7000, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 192, Loss: 0.2332, Val Acc: 0.6933, Test Acc: 0.7133\n",
      "Seed: 44, Epoch: 193, Loss: 0.2419, Val Acc: 0.6867, Test Acc: 0.7067\n",
      "Seed: 44, Epoch: 194, Loss: 0.2382, Val Acc: 0.6933, Test Acc: 0.7467\n",
      "Seed: 44, Epoch: 195, Loss: 0.2257, Val Acc: 0.6600, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 196, Loss: 0.2379, Val Acc: 0.6733, Test Acc: 0.7333\n",
      "Seed: 44, Epoch: 197, Loss: 0.2249, Val Acc: 0.6733, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 198, Loss: 0.2363, Val Acc: 0.6800, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 199, Loss: 0.2434, Val Acc: 0.6667, Test Acc: 0.7533\n",
      "Seed: 44, Epoch: 200, Loss: 0.2424, Val Acc: 0.6467, Test Acc: 0.7800\n",
      "Average Time: 291.88 seconds\n",
      "Var Time: 1053.12 seconds\n",
      "Average Memory: 5410.00 MB\n",
      "Average Best Val Acc: 0.7778\n",
      "Std Best Test Acc: 0.0196\n",
      "Average Test Acc: 0.7467\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "max_nodes = 500\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"IMDB-BINARY\",\n",
    "    transform=T.Compose([T.OneHotDegree(136), T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_hosc(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc, o = dense_hoscpool(x, adj, s, mu=0.1, alpha=0.7, new_ortho=False, mask=mask)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc_aux, o_aux = dense_hoscpool(x, adj, s, mu=0.1, alpha=0.7, new_ortho=False)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_hosc().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=512, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "    model = Net_hosc().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB-MULTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 1.0996, Val Acc: 0.2711, Test Acc: 0.3511\n",
      "Seed: 42, Epoch: 002, Loss: 1.0986, Val Acc: 0.2711, Test Acc: 0.3511\n",
      "Seed: 42, Epoch: 003, Loss: 1.0980, Val Acc: 0.2711, Test Acc: 0.3511\n",
      "Seed: 42, Epoch: 004, Loss: 1.0974, Val Acc: 0.2711, Test Acc: 0.3511\n",
      "Seed: 42, Epoch: 005, Loss: 1.0967, Val Acc: 0.2711, Test Acc: 0.3511\n",
      "Seed: 42, Epoch: 006, Loss: 1.0960, Val Acc: 0.2711, Test Acc: 0.3600\n",
      "Seed: 42, Epoch: 007, Loss: 1.0950, Val Acc: 0.2711, Test Acc: 0.3600\n",
      "Seed: 42, Epoch: 008, Loss: 1.0940, Val Acc: 0.2711, Test Acc: 0.3644\n",
      "Seed: 42, Epoch: 009, Loss: 1.0929, Val Acc: 0.2844, Test Acc: 0.3733\n",
      "Seed: 42, Epoch: 010, Loss: 1.0914, Val Acc: 0.2889, Test Acc: 0.3778\n",
      "Seed: 42, Epoch: 011, Loss: 1.0894, Val Acc: 0.2844, Test Acc: 0.3778\n",
      "Seed: 42, Epoch: 012, Loss: 1.0870, Val Acc: 0.3022, Test Acc: 0.3778\n",
      "Seed: 42, Epoch: 013, Loss: 1.0840, Val Acc: 0.3244, Test Acc: 0.4000\n",
      "Seed: 42, Epoch: 014, Loss: 1.0802, Val Acc: 0.3556, Test Acc: 0.4400\n",
      "Seed: 42, Epoch: 015, Loss: 1.0760, Val Acc: 0.3867, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 016, Loss: 1.0702, Val Acc: 0.4222, Test Acc: 0.4222\n",
      "Seed: 42, Epoch: 017, Loss: 1.0632, Val Acc: 0.3867, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 018, Loss: 1.0558, Val Acc: 0.4044, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 019, Loss: 1.0473, Val Acc: 0.4000, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 020, Loss: 1.0382, Val Acc: 0.4978, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 021, Loss: 1.0303, Val Acc: 0.4933, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 022, Loss: 1.0208, Val Acc: 0.4756, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 023, Loss: 1.0102, Val Acc: 0.4800, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 024, Loss: 1.0013, Val Acc: 0.4756, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 025, Loss: 0.9921, Val Acc: 0.4800, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 026, Loss: 0.9843, Val Acc: 0.4844, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 027, Loss: 0.9802, Val Acc: 0.5111, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 028, Loss: 0.9774, Val Acc: 0.5156, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 029, Loss: 0.9736, Val Acc: 0.5111, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 030, Loss: 0.9677, Val Acc: 0.5022, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 031, Loss: 0.9669, Val Acc: 0.5111, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 032, Loss: 0.9635, Val Acc: 0.4933, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 033, Loss: 0.9559, Val Acc: 0.4889, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 034, Loss: 0.9577, Val Acc: 0.4844, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 035, Loss: 0.9531, Val Acc: 0.4933, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 036, Loss: 0.9490, Val Acc: 0.4933, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 037, Loss: 0.9488, Val Acc: 0.5022, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 038, Loss: 0.9455, Val Acc: 0.4844, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 039, Loss: 0.9454, Val Acc: 0.4800, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 040, Loss: 0.9481, Val Acc: 0.4756, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 041, Loss: 0.9477, Val Acc: 0.4978, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 042, Loss: 0.9421, Val Acc: 0.4933, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 043, Loss: 0.9421, Val Acc: 0.4844, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 044, Loss: 0.9418, Val Acc: 0.4800, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 045, Loss: 0.9409, Val Acc: 0.4889, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 046, Loss: 0.9358, Val Acc: 0.4933, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 047, Loss: 0.9343, Val Acc: 0.4800, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 048, Loss: 0.9340, Val Acc: 0.4844, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 049, Loss: 0.9356, Val Acc: 0.4933, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 050, Loss: 0.9350, Val Acc: 0.4800, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 051, Loss: 0.9310, Val Acc: 0.4933, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 052, Loss: 0.9259, Val Acc: 0.4978, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 053, Loss: 0.9271, Val Acc: 0.4978, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 054, Loss: 0.9243, Val Acc: 0.5022, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 055, Loss: 0.9215, Val Acc: 0.4844, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 056, Loss: 0.9201, Val Acc: 0.4933, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 057, Loss: 0.9239, Val Acc: 0.4844, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 058, Loss: 0.9298, Val Acc: 0.4800, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 059, Loss: 0.9238, Val Acc: 0.4889, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 060, Loss: 0.9209, Val Acc: 0.4800, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 061, Loss: 0.9210, Val Acc: 0.4844, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 062, Loss: 0.9229, Val Acc: 0.4889, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 063, Loss: 0.9206, Val Acc: 0.4889, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 064, Loss: 0.9304, Val Acc: 0.4844, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 065, Loss: 0.9186, Val Acc: 0.4978, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 066, Loss: 0.9143, Val Acc: 0.4844, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 067, Loss: 0.9264, Val Acc: 0.4889, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 068, Loss: 0.9241, Val Acc: 0.5022, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 069, Loss: 0.9146, Val Acc: 0.4756, Test Acc: 0.5067\n",
      "Seed: 42, Epoch: 070, Loss: 0.9200, Val Acc: 0.4533, Test Acc: 0.5200\n",
      "Seed: 42, Epoch: 071, Loss: 0.9287, Val Acc: 0.4800, Test Acc: 0.5200\n",
      "Seed: 42, Epoch: 072, Loss: 0.9190, Val Acc: 0.4933, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 073, Loss: 0.9142, Val Acc: 0.4711, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 074, Loss: 0.9181, Val Acc: 0.4711, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 075, Loss: 0.9247, Val Acc: 0.4889, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 076, Loss: 0.9180, Val Acc: 0.4933, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 077, Loss: 0.9124, Val Acc: 0.4978, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 078, Loss: 0.9143, Val Acc: 0.4978, Test Acc: 0.5067\n",
      "Seed: 42, Epoch: 079, Loss: 0.9140, Val Acc: 0.4978, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 080, Loss: 0.9125, Val Acc: 0.4978, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 081, Loss: 0.9058, Val Acc: 0.4933, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 082, Loss: 0.9056, Val Acc: 0.4756, Test Acc: 0.5067\n",
      "Seed: 42, Epoch: 083, Loss: 0.9075, Val Acc: 0.4756, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 084, Loss: 0.9083, Val Acc: 0.4933, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 085, Loss: 0.9043, Val Acc: 0.4889, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 086, Loss: 0.9074, Val Acc: 0.4933, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 087, Loss: 0.9116, Val Acc: 0.5067, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 088, Loss: 0.9056, Val Acc: 0.5022, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 089, Loss: 0.9018, Val Acc: 0.5022, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 090, Loss: 0.9037, Val Acc: 0.4889, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 091, Loss: 0.9084, Val Acc: 0.4933, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 092, Loss: 0.9089, Val Acc: 0.4933, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 093, Loss: 0.9035, Val Acc: 0.4978, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 094, Loss: 0.9011, Val Acc: 0.5067, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 095, Loss: 0.8979, Val Acc: 0.4978, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 096, Loss: 0.8979, Val Acc: 0.4889, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 097, Loss: 0.8946, Val Acc: 0.4978, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 098, Loss: 0.8949, Val Acc: 0.4844, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 099, Loss: 0.8948, Val Acc: 0.4889, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 100, Loss: 0.8929, Val Acc: 0.4889, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 101, Loss: 0.8975, Val Acc: 0.5022, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 102, Loss: 0.8963, Val Acc: 0.4978, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 103, Loss: 0.8963, Val Acc: 0.5067, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 104, Loss: 0.8942, Val Acc: 0.4800, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 105, Loss: 0.8949, Val Acc: 0.4800, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 106, Loss: 0.8918, Val Acc: 0.4978, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 107, Loss: 0.8947, Val Acc: 0.4933, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 108, Loss: 0.8987, Val Acc: 0.5022, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 109, Loss: 0.8951, Val Acc: 0.4933, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 110, Loss: 0.8917, Val Acc: 0.5022, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 111, Loss: 0.8932, Val Acc: 0.5067, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 112, Loss: 0.8928, Val Acc: 0.4978, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 113, Loss: 0.8896, Val Acc: 0.4978, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 114, Loss: 0.8861, Val Acc: 0.4978, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 115, Loss: 0.8898, Val Acc: 0.4844, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 116, Loss: 0.8881, Val Acc: 0.4800, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 117, Loss: 0.8865, Val Acc: 0.4844, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 118, Loss: 0.8846, Val Acc: 0.4756, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 119, Loss: 0.8865, Val Acc: 0.4667, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 120, Loss: 0.8839, Val Acc: 0.4800, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 121, Loss: 0.8874, Val Acc: 0.4889, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 122, Loss: 0.8857, Val Acc: 0.4622, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 123, Loss: 0.9008, Val Acc: 0.4489, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 124, Loss: 0.9118, Val Acc: 0.4578, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 125, Loss: 0.9113, Val Acc: 0.4889, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 126, Loss: 0.9001, Val Acc: 0.5022, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 127, Loss: 0.8984, Val Acc: 0.4978, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 128, Loss: 0.8985, Val Acc: 0.4978, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 129, Loss: 0.8921, Val Acc: 0.4489, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 130, Loss: 0.8870, Val Acc: 0.4533, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 131, Loss: 0.8865, Val Acc: 0.4622, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 132, Loss: 0.8863, Val Acc: 0.4800, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 133, Loss: 0.8816, Val Acc: 0.4844, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 134, Loss: 0.8817, Val Acc: 0.4844, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 135, Loss: 0.8795, Val Acc: 0.4800, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 136, Loss: 0.8833, Val Acc: 0.4889, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 137, Loss: 0.8818, Val Acc: 0.4889, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 138, Loss: 0.8842, Val Acc: 0.4978, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 139, Loss: 0.8822, Val Acc: 0.4844, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 140, Loss: 0.8793, Val Acc: 0.4978, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 141, Loss: 0.8785, Val Acc: 0.4978, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 142, Loss: 0.8797, Val Acc: 0.4889, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 143, Loss: 0.8812, Val Acc: 0.4800, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 144, Loss: 0.8867, Val Acc: 0.4756, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 145, Loss: 0.8793, Val Acc: 0.4800, Test Acc: 0.5022\n",
      "Seed: 42, Epoch: 146, Loss: 0.8797, Val Acc: 0.4756, Test Acc: 0.5067\n",
      "Seed: 42, Epoch: 147, Loss: 0.8825, Val Acc: 0.4889, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 148, Loss: 0.8788, Val Acc: 0.4800, Test Acc: 0.5067\n",
      "Seed: 42, Epoch: 149, Loss: 0.8784, Val Acc: 0.4933, Test Acc: 0.4933\n",
      "Seed: 42, Epoch: 150, Loss: 0.8800, Val Acc: 0.4978, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 151, Loss: 0.8778, Val Acc: 0.5022, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 152, Loss: 0.8765, Val Acc: 0.4756, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 153, Loss: 0.8763, Val Acc: 0.4889, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 154, Loss: 0.8765, Val Acc: 0.4933, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 155, Loss: 0.8779, Val Acc: 0.4978, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 156, Loss: 0.8745, Val Acc: 0.4622, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 157, Loss: 0.8751, Val Acc: 0.4844, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 158, Loss: 0.8773, Val Acc: 0.4800, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 159, Loss: 0.8785, Val Acc: 0.4889, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 160, Loss: 0.8712, Val Acc: 0.5067, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 161, Loss: 0.8735, Val Acc: 0.4933, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 162, Loss: 0.8815, Val Acc: 0.5200, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 163, Loss: 0.8781, Val Acc: 0.5244, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 164, Loss: 0.8744, Val Acc: 0.5022, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 165, Loss: 0.8758, Val Acc: 0.4933, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 166, Loss: 0.8769, Val Acc: 0.4844, Test Acc: 0.4889\n",
      "Seed: 42, Epoch: 167, Loss: 0.8746, Val Acc: 0.5156, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 168, Loss: 0.8685, Val Acc: 0.5289, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 169, Loss: 0.8713, Val Acc: 0.5289, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 170, Loss: 0.8731, Val Acc: 0.5156, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 171, Loss: 0.8740, Val Acc: 0.5200, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 172, Loss: 0.8761, Val Acc: 0.5111, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 173, Loss: 0.8776, Val Acc: 0.5111, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 174, Loss: 0.8749, Val Acc: 0.5111, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 175, Loss: 0.8739, Val Acc: 0.5156, Test Acc: 0.4400\n",
      "Seed: 42, Epoch: 176, Loss: 0.8732, Val Acc: 0.4978, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 177, Loss: 0.8748, Val Acc: 0.5022, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 178, Loss: 0.8733, Val Acc: 0.5111, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 179, Loss: 0.8747, Val Acc: 0.5156, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 180, Loss: 0.8715, Val Acc: 0.4933, Test Acc: 0.4667\n",
      "Seed: 42, Epoch: 181, Loss: 0.8732, Val Acc: 0.5111, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 182, Loss: 0.8795, Val Acc: 0.5156, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 183, Loss: 0.8723, Val Acc: 0.5067, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 184, Loss: 0.8703, Val Acc: 0.5111, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 185, Loss: 0.8729, Val Acc: 0.5111, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 186, Loss: 0.8715, Val Acc: 0.5156, Test Acc: 0.4756\n",
      "Seed: 42, Epoch: 187, Loss: 0.8740, Val Acc: 0.5111, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 188, Loss: 0.8703, Val Acc: 0.4978, Test Acc: 0.4533\n",
      "Seed: 42, Epoch: 189, Loss: 0.8678, Val Acc: 0.5022, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 190, Loss: 0.8666, Val Acc: 0.4978, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 191, Loss: 0.8683, Val Acc: 0.5067, Test Acc: 0.4844\n",
      "Seed: 42, Epoch: 192, Loss: 0.8721, Val Acc: 0.5156, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 193, Loss: 0.8703, Val Acc: 0.4889, Test Acc: 0.4800\n",
      "Seed: 42, Epoch: 194, Loss: 0.8675, Val Acc: 0.4978, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 195, Loss: 0.8652, Val Acc: 0.5156, Test Acc: 0.4489\n",
      "Seed: 42, Epoch: 196, Loss: 0.8609, Val Acc: 0.5200, Test Acc: 0.4622\n",
      "Seed: 42, Epoch: 197, Loss: 0.8667, Val Acc: 0.5022, Test Acc: 0.4711\n",
      "Seed: 42, Epoch: 198, Loss: 0.8672, Val Acc: 0.5111, Test Acc: 0.4578\n",
      "Seed: 42, Epoch: 199, Loss: 0.8619, Val Acc: 0.5067, Test Acc: 0.4978\n",
      "Seed: 42, Epoch: 200, Loss: 0.8643, Val Acc: 0.4889, Test Acc: 0.4933\n",
      "Seed: 43, Epoch: 001, Loss: 1.1059, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 002, Loss: 1.1046, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 003, Loss: 1.1035, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 004, Loss: 1.1023, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 005, Loss: 1.1011, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 006, Loss: 1.0998, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 007, Loss: 1.0985, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 008, Loss: 1.0969, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 009, Loss: 1.0958, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 010, Loss: 1.0941, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 011, Loss: 1.0920, Val Acc: 0.3333, Test Acc: 0.3244\n",
      "Seed: 43, Epoch: 012, Loss: 1.0896, Val Acc: 0.3289, Test Acc: 0.3289\n",
      "Seed: 43, Epoch: 013, Loss: 1.0870, Val Acc: 0.3333, Test Acc: 0.3289\n",
      "Seed: 43, Epoch: 014, Loss: 1.0834, Val Acc: 0.3778, Test Acc: 0.3422\n",
      "Seed: 43, Epoch: 015, Loss: 1.0797, Val Acc: 0.4133, Test Acc: 0.3689\n",
      "Seed: 43, Epoch: 016, Loss: 1.0752, Val Acc: 0.4311, Test Acc: 0.3733\n",
      "Seed: 43, Epoch: 017, Loss: 1.0698, Val Acc: 0.5022, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 018, Loss: 1.0634, Val Acc: 0.4844, Test Acc: 0.4044\n",
      "Seed: 43, Epoch: 019, Loss: 1.0576, Val Acc: 0.4444, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 020, Loss: 1.0506, Val Acc: 0.4267, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 021, Loss: 1.0429, Val Acc: 0.4800, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 022, Loss: 1.0321, Val Acc: 0.5022, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 023, Loss: 1.0205, Val Acc: 0.5156, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 024, Loss: 1.0120, Val Acc: 0.5111, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 025, Loss: 0.9999, Val Acc: 0.4933, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 026, Loss: 0.9906, Val Acc: 0.4933, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 027, Loss: 0.9840, Val Acc: 0.4311, Test Acc: 0.4000\n",
      "Seed: 43, Epoch: 028, Loss: 0.9791, Val Acc: 0.4489, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 029, Loss: 0.9708, Val Acc: 0.5111, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 030, Loss: 0.9593, Val Acc: 0.5289, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 031, Loss: 0.9523, Val Acc: 0.5067, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 032, Loss: 0.9526, Val Acc: 0.5022, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 033, Loss: 0.9482, Val Acc: 0.5244, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 034, Loss: 0.9403, Val Acc: 0.5333, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 035, Loss: 0.9374, Val Acc: 0.5289, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 036, Loss: 0.9362, Val Acc: 0.5067, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 037, Loss: 0.9305, Val Acc: 0.5022, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 038, Loss: 0.9295, Val Acc: 0.5333, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 039, Loss: 0.9300, Val Acc: 0.5200, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 040, Loss: 0.9323, Val Acc: 0.5067, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 041, Loss: 0.9301, Val Acc: 0.5067, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 042, Loss: 0.9221, Val Acc: 0.5156, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 043, Loss: 0.9206, Val Acc: 0.4667, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 044, Loss: 0.9275, Val Acc: 0.4978, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 045, Loss: 0.9282, Val Acc: 0.5111, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 046, Loss: 0.9211, Val Acc: 0.5200, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 047, Loss: 0.9239, Val Acc: 0.5200, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 048, Loss: 0.9215, Val Acc: 0.4978, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 049, Loss: 0.9206, Val Acc: 0.4933, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 050, Loss: 0.9192, Val Acc: 0.4711, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 051, Loss: 0.9168, Val Acc: 0.5156, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 052, Loss: 0.9110, Val Acc: 0.5156, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 053, Loss: 0.9105, Val Acc: 0.5244, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 054, Loss: 0.9101, Val Acc: 0.5289, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 055, Loss: 0.9042, Val Acc: 0.5156, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 056, Loss: 0.9063, Val Acc: 0.5156, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 057, Loss: 0.9077, Val Acc: 0.5200, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 058, Loss: 0.9058, Val Acc: 0.5156, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 059, Loss: 0.8999, Val Acc: 0.5156, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 060, Loss: 0.9023, Val Acc: 0.5156, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 061, Loss: 0.9011, Val Acc: 0.5022, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 062, Loss: 0.9092, Val Acc: 0.5111, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 063, Loss: 0.9076, Val Acc: 0.5067, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 064, Loss: 0.9016, Val Acc: 0.5067, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 065, Loss: 0.9058, Val Acc: 0.5200, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 066, Loss: 0.9088, Val Acc: 0.5156, Test Acc: 0.4489\n",
      "Seed: 43, Epoch: 067, Loss: 0.9010, Val Acc: 0.5067, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 068, Loss: 0.9008, Val Acc: 0.4889, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 069, Loss: 0.9078, Val Acc: 0.5156, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 070, Loss: 0.9078, Val Acc: 0.5244, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 071, Loss: 0.9007, Val Acc: 0.5156, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 072, Loss: 0.8961, Val Acc: 0.5200, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 073, Loss: 0.8985, Val Acc: 0.5289, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 074, Loss: 0.8910, Val Acc: 0.5244, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 075, Loss: 0.8908, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 076, Loss: 0.8919, Val Acc: 0.5156, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 077, Loss: 0.8861, Val Acc: 0.5244, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 078, Loss: 0.8857, Val Acc: 0.5200, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 079, Loss: 0.8863, Val Acc: 0.5200, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 080, Loss: 0.8849, Val Acc: 0.5200, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 081, Loss: 0.8856, Val Acc: 0.5200, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 082, Loss: 0.8876, Val Acc: 0.5200, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 083, Loss: 0.8920, Val Acc: 0.5200, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 084, Loss: 0.8873, Val Acc: 0.5289, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 085, Loss: 0.8899, Val Acc: 0.5289, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 086, Loss: 0.8891, Val Acc: 0.5333, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 087, Loss: 0.8867, Val Acc: 0.5333, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 088, Loss: 0.8899, Val Acc: 0.5111, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 089, Loss: 0.8926, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 090, Loss: 0.8856, Val Acc: 0.5111, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 091, Loss: 0.8929, Val Acc: 0.5200, Test Acc: 0.4000\n",
      "Seed: 43, Epoch: 092, Loss: 0.9067, Val Acc: 0.5022, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 093, Loss: 0.9037, Val Acc: 0.5156, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 094, Loss: 0.8880, Val Acc: 0.5111, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 095, Loss: 0.8843, Val Acc: 0.5111, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 096, Loss: 0.8938, Val Acc: 0.4978, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 097, Loss: 0.9061, Val Acc: 0.5022, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 098, Loss: 0.8964, Val Acc: 0.5289, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 099, Loss: 0.8848, Val Acc: 0.5333, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 100, Loss: 0.8846, Val Acc: 0.5289, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 101, Loss: 0.8910, Val Acc: 0.5244, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 102, Loss: 0.8856, Val Acc: 0.5200, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 103, Loss: 0.8838, Val Acc: 0.5156, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 104, Loss: 0.8779, Val Acc: 0.5200, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 105, Loss: 0.8753, Val Acc: 0.5289, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 106, Loss: 0.8751, Val Acc: 0.5333, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 107, Loss: 0.8722, Val Acc: 0.5244, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 108, Loss: 0.8724, Val Acc: 0.5333, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 109, Loss: 0.8746, Val Acc: 0.5289, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 110, Loss: 0.8726, Val Acc: 0.5244, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 111, Loss: 0.8718, Val Acc: 0.5156, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 112, Loss: 0.8772, Val Acc: 0.5156, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 113, Loss: 0.8802, Val Acc: 0.5244, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 114, Loss: 0.8761, Val Acc: 0.5244, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 115, Loss: 0.8770, Val Acc: 0.5244, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 116, Loss: 0.8768, Val Acc: 0.5289, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 117, Loss: 0.8737, Val Acc: 0.5333, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 118, Loss: 0.8704, Val Acc: 0.5333, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 119, Loss: 0.8722, Val Acc: 0.5289, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 120, Loss: 0.8727, Val Acc: 0.5289, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 121, Loss: 0.8726, Val Acc: 0.5289, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 122, Loss: 0.8682, Val Acc: 0.5333, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 123, Loss: 0.8647, Val Acc: 0.5200, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 124, Loss: 0.8666, Val Acc: 0.5289, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 125, Loss: 0.8669, Val Acc: 0.5156, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 126, Loss: 0.8716, Val Acc: 0.5156, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 127, Loss: 0.8760, Val Acc: 0.5156, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 128, Loss: 0.8709, Val Acc: 0.5156, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 129, Loss: 0.8675, Val Acc: 0.5111, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 130, Loss: 0.8671, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 131, Loss: 0.8631, Val Acc: 0.5244, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 132, Loss: 0.8621, Val Acc: 0.5244, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 133, Loss: 0.8596, Val Acc: 0.5333, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 134, Loss: 0.8615, Val Acc: 0.5333, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 135, Loss: 0.8595, Val Acc: 0.5289, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 136, Loss: 0.8577, Val Acc: 0.5289, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 137, Loss: 0.8573, Val Acc: 0.5289, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 138, Loss: 0.8591, Val Acc: 0.5422, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 139, Loss: 0.8608, Val Acc: 0.5289, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 140, Loss: 0.8673, Val Acc: 0.5333, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 141, Loss: 0.8623, Val Acc: 0.5244, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 142, Loss: 0.8580, Val Acc: 0.5200, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 143, Loss: 0.8624, Val Acc: 0.5244, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 144, Loss: 0.8583, Val Acc: 0.5333, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 145, Loss: 0.8541, Val Acc: 0.5289, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 146, Loss: 0.8523, Val Acc: 0.5511, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 147, Loss: 0.8546, Val Acc: 0.4889, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 148, Loss: 0.8570, Val Acc: 0.5422, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 149, Loss: 0.8514, Val Acc: 0.5378, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 150, Loss: 0.8516, Val Acc: 0.5289, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 151, Loss: 0.8516, Val Acc: 0.5422, Test Acc: 0.4089\n",
      "Seed: 43, Epoch: 152, Loss: 0.8527, Val Acc: 0.5378, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 153, Loss: 0.8560, Val Acc: 0.5244, Test Acc: 0.4178\n",
      "Seed: 43, Epoch: 154, Loss: 0.8585, Val Acc: 0.5333, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 155, Loss: 0.8586, Val Acc: 0.5378, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 156, Loss: 0.8576, Val Acc: 0.5467, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 157, Loss: 0.8559, Val Acc: 0.5467, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 158, Loss: 0.8512, Val Acc: 0.5333, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 159, Loss: 0.8511, Val Acc: 0.5333, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 160, Loss: 0.8564, Val Acc: 0.5422, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 161, Loss: 0.8553, Val Acc: 0.5422, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 162, Loss: 0.8525, Val Acc: 0.5200, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 163, Loss: 0.8531, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 164, Loss: 0.8528, Val Acc: 0.5200, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 165, Loss: 0.8466, Val Acc: 0.5378, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 166, Loss: 0.8478, Val Acc: 0.5333, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 167, Loss: 0.8564, Val Acc: 0.5333, Test Acc: 0.4133\n",
      "Seed: 43, Epoch: 168, Loss: 0.8540, Val Acc: 0.5244, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 169, Loss: 0.8518, Val Acc: 0.5067, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 170, Loss: 0.8524, Val Acc: 0.5244, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 171, Loss: 0.8477, Val Acc: 0.5333, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 172, Loss: 0.8527, Val Acc: 0.5111, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 173, Loss: 0.8633, Val Acc: 0.5244, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 174, Loss: 0.8616, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 175, Loss: 0.8500, Val Acc: 0.4711, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 176, Loss: 0.8618, Val Acc: 0.4889, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 177, Loss: 0.8690, Val Acc: 0.5244, Test Acc: 0.4533\n",
      "Seed: 43, Epoch: 178, Loss: 0.8615, Val Acc: 0.5289, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 179, Loss: 0.8627, Val Acc: 0.5156, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 180, Loss: 0.8734, Val Acc: 0.5378, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 181, Loss: 0.8648, Val Acc: 0.5378, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 182, Loss: 0.8567, Val Acc: 0.5244, Test Acc: 0.4489\n",
      "Seed: 43, Epoch: 183, Loss: 0.8659, Val Acc: 0.5111, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 184, Loss: 0.8590, Val Acc: 0.5289, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 185, Loss: 0.8555, Val Acc: 0.5333, Test Acc: 0.4311\n",
      "Seed: 43, Epoch: 186, Loss: 0.8605, Val Acc: 0.5333, Test Acc: 0.4222\n",
      "Seed: 43, Epoch: 187, Loss: 0.8661, Val Acc: 0.5244, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 188, Loss: 0.8603, Val Acc: 0.5200, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 189, Loss: 0.8598, Val Acc: 0.5156, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 190, Loss: 0.8565, Val Acc: 0.5111, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 191, Loss: 0.8567, Val Acc: 0.5156, Test Acc: 0.4444\n",
      "Seed: 43, Epoch: 192, Loss: 0.8563, Val Acc: 0.5289, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 193, Loss: 0.8531, Val Acc: 0.5289, Test Acc: 0.4267\n",
      "Seed: 43, Epoch: 194, Loss: 0.8511, Val Acc: 0.5422, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 195, Loss: 0.8499, Val Acc: 0.5244, Test Acc: 0.4489\n",
      "Seed: 43, Epoch: 196, Loss: 0.8512, Val Acc: 0.5244, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 197, Loss: 0.8524, Val Acc: 0.5156, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 198, Loss: 0.8681, Val Acc: 0.5200, Test Acc: 0.4356\n",
      "Seed: 43, Epoch: 199, Loss: 0.8608, Val Acc: 0.5289, Test Acc: 0.4400\n",
      "Seed: 43, Epoch: 200, Loss: 0.8535, Val Acc: 0.5289, Test Acc: 0.4311\n",
      "Seed: 44, Epoch: 001, Loss: 1.1094, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 002, Loss: 1.1076, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 003, Loss: 1.1062, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 004, Loss: 1.1046, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 005, Loss: 1.1030, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 006, Loss: 1.1012, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 007, Loss: 1.0991, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 008, Loss: 1.0965, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 009, Loss: 1.0938, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 010, Loss: 1.0908, Val Acc: 0.3556, Test Acc: 0.3200\n",
      "Seed: 44, Epoch: 011, Loss: 1.0877, Val Acc: 0.3911, Test Acc: 0.3778\n",
      "Seed: 44, Epoch: 012, Loss: 1.0837, Val Acc: 0.4622, Test Acc: 0.4756\n",
      "Seed: 44, Epoch: 013, Loss: 1.0791, Val Acc: 0.3956, Test Acc: 0.4622\n",
      "Seed: 44, Epoch: 014, Loss: 1.0745, Val Acc: 0.4000, Test Acc: 0.4667\n",
      "Seed: 44, Epoch: 015, Loss: 1.0677, Val Acc: 0.4044, Test Acc: 0.4711\n",
      "Seed: 44, Epoch: 016, Loss: 1.0612, Val Acc: 0.4089, Test Acc: 0.4800\n",
      "Seed: 44, Epoch: 017, Loss: 1.0530, Val Acc: 0.4178, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 018, Loss: 1.0432, Val Acc: 0.4400, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 019, Loss: 1.0329, Val Acc: 0.4489, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 020, Loss: 1.0220, Val Acc: 0.4444, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 021, Loss: 1.0122, Val Acc: 0.4844, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 022, Loss: 1.0020, Val Acc: 0.4933, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 023, Loss: 0.9944, Val Acc: 0.4889, Test Acc: 0.4844\n",
      "Seed: 44, Epoch: 024, Loss: 0.9895, Val Acc: 0.4978, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 025, Loss: 0.9803, Val Acc: 0.4933, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 026, Loss: 0.9836, Val Acc: 0.4889, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 027, Loss: 0.9764, Val Acc: 0.4889, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 028, Loss: 0.9698, Val Acc: 0.4933, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 029, Loss: 0.9674, Val Acc: 0.4711, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 030, Loss: 0.9652, Val Acc: 0.4933, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 031, Loss: 0.9615, Val Acc: 0.4889, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 032, Loss: 0.9574, Val Acc: 0.4978, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 033, Loss: 0.9492, Val Acc: 0.4889, Test Acc: 0.4756\n",
      "Seed: 44, Epoch: 034, Loss: 0.9472, Val Acc: 0.4889, Test Acc: 0.4578\n",
      "Seed: 44, Epoch: 035, Loss: 0.9508, Val Acc: 0.5022, Test Acc: 0.4444\n",
      "Seed: 44, Epoch: 036, Loss: 0.9501, Val Acc: 0.4844, Test Acc: 0.4533\n",
      "Seed: 44, Epoch: 037, Loss: 0.9424, Val Acc: 0.5022, Test Acc: 0.4667\n",
      "Seed: 44, Epoch: 038, Loss: 0.9381, Val Acc: 0.4933, Test Acc: 0.4711\n",
      "Seed: 44, Epoch: 039, Loss: 0.9362, Val Acc: 0.4800, Test Acc: 0.4533\n",
      "Seed: 44, Epoch: 040, Loss: 0.9420, Val Acc: 0.4800, Test Acc: 0.4711\n",
      "Seed: 44, Epoch: 041, Loss: 0.9402, Val Acc: 0.4844, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 042, Loss: 0.9360, Val Acc: 0.4889, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 043, Loss: 0.9332, Val Acc: 0.4933, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 044, Loss: 0.9288, Val Acc: 0.5022, Test Acc: 0.4800\n",
      "Seed: 44, Epoch: 045, Loss: 0.9339, Val Acc: 0.4933, Test Acc: 0.4756\n",
      "Seed: 44, Epoch: 046, Loss: 0.9320, Val Acc: 0.4933, Test Acc: 0.4667\n",
      "Seed: 44, Epoch: 047, Loss: 0.9275, Val Acc: 0.4933, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 048, Loss: 0.9204, Val Acc: 0.4889, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 049, Loss: 0.9187, Val Acc: 0.4933, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 050, Loss: 0.9232, Val Acc: 0.4889, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 051, Loss: 0.9201, Val Acc: 0.4844, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 052, Loss: 0.9189, Val Acc: 0.4933, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 053, Loss: 0.9204, Val Acc: 0.5067, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 054, Loss: 0.9214, Val Acc: 0.4800, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 055, Loss: 0.9153, Val Acc: 0.4933, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 056, Loss: 0.9125, Val Acc: 0.4844, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 057, Loss: 0.9118, Val Acc: 0.5067, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 058, Loss: 0.9113, Val Acc: 0.5111, Test Acc: 0.4800\n",
      "Seed: 44, Epoch: 059, Loss: 0.9168, Val Acc: 0.5067, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 060, Loss: 0.9153, Val Acc: 0.4933, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 061, Loss: 0.9086, Val Acc: 0.4844, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 062, Loss: 0.9125, Val Acc: 0.4844, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 063, Loss: 0.9122, Val Acc: 0.4933, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 064, Loss: 0.9099, Val Acc: 0.4889, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 065, Loss: 0.9107, Val Acc: 0.4933, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 066, Loss: 0.9099, Val Acc: 0.5022, Test Acc: 0.4800\n",
      "Seed: 44, Epoch: 067, Loss: 0.9089, Val Acc: 0.5022, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 068, Loss: 0.9079, Val Acc: 0.4844, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 069, Loss: 0.9114, Val Acc: 0.5022, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 070, Loss: 0.9133, Val Acc: 0.4889, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 071, Loss: 0.9146, Val Acc: 0.5067, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 072, Loss: 0.9131, Val Acc: 0.5022, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 073, Loss: 0.9124, Val Acc: 0.4844, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 074, Loss: 0.9104, Val Acc: 0.4889, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 075, Loss: 0.9076, Val Acc: 0.4711, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 076, Loss: 0.9056, Val Acc: 0.4889, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 077, Loss: 0.9028, Val Acc: 0.4844, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 078, Loss: 0.9042, Val Acc: 0.4800, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 079, Loss: 0.9090, Val Acc: 0.4978, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 080, Loss: 0.9040, Val Acc: 0.5067, Test Acc: 0.5467\n",
      "Seed: 44, Epoch: 081, Loss: 0.9029, Val Acc: 0.5067, Test Acc: 0.5644\n",
      "Seed: 44, Epoch: 082, Loss: 0.9126, Val Acc: 0.5067, Test Acc: 0.5644\n",
      "Seed: 44, Epoch: 083, Loss: 0.9086, Val Acc: 0.4933, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 084, Loss: 0.8999, Val Acc: 0.4978, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 085, Loss: 0.9002, Val Acc: 0.5022, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 086, Loss: 0.8962, Val Acc: 0.5022, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 087, Loss: 0.9008, Val Acc: 0.5067, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 088, Loss: 0.8979, Val Acc: 0.5156, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 089, Loss: 0.8995, Val Acc: 0.5111, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 090, Loss: 0.9013, Val Acc: 0.5067, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 091, Loss: 0.8983, Val Acc: 0.4978, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 092, Loss: 0.8979, Val Acc: 0.4978, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 093, Loss: 0.8980, Val Acc: 0.4889, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 094, Loss: 0.8995, Val Acc: 0.4889, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 095, Loss: 0.9043, Val Acc: 0.4889, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 096, Loss: 0.9067, Val Acc: 0.4978, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 097, Loss: 0.9108, Val Acc: 0.4844, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 098, Loss: 0.9017, Val Acc: 0.4933, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 099, Loss: 0.8966, Val Acc: 0.4667, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 100, Loss: 0.9005, Val Acc: 0.4756, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 101, Loss: 0.9001, Val Acc: 0.4889, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 102, Loss: 0.8946, Val Acc: 0.5111, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 103, Loss: 0.9003, Val Acc: 0.5111, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 104, Loss: 0.9032, Val Acc: 0.5156, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 105, Loss: 0.9013, Val Acc: 0.5022, Test Acc: 0.5378\n",
      "Seed: 44, Epoch: 106, Loss: 0.9033, Val Acc: 0.5022, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 107, Loss: 0.8968, Val Acc: 0.4978, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 108, Loss: 0.8958, Val Acc: 0.4933, Test Acc: 0.4711\n",
      "Seed: 44, Epoch: 109, Loss: 0.9024, Val Acc: 0.5156, Test Acc: 0.4756\n",
      "Seed: 44, Epoch: 110, Loss: 0.9031, Val Acc: 0.4978, Test Acc: 0.4578\n",
      "Seed: 44, Epoch: 111, Loss: 0.8937, Val Acc: 0.5111, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 112, Loss: 0.8996, Val Acc: 0.5067, Test Acc: 0.5600\n",
      "Seed: 44, Epoch: 113, Loss: 0.9070, Val Acc: 0.5111, Test Acc: 0.5556\n",
      "Seed: 44, Epoch: 114, Loss: 0.8997, Val Acc: 0.4978, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 115, Loss: 0.8907, Val Acc: 0.5022, Test Acc: 0.4667\n",
      "Seed: 44, Epoch: 116, Loss: 0.8922, Val Acc: 0.4444, Test Acc: 0.4267\n",
      "Seed: 44, Epoch: 117, Loss: 0.8906, Val Acc: 0.5067, Test Acc: 0.4800\n",
      "Seed: 44, Epoch: 118, Loss: 0.8870, Val Acc: 0.5022, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 119, Loss: 0.8897, Val Acc: 0.4978, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 120, Loss: 0.8882, Val Acc: 0.5156, Test Acc: 0.4844\n",
      "Seed: 44, Epoch: 121, Loss: 0.8908, Val Acc: 0.5111, Test Acc: 0.4800\n",
      "Seed: 44, Epoch: 122, Loss: 0.8997, Val Acc: 0.5156, Test Acc: 0.4667\n",
      "Seed: 44, Epoch: 123, Loss: 0.9004, Val Acc: 0.5200, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 124, Loss: 0.8908, Val Acc: 0.5022, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 125, Loss: 0.8816, Val Acc: 0.4800, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 126, Loss: 0.8868, Val Acc: 0.4756, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 127, Loss: 0.8990, Val Acc: 0.4711, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 128, Loss: 0.8995, Val Acc: 0.4756, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 129, Loss: 0.8855, Val Acc: 0.5156, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 130, Loss: 0.8803, Val Acc: 0.5200, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 131, Loss: 0.8904, Val Acc: 0.5200, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 132, Loss: 0.8896, Val Acc: 0.5244, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 133, Loss: 0.8809, Val Acc: 0.4889, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 134, Loss: 0.8782, Val Acc: 0.4800, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 135, Loss: 0.8801, Val Acc: 0.4844, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 136, Loss: 0.8792, Val Acc: 0.4756, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 137, Loss: 0.8777, Val Acc: 0.4800, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 138, Loss: 0.8767, Val Acc: 0.4889, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 139, Loss: 0.8763, Val Acc: 0.4800, Test Acc: 0.4978\n",
      "Seed: 44, Epoch: 140, Loss: 0.8785, Val Acc: 0.4844, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 141, Loss: 0.8769, Val Acc: 0.4889, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 142, Loss: 0.8774, Val Acc: 0.4889, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 143, Loss: 0.8786, Val Acc: 0.4889, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 144, Loss: 0.8789, Val Acc: 0.4889, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 145, Loss: 0.8736, Val Acc: 0.5111, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 146, Loss: 0.8812, Val Acc: 0.5156, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 147, Loss: 0.8809, Val Acc: 0.4978, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 148, Loss: 0.8732, Val Acc: 0.4800, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 149, Loss: 0.8720, Val Acc: 0.5022, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 150, Loss: 0.8715, Val Acc: 0.5022, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 151, Loss: 0.8744, Val Acc: 0.4933, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 152, Loss: 0.8716, Val Acc: 0.5289, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 153, Loss: 0.8740, Val Acc: 0.5111, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 154, Loss: 0.8768, Val Acc: 0.5022, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 155, Loss: 0.8796, Val Acc: 0.4933, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 156, Loss: 0.8799, Val Acc: 0.4933, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 157, Loss: 0.8753, Val Acc: 0.4933, Test Acc: 0.4800\n",
      "Seed: 44, Epoch: 158, Loss: 0.8724, Val Acc: 0.4844, Test Acc: 0.4844\n",
      "Seed: 44, Epoch: 159, Loss: 0.8734, Val Acc: 0.4889, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 160, Loss: 0.8740, Val Acc: 0.4844, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 161, Loss: 0.8730, Val Acc: 0.4844, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 162, Loss: 0.8733, Val Acc: 0.5156, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 163, Loss: 0.8736, Val Acc: 0.5244, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 164, Loss: 0.8758, Val Acc: 0.5200, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 165, Loss: 0.8767, Val Acc: 0.5200, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 166, Loss: 0.8750, Val Acc: 0.4844, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 167, Loss: 0.8744, Val Acc: 0.5067, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 168, Loss: 0.8818, Val Acc: 0.5067, Test Acc: 0.5422\n",
      "Seed: 44, Epoch: 169, Loss: 0.8830, Val Acc: 0.5022, Test Acc: 0.5600\n",
      "Seed: 44, Epoch: 170, Loss: 0.8741, Val Acc: 0.5156, Test Acc: 0.5067\n",
      "Seed: 44, Epoch: 171, Loss: 0.8801, Val Acc: 0.5111, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 172, Loss: 0.8805, Val Acc: 0.5289, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 173, Loss: 0.8778, Val Acc: 0.5156, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 174, Loss: 0.8816, Val Acc: 0.4889, Test Acc: 0.5511\n",
      "Seed: 44, Epoch: 175, Loss: 0.8812, Val Acc: 0.5022, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 176, Loss: 0.8807, Val Acc: 0.5067, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 177, Loss: 0.8793, Val Acc: 0.5156, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 178, Loss: 0.8731, Val Acc: 0.5244, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 179, Loss: 0.8720, Val Acc: 0.5200, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 180, Loss: 0.8713, Val Acc: 0.5022, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 181, Loss: 0.8734, Val Acc: 0.5022, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 182, Loss: 0.8724, Val Acc: 0.5111, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 183, Loss: 0.8766, Val Acc: 0.5200, Test Acc: 0.4800\n",
      "Seed: 44, Epoch: 184, Loss: 0.8811, Val Acc: 0.5333, Test Acc: 0.4889\n",
      "Seed: 44, Epoch: 185, Loss: 0.8778, Val Acc: 0.5022, Test Acc: 0.5200\n",
      "Seed: 44, Epoch: 186, Loss: 0.8713, Val Acc: 0.4933, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 187, Loss: 0.8734, Val Acc: 0.4800, Test Acc: 0.5289\n",
      "Seed: 44, Epoch: 188, Loss: 0.8778, Val Acc: 0.4933, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 189, Loss: 0.8805, Val Acc: 0.4933, Test Acc: 0.5333\n",
      "Seed: 44, Epoch: 190, Loss: 0.8718, Val Acc: 0.5200, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 191, Loss: 0.8691, Val Acc: 0.5200, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 192, Loss: 0.8739, Val Acc: 0.5111, Test Acc: 0.5022\n",
      "Seed: 44, Epoch: 193, Loss: 0.8758, Val Acc: 0.5022, Test Acc: 0.5156\n",
      "Seed: 44, Epoch: 194, Loss: 0.8710, Val Acc: 0.4711, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 195, Loss: 0.8761, Val Acc: 0.4800, Test Acc: 0.4933\n",
      "Seed: 44, Epoch: 196, Loss: 0.8810, Val Acc: 0.4756, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 197, Loss: 0.8710, Val Acc: 0.4889, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 198, Loss: 0.8712, Val Acc: 0.5022, Test Acc: 0.5244\n",
      "Seed: 44, Epoch: 199, Loss: 0.8751, Val Acc: 0.5200, Test Acc: 0.5111\n",
      "Seed: 44, Epoch: 200, Loss: 0.8694, Val Acc: 0.5111, Test Acc: 0.5200\n",
      "Average Time: 478.25 seconds\n",
      "Var Time: 2316.89 seconds\n",
      "Average Memory: 5490.00 MB\n",
      "Average Best Val Acc: 0.5378\n",
      "Std Best Test Acc: 0.0277\n",
      "Average Test Acc: 0.4593\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "max_nodes = 500\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"IMDB-MULTI\",\n",
    "    transform=T.Compose([T.OneHotDegree(88), T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_hosc(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc, o = dense_hoscpool(x, adj, s, mu=0.1, alpha=0.7, new_ortho=False, mask=mask)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc_aux, o_aux = dense_hoscpool(x, adj, s, mu=0.1, alpha=0.7, new_ortho=False)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_hosc().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=512, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "    model = Net_hosc().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COLLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 42, Epoch: 001, Loss: 1.1240, Val Acc: 0.3213, Test Acc: 0.3320\n",
      "Seed: 42, Epoch: 002, Loss: 1.1014, Val Acc: 0.3213, Test Acc: 0.3320\n",
      "Seed: 42, Epoch: 003, Loss: 1.0578, Val Acc: 0.3213, Test Acc: 0.3320\n",
      "Seed: 42, Epoch: 004, Loss: 0.9834, Val Acc: 0.4293, Test Acc: 0.4653\n",
      "Seed: 42, Epoch: 005, Loss: 0.8906, Val Acc: 0.6400, Test Acc: 0.6387\n",
      "Seed: 42, Epoch: 006, Loss: 0.7986, Val Acc: 0.6053, Test Acc: 0.6227\n",
      "Seed: 42, Epoch: 007, Loss: 0.7194, Val Acc: 0.6240, Test Acc: 0.6373\n",
      "Seed: 42, Epoch: 008, Loss: 0.6428, Val Acc: 0.6440, Test Acc: 0.6520\n",
      "Seed: 42, Epoch: 009, Loss: 0.5863, Val Acc: 0.6587, Test Acc: 0.6707\n",
      "Seed: 42, Epoch: 010, Loss: 0.5544, Val Acc: 0.6813, Test Acc: 0.6827\n",
      "Seed: 42, Epoch: 011, Loss: 0.5312, Val Acc: 0.6800, Test Acc: 0.6880\n",
      "Seed: 42, Epoch: 012, Loss: 0.5124, Val Acc: 0.7107, Test Acc: 0.6987\n",
      "Seed: 42, Epoch: 013, Loss: 0.4944, Val Acc: 0.7160, Test Acc: 0.7013\n",
      "Seed: 42, Epoch: 014, Loss: 0.4817, Val Acc: 0.7213, Test Acc: 0.7053\n",
      "Seed: 42, Epoch: 015, Loss: 0.4703, Val Acc: 0.7160, Test Acc: 0.7040\n",
      "Seed: 42, Epoch: 016, Loss: 0.4594, Val Acc: 0.7187, Test Acc: 0.7040\n",
      "Seed: 42, Epoch: 017, Loss: 0.4483, Val Acc: 0.7293, Test Acc: 0.7093\n",
      "Seed: 42, Epoch: 018, Loss: 0.4389, Val Acc: 0.7467, Test Acc: 0.7173\n",
      "Seed: 42, Epoch: 019, Loss: 0.4321, Val Acc: 0.7373, Test Acc: 0.7200\n",
      "Seed: 42, Epoch: 020, Loss: 0.4262, Val Acc: 0.7520, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 021, Loss: 0.4153, Val Acc: 0.7747, Test Acc: 0.7493\n",
      "Seed: 42, Epoch: 022, Loss: 0.4076, Val Acc: 0.7800, Test Acc: 0.7493\n",
      "Seed: 42, Epoch: 023, Loss: 0.4015, Val Acc: 0.7813, Test Acc: 0.7507\n",
      "Seed: 42, Epoch: 024, Loss: 0.3975, Val Acc: 0.7867, Test Acc: 0.7413\n",
      "Seed: 42, Epoch: 025, Loss: 0.3898, Val Acc: 0.7840, Test Acc: 0.7507\n",
      "Seed: 42, Epoch: 026, Loss: 0.3845, Val Acc: 0.7813, Test Acc: 0.7507\n",
      "Seed: 42, Epoch: 027, Loss: 0.3789, Val Acc: 0.7880, Test Acc: 0.7480\n",
      "Seed: 42, Epoch: 028, Loss: 0.3756, Val Acc: 0.7840, Test Acc: 0.7587\n",
      "Seed: 42, Epoch: 029, Loss: 0.3738, Val Acc: 0.7760, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 030, Loss: 0.3674, Val Acc: 0.7893, Test Acc: 0.7440\n",
      "Seed: 42, Epoch: 031, Loss: 0.3668, Val Acc: 0.7747, Test Acc: 0.7360\n",
      "Seed: 42, Epoch: 032, Loss: 0.3594, Val Acc: 0.7853, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 033, Loss: 0.3548, Val Acc: 0.7947, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 034, Loss: 0.3478, Val Acc: 0.7827, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 035, Loss: 0.3449, Val Acc: 0.7880, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 036, Loss: 0.3392, Val Acc: 0.7947, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 037, Loss: 0.3356, Val Acc: 0.7933, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 038, Loss: 0.3331, Val Acc: 0.7947, Test Acc: 0.7573\n",
      "Seed: 42, Epoch: 039, Loss: 0.3293, Val Acc: 0.7853, Test Acc: 0.7547\n",
      "Seed: 42, Epoch: 040, Loss: 0.3268, Val Acc: 0.7933, Test Acc: 0.7587\n",
      "Seed: 42, Epoch: 041, Loss: 0.3192, Val Acc: 0.7880, Test Acc: 0.7640\n",
      "Seed: 42, Epoch: 042, Loss: 0.3158, Val Acc: 0.7933, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 043, Loss: 0.3128, Val Acc: 0.7773, Test Acc: 0.7547\n",
      "Seed: 42, Epoch: 044, Loss: 0.3136, Val Acc: 0.7787, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 045, Loss: 0.3061, Val Acc: 0.7787, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 046, Loss: 0.3087, Val Acc: 0.7893, Test Acc: 0.7640\n",
      "Seed: 42, Epoch: 047, Loss: 0.3012, Val Acc: 0.7840, Test Acc: 0.7587\n",
      "Seed: 42, Epoch: 048, Loss: 0.2947, Val Acc: 0.7893, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 049, Loss: 0.2903, Val Acc: 0.7813, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 050, Loss: 0.2885, Val Acc: 0.7907, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 051, Loss: 0.2868, Val Acc: 0.7933, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 052, Loss: 0.2819, Val Acc: 0.7907, Test Acc: 0.7587\n",
      "Seed: 42, Epoch: 053, Loss: 0.2805, Val Acc: 0.7827, Test Acc: 0.7547\n",
      "Seed: 42, Epoch: 054, Loss: 0.2740, Val Acc: 0.7947, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 055, Loss: 0.2678, Val Acc: 0.7933, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 056, Loss: 0.2698, Val Acc: 0.8000, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 057, Loss: 0.2686, Val Acc: 0.7947, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 058, Loss: 0.2626, Val Acc: 0.7920, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 059, Loss: 0.2563, Val Acc: 0.7960, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 060, Loss: 0.2577, Val Acc: 0.7933, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 061, Loss: 0.2464, Val Acc: 0.8080, Test Acc: 0.7533\n",
      "Seed: 42, Epoch: 062, Loss: 0.2471, Val Acc: 0.7893, Test Acc: 0.7587\n",
      "Seed: 42, Epoch: 063, Loss: 0.2486, Val Acc: 0.7973, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 064, Loss: 0.2397, Val Acc: 0.7987, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 065, Loss: 0.2377, Val Acc: 0.7907, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 066, Loss: 0.2358, Val Acc: 0.8027, Test Acc: 0.7640\n",
      "Seed: 42, Epoch: 067, Loss: 0.2287, Val Acc: 0.7987, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 068, Loss: 0.2240, Val Acc: 0.7973, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 069, Loss: 0.2221, Val Acc: 0.7973, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 070, Loss: 0.2182, Val Acc: 0.7867, Test Acc: 0.7467\n",
      "Seed: 42, Epoch: 071, Loss: 0.2146, Val Acc: 0.7800, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 072, Loss: 0.2124, Val Acc: 0.8053, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 073, Loss: 0.2087, Val Acc: 0.8027, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 074, Loss: 0.2137, Val Acc: 0.8093, Test Acc: 0.7707\n",
      "Seed: 42, Epoch: 075, Loss: 0.2088, Val Acc: 0.7867, Test Acc: 0.7867\n",
      "Seed: 42, Epoch: 076, Loss: 0.2073, Val Acc: 0.7920, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 077, Loss: 0.2049, Val Acc: 0.8040, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 078, Loss: 0.1993, Val Acc: 0.7880, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 079, Loss: 0.1955, Val Acc: 0.8013, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 080, Loss: 0.1927, Val Acc: 0.7880, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 081, Loss: 0.1900, Val Acc: 0.8027, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 082, Loss: 0.1867, Val Acc: 0.7800, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 083, Loss: 0.1830, Val Acc: 0.7960, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 084, Loss: 0.1821, Val Acc: 0.7880, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 085, Loss: 0.1801, Val Acc: 0.7840, Test Acc: 0.7853\n",
      "Seed: 42, Epoch: 086, Loss: 0.1821, Val Acc: 0.7853, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 087, Loss: 0.1767, Val Acc: 0.7853, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 088, Loss: 0.1701, Val Acc: 0.7880, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 089, Loss: 0.1716, Val Acc: 0.7813, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 090, Loss: 0.1755, Val Acc: 0.8027, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 091, Loss: 0.1777, Val Acc: 0.7880, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 092, Loss: 0.1765, Val Acc: 0.7920, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 093, Loss: 0.1716, Val Acc: 0.8053, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 094, Loss: 0.1732, Val Acc: 0.8000, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 095, Loss: 0.1708, Val Acc: 0.8053, Test Acc: 0.7587\n",
      "Seed: 42, Epoch: 096, Loss: 0.1719, Val Acc: 0.7893, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 097, Loss: 0.1681, Val Acc: 0.7987, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 098, Loss: 0.1627, Val Acc: 0.7973, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 099, Loss: 0.1636, Val Acc: 0.7907, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 100, Loss: 0.1647, Val Acc: 0.7920, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 101, Loss: 0.1598, Val Acc: 0.7893, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 102, Loss: 0.1678, Val Acc: 0.8027, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 103, Loss: 0.1693, Val Acc: 0.7907, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 104, Loss: 0.1678, Val Acc: 0.7987, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 105, Loss: 0.1682, Val Acc: 0.7907, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 106, Loss: 0.1672, Val Acc: 0.7960, Test Acc: 0.7787\n",
      "Seed: 42, Epoch: 107, Loss: 0.1629, Val Acc: 0.8027, Test Acc: 0.7880\n",
      "Seed: 42, Epoch: 108, Loss: 0.1655, Val Acc: 0.7747, Test Acc: 0.7960\n",
      "Seed: 42, Epoch: 109, Loss: 0.1527, Val Acc: 0.7893, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 110, Loss: 0.1522, Val Acc: 0.7813, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 111, Loss: 0.1444, Val Acc: 0.7960, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 112, Loss: 0.1415, Val Acc: 0.7920, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 113, Loss: 0.1434, Val Acc: 0.7707, Test Acc: 0.7707\n",
      "Seed: 42, Epoch: 114, Loss: 0.1414, Val Acc: 0.7947, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 115, Loss: 0.1385, Val Acc: 0.7813, Test Acc: 0.7853\n",
      "Seed: 42, Epoch: 116, Loss: 0.1357, Val Acc: 0.7933, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 117, Loss: 0.1382, Val Acc: 0.7880, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 118, Loss: 0.1303, Val Acc: 0.8000, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 119, Loss: 0.1287, Val Acc: 0.7893, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 120, Loss: 0.1368, Val Acc: 0.7800, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 121, Loss: 0.1283, Val Acc: 0.7907, Test Acc: 0.7707\n",
      "Seed: 42, Epoch: 122, Loss: 0.1249, Val Acc: 0.7680, Test Acc: 0.7427\n",
      "Seed: 42, Epoch: 123, Loss: 0.1306, Val Acc: 0.7933, Test Acc: 0.7640\n",
      "Seed: 42, Epoch: 124, Loss: 0.1308, Val Acc: 0.7867, Test Acc: 0.7520\n",
      "Seed: 42, Epoch: 125, Loss: 0.1481, Val Acc: 0.7800, Test Acc: 0.7600\n",
      "Seed: 42, Epoch: 126, Loss: 0.1591, Val Acc: 0.8040, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 127, Loss: 0.1559, Val Acc: 0.7840, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 128, Loss: 0.1525, Val Acc: 0.7840, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 129, Loss: 0.1510, Val Acc: 0.8080, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 130, Loss: 0.1428, Val Acc: 0.7960, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 131, Loss: 0.1337, Val Acc: 0.7907, Test Acc: 0.7573\n",
      "Seed: 42, Epoch: 132, Loss: 0.1302, Val Acc: 0.7907, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 133, Loss: 0.1220, Val Acc: 0.7973, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 134, Loss: 0.1212, Val Acc: 0.8040, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 135, Loss: 0.1146, Val Acc: 0.8160, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 136, Loss: 0.1218, Val Acc: 0.8093, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 137, Loss: 0.1200, Val Acc: 0.7827, Test Acc: 0.7640\n",
      "Seed: 42, Epoch: 138, Loss: 0.1158, Val Acc: 0.8013, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 139, Loss: 0.1148, Val Acc: 0.7987, Test Acc: 0.7707\n",
      "Seed: 42, Epoch: 140, Loss: 0.1145, Val Acc: 0.7920, Test Acc: 0.7573\n",
      "Seed: 42, Epoch: 141, Loss: 0.1135, Val Acc: 0.7893, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 142, Loss: 0.1214, Val Acc: 0.7973, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 143, Loss: 0.1196, Val Acc: 0.8093, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 144, Loss: 0.1191, Val Acc: 0.7933, Test Acc: 0.7707\n",
      "Seed: 42, Epoch: 145, Loss: 0.1207, Val Acc: 0.7787, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 146, Loss: 0.1204, Val Acc: 0.7893, Test Acc: 0.7813\n",
      "Seed: 42, Epoch: 147, Loss: 0.1187, Val Acc: 0.8013, Test Acc: 0.7707\n",
      "Seed: 42, Epoch: 148, Loss: 0.1121, Val Acc: 0.8013, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 149, Loss: 0.1111, Val Acc: 0.7947, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 150, Loss: 0.1032, Val Acc: 0.8000, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 151, Loss: 0.1042, Val Acc: 0.8027, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 152, Loss: 0.1051, Val Acc: 0.8067, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 153, Loss: 0.1030, Val Acc: 0.8000, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 154, Loss: 0.1033, Val Acc: 0.7893, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 155, Loss: 0.1003, Val Acc: 0.7840, Test Acc: 0.7693\n",
      "Seed: 42, Epoch: 156, Loss: 0.1032, Val Acc: 0.7933, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 157, Loss: 0.0985, Val Acc: 0.8013, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 158, Loss: 0.1021, Val Acc: 0.8027, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 159, Loss: 0.0987, Val Acc: 0.8107, Test Acc: 0.7787\n",
      "Seed: 42, Epoch: 160, Loss: 0.0974, Val Acc: 0.8040, Test Acc: 0.7787\n",
      "Seed: 42, Epoch: 161, Loss: 0.0978, Val Acc: 0.7947, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 162, Loss: 0.0987, Val Acc: 0.8000, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 163, Loss: 0.0965, Val Acc: 0.7933, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 164, Loss: 0.0931, Val Acc: 0.7947, Test Acc: 0.7813\n",
      "Seed: 42, Epoch: 165, Loss: 0.0959, Val Acc: 0.7920, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 166, Loss: 0.0930, Val Acc: 0.8027, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 167, Loss: 0.0922, Val Acc: 0.8080, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 168, Loss: 0.0941, Val Acc: 0.8120, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 169, Loss: 0.0948, Val Acc: 0.8053, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 170, Loss: 0.0949, Val Acc: 0.7920, Test Acc: 0.7733\n",
      "Seed: 42, Epoch: 171, Loss: 0.0891, Val Acc: 0.8080, Test Acc: 0.7707\n",
      "Seed: 42, Epoch: 172, Loss: 0.0873, Val Acc: 0.8093, Test Acc: 0.7787\n",
      "Seed: 42, Epoch: 173, Loss: 0.0914, Val Acc: 0.8093, Test Acc: 0.7760\n",
      "Seed: 42, Epoch: 174, Loss: 0.0941, Val Acc: 0.8133, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 175, Loss: 0.0897, Val Acc: 0.7907, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 176, Loss: 0.0926, Val Acc: 0.8000, Test Acc: 0.7800\n",
      "Seed: 42, Epoch: 177, Loss: 0.0929, Val Acc: 0.7960, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 178, Loss: 0.0866, Val Acc: 0.7933, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 179, Loss: 0.0882, Val Acc: 0.8067, Test Acc: 0.7560\n",
      "Seed: 42, Epoch: 180, Loss: 0.0883, Val Acc: 0.8053, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 181, Loss: 0.0843, Val Acc: 0.8120, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 182, Loss: 0.0876, Val Acc: 0.7987, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 183, Loss: 0.0891, Val Acc: 0.7933, Test Acc: 0.7667\n",
      "Seed: 42, Epoch: 184, Loss: 0.1042, Val Acc: 0.8000, Test Acc: 0.7640\n",
      "Seed: 42, Epoch: 185, Loss: 0.1153, Val Acc: 0.7960, Test Acc: 0.7493\n",
      "Seed: 42, Epoch: 186, Loss: 0.1326, Val Acc: 0.7893, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 187, Loss: 0.1275, Val Acc: 0.7907, Test Acc: 0.7747\n",
      "Seed: 42, Epoch: 188, Loss: 0.1184, Val Acc: 0.8027, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 189, Loss: 0.1335, Val Acc: 0.7880, Test Acc: 0.7720\n",
      "Seed: 42, Epoch: 190, Loss: 0.1214, Val Acc: 0.7960, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 191, Loss: 0.1134, Val Acc: 0.7773, Test Acc: 0.7627\n",
      "Seed: 42, Epoch: 192, Loss: 0.1078, Val Acc: 0.7907, Test Acc: 0.7653\n",
      "Seed: 42, Epoch: 193, Loss: 0.1093, Val Acc: 0.8013, Test Acc: 0.7827\n",
      "Seed: 42, Epoch: 194, Loss: 0.1048, Val Acc: 0.8067, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 195, Loss: 0.1061, Val Acc: 0.8053, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 196, Loss: 0.1033, Val Acc: 0.8067, Test Acc: 0.7613\n",
      "Seed: 42, Epoch: 197, Loss: 0.1002, Val Acc: 0.8133, Test Acc: 0.7773\n",
      "Seed: 42, Epoch: 198, Loss: 0.0970, Val Acc: 0.7987, Test Acc: 0.7680\n",
      "Seed: 42, Epoch: 199, Loss: 0.0931, Val Acc: 0.7973, Test Acc: 0.7547\n",
      "Seed: 42, Epoch: 200, Loss: 0.0882, Val Acc: 0.8027, Test Acc: 0.7693\n",
      "Seed: 43, Epoch: 001, Loss: 1.1350, Val Acc: 0.1507, Test Acc: 0.1533\n",
      "Seed: 43, Epoch: 002, Loss: 1.0961, Val Acc: 0.2973, Test Acc: 0.2920\n",
      "Seed: 43, Epoch: 003, Loss: 1.0316, Val Acc: 0.5560, Test Acc: 0.5627\n",
      "Seed: 43, Epoch: 004, Loss: 0.9401, Val Acc: 0.5667, Test Acc: 0.5760\n",
      "Seed: 43, Epoch: 005, Loss: 0.8410, Val Acc: 0.5760, Test Acc: 0.5827\n",
      "Seed: 43, Epoch: 006, Loss: 0.7655, Val Acc: 0.6400, Test Acc: 0.6307\n",
      "Seed: 43, Epoch: 007, Loss: 0.6974, Val Acc: 0.6693, Test Acc: 0.6467\n",
      "Seed: 43, Epoch: 008, Loss: 0.6377, Val Acc: 0.6787, Test Acc: 0.6720\n",
      "Seed: 43, Epoch: 009, Loss: 0.5993, Val Acc: 0.6880, Test Acc: 0.6813\n",
      "Seed: 43, Epoch: 010, Loss: 0.5711, Val Acc: 0.7200, Test Acc: 0.7227\n",
      "Seed: 43, Epoch: 011, Loss: 0.5505, Val Acc: 0.7227, Test Acc: 0.7253\n",
      "Seed: 43, Epoch: 012, Loss: 0.5296, Val Acc: 0.7240, Test Acc: 0.7280\n",
      "Seed: 43, Epoch: 013, Loss: 0.5141, Val Acc: 0.7213, Test Acc: 0.7240\n",
      "Seed: 43, Epoch: 014, Loss: 0.5019, Val Acc: 0.7413, Test Acc: 0.7440\n",
      "Seed: 43, Epoch: 015, Loss: 0.4897, Val Acc: 0.7493, Test Acc: 0.7360\n",
      "Seed: 43, Epoch: 016, Loss: 0.4798, Val Acc: 0.7640, Test Acc: 0.7453\n",
      "Seed: 43, Epoch: 017, Loss: 0.4670, Val Acc: 0.7680, Test Acc: 0.7480\n",
      "Seed: 43, Epoch: 018, Loss: 0.4591, Val Acc: 0.7787, Test Acc: 0.7333\n",
      "Seed: 43, Epoch: 019, Loss: 0.4514, Val Acc: 0.7773, Test Acc: 0.7440\n",
      "Seed: 43, Epoch: 020, Loss: 0.4418, Val Acc: 0.7707, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 021, Loss: 0.4329, Val Acc: 0.7800, Test Acc: 0.7560\n",
      "Seed: 43, Epoch: 022, Loss: 0.4259, Val Acc: 0.7840, Test Acc: 0.7640\n",
      "Seed: 43, Epoch: 023, Loss: 0.4193, Val Acc: 0.7853, Test Acc: 0.7547\n",
      "Seed: 43, Epoch: 024, Loss: 0.4155, Val Acc: 0.7827, Test Acc: 0.7467\n",
      "Seed: 43, Epoch: 025, Loss: 0.4110, Val Acc: 0.7920, Test Acc: 0.7840\n",
      "Seed: 43, Epoch: 026, Loss: 0.4012, Val Acc: 0.7800, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 027, Loss: 0.3994, Val Acc: 0.7853, Test Acc: 0.7733\n",
      "Seed: 43, Epoch: 028, Loss: 0.3908, Val Acc: 0.7893, Test Acc: 0.7627\n",
      "Seed: 43, Epoch: 029, Loss: 0.3886, Val Acc: 0.7853, Test Acc: 0.7773\n",
      "Seed: 43, Epoch: 030, Loss: 0.3826, Val Acc: 0.7787, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 031, Loss: 0.3809, Val Acc: 0.7853, Test Acc: 0.7720\n",
      "Seed: 43, Epoch: 032, Loss: 0.3739, Val Acc: 0.7893, Test Acc: 0.7667\n",
      "Seed: 43, Epoch: 033, Loss: 0.3690, Val Acc: 0.7907, Test Acc: 0.7787\n",
      "Seed: 43, Epoch: 034, Loss: 0.3640, Val Acc: 0.7893, Test Acc: 0.7773\n",
      "Seed: 43, Epoch: 035, Loss: 0.3600, Val Acc: 0.7893, Test Acc: 0.7840\n",
      "Seed: 43, Epoch: 036, Loss: 0.3519, Val Acc: 0.7947, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 037, Loss: 0.3452, Val Acc: 0.7973, Test Acc: 0.7853\n",
      "Seed: 43, Epoch: 038, Loss: 0.3407, Val Acc: 0.7920, Test Acc: 0.7840\n",
      "Seed: 43, Epoch: 039, Loss: 0.3410, Val Acc: 0.7947, Test Acc: 0.7827\n",
      "Seed: 43, Epoch: 040, Loss: 0.3351, Val Acc: 0.7800, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 041, Loss: 0.3284, Val Acc: 0.7947, Test Acc: 0.7853\n",
      "Seed: 43, Epoch: 042, Loss: 0.3246, Val Acc: 0.7947, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 043, Loss: 0.3192, Val Acc: 0.7933, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 044, Loss: 0.3141, Val Acc: 0.7907, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 045, Loss: 0.3094, Val Acc: 0.7987, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 046, Loss: 0.3084, Val Acc: 0.7920, Test Acc: 0.7840\n",
      "Seed: 43, Epoch: 047, Loss: 0.3039, Val Acc: 0.7960, Test Acc: 0.7853\n",
      "Seed: 43, Epoch: 048, Loss: 0.3000, Val Acc: 0.7893, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 049, Loss: 0.2930, Val Acc: 0.7947, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 050, Loss: 0.2934, Val Acc: 0.7947, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 051, Loss: 0.2859, Val Acc: 0.7787, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 052, Loss: 0.2828, Val Acc: 0.7773, Test Acc: 0.7853\n",
      "Seed: 43, Epoch: 053, Loss: 0.2778, Val Acc: 0.7973, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 054, Loss: 0.2682, Val Acc: 0.7920, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 055, Loss: 0.2711, Val Acc: 0.7787, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 056, Loss: 0.2766, Val Acc: 0.7867, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 057, Loss: 0.2736, Val Acc: 0.7813, Test Acc: 0.7880\n",
      "Seed: 43, Epoch: 058, Loss: 0.2692, Val Acc: 0.7800, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 059, Loss: 0.2675, Val Acc: 0.7933, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 060, Loss: 0.2643, Val Acc: 0.7840, Test Acc: 0.7813\n",
      "Seed: 43, Epoch: 061, Loss: 0.2580, Val Acc: 0.7987, Test Acc: 0.7840\n",
      "Seed: 43, Epoch: 062, Loss: 0.2556, Val Acc: 0.7813, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 063, Loss: 0.2516, Val Acc: 0.7947, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 064, Loss: 0.2571, Val Acc: 0.7813, Test Acc: 0.7853\n",
      "Seed: 43, Epoch: 065, Loss: 0.2584, Val Acc: 0.7813, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 066, Loss: 0.2644, Val Acc: 0.7907, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 067, Loss: 0.2486, Val Acc: 0.7893, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 068, Loss: 0.2441, Val Acc: 0.7853, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 069, Loss: 0.2384, Val Acc: 0.7893, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 070, Loss: 0.2328, Val Acc: 0.7907, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 071, Loss: 0.2280, Val Acc: 0.7933, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 072, Loss: 0.2201, Val Acc: 0.7947, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 073, Loss: 0.2133, Val Acc: 0.7853, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 074, Loss: 0.2155, Val Acc: 0.8067, Test Acc: 0.7880\n",
      "Seed: 43, Epoch: 075, Loss: 0.2121, Val Acc: 0.7920, Test Acc: 0.7880\n",
      "Seed: 43, Epoch: 076, Loss: 0.2075, Val Acc: 0.8040, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 077, Loss: 0.2020, Val Acc: 0.7880, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 078, Loss: 0.2043, Val Acc: 0.8000, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 079, Loss: 0.2096, Val Acc: 0.7773, Test Acc: 0.7747\n",
      "Seed: 43, Epoch: 080, Loss: 0.2082, Val Acc: 0.7920, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 081, Loss: 0.2013, Val Acc: 0.8173, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 082, Loss: 0.1983, Val Acc: 0.7933, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 083, Loss: 0.1905, Val Acc: 0.7987, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 084, Loss: 0.1879, Val Acc: 0.8013, Test Acc: 0.7840\n",
      "Seed: 43, Epoch: 085, Loss: 0.1821, Val Acc: 0.8053, Test Acc: 0.8093\n",
      "Seed: 43, Epoch: 086, Loss: 0.1830, Val Acc: 0.8013, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 087, Loss: 0.1757, Val Acc: 0.8013, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 088, Loss: 0.1754, Val Acc: 0.7920, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 089, Loss: 0.1790, Val Acc: 0.7933, Test Acc: 0.7853\n",
      "Seed: 43, Epoch: 090, Loss: 0.1777, Val Acc: 0.7907, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 091, Loss: 0.1825, Val Acc: 0.7987, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 092, Loss: 0.1818, Val Acc: 0.7920, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 093, Loss: 0.1852, Val Acc: 0.8040, Test Acc: 0.8093\n",
      "Seed: 43, Epoch: 094, Loss: 0.1867, Val Acc: 0.8027, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 095, Loss: 0.1803, Val Acc: 0.7800, Test Acc: 0.7853\n",
      "Seed: 43, Epoch: 096, Loss: 0.1740, Val Acc: 0.7960, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 097, Loss: 0.1664, Val Acc: 0.8133, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 098, Loss: 0.1660, Val Acc: 0.8133, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 099, Loss: 0.1622, Val Acc: 0.7840, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 100, Loss: 0.1573, Val Acc: 0.7893, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 101, Loss: 0.1577, Val Acc: 0.7947, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 102, Loss: 0.1561, Val Acc: 0.7973, Test Acc: 0.8160\n",
      "Seed: 43, Epoch: 103, Loss: 0.1599, Val Acc: 0.7920, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 104, Loss: 0.1569, Val Acc: 0.7960, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 105, Loss: 0.1586, Val Acc: 0.7827, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 106, Loss: 0.1610, Val Acc: 0.7947, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 107, Loss: 0.1625, Val Acc: 0.8013, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 108, Loss: 0.1689, Val Acc: 0.7880, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 109, Loss: 0.1671, Val Acc: 0.8040, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 110, Loss: 0.1669, Val Acc: 0.8027, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 111, Loss: 0.1735, Val Acc: 0.7747, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 112, Loss: 0.1739, Val Acc: 0.8067, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 113, Loss: 0.1667, Val Acc: 0.8040, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 114, Loss: 0.1654, Val Acc: 0.7920, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 115, Loss: 0.1564, Val Acc: 0.8000, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 116, Loss: 0.1633, Val Acc: 0.7867, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 117, Loss: 0.1541, Val Acc: 0.7867, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 118, Loss: 0.1534, Val Acc: 0.7987, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 119, Loss: 0.1502, Val Acc: 0.8027, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 120, Loss: 0.1456, Val Acc: 0.7987, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 121, Loss: 0.1415, Val Acc: 0.7907, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 122, Loss: 0.1422, Val Acc: 0.7987, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 123, Loss: 0.1398, Val Acc: 0.8080, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 124, Loss: 0.1430, Val Acc: 0.8080, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 125, Loss: 0.1377, Val Acc: 0.8187, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 126, Loss: 0.1332, Val Acc: 0.8147, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 127, Loss: 0.1335, Val Acc: 0.7893, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 128, Loss: 0.1308, Val Acc: 0.7973, Test Acc: 0.8080\n",
      "Seed: 43, Epoch: 129, Loss: 0.1307, Val Acc: 0.8093, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 130, Loss: 0.1370, Val Acc: 0.8067, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 131, Loss: 0.1410, Val Acc: 0.8120, Test Acc: 0.7853\n",
      "Seed: 43, Epoch: 132, Loss: 0.1421, Val Acc: 0.7867, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 133, Loss: 0.1386, Val Acc: 0.7800, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 134, Loss: 0.1495, Val Acc: 0.7933, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 135, Loss: 0.1498, Val Acc: 0.7893, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 136, Loss: 0.1459, Val Acc: 0.7907, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 137, Loss: 0.1397, Val Acc: 0.7853, Test Acc: 0.7867\n",
      "Seed: 43, Epoch: 138, Loss: 0.1406, Val Acc: 0.7720, Test Acc: 0.7853\n",
      "Seed: 43, Epoch: 139, Loss: 0.1381, Val Acc: 0.7880, Test Acc: 0.7880\n",
      "Seed: 43, Epoch: 140, Loss: 0.1434, Val Acc: 0.7973, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 141, Loss: 0.1366, Val Acc: 0.7933, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 142, Loss: 0.1305, Val Acc: 0.7867, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 143, Loss: 0.1254, Val Acc: 0.7960, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 144, Loss: 0.1278, Val Acc: 0.8027, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 145, Loss: 0.1212, Val Acc: 0.7853, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 146, Loss: 0.1281, Val Acc: 0.7973, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 147, Loss: 0.1269, Val Acc: 0.8000, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 148, Loss: 0.1267, Val Acc: 0.7947, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 149, Loss: 0.1286, Val Acc: 0.8080, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 150, Loss: 0.1218, Val Acc: 0.7920, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 151, Loss: 0.1214, Val Acc: 0.7813, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 152, Loss: 0.1210, Val Acc: 0.7933, Test Acc: 0.8093\n",
      "Seed: 43, Epoch: 153, Loss: 0.1193, Val Acc: 0.7947, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 154, Loss: 0.1213, Val Acc: 0.8027, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 155, Loss: 0.1179, Val Acc: 0.7920, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 156, Loss: 0.1198, Val Acc: 0.7960, Test Acc: 0.8160\n",
      "Seed: 43, Epoch: 157, Loss: 0.1212, Val Acc: 0.7973, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 158, Loss: 0.1158, Val Acc: 0.7947, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 159, Loss: 0.1141, Val Acc: 0.7960, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 160, Loss: 0.1170, Val Acc: 0.7960, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 161, Loss: 0.1198, Val Acc: 0.8053, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 162, Loss: 0.1164, Val Acc: 0.8187, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 163, Loss: 0.1162, Val Acc: 0.8040, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 164, Loss: 0.1209, Val Acc: 0.8000, Test Acc: 0.7853\n",
      "Seed: 43, Epoch: 165, Loss: 0.1158, Val Acc: 0.8040, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 166, Loss: 0.1136, Val Acc: 0.7947, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 167, Loss: 0.1137, Val Acc: 0.7960, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 168, Loss: 0.1168, Val Acc: 0.7800, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 169, Loss: 0.1188, Val Acc: 0.7733, Test Acc: 0.7800\n",
      "Seed: 43, Epoch: 170, Loss: 0.1324, Val Acc: 0.7827, Test Acc: 0.7880\n",
      "Seed: 43, Epoch: 171, Loss: 0.1217, Val Acc: 0.7840, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 172, Loss: 0.1285, Val Acc: 0.7947, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 173, Loss: 0.1212, Val Acc: 0.7773, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 174, Loss: 0.1156, Val Acc: 0.7880, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 175, Loss: 0.1195, Val Acc: 0.8040, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 176, Loss: 0.1127, Val Acc: 0.7987, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 177, Loss: 0.1107, Val Acc: 0.7733, Test Acc: 0.8000\n",
      "Seed: 43, Epoch: 178, Loss: 0.1109, Val Acc: 0.7893, Test Acc: 0.8053\n",
      "Seed: 43, Epoch: 179, Loss: 0.1100, Val Acc: 0.7973, Test Acc: 0.7960\n",
      "Seed: 43, Epoch: 180, Loss: 0.1082, Val Acc: 0.7920, Test Acc: 0.8027\n",
      "Seed: 43, Epoch: 181, Loss: 0.1073, Val Acc: 0.8027, Test Acc: 0.8160\n",
      "Seed: 43, Epoch: 182, Loss: 0.1054, Val Acc: 0.8027, Test Acc: 0.8173\n",
      "Seed: 43, Epoch: 183, Loss: 0.1028, Val Acc: 0.8067, Test Acc: 0.8040\n",
      "Seed: 43, Epoch: 184, Loss: 0.1026, Val Acc: 0.7973, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 185, Loss: 0.1026, Val Acc: 0.7920, Test Acc: 0.8120\n",
      "Seed: 43, Epoch: 186, Loss: 0.0989, Val Acc: 0.8040, Test Acc: 0.8120\n",
      "Seed: 43, Epoch: 187, Loss: 0.1024, Val Acc: 0.8000, Test Acc: 0.8093\n",
      "Seed: 43, Epoch: 188, Loss: 0.1010, Val Acc: 0.7933, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 189, Loss: 0.1000, Val Acc: 0.7893, Test Acc: 0.7907\n",
      "Seed: 43, Epoch: 190, Loss: 0.0978, Val Acc: 0.8053, Test Acc: 0.8067\n",
      "Seed: 43, Epoch: 191, Loss: 0.0965, Val Acc: 0.8040, Test Acc: 0.8013\n",
      "Seed: 43, Epoch: 192, Loss: 0.0959, Val Acc: 0.8067, Test Acc: 0.7933\n",
      "Seed: 43, Epoch: 193, Loss: 0.0994, Val Acc: 0.7893, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 194, Loss: 0.0974, Val Acc: 0.7973, Test Acc: 0.7920\n",
      "Seed: 43, Epoch: 195, Loss: 0.1019, Val Acc: 0.7880, Test Acc: 0.7947\n",
      "Seed: 43, Epoch: 196, Loss: 0.1040, Val Acc: 0.8000, Test Acc: 0.8093\n",
      "Seed: 43, Epoch: 197, Loss: 0.0977, Val Acc: 0.7973, Test Acc: 0.7987\n",
      "Seed: 43, Epoch: 198, Loss: 0.1063, Val Acc: 0.7853, Test Acc: 0.7893\n",
      "Seed: 43, Epoch: 199, Loss: 0.1043, Val Acc: 0.7773, Test Acc: 0.7973\n",
      "Seed: 43, Epoch: 200, Loss: 0.1060, Val Acc: 0.7800, Test Acc: 0.7987\n",
      "Seed: 44, Epoch: 001, Loss: 1.0857, Val Acc: 0.3587, Test Acc: 0.3320\n",
      "Seed: 44, Epoch: 002, Loss: 1.0649, Val Acc: 0.6413, Test Acc: 0.6200\n",
      "Seed: 44, Epoch: 003, Loss: 1.0320, Val Acc: 0.6160, Test Acc: 0.6347\n",
      "Seed: 44, Epoch: 004, Loss: 0.9833, Val Acc: 0.6320, Test Acc: 0.6453\n",
      "Seed: 44, Epoch: 005, Loss: 0.9179, Val Acc: 0.6387, Test Acc: 0.6587\n",
      "Seed: 44, Epoch: 006, Loss: 0.8419, Val Acc: 0.6427, Test Acc: 0.6640\n",
      "Seed: 44, Epoch: 007, Loss: 0.7609, Val Acc: 0.6467, Test Acc: 0.6640\n",
      "Seed: 44, Epoch: 008, Loss: 0.6919, Val Acc: 0.6613, Test Acc: 0.6693\n",
      "Seed: 44, Epoch: 009, Loss: 0.6459, Val Acc: 0.7000, Test Acc: 0.7080\n",
      "Seed: 44, Epoch: 010, Loss: 0.6090, Val Acc: 0.7160, Test Acc: 0.7093\n",
      "Seed: 44, Epoch: 011, Loss: 0.5826, Val Acc: 0.7293, Test Acc: 0.7160\n",
      "Seed: 44, Epoch: 012, Loss: 0.5622, Val Acc: 0.7320, Test Acc: 0.7173\n",
      "Seed: 44, Epoch: 013, Loss: 0.5444, Val Acc: 0.7267, Test Acc: 0.7147\n",
      "Seed: 44, Epoch: 014, Loss: 0.5269, Val Acc: 0.7293, Test Acc: 0.7160\n",
      "Seed: 44, Epoch: 015, Loss: 0.5178, Val Acc: 0.7267, Test Acc: 0.7187\n",
      "Seed: 44, Epoch: 016, Loss: 0.5061, Val Acc: 0.7293, Test Acc: 0.7160\n",
      "Seed: 44, Epoch: 017, Loss: 0.4937, Val Acc: 0.7253, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 018, Loss: 0.4814, Val Acc: 0.7293, Test Acc: 0.7200\n",
      "Seed: 44, Epoch: 019, Loss: 0.4715, Val Acc: 0.7320, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 020, Loss: 0.4637, Val Acc: 0.7307, Test Acc: 0.7293\n",
      "Seed: 44, Epoch: 021, Loss: 0.4572, Val Acc: 0.7253, Test Acc: 0.7240\n",
      "Seed: 44, Epoch: 022, Loss: 0.4465, Val Acc: 0.7280, Test Acc: 0.7187\n",
      "Seed: 44, Epoch: 023, Loss: 0.4388, Val Acc: 0.7347, Test Acc: 0.7307\n",
      "Seed: 44, Epoch: 024, Loss: 0.4309, Val Acc: 0.7307, Test Acc: 0.7347\n",
      "Seed: 44, Epoch: 025, Loss: 0.4244, Val Acc: 0.7280, Test Acc: 0.7253\n",
      "Seed: 44, Epoch: 026, Loss: 0.4149, Val Acc: 0.7560, Test Acc: 0.7480\n",
      "Seed: 44, Epoch: 027, Loss: 0.4072, Val Acc: 0.7587, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 028, Loss: 0.4004, Val Acc: 0.7480, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 029, Loss: 0.3979, Val Acc: 0.7560, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 030, Loss: 0.3915, Val Acc: 0.7520, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 031, Loss: 0.3826, Val Acc: 0.7493, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 032, Loss: 0.3792, Val Acc: 0.7600, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 033, Loss: 0.3752, Val Acc: 0.7573, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 034, Loss: 0.3712, Val Acc: 0.7613, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 035, Loss: 0.3664, Val Acc: 0.7387, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 036, Loss: 0.3602, Val Acc: 0.7547, Test Acc: 0.7760\n",
      "Seed: 44, Epoch: 037, Loss: 0.3560, Val Acc: 0.7560, Test Acc: 0.7760\n",
      "Seed: 44, Epoch: 038, Loss: 0.3543, Val Acc: 0.7600, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 039, Loss: 0.3527, Val Acc: 0.7573, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 040, Loss: 0.3485, Val Acc: 0.7533, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 041, Loss: 0.3455, Val Acc: 0.7720, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 042, Loss: 0.3433, Val Acc: 0.7560, Test Acc: 0.7947\n",
      "Seed: 44, Epoch: 043, Loss: 0.3401, Val Acc: 0.7467, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 044, Loss: 0.3384, Val Acc: 0.7480, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 045, Loss: 0.3295, Val Acc: 0.7587, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 046, Loss: 0.3250, Val Acc: 0.7560, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 047, Loss: 0.3221, Val Acc: 0.7667, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 048, Loss: 0.3162, Val Acc: 0.7707, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 049, Loss: 0.3121, Val Acc: 0.7627, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 050, Loss: 0.3103, Val Acc: 0.7627, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 051, Loss: 0.3099, Val Acc: 0.7547, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 052, Loss: 0.3048, Val Acc: 0.7640, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 053, Loss: 0.3069, Val Acc: 0.7467, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 054, Loss: 0.3048, Val Acc: 0.7613, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 055, Loss: 0.3000, Val Acc: 0.7533, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 056, Loss: 0.2954, Val Acc: 0.7640, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 057, Loss: 0.2978, Val Acc: 0.7600, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 058, Loss: 0.2886, Val Acc: 0.7587, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 059, Loss: 0.2860, Val Acc: 0.7667, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 060, Loss: 0.2814, Val Acc: 0.7640, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 061, Loss: 0.2797, Val Acc: 0.7653, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 062, Loss: 0.2776, Val Acc: 0.7613, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 063, Loss: 0.2763, Val Acc: 0.7587, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 064, Loss: 0.2741, Val Acc: 0.7587, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 065, Loss: 0.2735, Val Acc: 0.7587, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 066, Loss: 0.2682, Val Acc: 0.7773, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 067, Loss: 0.2682, Val Acc: 0.7667, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 068, Loss: 0.2639, Val Acc: 0.7547, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 069, Loss: 0.2644, Val Acc: 0.7707, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 070, Loss: 0.2581, Val Acc: 0.7733, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 071, Loss: 0.2534, Val Acc: 0.7773, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 072, Loss: 0.2534, Val Acc: 0.7613, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 073, Loss: 0.2527, Val Acc: 0.7747, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 074, Loss: 0.2458, Val Acc: 0.7680, Test Acc: 0.7600\n",
      "Seed: 44, Epoch: 075, Loss: 0.2423, Val Acc: 0.7680, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 076, Loss: 0.2415, Val Acc: 0.7640, Test Acc: 0.7787\n",
      "Seed: 44, Epoch: 077, Loss: 0.2442, Val Acc: 0.7600, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 078, Loss: 0.2473, Val Acc: 0.7533, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 079, Loss: 0.2493, Val Acc: 0.7667, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 080, Loss: 0.2525, Val Acc: 0.7640, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 081, Loss: 0.2536, Val Acc: 0.7707, Test Acc: 0.7880\n",
      "Seed: 44, Epoch: 082, Loss: 0.2498, Val Acc: 0.7760, Test Acc: 0.7720\n",
      "Seed: 44, Epoch: 083, Loss: 0.2484, Val Acc: 0.7600, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 084, Loss: 0.2435, Val Acc: 0.7800, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 085, Loss: 0.2395, Val Acc: 0.7587, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 086, Loss: 0.2327, Val Acc: 0.7867, Test Acc: 0.7933\n",
      "Seed: 44, Epoch: 087, Loss: 0.2259, Val Acc: 0.7787, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 088, Loss: 0.2230, Val Acc: 0.7800, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 089, Loss: 0.2186, Val Acc: 0.7653, Test Acc: 0.7720\n",
      "Seed: 44, Epoch: 090, Loss: 0.2186, Val Acc: 0.7627, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 091, Loss: 0.2146, Val Acc: 0.7760, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 092, Loss: 0.2158, Val Acc: 0.7747, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 093, Loss: 0.2154, Val Acc: 0.7747, Test Acc: 0.7760\n",
      "Seed: 44, Epoch: 094, Loss: 0.2121, Val Acc: 0.7560, Test Acc: 0.7587\n",
      "Seed: 44, Epoch: 095, Loss: 0.2108, Val Acc: 0.7707, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 096, Loss: 0.2050, Val Acc: 0.7813, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 097, Loss: 0.2082, Val Acc: 0.7720, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 098, Loss: 0.2052, Val Acc: 0.7640, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 099, Loss: 0.2063, Val Acc: 0.7573, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 100, Loss: 0.2014, Val Acc: 0.7747, Test Acc: 0.7787\n",
      "Seed: 44, Epoch: 101, Loss: 0.1971, Val Acc: 0.7840, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 102, Loss: 0.1971, Val Acc: 0.7680, Test Acc: 0.7640\n",
      "Seed: 44, Epoch: 103, Loss: 0.1908, Val Acc: 0.7840, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 104, Loss: 0.1889, Val Acc: 0.7853, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 105, Loss: 0.1800, Val Acc: 0.7680, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 106, Loss: 0.1781, Val Acc: 0.7760, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 107, Loss: 0.1756, Val Acc: 0.7733, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 108, Loss: 0.1689, Val Acc: 0.7840, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 109, Loss: 0.1753, Val Acc: 0.7760, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 110, Loss: 0.1718, Val Acc: 0.7773, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 111, Loss: 0.1737, Val Acc: 0.7840, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 112, Loss: 0.1714, Val Acc: 0.7773, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 113, Loss: 0.1644, Val Acc: 0.7733, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 114, Loss: 0.1560, Val Acc: 0.7760, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 115, Loss: 0.1605, Val Acc: 0.7827, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 116, Loss: 0.1550, Val Acc: 0.7760, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 117, Loss: 0.1613, Val Acc: 0.7747, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 118, Loss: 0.1614, Val Acc: 0.7653, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 119, Loss: 0.1630, Val Acc: 0.7707, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 120, Loss: 0.1543, Val Acc: 0.7693, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 121, Loss: 0.1574, Val Acc: 0.7760, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 122, Loss: 0.1612, Val Acc: 0.7827, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 123, Loss: 0.1500, Val Acc: 0.7640, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 124, Loss: 0.1510, Val Acc: 0.7813, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 125, Loss: 0.1394, Val Acc: 0.7773, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 126, Loss: 0.1340, Val Acc: 0.7587, Test Acc: 0.7667\n",
      "Seed: 44, Epoch: 127, Loss: 0.1356, Val Acc: 0.7707, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 128, Loss: 0.1317, Val Acc: 0.7720, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 129, Loss: 0.1309, Val Acc: 0.7653, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 130, Loss: 0.1267, Val Acc: 0.7640, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 131, Loss: 0.1454, Val Acc: 0.7640, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 132, Loss: 0.1466, Val Acc: 0.7640, Test Acc: 0.7787\n",
      "Seed: 44, Epoch: 133, Loss: 0.1388, Val Acc: 0.7760, Test Acc: 0.7787\n",
      "Seed: 44, Epoch: 134, Loss: 0.1328, Val Acc: 0.7760, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 135, Loss: 0.1297, Val Acc: 0.7720, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 136, Loss: 0.1313, Val Acc: 0.7760, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 137, Loss: 0.1301, Val Acc: 0.7653, Test Acc: 0.7787\n",
      "Seed: 44, Epoch: 138, Loss: 0.1254, Val Acc: 0.7707, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 139, Loss: 0.1212, Val Acc: 0.7813, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 140, Loss: 0.1192, Val Acc: 0.7693, Test Acc: 0.7800\n",
      "Seed: 44, Epoch: 141, Loss: 0.1216, Val Acc: 0.7773, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 142, Loss: 0.1164, Val Acc: 0.7613, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 143, Loss: 0.1164, Val Acc: 0.7733, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 144, Loss: 0.1166, Val Acc: 0.7840, Test Acc: 0.7947\n",
      "Seed: 44, Epoch: 145, Loss: 0.1109, Val Acc: 0.7747, Test Acc: 0.7987\n",
      "Seed: 44, Epoch: 146, Loss: 0.1098, Val Acc: 0.7773, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 147, Loss: 0.1167, Val Acc: 0.7760, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 148, Loss: 0.1301, Val Acc: 0.7747, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 149, Loss: 0.1242, Val Acc: 0.7667, Test Acc: 0.7640\n",
      "Seed: 44, Epoch: 150, Loss: 0.1256, Val Acc: 0.7627, Test Acc: 0.7720\n",
      "Seed: 44, Epoch: 151, Loss: 0.1170, Val Acc: 0.7720, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 152, Loss: 0.1174, Val Acc: 0.7733, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 153, Loss: 0.1101, Val Acc: 0.7720, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 154, Loss: 0.1072, Val Acc: 0.7880, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 155, Loss: 0.1040, Val Acc: 0.7667, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 156, Loss: 0.1077, Val Acc: 0.7853, Test Acc: 0.7893\n",
      "Seed: 44, Epoch: 157, Loss: 0.1060, Val Acc: 0.7773, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 158, Loss: 0.1008, Val Acc: 0.7827, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 159, Loss: 0.1012, Val Acc: 0.7747, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 160, Loss: 0.0984, Val Acc: 0.7733, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 161, Loss: 0.0970, Val Acc: 0.7747, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 162, Loss: 0.0992, Val Acc: 0.7827, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 163, Loss: 0.0952, Val Acc: 0.7720, Test Acc: 0.7840\n",
      "Seed: 44, Epoch: 164, Loss: 0.0906, Val Acc: 0.7733, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 165, Loss: 0.0916, Val Acc: 0.7760, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 166, Loss: 0.0896, Val Acc: 0.7840, Test Acc: 0.7760\n",
      "Seed: 44, Epoch: 167, Loss: 0.0898, Val Acc: 0.7853, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 168, Loss: 0.0908, Val Acc: 0.7787, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 169, Loss: 0.0955, Val Acc: 0.7813, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 170, Loss: 0.0924, Val Acc: 0.7787, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 171, Loss: 0.0955, Val Acc: 0.7787, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 172, Loss: 0.0933, Val Acc: 0.7773, Test Acc: 0.7653\n",
      "Seed: 44, Epoch: 173, Loss: 0.0956, Val Acc: 0.7747, Test Acc: 0.7680\n",
      "Seed: 44, Epoch: 174, Loss: 0.1003, Val Acc: 0.7720, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 175, Loss: 0.0965, Val Acc: 0.7707, Test Acc: 0.7760\n",
      "Seed: 44, Epoch: 176, Loss: 0.0920, Val Acc: 0.7707, Test Acc: 0.7853\n",
      "Seed: 44, Epoch: 177, Loss: 0.0960, Val Acc: 0.7787, Test Acc: 0.7907\n",
      "Seed: 44, Epoch: 178, Loss: 0.0919, Val Acc: 0.7800, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 179, Loss: 0.0915, Val Acc: 0.7707, Test Acc: 0.7787\n",
      "Seed: 44, Epoch: 180, Loss: 0.0984, Val Acc: 0.7733, Test Acc: 0.7627\n",
      "Seed: 44, Epoch: 181, Loss: 0.1103, Val Acc: 0.7600, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 182, Loss: 0.0943, Val Acc: 0.7720, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 183, Loss: 0.0887, Val Acc: 0.7787, Test Acc: 0.7867\n",
      "Seed: 44, Epoch: 184, Loss: 0.0873, Val Acc: 0.7813, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 185, Loss: 0.0877, Val Acc: 0.7827, Test Acc: 0.7587\n",
      "Seed: 44, Epoch: 186, Loss: 0.0863, Val Acc: 0.7867, Test Acc: 0.7827\n",
      "Seed: 44, Epoch: 187, Loss: 0.0828, Val Acc: 0.7680, Test Acc: 0.7707\n",
      "Seed: 44, Epoch: 188, Loss: 0.0829, Val Acc: 0.7947, Test Acc: 0.7733\n",
      "Seed: 44, Epoch: 189, Loss: 0.0840, Val Acc: 0.7827, Test Acc: 0.7720\n",
      "Seed: 44, Epoch: 190, Loss: 0.0813, Val Acc: 0.7827, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 191, Loss: 0.0833, Val Acc: 0.7693, Test Acc: 0.7627\n",
      "Seed: 44, Epoch: 192, Loss: 0.0863, Val Acc: 0.7707, Test Acc: 0.7720\n",
      "Seed: 44, Epoch: 193, Loss: 0.0881, Val Acc: 0.7800, Test Acc: 0.7773\n",
      "Seed: 44, Epoch: 194, Loss: 0.0907, Val Acc: 0.7827, Test Acc: 0.7813\n",
      "Seed: 44, Epoch: 195, Loss: 0.0891, Val Acc: 0.7640, Test Acc: 0.7747\n",
      "Seed: 44, Epoch: 196, Loss: 0.0884, Val Acc: 0.7680, Test Acc: 0.7613\n",
      "Seed: 44, Epoch: 197, Loss: 0.0795, Val Acc: 0.7853, Test Acc: 0.7720\n",
      "Seed: 44, Epoch: 198, Loss: 0.0934, Val Acc: 0.7747, Test Acc: 0.7693\n",
      "Seed: 44, Epoch: 199, Loss: 0.0974, Val Acc: 0.7853, Test Acc: 0.7520\n",
      "Seed: 44, Epoch: 200, Loss: 0.0991, Val Acc: 0.7773, Test Acc: 0.7667\n",
      "Average Time: 1660.73 seconds\n",
      "Var Time: 3662.45 seconds\n",
      "Average Memory: 6782.00 MB\n",
      "Average Best Val Acc: 0.8098\n",
      "Std Best Test Acc: 0.0169\n",
      "Average Test Acc: 0.7818\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_nodes = 500\n",
    "data_path = \"/data/XXX/Pooling\"\n",
    "\n",
    "dataset_dense = TUDataset(\n",
    "    data_path,\n",
    "    name=\"COLLAB\",\n",
    "    transform=T.Compose([T.OneHotDegree(491), T.ToDense(max_nodes)]),\n",
    "    use_node_attr=True,\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "import random\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import os.path as osp\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ASAPooling\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin:\n",
    "            self.lin = torch.nn.Linear(out_channels, out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        x = self.bn(1, self.conv1(x, adj, mask).relu())\n",
    "        x = self.bn(2, self.conv2(x, adj, mask).relu())\n",
    "        x = self.bn(3, self.conv3(x, adj, mask).relu())\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net_hosc(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn1_pool = GNN(dataset_dense.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = DenseGCNConv(dataset_dense.num_features, 64)\n",
    "\n",
    "        num_nodes = 64\n",
    "        self.gnn2_pool = GNN(64, 64, num_nodes)\n",
    "        self.gnn2_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.gnn3_embed = DenseGCNConv(64, 64)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(64, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, dataset_dense.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc, o = dense_hoscpool(x, adj, s, mu=0.3, alpha=0.5, new_ortho=False, mask=mask)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x, adj, mc_aux, o_aux = dense_hoscpool(x, adj, s, mu=0.3, alpha=0.5, new_ortho=False)\n",
    "\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = Net_hosc().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        total_loss += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x, data.adj, data.mask)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seeds = [42, 43, 44]\n",
    "times = []\n",
    "memories = []\n",
    "best_val_accs = []\n",
    "best_test_accs = []\n",
    "\n",
    "early_stop_patience = 150\n",
    "tolerance = 0.0001\n",
    "\n",
    "for seed in seeds:\n",
    "    set_seed(seed)\n",
    "    dataset_dense = dataset_dense.shuffle()\n",
    "\n",
    "    train_ratio = 0.7\n",
    "    val_ratio = 0.15\n",
    "    val_ratio = 0.15\n",
    "    # Calculate the sizes of each subset\n",
    "    num_total = len(dataset_dense)\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_val = int(num_total * val_ratio)\n",
    "    num_test = num_total - num_train - num_val\n",
    "    train_dataset = dataset_dense[:num_train]\n",
    "    val_dataset = dataset_dense[num_train:num_train + num_val]\n",
    "    test_dataset = dataset_dense[num_train + num_val:]\n",
    "    train_loader = DenseDataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "    valid_loader = DenseDataLoader(val_dataset, batch_size=512, shuffle=False)\n",
    "    test_loader = DenseDataLoader(test_dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "    model = Net_hosc().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    best_val_acc = 0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        loss = train()\n",
    "        val_acc = test(valid_loader)\n",
    "        test_acc = test(test_loader)\n",
    "        if val_acc > best_val_acc + tolerance:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f'Seed: {seed}, Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f'Early stopping at epoch {epoch} for seed {seed}')\n",
    "            break\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    memory_allocated = torch.cuda.memory_reserved(device) / (1024 ** 2)  # Convert to MB\n",
    "\n",
    "    times.append(total_time)\n",
    "    memories.append(memory_allocated)\n",
    "    best_val_accs.append(best_val_acc)\n",
    "    best_test_accs.append(best_test_acc)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Average Time: {np.mean(times):.2f} seconds')\n",
    "print(f'Var Time: {np.var(times):.2f} seconds')\n",
    "print(f'Average Memory: {np.mean(memories):.2f} MB')\n",
    "print(f'Average Best Val Acc: {np.mean(best_val_accs):.4f}')\n",
    "print(f'Std Best Test Acc: {np.std(best_test_accs):.4f}')\n",
    "print(f'Average Test Acc: {np.mean(best_test_accs):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QM7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existed dataset loaded: datasets/processed/qm7.pt\n",
      "\n",
      "Current dataset: qm7, include 6832 molecules and 1 regression tasks\n",
      "\n",
      "Splitting, finish 1/1  \n",
      "Epoch: 1/500MAE=1545.3601 MAE=1462.0270 MAE=1374.7219 MAE=1404.1001 MAE=1220.8877 MAE=1352.8748 MAE=1275.0078 MAE=1155.1167 MAE=1121.7788 Epoch: 10/500MAE=996.9196 MAE=876.5198 MAE=591.0928 MAE=533.2172 MAE=701.3717 MAE=379.4106 MAE=644.5787 MAE=554.1118 MAE=275.7677 MAE=210.0068 Epoch: 20/500MAE=272.9962 MAE=541.7998 MAE=731.6129 MAE=141.0365 MAE=112.0555 MAE=127.7508 MAE=78.6844 MAE=71.7933 MAE=76.6619 MAE=72.2410 Epoch: 30/500MAE=382.3224 MAE=190.6062 MAE=100.2302 MAE=90.9659 MAE=103.1871 MAE=61.7845 MAE=54.1816 MAE=124.0387 MAE=59.9093 MAE=72.5676 Epoch: 40/500MAE=84.4918 MAE=56.4927 MAE=51.8493 MAE=72.5265 MAE=52.0390 MAE=51.7178 MAE=75.9519 MAE=53.4465 MAE=55.1383 MAE=68.4591 Epoch: 50/500MAE=53.7295 MAE=54.7499 MAE=55.5125 MAE=51.8730 MAE=51.7146 MAE=51.1614 MAE=54.3166 MAE=51.2502 MAE=52.3182 MAE=50.9919 Epoch: 60/500MAE=49.7038 MAE=54.4676 MAE=50.2257 MAE=50.7278 MAE=56.7334 MAE=52.7224 MAE=51.0197 MAE=51.6121 MAE=53.5693 MAE=51.2397 Epoch: 70/500MAE=51.3338 MAE=51.0614 MAE=50.2973 MAE=50.6983 MAE=50.4767 MAE=51.0548 MAE=50.7801 MAE=50.6211 MAE=50.6944 MAE=50.6238 Epoch: 80/500MAE=50.7968 MAE=50.4899 MAE=50.4978 MAE=50.4325 MAE=50.6459 MAE=50.4860 MAE=50.4460 MAE=50.4362 MAE=50.5336 MAE=50.5025 Epoch: 90/500MAE=50.5325 MAE=50.5159 MAE=50.5263 MAE=50.4557 MAE=50.4448 MAE=50.4003 MAE=50.4332 MAE=50.5382 MAE=50.4794 MAE=50.5133 Epoch: 100/500MAE=50.4264 MAE=50.3843 MAE=50.4179 MAE=50.4607 MAE=50.4375 MAE=50.4201 MAE=50.5009 MAE=50.4528 MAE=50.4566 MAE=50.4865 Epoch: 110/500MAE=50.4757 MAE=50.5239 MAE=50.4984 MAE=50.4293 MAE=50.4743 MAE=50.5162 MAE=50.5169 MAE=50.4847 MAE=50.4796 MAE=50.4325 Epoch: 120/500MAE=50.4374 MAE=50.3641 MAE=50.3684 MAE=50.4213 MAE=50.4285 MAE=50.4288 MAE=50.4021 MAE=50.3483 MAE=50.3614 MAE=50.4007 Epoch: 130/500MAE=50.3067 MAE=50.3218 MAE=50.3649 MAE=50.3535 MAE=50.3288 MAE=50.4190 MAE=50.4013 MAE=50.3720 MAE=50.3258 MAE=50.3117 Epoch: 140/500MAE=50.3249 MAE=50.3062 MAE=50.2960 MAE=50.3392 MAE=50.3000 MAE=50.2608 MAE=50.3063 MAE=50.2748 MAE=50.2861 MAE=50.3462 Epoch: 150/500MAE=50.3461 MAE=50.2168 MAE=50.2913 MAE=50.3223 MAE=50.3673 MAE=50.4003 MAE=50.3981 MAE=50.3206 MAE=50.2806 MAE=50.3394 Epoch: 160/500MAE=50.3816 MAE=50.4321 MAE=50.3786 MAE=50.3219 MAE=50.3641 MAE=50.3549 MAE=50.2837 MAE=50.3942 MAE=50.2785 MAE=50.2605 Epoch: 170/500MAE=50.1986 MAE=50.2901 MAE=50.2836 MAE=50.3431 MAE=50.4259 MAE=50.3302 MAE=50.3667 MAE=50.4030 MAE=50.3586 MAE=50.3650 Epoch: 180/500MAE=50.2987 MAE=50.2838 MAE=50.3163 MAE=50.3141 MAE=50.3276 MAE=50.3356 MAE=50.3387 MAE=50.3546 MAE=50.2586 MAE=50.3434 Epoch: 190/500MAE=50.3138 MAE=50.3225 MAE=50.4273 MAE=50.3016 MAE=50.3159 MAE=50.3130 MAE=50.2753 MAE=50.1807 MAE=50.2582 MAE=50.2773 Epoch: 200/500MAE=50.2756 MAE=50.3649 MAE=50.3663 MAE=50.3743 MAE=50.2667 MAE=50.2370 MAE=50.2689 MAE=50.2696 MAE=50.2321 MAE=50.2040 Epoch: 210/500MAE=50.2150 MAE=48.3877 \n",
      "********************1's fold 1's run over********************\n",
      "MAE: 48.388 +/- 0.000\n",
      "\n",
      "Epoch: 1/500MAE=1546.3807 MAE=1459.3928 MAE=1325.4595 MAE=1366.6747 MAE=1300.8381 MAE=1280.2750 MAE=1224.8607 MAE=1180.1840 MAE=1236.0625 Epoch: 10/500MAE=1138.8413 MAE=984.0067 MAE=727.6207 MAE=789.2357 MAE=581.9540 MAE=549.6969 MAE=696.5117 MAE=519.9368 MAE=400.2627 MAE=360.8775 Epoch: 20/500MAE=203.2372 MAE=142.2884 MAE=100.4755 MAE=1393.5483 MAE=372.3545 MAE=79.4431 MAE=109.2372 MAE=71.3920 MAE=129.0728 MAE=80.6596 Epoch: 30/500MAE=82.3065 MAE=215.4767 MAE=58.6788 MAE=153.2018 MAE=71.1210 MAE=93.2346 MAE=61.1533 MAE=74.8964 MAE=61.4972 MAE=67.4387 Epoch: 40/500MAE=51.9282 MAE=115.6560 MAE=60.5916 MAE=74.2950 MAE=52.4020 MAE=53.3555 MAE=51.3382 MAE=58.3958 MAE=51.4684 MAE=56.5020 Epoch: 50/500MAE=54.6768 MAE=51.7945 MAE=51.3677 MAE=55.4022 MAE=57.2048 MAE=53.3211 MAE=56.4870 MAE=54.0627 MAE=54.7741 MAE=57.3802 Epoch: 60/500MAE=56.2934 MAE=57.9689 MAE=58.7078 MAE=55.8488 MAE=56.7821 MAE=56.2038 MAE=56.6240 MAE=56.5422 MAE=56.4752 MAE=56.6734 Epoch: 70/500MAE=56.2395 MAE=56.5003 MAE=56.5844 MAE=56.3737 MAE=56.5556 MAE=56.5373 MAE=56.6123 MAE=56.4743 MAE=56.5303 MAE=56.5649 Epoch: 80/500MAE=56.4860 MAE=56.6195 MAE=56.3371 MAE=56.5264 MAE=56.5671 MAE=56.5813 MAE=56.4153 MAE=56.4681 MAE=56.4627 MAE=56.4406 Epoch: 90/500MAE=56.4730 MAE=56.3600 MAE=56.3754 MAE=56.3902 MAE=56.5408 MAE=56.4646 MAE=56.4966 MAE=56.3035 MAE=56.3481 MAE=56.4064 Epoch: 100/500MAE=56.4775 MAE=56.3173 MAE=56.6110 MAE=56.5394 MAE=56.4816 MAE=56.2906 MAE=56.4906 MAE=56.2727 MAE=56.4173 MAE=56.4104 Epoch: 110/500MAE=56.4958 MAE=56.5234 MAE=56.3997 MAE=56.2494 MAE=56.2775 MAE=56.3487 MAE=56.2884 MAE=56.2816 MAE=56.3795 MAE=56.4605 Epoch: 120/500MAE=56.3448 MAE=56.4165 MAE=56.4177 MAE=56.3884 MAE=56.3463 MAE=56.4396 MAE=56.3553 MAE=56.4087 MAE=56.3515 MAE=56.5147 Epoch: 130/500MAE=56.4517 MAE=56.4647 MAE=56.3158 MAE=56.2795 MAE=56.1869 MAE=56.2243 MAE=56.2375 MAE=56.3532 MAE=56.4514 MAE=56.4487 Epoch: 140/500MAE=56.3885 MAE=56.2427 MAE=56.5179 MAE=56.4192 MAE=56.3180 MAE=56.2804 MAE=56.2178 MAE=56.1084 MAE=56.3550 MAE=56.3623 Epoch: 150/500MAE=56.2199 MAE=56.2008 MAE=56.2152 MAE=56.2564 MAE=56.2967 MAE=56.3804 MAE=56.1616 MAE=56.2247 MAE=56.3057 MAE=56.3344 Epoch: 160/500MAE=56.4822 MAE=56.3208 MAE=56.2838 MAE=56.3207 MAE=56.3501 MAE=56.3135 MAE=56.3821 MAE=56.2870 MAE=56.4545 MAE=56.0745 Epoch: 170/500MAE=56.4377 MAE=56.2205 MAE=56.4581 MAE=56.5389 MAE=56.2486 MAE=56.4774 MAE=56.3072 MAE=56.3473 MAE=56.2688 MAE=56.4029 Epoch: 180/500MAE=56.4233 MAE=56.2358 MAE=56.3691 MAE=56.0637 MAE=56.2498 MAE=56.3025 MAE=56.2970 MAE=56.1700 MAE=56.3026 MAE=56.3200 Epoch: 190/500MAE=56.3087 MAE=56.4166 MAE=56.2751 MAE=56.2907 MAE=56.3649 MAE=56.4035 MAE=56.2417 MAE=49.9015 \n",
      "********************1's fold 2's run over********************\n",
      "MAE: 49.145 +/- 0.757\n",
      "\n",
      "Epoch: 1/500MAE=1547.0339 MAE=1450.6332 MAE=1410.3109 MAE=1308.8245 MAE=1382.1479 MAE=1373.1764 MAE=1111.4729 MAE=952.1242 MAE=1048.0842 Epoch: 10/500MAE=1253.1478 MAE=913.6374 MAE=696.4479 MAE=663.9470 MAE=449.3339 MAE=436.3786 MAE=230.5655 MAE=566.7278 MAE=469.4543 MAE=237.0994 Epoch: 20/500MAE=205.4892 MAE=311.7846 MAE=214.5426 MAE=90.3746 MAE=173.5811 MAE=146.1947 MAE=109.6969 MAE=267.0652 MAE=64.0838 MAE=73.0707 Epoch: 30/500MAE=95.1678 MAE=159.8527 MAE=136.2594 MAE=51.8718 MAE=72.3527 MAE=52.2572 MAE=59.7788 MAE=60.1647 MAE=53.3646 MAE=49.4665 Epoch: 40/500MAE=49.9325 MAE=61.9495 MAE=62.0521 MAE=59.1842 MAE=52.0994 MAE=59.8558 MAE=55.4259 MAE=54.0540 MAE=50.3982 MAE=54.2792 Epoch: 50/500MAE=54.4211 MAE=54.8456 MAE=50.8136 MAE=54.5443 MAE=53.3162 MAE=52.6291 MAE=51.9128 MAE=53.0990 MAE=52.3623 MAE=53.2333 Epoch: 60/500MAE=53.3409 MAE=52.8191 MAE=52.7127 MAE=52.8641 MAE=52.7895 MAE=52.6627 MAE=52.7646 MAE=53.0062 MAE=52.9232 MAE=52.8569 Epoch: 70/500MAE=53.0009 MAE=52.9161 MAE=52.9086 MAE=52.6741 MAE=53.0592 MAE=52.8404 MAE=52.8051 MAE=52.6516 MAE=53.0008 MAE=52.6673 Epoch: 80/500MAE=52.9841 MAE=52.9073 MAE=52.9538 MAE=52.8842 MAE=52.8520 MAE=53.0188 MAE=52.9644 MAE=52.8251 MAE=52.9205 MAE=52.7020 Epoch: 90/500MAE=52.9430 MAE=53.0318 MAE=52.7243 MAE=52.8886 MAE=53.0058 MAE=52.9993 MAE=52.9655 MAE=52.6924 MAE=52.6453 MAE=52.8702 Epoch: 100/500MAE=52.5082 MAE=52.5861 MAE=52.7288 MAE=52.9318 MAE=52.6677 MAE=53.0186 MAE=52.5022 MAE=52.7455 MAE=52.7415 MAE=52.7722 Epoch: 110/500MAE=52.7209 MAE=52.7015 MAE=52.7673 MAE=52.7988 MAE=52.6538 MAE=52.6189 MAE=52.8273 MAE=52.7312 MAE=52.7910 MAE=52.8891 Epoch: 120/500MAE=52.7968 MAE=52.9343 MAE=52.7704 MAE=52.9755 MAE=53.0421 MAE=52.7411 MAE=52.8295 MAE=52.9655 MAE=53.0204 MAE=52.7743 Epoch: 130/500MAE=52.8254 MAE=52.7253 MAE=52.6682 MAE=52.8721 MAE=52.9065 MAE=52.8779 MAE=52.6103 MAE=53.0789 MAE=52.8452 MAE=52.9515 Epoch: 140/500MAE=52.8181 MAE=52.8041 MAE=52.8287 MAE=52.8164 MAE=52.8751 MAE=52.7971 MAE=52.6859 MAE=52.7241 MAE=52.9790 MAE=52.8154 Epoch: 150/500MAE=52.9454 MAE=52.8781 MAE=52.9444 MAE=52.6665 MAE=52.8873 MAE=52.7443 MAE=52.9279 MAE=52.9932 MAE=52.8129 MAE=52.8402 Epoch: 160/500MAE=52.8854 MAE=52.9054 MAE=52.8958 MAE=53.0326 MAE=53.0467 MAE=52.5689 MAE=52.8192 MAE=52.6869 MAE=52.8256 MAE=52.6833 Epoch: 170/500MAE=52.7219 MAE=52.6650 MAE=52.6603 MAE=52.6638 MAE=52.8859 MAE=52.7035 MAE=52.8752 MAE=52.7994 MAE=52.6951 MAE=52.9707 Epoch: 180/500MAE=52.4860 MAE=52.7820 MAE=53.0673 MAE=52.9503 MAE=52.7457 MAE=52.8539 MAE=52.8824 MAE=52.8032 MAE=52.8849 MAE=52.9722 MAE=46.3616 \n",
      "********************1's fold 3's run over********************\n",
      "MAE: 48.217 +/- 1.450\n",
      "\n",
      "Epoch: 1/500MAE=1546.3362 MAE=1464.2449 MAE=1437.5963 MAE=1436.5049 MAE=1290.3884 MAE=1408.7402 MAE=1077.1615 MAE=1246.1729 MAE=1049.0615 Epoch: 10/500MAE=856.0146 MAE=494.3946 MAE=642.0066 MAE=921.5958 MAE=767.8436 MAE=252.8792 MAE=577.8198 MAE=243.5603 MAE=253.3811 MAE=323.7968 Epoch: 20/500MAE=315.5641 MAE=235.8252 MAE=267.5807 MAE=239.2868 MAE=521.4182 MAE=129.4633 MAE=83.8880 MAE=70.9592 MAE=72.7524 MAE=64.5447 Epoch: 30/500MAE=69.1835 MAE=98.1721 MAE=78.1040 MAE=73.6629 MAE=62.1745 MAE=96.4787 MAE=70.4861 MAE=51.4847 MAE=103.6749 MAE=90.7814 Epoch: 40/500MAE=54.6485 MAE=53.8287 MAE=83.7879 MAE=71.8877 MAE=80.7947 MAE=94.8150 MAE=83.2819 MAE=78.4593 MAE=88.2819 MAE=63.4605 Epoch: 50/500MAE=77.2102 MAE=67.9776 MAE=67.6818 MAE=65.4477 MAE=70.5130 MAE=67.2240 MAE=72.8212 MAE=73.1184 MAE=76.0643 MAE=70.3978 Epoch: 60/500MAE=73.6587 MAE=74.7949 MAE=73.5342 MAE=73.4565 MAE=72.1528 MAE=75.4659 MAE=74.8255 MAE=74.7619 MAE=73.9594 MAE=73.9374 Epoch: 70/500MAE=74.4794 MAE=74.1427 MAE=74.5430 MAE=74.1703 MAE=74.4372 MAE=74.5102 MAE=74.3358 MAE=74.4133 MAE=74.2515 MAE=74.1691 Epoch: 80/500MAE=74.1285 MAE=74.2942 MAE=74.2898 MAE=74.0944 MAE=74.2001 MAE=74.2105 MAE=74.1058 MAE=74.0396 MAE=74.1584 MAE=74.2572 Epoch: 90/500MAE=74.1108 MAE=74.2303 MAE=74.1859 MAE=74.2035 MAE=74.3347 MAE=74.2249 MAE=74.3743 MAE=74.3221 MAE=74.1291 MAE=74.1855 Epoch: 100/500MAE=74.2672 MAE=74.2872 MAE=74.2773 MAE=74.2034 MAE=74.4938 MAE=74.2156 MAE=74.1971 MAE=74.1450 MAE=74.4671 MAE=74.5202 Epoch: 110/500MAE=74.4082 MAE=74.1307 MAE=74.3939 MAE=74.2931 MAE=74.4604 MAE=74.1815 MAE=74.3044 MAE=74.1861 MAE=74.1426 MAE=74.1268 Epoch: 120/500MAE=73.8657 MAE=73.9024 MAE=74.0449 MAE=74.2330 MAE=74.2416 MAE=74.3260 MAE=74.2623 MAE=74.2148 MAE=74.6887 MAE=74.6348 Epoch: 130/500MAE=74.7001 MAE=74.7780 MAE=74.6778 MAE=74.7113 MAE=74.5536 MAE=74.5752 MAE=74.6956 MAE=74.2706 MAE=74.1985 MAE=74.0393 Epoch: 140/500MAE=74.1549 MAE=74.2100 MAE=74.1582 MAE=74.2608 MAE=74.1416 MAE=74.3725 MAE=74.3357 MAE=74.2772 MAE=74.3385 MAE=74.2779 Epoch: 150/500MAE=74.6650 MAE=74.6096 MAE=74.7346 MAE=74.4456 MAE=74.6493 MAE=74.8079 MAE=74.9575 MAE=74.6135 MAE=74.7086 MAE=74.6064 Epoch: 160/500MAE=75.0874 MAE=74.6926 MAE=74.7088 MAE=74.6447 MAE=74.6261 MAE=74.4081 MAE=74.4983 MAE=74.6632 MAE=74.4695 MAE=74.6004 Epoch: 170/500MAE=74.6349 MAE=74.7236 MAE=74.6057 MAE=74.7600 MAE=74.7254 MAE=74.9641 MAE=74.8312 MAE=74.8195 MAE=74.9633 MAE=75.0921 Epoch: 180/500MAE=75.0111 MAE=75.1281 MAE=75.0510 MAE=74.9306 MAE=74.8457 MAE=74.8367 MAE=74.7540 MAE=74.9057 MAE=50.2129 \n",
      "********************1's fold 4's run over********************\n",
      "MAE: 48.716 +/- 1.525\n",
      "\n",
      "Epoch: 1/500MAE=1544.6372 MAE=1479.4576 MAE=1404.1633 MAE=1365.6265 MAE=1372.0115 MAE=1162.1492 MAE=1290.9226 MAE=1279.1208 MAE=1214.1873 Epoch: 10/500MAE=1248.2095 MAE=1209.2351 MAE=1154.6537 MAE=1021.4309 MAE=1077.8113 MAE=680.6569 MAE=699.2986 MAE=879.0640 MAE=746.8109 MAE=660.9422 Epoch: 20/500MAE=820.3578 MAE=642.9183 MAE=586.4946 MAE=503.8270 MAE=533.4994 MAE=484.1715 MAE=503.4872 MAE=223.3835 MAE=384.1656 MAE=343.4887 Epoch: 30/500MAE=341.3605 MAE=372.3573 MAE=204.3956 MAE=244.7663 MAE=179.8328 MAE=179.8820 MAE=229.9621 MAE=229.9483 MAE=175.5258 MAE=260.3570 Epoch: 40/500MAE=140.2884 MAE=176.7748 MAE=159.5988 MAE=221.3182 MAE=179.8576 MAE=244.0922 MAE=312.8162 MAE=96.5308 MAE=162.0383 MAE=113.5373 Epoch: 50/500MAE=231.0179 MAE=258.3962 MAE=146.4833 MAE=173.6498 MAE=132.2467 MAE=148.8936 MAE=119.0894 MAE=101.7818 MAE=116.9224 MAE=122.6065 Epoch: 60/500MAE=117.4179 MAE=113.7958 MAE=116.1741 MAE=120.2097 MAE=118.4448 MAE=119.1527 MAE=119.4755 MAE=121.3111 MAE=120.0818 MAE=118.6226 Epoch: 70/500MAE=121.3278 MAE=119.5123 MAE=120.1498 MAE=119.5912 MAE=120.2242 MAE=120.0524 MAE=119.5296 MAE=119.4786 MAE=119.6731 MAE=119.4788 Epoch: 80/500MAE=118.7605 MAE=119.0700 MAE=119.2102 MAE=119.4289 MAE=119.1533 MAE=119.2001 MAE=119.0803 MAE=118.8729 MAE=118.9252 MAE=118.8878 Epoch: 90/500MAE=118.8197 MAE=118.4062 MAE=118.9215 MAE=118.8338 MAE=118.5512 MAE=118.3381 MAE=118.2428 MAE=118.7424 MAE=118.5189 MAE=118.1193 Epoch: 100/500MAE=118.1746 MAE=118.4422 MAE=118.5571 MAE=118.2701 MAE=118.4855 MAE=118.2260 MAE=118.0537 MAE=118.0526 MAE=118.2609 MAE=118.3579 Epoch: 110/500MAE=118.4162 MAE=118.0549 MAE=117.8255 MAE=118.0078 MAE=117.7051 MAE=117.6031 MAE=118.1041 MAE=117.6326 MAE=117.9446 MAE=117.5815 Epoch: 120/500MAE=117.2896 MAE=117.5030 MAE=117.4126 MAE=117.7111 MAE=117.5750 MAE=117.3511 MAE=117.2247 MAE=117.1947 MAE=117.1737 MAE=117.1712 Epoch: 130/500MAE=117.0545 MAE=117.2578 MAE=116.6686 MAE=116.8849 MAE=116.7701 MAE=116.6831 MAE=116.8525 MAE=116.6586 MAE=116.5712 MAE=116.3342 Epoch: 140/500MAE=116.4315 MAE=116.6246 MAE=116.4245 MAE=116.4110 MAE=116.1485 MAE=116.2932 MAE=116.2655 MAE=116.3558 MAE=116.3496 MAE=116.0331 Epoch: 150/500MAE=116.1696 MAE=115.7053 MAE=116.2758 MAE=115.9774 MAE=115.9750 MAE=115.8964 MAE=115.9342 MAE=116.1050 MAE=115.7605 MAE=115.4491 Epoch: 160/500MAE=115.5865 MAE=115.8320 MAE=115.4663 MAE=115.6904 MAE=115.4083 MAE=115.4885 MAE=115.4677 MAE=115.3634 MAE=115.6813 MAE=115.3652 Epoch: 170/500MAE=115.2249 MAE=115.2553 MAE=114.9980 MAE=115.2814 MAE=115.1502 MAE=115.2733 MAE=114.7338 MAE=115.1042 MAE=114.9874 MAE=115.2510 Epoch: 180/500MAE=115.6051 MAE=115.0429 MAE=115.4270 MAE=115.3344 MAE=115.0042 MAE=114.5240 MAE=115.1218 MAE=114.3864 MAE=114.7598 MAE=115.0351 Epoch: 190/500MAE=115.3367 MAE=114.4268 MAE=115.2928 MAE=115.1223 MAE=115.1277 MAE=115.2709 MAE=115.1633 MAE=114.7486 MAE=102.3163 \n",
      "********************1's fold 5's run over********************\n",
      "MAE: 59.436 +/- 21.483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python /data/XXX/Pooling/Graph_Pooling_Benchmark/Regression/run_regression.py --dataset=qm7 --cuda_num 0 --run_times=5 --patience=150 --epochs=500 --pooling='Hosc'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CG-ODE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
