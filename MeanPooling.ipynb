{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/boot/anaconda3/envs/XXX1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": "import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\nimport sys\nimport torch\nfrom transformers.optimization import get_cosine_schedule_with_warmup\nimport torch.nn.functional as F\nimport torch_geometric.transforms as T\nfrom ogb.graphproppred import PygGraphPropPredDataset, Evaluator\nfrom torch_geometric.loader import DataLoader\nimport os\nimport random\nimport pandas as pd\nimport torch\nimport torch_geometric.transforms as T\nfrom typing import Optional\nimport torch\nfrom torch import Tensor\nfrom torch_geometric.data import Data\nfrom torch_geometric.data.datapipes import functional_transform\nfrom torch_geometric.transforms import BaseTransform\nimport torch_geometric.transforms as T\nfrom torch_geometric.datasets import Planetoid\nfrom torch_geometric.datasets import WebKB\nfrom torch_geometric.datasets import Actor\nfrom torch_geometric.datasets import GNNBenchmarkDataset\nfrom torch_geometric.datasets import TUDataset\nfrom sklearn.metrics import r2_score\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import MoleculeNet\nfrom torch_geometric.nn import GCNConv\nfrom torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\nfrom torch_geometric.utils import to_networkx\nfrom torch.nn import Linear\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport numpy as np\nimport os\nimport random\nimport pandas as pd\nimport time\nimport psutil\nimport torch\nimport torch.nn.functional as F\nimport warnings\nwarnings.filterwarnings(\"ignore\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Node Classification"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Cora"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
                        "Seed 42, Fold 1 Val Acc: 0.887\n",
                        "Seed 42, Fold 2 Val Acc: 0.891\n",
                        "Seed 42, Fold 3 Val Acc: 0.882\n",
                        "Seed 42, Fold 4 Val Acc: 0.887\n",
                        "Early stopping at epoch 193 for fold 5\n",
                        "Seed 42, Fold 5 Val Acc: 0.906\n",
                        "Seed 42 Results: Mean Val Acc: 0.891, Time: 17.106 seconds, Memory: 31.477 MB, GPU Memory: 369.099 MB\n",
                        "Early stopping at epoch 188 for fold 1\n",
                        "Seed 123, Fold 1 Val Acc: 0.900\n",
                        "Seed 123, Fold 2 Val Acc: 0.904\n",
                        "Seed 123, Fold 3 Val Acc: 0.895\n",
                        "Seed 123, Fold 4 Val Acc: 0.891\n",
                        "Seed 123, Fold 5 Val Acc: 0.880\n",
                        "Seed 123 Results: Mean Val Acc: 0.894, Time: 16.858 seconds, Memory: 0.281 MB, GPU Memory: 369.099 MB\n",
                        "Seed 456, Fold 1 Val Acc: 0.897\n",
                        "Seed 456, Fold 2 Val Acc: 0.876\n",
                        "Seed 456, Fold 3 Val Acc: 0.902\n",
                        "Seed 456, Fold 4 Val Acc: 0.898\n",
                        "Early stopping at epoch 182 for fold 5\n",
                        "Seed 456, Fold 5 Val Acc: 0.911\n",
                        "Seed 456 Results: Mean Val Acc: 0.897, Time: 16.967 seconds, Memory: 0.286 MB, GPU Memory: 369.099 MB\n",
                        "Seed 789, Fold 1 Val Acc: 0.876\n",
                        "Seed 789, Fold 2 Val Acc: 0.897\n",
                        "Seed 789, Fold 3 Val Acc: 0.908\n",
                        "Seed 789, Fold 4 Val Acc: 0.902\n",
                        "Seed 789, Fold 5 Val Acc: 0.904\n",
                        "Seed 789 Results: Mean Val Acc: 0.897, Time: 15.354 seconds, Memory: 0.280 MB, GPU Memory: 369.099 MB\n",
                        "Early stopping at epoch 196 for fold 1\n",
                        "Seed 101, Fold 1 Val Acc: 0.913\n",
                        "Seed 101, Fold 2 Val Acc: 0.897\n",
                        "Seed 101, Fold 3 Val Acc: 0.897\n",
                        "Seed 101, Fold 4 Val Acc: 0.889\n",
                        "Seed 101, Fold 5 Val Acc: 0.878\n",
                        "Seed 101 Results: Mean Val Acc: 0.895, Time: 14.646 seconds, Memory: 0.281 MB, GPU Memory: 369.099 MB\n",
                        "{'seed': 42, 'mean_val_acc': 0.890698515118238, 'time': 17.10606622695923, 'memory': 31.476575, 'gpu_memory': 369.098752}\n",
                        "{'seed': 123, 'mean_val_acc': 0.8940113634038372, 'time': 16.857980489730835, 'memory': 0.280998, 'gpu_memory': 369.098752}\n",
                        "{'seed': 456, 'mean_val_acc': 0.896977716542415, 'time': 16.966954231262207, 'memory': 0.285788, 'gpu_memory': 369.098752}\n",
                        "{'seed': 789, 'mean_val_acc': 0.8973453560783297, 'time': 15.353501319885254, 'memory': 0.279567, 'gpu_memory': 369.098752}\n",
                        "{'seed': 101, 'mean_val_acc': 0.894748006629789, 'time': 14.646052122116089, 'memory': 0.28065, 'gpu_memory': 369.098752}\n",
                        "Total Mean Val Acc: 0.89\n",
                        "Standard Deviation: 0.00\n"
                    ]
                }
            ],
            "source": "dataset_sparse = Planetoid(root=\"/data/XXX/Pooling\", name='Cora')\ndataset_sparse = dataset_sparse.shuffle()\nprint(dataset_sparse[0])\nimport time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, TopKPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = dataset_sparse\ngraph = dataset[0]\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.5, 0.5]\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\nclass HierarchicalGCN_NOPool(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_NOPool, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.sum_res = sum_res\n        self.act = act\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        xs = [x]\n        edge_indices = [edge_index]\n        for i in range(1, self.depth + 1):\n            x = self.down_convs[i](x, edge_index)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            up = res\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            print(f'Early stopping at epoch {epoch} for fold {fold + 1}')\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456, 789, 101]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_NOPool(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values)\nstandard_deviation = np.std(mean_val_acc_values)\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}\")\nprint(f\"Standard Deviation: {standard_deviation:.2f}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### CiteSeer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])\n",
                        "Early stopping at epoch 176 for fold 1\n",
                        "Seed 42, Fold 1 Val Acc: 0.794\n",
                        "Early stopping at epoch 179 for fold 2\n",
                        "Seed 42, Fold 2 Val Acc: 0.779\n",
                        "Early stopping at epoch 183 for fold 3\n",
                        "Seed 42, Fold 3 Val Acc: 0.777\n",
                        "Early stopping at epoch 181 for fold 4\n",
                        "Seed 42, Fold 4 Val Acc: 0.756\n",
                        "Early stopping at epoch 175 for fold 5\n",
                        "Seed 42, Fold 5 Val Acc: 0.759\n",
                        "Seed 42 Results: Mean Val Acc: 0.773, Time: 14.035 seconds, Memory: 0.312 MB, GPU Memory: 471.859 MB\n",
                        "Early stopping at epoch 184 for fold 1\n",
                        "Seed 123, Fold 1 Val Acc: 0.769\n",
                        "Early stopping at epoch 178 for fold 2\n",
                        "Seed 123, Fold 2 Val Acc: 0.787\n",
                        "Early stopping at epoch 179 for fold 3\n",
                        "Seed 123, Fold 3 Val Acc: 0.783\n",
                        "Early stopping at epoch 194 for fold 4\n",
                        "Seed 123, Fold 4 Val Acc: 0.756\n",
                        "Early stopping at epoch 180 for fold 5\n",
                        "Seed 123, Fold 5 Val Acc: 0.786\n",
                        "Seed 123 Results: Mean Val Acc: 0.776, Time: 14.145 seconds, Memory: 0.298 MB, GPU Memory: 473.956 MB\n",
                        "Early stopping at epoch 171 for fold 1\n",
                        "Seed 456, Fold 1 Val Acc: 0.782\n",
                        "Early stopping at epoch 178 for fold 2\n",
                        "Seed 456, Fold 2 Val Acc: 0.776\n",
                        "Early stopping at epoch 181 for fold 3\n",
                        "Seed 456, Fold 3 Val Acc: 0.764\n",
                        "Early stopping at epoch 173 for fold 4\n",
                        "Seed 456, Fold 4 Val Acc: 0.767\n",
                        "Early stopping at epoch 183 for fold 5\n",
                        "Seed 456, Fold 5 Val Acc: 0.794\n",
                        "Seed 456 Results: Mean Val Acc: 0.777, Time: 13.639 seconds, Memory: 0.295 MB, GPU Memory: 473.956 MB\n",
                        "Early stopping at epoch 176 for fold 1\n",
                        "Seed 789, Fold 1 Val Acc: 0.766\n",
                        "Early stopping at epoch 186 for fold 2\n",
                        "Seed 789, Fold 2 Val Acc: 0.782\n",
                        "Early stopping at epoch 176 for fold 3\n",
                        "Seed 789, Fold 3 Val Acc: 0.779\n",
                        "Early stopping at epoch 189 for fold 4\n",
                        "Seed 789, Fold 4 Val Acc: 0.770\n",
                        "Early stopping at epoch 189 for fold 5\n",
                        "Seed 789, Fold 5 Val Acc: 0.798\n",
                        "Seed 789 Results: Mean Val Acc: 0.779, Time: 14.174 seconds, Memory: 0.294 MB, GPU Memory: 473.956 MB\n",
                        "Early stopping at epoch 178 for fold 1\n",
                        "Seed 101, Fold 1 Val Acc: 0.788\n",
                        "Early stopping at epoch 180 for fold 2\n",
                        "Seed 101, Fold 2 Val Acc: 0.776\n",
                        "Early stopping at epoch 175 for fold 3\n",
                        "Seed 101, Fold 3 Val Acc: 0.774\n",
                        "Early stopping at epoch 173 for fold 4\n",
                        "Seed 101, Fold 4 Val Acc: 0.788\n",
                        "Early stopping at epoch 186 for fold 5\n",
                        "Seed 101, Fold 5 Val Acc: 0.768\n",
                        "Seed 101 Results: Mean Val Acc: 0.779, Time: 13.874 seconds, Memory: 0.295 MB, GPU Memory: 473.956 MB\n",
                        "{'seed': 42, 'mean_val_acc': 0.7733613312560681, 'time': 14.034903526306152, 'memory': 0.311988, 'gpu_memory': 471.8592}\n",
                        "{'seed': 123, 'mean_val_acc': 0.7763742690058479, 'time': 14.144784212112427, 'memory': 0.298126, 'gpu_memory': 473.956352}\n",
                        "{'seed': 456, 'mean_val_acc': 0.7766741177267493, 'time': 13.63916015625, 'memory': 0.295311, 'gpu_memory': 473.956352}\n",
                        "{'seed': 789, 'mean_val_acc': 0.7790832938201359, 'time': 14.173516035079956, 'memory': 0.294314, 'gpu_memory': 473.956352}\n",
                        "{'seed': 101, 'mean_val_acc': 0.7790783264467475, 'time': 13.874049425125122, 'memory': 0.295017, 'gpu_memory': 473.956352}\n",
                        "Total Mean Val Acc: 0.78\n",
                        "Standard Deviation: 0.00\n"
                    ]
                }
            ],
            "source": "dataset_sparse = Planetoid(root=\"/data/XXX/Pooling\", name='CiteSeer')\ndataset_sparse = dataset_sparse.shuffle()\nprint(dataset_sparse[0])\nimport time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, TopKPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = dataset_sparse\ngraph = dataset[0]\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.5, 0.5]\nclass HierarchicalGCN_NOPool(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_NOPool, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.sum_res = sum_res\n        self.act = act\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        xs = [x]\n        edge_indices = [edge_index]\n        for i in range(1, self.depth + 1):\n            x = self.down_convs[i](x, edge_index)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            up = res\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            print(f'Early stopping at epoch {epoch} for fold {fold + 1}')\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456, 789, 101]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_NOPool(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values)\nstandard_deviation = np.std(mean_val_acc_values)\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}\")\nprint(f\"Standard Deviation: {standard_deviation:.2f}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Pubmed"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data(x=[19717, 500], edge_index=[2, 88648], y=[19717], train_mask=[19717], val_mask=[19717], test_mask=[19717])\n",
                        "Seed 42, Fold 1 Val Acc: 0.863\n",
                        "Seed 42, Fold 2 Val Acc: 0.866\n",
                        "Seed 42, Fold 3 Val Acc: 0.850\n",
                        "Seed 42, Fold 4 Val Acc: 0.860\n",
                        "Seed 42, Fold 5 Val Acc: 0.866\n",
                        "Seed 42 Results: Mean Val Acc: 0.861, Time: 16.454 seconds, Memory: 0.793 MB, GPU Memory: 532.677 MB\n",
                        "Seed 123, Fold 1 Val Acc: 0.853\n",
                        "Seed 123, Fold 2 Val Acc: 0.852\n",
                        "Seed 123, Fold 3 Val Acc: 0.870\n",
                        "Seed 123, Fold 4 Val Acc: 0.862\n",
                        "Seed 123, Fold 5 Val Acc: 0.866\n",
                        "Seed 123 Results: Mean Val Acc: 0.861, Time: 16.857 seconds, Memory: 0.782 MB, GPU Memory: 532.677 MB\n",
                        "Seed 456, Fold 1 Val Acc: 0.864\n",
                        "Seed 456, Fold 2 Val Acc: 0.859\n",
                        "Seed 456, Fold 3 Val Acc: 0.866\n",
                        "Seed 456, Fold 4 Val Acc: 0.858\n",
                        "Seed 456, Fold 5 Val Acc: 0.857\n",
                        "Seed 456 Results: Mean Val Acc: 0.861, Time: 15.540 seconds, Memory: 0.781 MB, GPU Memory: 532.677 MB\n",
                        "Seed 789, Fold 1 Val Acc: 0.860\n",
                        "Seed 789, Fold 2 Val Acc: 0.860\n",
                        "Seed 789, Fold 3 Val Acc: 0.864\n",
                        "Seed 789, Fold 4 Val Acc: 0.863\n",
                        "Seed 789, Fold 5 Val Acc: 0.864\n",
                        "Seed 789 Results: Mean Val Acc: 0.862, Time: 17.034 seconds, Memory: 0.780 MB, GPU Memory: 532.677 MB\n",
                        "Seed 101, Fold 1 Val Acc: 0.868\n",
                        "Seed 101, Fold 2 Val Acc: 0.856\n",
                        "Seed 101, Fold 3 Val Acc: 0.852\n",
                        "Seed 101, Fold 4 Val Acc: 0.857\n",
                        "Seed 101, Fold 5 Val Acc: 0.869\n",
                        "Seed 101 Results: Mean Val Acc: 0.860, Time: 17.105 seconds, Memory: 0.784 MB, GPU Memory: 532.677 MB\n",
                        "{'seed': 42, 'mean_val_acc': 0.8608811337420308, 'time': 16.453559637069702, 'memory': 0.792887, 'gpu_memory': 532.676608}\n",
                        "{'seed': 123, 'mean_val_acc': 0.860730135670629, 'time': 16.856635332107544, 'memory': 0.782172, 'gpu_memory': 532.676608}\n",
                        "{'seed': 456, 'mean_val_acc': 0.860932113756939, 'time': 15.540224552154541, 'memory': 0.780718, 'gpu_memory': 532.676608}\n",
                        "{'seed': 789, 'mean_val_acc': 0.862048169683713, 'time': 17.034347772598267, 'memory': 0.779686, 'gpu_memory': 532.676608}\n",
                        "{'seed': 101, 'mean_val_acc': 0.8603234272974059, 'time': 17.10546875, 'memory': 0.783987, 'gpu_memory': 532.676608}\n",
                        "Total Mean Val Acc: 0.86\n",
                        "Standard Deviation: 0.00\n"
                    ]
                }
            ],
            "source": "dataset_sparse = Planetoid(root=\"/data/XXX/Pooling\", name='PubMed')\ndataset_sparse = dataset_sparse.shuffle()\nprint(dataset_sparse[0])\nimport time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, TopKPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = dataset_sparse\ngraph = dataset[0]\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.5, 0.5]\nclass HierarchicalGCN_NOPool(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_NOPool, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.sum_res = sum_res\n        self.act = act\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        xs = [x]\n        edge_indices = [edge_index]\n        for i in range(1, self.depth + 1):\n            x = self.down_convs[i](x, edge_index)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            up = res\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            print(f'Early stopping at epoch {epoch} for fold {fold + 1}')\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456, 789, 101]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_NOPool(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values)\nstandard_deviation = np.std(mean_val_acc_values)\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}\")\nprint(f\"Standard Deviation: {standard_deviation:.2f}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Cornell"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data(x=[183, 1703], edge_index=[2, 298], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10])\n",
                        "Early stopping at epoch 170 for fold 1\n",
                        "Seed 42, Fold 1 Val Acc: 0.541\n",
                        "Seed 42, Fold 2 Val Acc: 0.432\n",
                        "Early stopping at epoch 151 for fold 3\n",
                        "Seed 42, Fold 3 Val Acc: 0.459\n",
                        "Seed 42, Fold 4 Val Acc: 0.500\n",
                        "Early stopping at epoch 151 for fold 5\n",
                        "Seed 42, Fold 5 Val Acc: 0.444\n",
                        "Seed 42 Results: Mean Val Acc: 0.475, Time: 13.516 seconds, Memory: 0.253 MB, GPU Memory: 9965.666 MB\n",
                        "Early stopping at epoch 153 for fold 1\n",
                        "Seed 123, Fold 1 Val Acc: 0.486\n",
                        "Early stopping at epoch 179 for fold 2\n",
                        "Seed 123, Fold 2 Val Acc: 0.459\n",
                        "Early stopping at epoch 155 for fold 3\n",
                        "Seed 123, Fold 3 Val Acc: 0.459\n",
                        "Early stopping at epoch 152 for fold 4\n",
                        "Seed 123, Fold 4 Val Acc: 0.472\n",
                        "Early stopping at epoch 153 for fold 5\n",
                        "Seed 123, Fold 5 Val Acc: 0.500\n",
                        "Seed 123 Results: Mean Val Acc: 0.476, Time: 12.134 seconds, Memory: 0.219 MB, GPU Memory: 9965.666 MB\n",
                        "Seed 456, Fold 1 Val Acc: 0.459\n",
                        "Early stopping at epoch 152 for fold 2\n",
                        "Seed 456, Fold 2 Val Acc: 0.568\n",
                        "Seed 456, Fold 3 Val Acc: 0.486\n",
                        "Early stopping at epoch 167 for fold 4\n",
                        "Seed 456, Fold 4 Val Acc: 0.444\n",
                        "Early stopping at epoch 151 for fold 5\n",
                        "Seed 456, Fold 5 Val Acc: 0.528\n",
                        "Seed 456 Results: Mean Val Acc: 0.497, Time: 14.147 seconds, Memory: 0.217 MB, GPU Memory: 9965.666 MB\n",
                        "Seed 789, Fold 1 Val Acc: 0.514\n",
                        "Early stopping at epoch 152 for fold 2\n",
                        "Seed 789, Fold 2 Val Acc: 0.405\n",
                        "Early stopping at epoch 159 for fold 3\n",
                        "Seed 789, Fold 3 Val Acc: 0.703\n",
                        "Seed 789, Fold 4 Val Acc: 0.500\n",
                        "Seed 789, Fold 5 Val Acc: 0.389\n",
                        "Seed 789 Results: Mean Val Acc: 0.502, Time: 14.733 seconds, Memory: 0.220 MB, GPU Memory: 9965.666 MB\n",
                        "Early stopping at epoch 152 for fold 1\n",
                        "Seed 101, Fold 1 Val Acc: 0.486\n",
                        "Early stopping at epoch 154 for fold 2\n",
                        "Seed 101, Fold 2 Val Acc: 0.459\n",
                        "Seed 101, Fold 3 Val Acc: 0.541\n",
                        "Seed 101, Fold 4 Val Acc: 0.472\n",
                        "Seed 101, Fold 5 Val Acc: 0.500\n",
                        "Seed 101 Results: Mean Val Acc: 0.492, Time: 14.050 seconds, Memory: 0.221 MB, GPU Memory: 9965.666 MB\n",
                        "{'seed': 42, 'mean_val_acc': 0.47537537537537544, 'time': 13.515649318695068, 'memory': 0.252773, 'gpu_memory': 9965.666304}\n",
                        "{'seed': 123, 'mean_val_acc': 0.4755255255255255, 'time': 12.133843898773193, 'memory': 0.219179, 'gpu_memory': 9965.666304}\n",
                        "{'seed': 456, 'mean_val_acc': 0.4971471471471472, 'time': 14.14650011062622, 'memory': 0.217044, 'gpu_memory': 9965.666304}\n",
                        "{'seed': 789, 'mean_val_acc': 0.502102102102102, 'time': 14.733386278152466, 'memory': 0.22035, 'gpu_memory': 9965.666304}\n",
                        "{'seed': 101, 'mean_val_acc': 0.49174174174174173, 'time': 14.049824237823486, 'memory': 0.221119, 'gpu_memory': 9965.666304}\n",
                        "Total Mean Val Acc: 0.49\n",
                        "Standard Deviation: 0.01\n"
                    ]
                }
            ],
            "source": "from torch_geometric.datasets import WebKB\ndataset_sparse = WebKB(root=\"/data/XXX/Pooling\", name='Cornell')\ndataset_sparse = dataset_sparse.shuffle()\nprint(dataset_sparse[0])\nimport time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, TopKPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = dataset_sparse\ngraph = dataset[0]\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.5, 0.5]\nclass HierarchicalGCN_NOPool(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_NOPool, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.sum_res = sum_res\n        self.act = act\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        x = F.relu(x)  \n        xs = [x]\n        edge_indices = [edge_index]\n        for i in range(1, self.depth + 1):\n            x = self.down_convs[i](x, edge_index)\n            x = F.relu(x)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            up = res\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n            x = F.relu(x)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            print(f'Early stopping at epoch {epoch} for fold {fold + 1}')\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456, 789, 101]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_NOPool(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values)\nstandard_deviation = np.std(mean_val_acc_values)\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}\")\nprint(f\"Standard Deviation: {standard_deviation:.2f}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Texas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data(x=[183, 1703], edge_index=[2, 325], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10])\n",
                        "Early stopping at epoch 153 for fold 1\n",
                        "Seed 42, Fold 1 Val Acc: 0.541\n",
                        "Early stopping at epoch 153 for fold 2\n",
                        "Seed 42, Fold 2 Val Acc: 0.595\n",
                        "Early stopping at epoch 151 for fold 3\n",
                        "Seed 42, Fold 3 Val Acc: 0.568\n",
                        "Early stopping at epoch 158 for fold 4\n",
                        "Seed 42, Fold 4 Val Acc: 0.583\n",
                        "Early stopping at epoch 153 for fold 5\n",
                        "Seed 42, Fold 5 Val Acc: 0.472\n",
                        "Seed 42 Results: Mean Val Acc: 0.552, Time: 12.252 seconds, Memory: 0.236 MB, GPU Memory: 9965.666 MB\n",
                        "Early stopping at epoch 165 for fold 1\n",
                        "Seed 123, Fold 1 Val Acc: 0.703\n",
                        "Early stopping at epoch 152 for fold 2\n",
                        "Seed 123, Fold 2 Val Acc: 0.459\n",
                        "Early stopping at epoch 155 for fold 3\n",
                        "Seed 123, Fold 3 Val Acc: 0.757\n",
                        "Early stopping at epoch 158 for fold 4\n",
                        "Seed 123, Fold 4 Val Acc: 0.611\n",
                        "Early stopping at epoch 154 for fold 5\n",
                        "Seed 123, Fold 5 Val Acc: 0.361\n",
                        "Seed 123 Results: Mean Val Acc: 0.578, Time: 12.182 seconds, Memory: 0.217 MB, GPU Memory: 9965.666 MB\n",
                        "Early stopping at epoch 153 for fold 1\n",
                        "Seed 456, Fold 1 Val Acc: 0.459\n",
                        "Early stopping at epoch 158 for fold 2\n",
                        "Seed 456, Fold 2 Val Acc: 0.541\n",
                        "Early stopping at epoch 154 for fold 3\n",
                        "Seed 456, Fold 3 Val Acc: 0.595\n",
                        "Early stopping at epoch 154 for fold 4\n",
                        "Seed 456, Fold 4 Val Acc: 0.639\n",
                        "Early stopping at epoch 151 for fold 5\n",
                        "Seed 456, Fold 5 Val Acc: 0.556\n",
                        "Seed 456 Results: Mean Val Acc: 0.558, Time: 11.558 seconds, Memory: 0.219 MB, GPU Memory: 9965.666 MB\n",
                        "Early stopping at epoch 152 for fold 1\n",
                        "Seed 789, Fold 1 Val Acc: 0.486\n",
                        "Early stopping at epoch 164 for fold 2\n",
                        "Seed 789, Fold 2 Val Acc: 0.595\n",
                        "Early stopping at epoch 151 for fold 3\n",
                        "Seed 789, Fold 3 Val Acc: 0.568\n",
                        "Early stopping at epoch 155 for fold 4\n",
                        "Seed 789, Fold 4 Val Acc: 0.472\n",
                        "Early stopping at epoch 153 for fold 5\n",
                        "Seed 789, Fold 5 Val Acc: 0.750\n",
                        "Seed 789 Results: Mean Val Acc: 0.574, Time: 11.708 seconds, Memory: 0.218 MB, GPU Memory: 9965.666 MB\n",
                        "Early stopping at epoch 153 for fold 1\n",
                        "Seed 101, Fold 1 Val Acc: 0.514\n",
                        "Early stopping at epoch 156 for fold 2\n",
                        "Seed 101, Fold 2 Val Acc: 0.541\n",
                        "Early stopping at epoch 151 for fold 3\n",
                        "Seed 101, Fold 3 Val Acc: 0.568\n",
                        "Early stopping at epoch 151 for fold 4\n",
                        "Seed 101, Fold 4 Val Acc: 0.639\n",
                        "Early stopping at epoch 153 for fold 5\n",
                        "Seed 101, Fold 5 Val Acc: 0.556\n",
                        "Seed 101 Results: Mean Val Acc: 0.563, Time: 10.612 seconds, Memory: 0.216 MB, GPU Memory: 9965.666 MB\n",
                        "{'seed': 42, 'mean_val_acc': 0.5516516516516516, 'time': 12.251810312271118, 'memory': 0.23593, 'gpu_memory': 9965.666304}\n",
                        "{'seed': 123, 'mean_val_acc': 0.5782282282282283, 'time': 12.182215213775635, 'memory': 0.216984, 'gpu_memory': 9965.666304}\n",
                        "{'seed': 456, 'mean_val_acc': 0.5578078078078079, 'time': 11.557883262634277, 'memory': 0.218537, 'gpu_memory': 9965.666304}\n",
                        "{'seed': 789, 'mean_val_acc': 0.5741741741741742, 'time': 11.708084106445312, 'memory': 0.217794, 'gpu_memory': 9965.666304}\n",
                        "{'seed': 101, 'mean_val_acc': 0.5632132132132132, 'time': 10.612060070037842, 'memory': 0.216039, 'gpu_memory': 9965.666304}\n",
                        "Total Mean Val Acc: 0.57\n",
                        "Standard Deviation: 0.01\n"
                    ]
                }
            ],
            "source": "from torch_geometric.datasets import WebKB\ndataset_sparse = WebKB(root=\"/data/XXX/Pooling\", name='texas')\ndataset_sparse = dataset_sparse.shuffle()\nprint(dataset_sparse[0])\nimport time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, TopKPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = dataset_sparse\ngraph = dataset[0]\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.5, 0.5]\nclass HierarchicalGCN_NOPool(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_NOPool, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.sum_res = sum_res\n        self.act = act\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        x = F.relu(x)  \n        xs = [x]\n        edge_indices = [edge_index]\n        for i in range(1, self.depth + 1):\n            x = self.down_convs[i](x, edge_index)\n            x = F.relu(x)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            up = res\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n            x = F.relu(x)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            print(f'Early stopping at epoch {epoch} for fold {fold + 1}')\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456, 789, 101]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_NOPool(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values)\nstandard_deviation = np.std(mean_val_acc_values)\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}\")\nprint(f\"Standard Deviation: {standard_deviation:.2f}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Wisconsin"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data(x=[251, 1703], edge_index=[2, 515], y=[251], train_mask=[251, 10], val_mask=[251, 10], test_mask=[251, 10])\n",
                        "Early stopping at epoch 153 for fold 1\n",
                        "Seed 42, Fold 1 Val Acc: 0.549\n",
                        "Early stopping at epoch 161 for fold 2\n",
                        "Seed 42, Fold 2 Val Acc: 0.540\n",
                        "Early stopping at epoch 157 for fold 3\n",
                        "Seed 42, Fold 3 Val Acc: 0.580\n",
                        "Early stopping at epoch 156 for fold 4\n",
                        "Seed 42, Fold 4 Val Acc: 0.640\n",
                        "Early stopping at epoch 163 for fold 5\n",
                        "Seed 42, Fold 5 Val Acc: 0.500\n",
                        "Seed 42 Results: Mean Val Acc: 0.562, Time: 11.768 seconds, Memory: 0.236 MB, GPU Memory: 9965.666 MB\n",
                        "Early stopping at epoch 164 for fold 1\n",
                        "Seed 123, Fold 1 Val Acc: 0.510\n",
                        "Early stopping at epoch 151 for fold 2\n",
                        "Seed 123, Fold 2 Val Acc: 0.500\n",
                        "Seed 123, Fold 3 Val Acc: 0.580\n",
                        "Early stopping at epoch 153 for fold 4\n",
                        "Seed 123, Fold 4 Val Acc: 0.540\n",
                        "Early stopping at epoch 158 for fold 5\n",
                        "Seed 123, Fold 5 Val Acc: 0.640\n",
                        "Seed 123 Results: Mean Val Acc: 0.554, Time: 12.323 seconds, Memory: 0.226 MB, GPU Memory: 9965.666 MB\n",
                        "Early stopping at epoch 157 for fold 1\n",
                        "Seed 456, Fold 1 Val Acc: 0.549\n",
                        "Early stopping at epoch 179 for fold 2\n",
                        "Seed 456, Fold 2 Val Acc: 0.560\n",
                        "Early stopping at epoch 171 for fold 3\n",
                        "Seed 456, Fold 3 Val Acc: 0.560\n",
                        "Early stopping at epoch 153 for fold 4\n",
                        "Seed 456, Fold 4 Val Acc: 0.540\n",
                        "Early stopping at epoch 162 for fold 5\n",
                        "Seed 456, Fold 5 Val Acc: 0.480\n",
                        "Seed 456 Results: Mean Val Acc: 0.538, Time: 12.414 seconds, Memory: 0.220 MB, GPU Memory: 9965.666 MB\n",
                        "Early stopping at epoch 157 for fold 1\n",
                        "Seed 789, Fold 1 Val Acc: 0.510\n",
                        "Early stopping at epoch 158 for fold 2\n",
                        "Seed 789, Fold 2 Val Acc: 0.520\n",
                        "Early stopping at epoch 159 for fold 3\n",
                        "Seed 789, Fold 3 Val Acc: 0.520\n",
                        "Early stopping at epoch 159 for fold 4\n",
                        "Seed 789, Fold 4 Val Acc: 0.560\n",
                        "Early stopping at epoch 152 for fold 5\n",
                        "Seed 789, Fold 5 Val Acc: 0.500\n",
                        "Seed 789 Results: Mean Val Acc: 0.522, Time: 11.772 seconds, Memory: 0.220 MB, GPU Memory: 9965.666 MB\n",
                        "Seed 101, Fold 1 Val Acc: 0.510\n",
                        "Early stopping at epoch 159 for fold 2\n",
                        "Seed 101, Fold 2 Val Acc: 0.600\n",
                        "Early stopping at epoch 158 for fold 3\n",
                        "Seed 101, Fold 3 Val Acc: 0.520\n",
                        "Early stopping at epoch 161 for fold 4\n",
                        "Seed 101, Fold 4 Val Acc: 0.540\n",
                        "Early stopping at epoch 162 for fold 5\n",
                        "Seed 101, Fold 5 Val Acc: 0.560\n",
                        "Seed 101 Results: Mean Val Acc: 0.546, Time: 11.397 seconds, Memory: 0.221 MB, GPU Memory: 9965.666 MB\n",
                        "{'seed': 42, 'mean_val_acc': 0.5618039215686275, 'time': 11.767575740814209, 'memory': 0.236133, 'gpu_memory': 9965.666304}\n",
                        "{'seed': 123, 'mean_val_acc': 0.5539607843137255, 'time': 12.323111295700073, 'memory': 0.226199, 'gpu_memory': 9965.666304}\n",
                        "{'seed': 456, 'mean_val_acc': 0.5378039215686274, 'time': 12.413836240768433, 'memory': 0.220297, 'gpu_memory': 9965.666304}\n",
                        "{'seed': 789, 'mean_val_acc': 0.5219607843137255, 'time': 11.772452592849731, 'memory': 0.220091, 'gpu_memory': 9965.666304}\n",
                        "{'seed': 101, 'mean_val_acc': 0.5459607843137255, 'time': 11.396892309188843, 'memory': 0.220923, 'gpu_memory': 9965.666304}\n",
                        "Total Mean Val Acc: 0.54\n",
                        "Standard Deviation: 0.01\n"
                    ]
                }
            ],
            "source": "from torch_geometric.datasets import WebKB\ndataset_sparse = WebKB(root=\"/data/XXX/Pooling\", name='wisconsin')\ndataset_sparse = dataset_sparse.shuffle()\nprint(dataset_sparse[0])\nimport time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, TopKPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = dataset_sparse\ngraph = dataset[0]\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.5, 0.5]\nclass HierarchicalGCN_NOPool(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_NOPool, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.sum_res = sum_res\n        self.act = act\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        x = F.relu(x)  \n        xs = [x]\n        edge_indices = [edge_index]\n        for i in range(1, self.depth + 1):\n            x = self.down_convs[i](x, edge_index)\n            x = F.relu(x)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            up = res\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n            x = F.relu(x)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            print(f'Early stopping at epoch {epoch} for fold {fold + 1}')\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456, 789, 101]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_NOPool(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values)\nstandard_deviation = np.std(mean_val_acc_values)\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}\")\nprint(f\"Standard Deviation: {standard_deviation:.2f}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Github"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data(x=[37700, 128], edge_index=[2, 578006], y=[37700])\n",
                        "Seed 42, Fold 1 Val Acc: 0.859\n",
                        "Seed 42, Fold 2 Val Acc: 0.872\n",
                        "Seed 42, Fold 3 Val Acc: 0.861\n",
                        "Seed 42, Fold 4 Val Acc: 0.865\n",
                        "Seed 42, Fold 5 Val Acc: 0.866\n",
                        "Seed 42 Results: Mean Val Acc: 0.865, Time: 28.486 seconds, Memory: 1.391 MB, GPU Memory: 851.444 MB\n",
                        "Seed 123, Fold 1 Val Acc: 0.862\n",
                        "Seed 123, Fold 2 Val Acc: 0.862\n",
                        "Seed 123, Fold 3 Val Acc: 0.862\n",
                        "Seed 123, Fold 4 Val Acc: 0.871\n",
                        "Seed 123, Fold 5 Val Acc: 0.867\n",
                        "Seed 123 Results: Mean Val Acc: 0.865, Time: 28.681 seconds, Memory: 1.382 MB, GPU Memory: 851.444 MB\n",
                        "Seed 456, Fold 1 Val Acc: 0.857\n",
                        "Seed 456, Fold 2 Val Acc: 0.871\n",
                        "Seed 456, Fold 3 Val Acc: 0.865\n",
                        "Seed 456, Fold 4 Val Acc: 0.864\n",
                        "Seed 456, Fold 5 Val Acc: 0.866\n",
                        "Seed 456 Results: Mean Val Acc: 0.864, Time: 29.084 seconds, Memory: 1.375 MB, GPU Memory: 851.444 MB\n",
                        "Seed 789, Fold 1 Val Acc: 0.866\n",
                        "Seed 789, Fold 2 Val Acc: 0.866\n",
                        "Seed 789, Fold 3 Val Acc: 0.861\n",
                        "Seed 789, Fold 4 Val Acc: 0.864\n",
                        "Seed 789, Fold 5 Val Acc: 0.865\n",
                        "Seed 789 Results: Mean Val Acc: 0.865, Time: 28.959 seconds, Memory: 1.375 MB, GPU Memory: 851.444 MB\n",
                        "Seed 101, Fold 1 Val Acc: 0.862\n",
                        "Seed 101, Fold 2 Val Acc: 0.869\n",
                        "Seed 101, Fold 3 Val Acc: 0.866\n",
                        "Seed 101, Fold 4 Val Acc: 0.863\n",
                        "Seed 101, Fold 5 Val Acc: 0.865\n",
                        "Seed 101 Results: Mean Val Acc: 0.865, Time: 28.918 seconds, Memory: 1.374 MB, GPU Memory: 851.444 MB\n",
                        "{'seed': 42, 'mean_val_acc': 0.8645092838196285, 'time': 28.485674381256104, 'memory': 1.39096, 'gpu_memory': 851.443712}\n",
                        "{'seed': 123, 'mean_val_acc': 0.8648806366047745, 'time': 28.681262731552124, 'memory': 1.382042, 'gpu_memory': 851.443712}\n",
                        "{'seed': 456, 'mean_val_acc': 0.8644562334217506, 'time': 29.08366370201111, 'memory': 1.37529, 'gpu_memory': 851.443712}\n",
                        "{'seed': 789, 'mean_val_acc': 0.8645092838196288, 'time': 28.958523273468018, 'memory': 1.374932, 'gpu_memory': 851.443712}\n",
                        "{'seed': 101, 'mean_val_acc': 0.8647745358090185, 'time': 28.918110609054565, 'memory': 1.373989, 'gpu_memory': 851.443712}\n",
                        "Total Mean Val Acc: 0.86\n",
                        "Standard Deviation: 0.00\n"
                    ]
                }
            ],
            "source": "from torch_geometric.datasets import GitHub\ndataset_sparse = GitHub(root=\"/data/XXX/Pooling/GitHub\")\ndataset_sparse = dataset_sparse.shuffle()\nprint(dataset_sparse[0])\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nimport time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, TopKPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = dataset_sparse\ngraph = dataset[0]\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.5, 0.5]\nclass HierarchicalGCN_NOPool(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_NOPool, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.sum_res = sum_res\n        self.act = act\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        xs = [x]\n        edge_indices = [edge_index]\n        for i in range(1, self.depth + 1):\n            x = self.down_convs[i](x, edge_index)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            up = res\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            print(f'Early stopping at epoch {epoch} for fold {fold + 1}')\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456, 789, 101]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_NOPool(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values)\nstandard_deviation = np.std(mean_val_acc_values)\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}\")\nprint(f\"Standard Deviation: {standard_deviation:.2f}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ogbn-arxiv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/boot/anaconda3/envs/XXX1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": "import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\nimport sys\nimport torch\nfrom transformers.optimization import get_cosine_schedule_with_warmup\nimport torch.nn.functional as F\nimport torch_geometric.transforms as T\nfrom ogb.nodeproppred import PygNodePropPredDataset, Evaluator\nfrom torch_geometric.loader import DataLoader\nimport os\nimport random\nimport pandas as pd\nimport torch\nimport torch_geometric.transforms as T\nfrom typing import Optional\nimport torch\nfrom torch import Tensor\nfrom torch_geometric.data import Data\nfrom torch_geometric.data.datapipes import functional_transform\nfrom torch_geometric.transforms import BaseTransform\nimport torch_geometric.transforms as T\nfrom torch_geometric.datasets import Planetoid\nfrom torch_geometric.datasets import WebKB\nfrom torch_geometric.datasets import Actor\nfrom torch_geometric.datasets import GNNBenchmarkDataset\nfrom torch_geometric.datasets import TUDataset\nfrom sklearn.metrics import r2_score\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import MoleculeNet\nfrom torch_geometric.nn import GCNConv\nfrom torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\nfrom torch_geometric.utils import to_networkx\nfrom torch.nn import Linear\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport numpy as np\nimport os\nimport random\nimport pandas as pd\nimport time\nimport psutil\nimport torch\nimport torch.nn.functional as F\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nmax_nodes = 150\ndataset_sparse = PygNodePropPredDataset(root='/data/XXX/Pooling', name=\"ogbn-arxiv\")\nevaluator = Evaluator(\"ogbn-arxiv\")\neval_metric = dataset_sparse.eval_metric"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Seed: 042, Epoch: 010, Loss: 3.0037, Train Acc: 0.2701, Val Acc: 0.3018, Test Acc: 0.3320\n",
                        "Seed: 042, Epoch: 020, Loss: 2.3124, Train Acc: 0.4146, Val Acc: 0.4447, Test Acc: 0.4008\n",
                        "Seed: 042, Epoch: 030, Loss: 1.9781, Train Acc: 0.4658, Val Acc: 0.4647, Test Acc: 0.3967\n",
                        "Seed: 042, Epoch: 040, Loss: 1.8068, Train Acc: 0.5143, Val Acc: 0.4991, Test Acc: 0.4390\n",
                        "Seed: 042, Epoch: 050, Loss: 1.6787, Train Acc: 0.5385, Val Acc: 0.5242, Test Acc: 0.4645\n",
                        "Seed: 042, Epoch: 060, Loss: 1.6096, Train Acc: 0.5526, Val Acc: 0.5350, Test Acc: 0.4680\n",
                        "Seed: 042, Epoch: 070, Loss: 1.5674, Train Acc: 0.5642, Val Acc: 0.5406, Test Acc: 0.4735\n",
                        "Seed: 042, Epoch: 080, Loss: 1.5374, Train Acc: 0.5702, Val Acc: 0.5468, Test Acc: 0.4775\n",
                        "Seed: 042, Epoch: 090, Loss: 1.5089, Train Acc: 0.5770, Val Acc: 0.5541, Test Acc: 0.4887\n",
                        "Seed: 042, Epoch: 100, Loss: 1.5275, Train Acc: 0.5771, Val Acc: 0.5617, Test Acc: 0.5005\n",
                        "Seed: 042, Epoch: 110, Loss: 1.4752, Train Acc: 0.5829, Val Acc: 0.5584, Test Acc: 0.4924\n",
                        "Seed: 042, Epoch: 120, Loss: 1.4612, Train Acc: 0.5865, Val Acc: 0.5631, Test Acc: 0.4970\n",
                        "Seed: 042, Epoch: 130, Loss: 1.4480, Train Acc: 0.5895, Val Acc: 0.5613, Test Acc: 0.4910\n",
                        "Seed: 042, Epoch: 140, Loss: 1.4400, Train Acc: 0.5901, Val Acc: 0.5649, Test Acc: 0.5032\n",
                        "Seed: 042, Epoch: 150, Loss: 1.4254, Train Acc: 0.5953, Val Acc: 0.5681, Test Acc: 0.4988\n",
                        "Seed: 042, Epoch: 160, Loss: 1.4158, Train Acc: 0.5980, Val Acc: 0.5696, Test Acc: 0.5023\n",
                        "Seed: 042, Epoch: 170, Loss: 1.4062, Train Acc: 0.6000, Val Acc: 0.5715, Test Acc: 0.5041\n",
                        "Seed: 042, Epoch: 180, Loss: 1.4214, Train Acc: 0.5927, Val Acc: 0.5765, Test Acc: 0.5182\n",
                        "Seed: 042, Epoch: 190, Loss: 1.4047, Train Acc: 0.6025, Val Acc: 0.5768, Test Acc: 0.5098\n",
                        "Seed: 042, Epoch: 200, Loss: 1.3882, Train Acc: 0.6039, Val Acc: 0.5743, Test Acc: 0.5090\n",
                        "Seed: 042, Epoch: 210, Loss: 1.4156, Train Acc: 0.6034, Val Acc: 0.5716, Test Acc: 0.5042\n",
                        "Seed: 042, Epoch: 220, Loss: 1.3852, Train Acc: 0.6070, Val Acc: 0.5807, Test Acc: 0.5138\n",
                        "Seed: 042, Epoch: 230, Loss: 1.3733, Train Acc: 0.6080, Val Acc: 0.5811, Test Acc: 0.5146\n",
                        "Seed: 042, Epoch: 240, Loss: 1.3670, Train Acc: 0.6074, Val Acc: 0.5773, Test Acc: 0.5092\n",
                        "Seed: 042, Epoch: 250, Loss: 1.3645, Train Acc: 0.6101, Val Acc: 0.5805, Test Acc: 0.5168\n",
                        "Seed: 042, Epoch: 260, Loss: 1.3578, Train Acc: 0.6119, Val Acc: 0.5806, Test Acc: 0.5144\n",
                        "Seed: 042, Epoch: 270, Loss: 1.3633, Train Acc: 0.6069, Val Acc: 0.5719, Test Acc: 0.5102\n",
                        "Seed: 042, Epoch: 280, Loss: 1.3572, Train Acc: 0.6101, Val Acc: 0.5767, Test Acc: 0.5134\n",
                        "Seed: 042, Epoch: 290, Loss: 1.3515, Train Acc: 0.6131, Val Acc: 0.5857, Test Acc: 0.5179\n",
                        "Seed: 042, Epoch: 300, Loss: 1.3422, Train Acc: 0.6145, Val Acc: 0.5818, Test Acc: 0.5173\n",
                        "Seed: 042, Epoch: 310, Loss: 1.3374, Train Acc: 0.6170, Val Acc: 0.5859, Test Acc: 0.5217\n",
                        "Seed: 042, Epoch: 320, Loss: 1.3434, Train Acc: 0.6168, Val Acc: 0.5819, Test Acc: 0.5157\n",
                        "Seed: 042, Epoch: 330, Loss: 1.3392, Train Acc: 0.6172, Val Acc: 0.5877, Test Acc: 0.5217\n",
                        "Seed: 042, Epoch: 340, Loss: 1.3385, Train Acc: 0.6166, Val Acc: 0.5819, Test Acc: 0.5094\n",
                        "Seed: 042, Epoch: 350, Loss: 1.3271, Train Acc: 0.6188, Val Acc: 0.5821, Test Acc: 0.5158\n",
                        "Seed: 042, Epoch: 360, Loss: 1.3313, Train Acc: 0.6154, Val Acc: 0.5833, Test Acc: 0.5214\n",
                        "Seed: 042, Epoch: 370, Loss: 1.3226, Train Acc: 0.6190, Val Acc: 0.5828, Test Acc: 0.5223\n",
                        "Seed: 042, Epoch: 380, Loss: 1.3210, Train Acc: 0.6202, Val Acc: 0.5862, Test Acc: 0.5240\n",
                        "Seed: 042, Epoch: 390, Loss: 1.3176, Train Acc: 0.6204, Val Acc: 0.5903, Test Acc: 0.5277\n",
                        "Seed: 042, Epoch: 400, Loss: 1.3126, Train Acc: 0.6214, Val Acc: 0.5874, Test Acc: 0.5228\n",
                        "Seed: 042, Epoch: 410, Loss: 1.3108, Train Acc: 0.6216, Val Acc: 0.5882, Test Acc: 0.5231\n",
                        "Seed: 042, Epoch: 420, Loss: 1.3173, Train Acc: 0.6202, Val Acc: 0.5846, Test Acc: 0.5273\n",
                        "Seed: 042, Epoch: 430, Loss: 1.3168, Train Acc: 0.6206, Val Acc: 0.5883, Test Acc: 0.5284\n",
                        "Seed: 042, Epoch: 440, Loss: 1.3047, Train Acc: 0.6231, Val Acc: 0.5899, Test Acc: 0.5254\n",
                        "Seed: 042, Epoch: 450, Loss: 1.3022, Train Acc: 0.6247, Val Acc: 0.5899, Test Acc: 0.5284\n",
                        "Seed: 042, Epoch: 460, Loss: 1.3006, Train Acc: 0.6250, Val Acc: 0.5873, Test Acc: 0.5219\n",
                        "Seed: 042, Epoch: 470, Loss: 1.3554, Train Acc: 0.6178, Val Acc: 0.5847, Test Acc: 0.5362\n",
                        "Seed: 042, Epoch: 480, Loss: 1.3279, Train Acc: 0.6231, Val Acc: 0.5822, Test Acc: 0.5161\n",
                        "Seed: 042, Epoch: 490, Loss: 1.3095, Train Acc: 0.6222, Val Acc: 0.5830, Test Acc: 0.5231\n",
                        "Seed: 042, Epoch: 500, Loss: 1.3047, Train Acc: 0.6248, Val Acc: 0.5866, Test Acc: 0.5262\n",
                        "Seed: 123, Epoch: 010, Loss: 3.0833, Train Acc: 0.2450, Val Acc: 0.2185, Test Acc: 0.2307\n",
                        "Seed: 123, Epoch: 020, Loss: 2.4892, Train Acc: 0.3796, Val Acc: 0.4163, Test Acc: 0.3784\n",
                        "Seed: 123, Epoch: 030, Loss: 2.0953, Train Acc: 0.4430, Val Acc: 0.4440, Test Acc: 0.3937\n",
                        "Seed: 123, Epoch: 040, Loss: 1.8686, Train Acc: 0.5002, Val Acc: 0.4917, Test Acc: 0.4318\n",
                        "Seed: 123, Epoch: 050, Loss: 1.7285, Train Acc: 0.5288, Val Acc: 0.5144, Test Acc: 0.4576\n",
                        "Seed: 123, Epoch: 060, Loss: 1.6601, Train Acc: 0.5441, Val Acc: 0.5268, Test Acc: 0.4663\n",
                        "Seed: 123, Epoch: 070, Loss: 1.5963, Train Acc: 0.5579, Val Acc: 0.5447, Test Acc: 0.4826\n",
                        "Seed: 123, Epoch: 080, Loss: 1.5560, Train Acc: 0.5671, Val Acc: 0.5510, Test Acc: 0.4879\n",
                        "Seed: 123, Epoch: 090, Loss: 1.5478, Train Acc: 0.5675, Val Acc: 0.5477, Test Acc: 0.4900\n",
                        "Seed: 123, Epoch: 100, Loss: 1.5146, Train Acc: 0.5780, Val Acc: 0.5530, Test Acc: 0.4886\n",
                        "Seed: 123, Epoch: 110, Loss: 1.4926, Train Acc: 0.5811, Val Acc: 0.5571, Test Acc: 0.4951\n",
                        "Seed: 123, Epoch: 120, Loss: 1.4710, Train Acc: 0.5860, Val Acc: 0.5606, Test Acc: 0.4996\n",
                        "Seed: 123, Epoch: 130, Loss: 1.4563, Train Acc: 0.5903, Val Acc: 0.5623, Test Acc: 0.4991\n",
                        "Seed: 123, Epoch: 140, Loss: 1.4534, Train Acc: 0.5900, Val Acc: 0.5643, Test Acc: 0.5067\n",
                        "Seed: 123, Epoch: 150, Loss: 1.4337, Train Acc: 0.5941, Val Acc: 0.5699, Test Acc: 0.5099\n",
                        "Seed: 123, Epoch: 160, Loss: 1.4248, Train Acc: 0.5980, Val Acc: 0.5730, Test Acc: 0.5152\n",
                        "Seed: 123, Epoch: 170, Loss: 1.4168, Train Acc: 0.5995, Val Acc: 0.5742, Test Acc: 0.5134\n",
                        "Seed: 123, Epoch: 180, Loss: 1.4073, Train Acc: 0.6012, Val Acc: 0.5751, Test Acc: 0.5108\n",
                        "Seed: 123, Epoch: 190, Loss: 1.4027, Train Acc: 0.6023, Val Acc: 0.5764, Test Acc: 0.5149\n",
                        "Seed: 123, Epoch: 200, Loss: 1.3982, Train Acc: 0.6028, Val Acc: 0.5786, Test Acc: 0.5188\n",
                        "Seed: 123, Epoch: 210, Loss: 1.3890, Train Acc: 0.6053, Val Acc: 0.5768, Test Acc: 0.5154\n",
                        "Seed: 123, Epoch: 220, Loss: 1.4002, Train Acc: 0.5989, Val Acc: 0.5777, Test Acc: 0.5218\n",
                        "Seed: 123, Epoch: 230, Loss: 1.3784, Train Acc: 0.6070, Val Acc: 0.5759, Test Acc: 0.5132\n",
                        "Seed: 123, Epoch: 240, Loss: 1.3738, Train Acc: 0.6080, Val Acc: 0.5844, Test Acc: 0.5232\n",
                        "Seed: 123, Epoch: 250, Loss: 1.3689, Train Acc: 0.6104, Val Acc: 0.5806, Test Acc: 0.5158\n",
                        "Seed: 123, Epoch: 260, Loss: 1.3651, Train Acc: 0.6063, Val Acc: 0.5838, Test Acc: 0.5298\n",
                        "Seed: 123, Epoch: 270, Loss: 1.3643, Train Acc: 0.6120, Val Acc: 0.5843, Test Acc: 0.5205\n",
                        "Seed: 123, Epoch: 280, Loss: 1.3550, Train Acc: 0.6131, Val Acc: 0.5834, Test Acc: 0.5223\n",
                        "Seed: 123, Epoch: 290, Loss: 1.3513, Train Acc: 0.6152, Val Acc: 0.5832, Test Acc: 0.5206\n",
                        "Seed: 123, Epoch: 300, Loss: 1.3575, Train Acc: 0.6153, Val Acc: 0.5849, Test Acc: 0.5227\n",
                        "Seed: 123, Epoch: 310, Loss: 1.3509, Train Acc: 0.6151, Val Acc: 0.5902, Test Acc: 0.5298\n",
                        "Seed: 123, Epoch: 320, Loss: 1.3499, Train Acc: 0.6163, Val Acc: 0.5858, Test Acc: 0.5225\n",
                        "Seed: 123, Epoch: 330, Loss: 1.3412, Train Acc: 0.6162, Val Acc: 0.5848, Test Acc: 0.5235\n",
                        "Seed: 123, Epoch: 340, Loss: 1.3943, Train Acc: 0.6064, Val Acc: 0.5801, Test Acc: 0.5224\n",
                        "Seed: 123, Epoch: 350, Loss: 1.3500, Train Acc: 0.6176, Val Acc: 0.5867, Test Acc: 0.5250\n",
                        "Seed: 123, Epoch: 360, Loss: 1.3393, Train Acc: 0.6193, Val Acc: 0.5856, Test Acc: 0.5243\n",
                        "Seed: 123, Epoch: 370, Loss: 1.3305, Train Acc: 0.6191, Val Acc: 0.5855, Test Acc: 0.5197\n",
                        "Seed: 123, Epoch: 380, Loss: 1.3412, Train Acc: 0.6168, Val Acc: 0.5808, Test Acc: 0.5161\n",
                        "Seed: 123, Epoch: 390, Loss: 1.3260, Train Acc: 0.6209, Val Acc: 0.5881, Test Acc: 0.5275\n",
                        "Seed: 123, Epoch: 400, Loss: 1.3239, Train Acc: 0.6209, Val Acc: 0.5873, Test Acc: 0.5232\n",
                        "Seed: 123, Epoch: 410, Loss: 1.3183, Train Acc: 0.6220, Val Acc: 0.5882, Test Acc: 0.5275\n",
                        "Seed: 123, Epoch: 420, Loss: 1.3172, Train Acc: 0.6230, Val Acc: 0.5906, Test Acc: 0.5296\n",
                        "Seed: 123, Epoch: 430, Loss: 1.3139, Train Acc: 0.6228, Val Acc: 0.5926, Test Acc: 0.5370\n",
                        "Seed: 123, Epoch: 440, Loss: 1.3255, Train Acc: 0.6162, Val Acc: 0.5859, Test Acc: 0.5327\n",
                        "Seed: 123, Epoch: 450, Loss: 1.3160, Train Acc: 0.6166, Val Acc: 0.5714, Test Acc: 0.5079\n",
                        "Seed: 123, Epoch: 460, Loss: 1.3242, Train Acc: 0.6164, Val Acc: 0.5772, Test Acc: 0.5182\n",
                        "Seed: 123, Epoch: 470, Loss: 1.3148, Train Acc: 0.6237, Val Acc: 0.5921, Test Acc: 0.5339\n",
                        "Seed: 123, Epoch: 480, Loss: 1.3036, Train Acc: 0.6249, Val Acc: 0.5876, Test Acc: 0.5247\n",
                        "Seed: 123, Epoch: 490, Loss: 1.3009, Train Acc: 0.6255, Val Acc: 0.5919, Test Acc: 0.5318\n",
                        "Seed: 123, Epoch: 500, Loss: 1.3214, Train Acc: 0.6222, Val Acc: 0.5894, Test Acc: 0.5300\n",
                        "Seed: 456, Epoch: 010, Loss: 3.2399, Train Acc: 0.2308, Val Acc: 0.1942, Test Acc: 0.1992\n",
                        "Seed: 456, Epoch: 020, Loss: 2.5833, Train Acc: 0.3521, Val Acc: 0.3745, Test Acc: 0.3287\n",
                        "Seed: 456, Epoch: 030, Loss: 2.1568, Train Acc: 0.4232, Val Acc: 0.4344, Test Acc: 0.3828\n",
                        "Seed: 456, Epoch: 040, Loss: 1.9736, Train Acc: 0.4728, Val Acc: 0.4628, Test Acc: 0.3953\n",
                        "Seed: 456, Epoch: 050, Loss: 1.7914, Train Acc: 0.5136, Val Acc: 0.4969, Test Acc: 0.4319\n",
                        "Seed: 456, Epoch: 060, Loss: 1.6899, Train Acc: 0.5392, Val Acc: 0.5227, Test Acc: 0.4598\n",
                        "Seed: 456, Epoch: 070, Loss: 1.6126, Train Acc: 0.5535, Val Acc: 0.5346, Test Acc: 0.4685\n",
                        "Seed: 456, Epoch: 080, Loss: 1.5757, Train Acc: 0.5630, Val Acc: 0.5483, Test Acc: 0.4872\n",
                        "Seed: 456, Epoch: 090, Loss: 1.5405, Train Acc: 0.5712, Val Acc: 0.5493, Test Acc: 0.4810\n",
                        "Seed: 456, Epoch: 100, Loss: 1.5156, Train Acc: 0.5763, Val Acc: 0.5556, Test Acc: 0.4894\n",
                        "Seed: 456, Epoch: 110, Loss: 1.4978, Train Acc: 0.5752, Val Acc: 0.5469, Test Acc: 0.4810\n",
                        "Seed: 456, Epoch: 120, Loss: 1.4918, Train Acc: 0.5830, Val Acc: 0.5651, Test Acc: 0.5052\n",
                        "Seed: 456, Epoch: 130, Loss: 1.4699, Train Acc: 0.5857, Val Acc: 0.5630, Test Acc: 0.4995\n",
                        "Seed: 456, Epoch: 140, Loss: 1.4630, Train Acc: 0.5862, Val Acc: 0.5643, Test Acc: 0.5005\n",
                        "Seed: 456, Epoch: 150, Loss: 1.4461, Train Acc: 0.5921, Val Acc: 0.5632, Test Acc: 0.4988\n",
                        "Seed: 456, Epoch: 160, Loss: 1.4361, Train Acc: 0.5947, Val Acc: 0.5717, Test Acc: 0.5094\n",
                        "Seed: 456, Epoch: 170, Loss: 1.4280, Train Acc: 0.5966, Val Acc: 0.5714, Test Acc: 0.5077\n",
                        "Seed: 456, Epoch: 180, Loss: 1.4256, Train Acc: 0.5977, Val Acc: 0.5719, Test Acc: 0.5081\n",
                        "Seed: 456, Epoch: 190, Loss: 1.4168, Train Acc: 0.5995, Val Acc: 0.5768, Test Acc: 0.5127\n",
                        "Seed: 456, Epoch: 200, Loss: 1.4072, Train Acc: 0.6017, Val Acc: 0.5732, Test Acc: 0.5079\n",
                        "Seed: 456, Epoch: 210, Loss: 1.3998, Train Acc: 0.6027, Val Acc: 0.5754, Test Acc: 0.5097\n",
                        "Seed: 456, Epoch: 220, Loss: 1.3947, Train Acc: 0.6030, Val Acc: 0.5769, Test Acc: 0.5153\n",
                        "Seed: 456, Epoch: 230, Loss: 1.3893, Train Acc: 0.6043, Val Acc: 0.5760, Test Acc: 0.5141\n",
                        "Seed: 456, Epoch: 240, Loss: 1.3928, Train Acc: 0.6042, Val Acc: 0.5733, Test Acc: 0.5102\n",
                        "Seed: 456, Epoch: 250, Loss: 1.3834, Train Acc: 0.6064, Val Acc: 0.5764, Test Acc: 0.5120\n",
                        "Seed: 456, Epoch: 260, Loss: 1.3795, Train Acc: 0.6057, Val Acc: 0.5792, Test Acc: 0.5149\n",
                        "Seed: 456, Epoch: 270, Loss: 1.3748, Train Acc: 0.6089, Val Acc: 0.5792, Test Acc: 0.5141\n",
                        "Seed: 456, Epoch: 280, Loss: 1.3689, Train Acc: 0.6085, Val Acc: 0.5769, Test Acc: 0.5100\n",
                        "Seed: 456, Epoch: 290, Loss: 1.3736, Train Acc: 0.6098, Val Acc: 0.5848, Test Acc: 0.5267\n",
                        "Seed: 456, Epoch: 300, Loss: 1.3617, Train Acc: 0.6109, Val Acc: 0.5824, Test Acc: 0.5167\n",
                        "Seed: 456, Epoch: 310, Loss: 1.3565, Train Acc: 0.6122, Val Acc: 0.5813, Test Acc: 0.5167\n",
                        "Seed: 456, Epoch: 320, Loss: 1.3781, Train Acc: 0.6064, Val Acc: 0.5785, Test Acc: 0.5185\n",
                        "Seed: 456, Epoch: 330, Loss: 1.3540, Train Acc: 0.6132, Val Acc: 0.5810, Test Acc: 0.5149\n",
                        "Seed: 456, Epoch: 340, Loss: 1.3507, Train Acc: 0.6140, Val Acc: 0.5849, Test Acc: 0.5217\n",
                        "Seed: 456, Epoch: 350, Loss: 1.3515, Train Acc: 0.6131, Val Acc: 0.5810, Test Acc: 0.5143\n",
                        "Seed: 456, Epoch: 360, Loss: 1.3457, Train Acc: 0.6156, Val Acc: 0.5843, Test Acc: 0.5214\n",
                        "Seed: 456, Epoch: 370, Loss: 1.3422, Train Acc: 0.6157, Val Acc: 0.5824, Test Acc: 0.5163\n",
                        "Seed: 456, Epoch: 380, Loss: 1.3438, Train Acc: 0.6152, Val Acc: 0.5905, Test Acc: 0.5338\n",
                        "Seed: 456, Epoch: 390, Loss: 1.3385, Train Acc: 0.6156, Val Acc: 0.5824, Test Acc: 0.5166\n",
                        "Seed: 456, Epoch: 400, Loss: 1.3346, Train Acc: 0.6172, Val Acc: 0.5872, Test Acc: 0.5266\n",
                        "Seed: 456, Epoch: 410, Loss: 1.3413, Train Acc: 0.6167, Val Acc: 0.5871, Test Acc: 0.5267\n",
                        "Seed: 456, Epoch: 420, Loss: 1.3318, Train Acc: 0.6174, Val Acc: 0.5849, Test Acc: 0.5266\n",
                        "Seed: 456, Epoch: 430, Loss: 1.3271, Train Acc: 0.6187, Val Acc: 0.5855, Test Acc: 0.5216\n",
                        "Seed: 456, Epoch: 440, Loss: 1.3286, Train Acc: 0.6181, Val Acc: 0.5858, Test Acc: 0.5206\n",
                        "Seed: 456, Epoch: 450, Loss: 1.3469, Train Acc: 0.6163, Val Acc: 0.5760, Test Acc: 0.5137\n",
                        "Seed: 456, Epoch: 460, Loss: 1.3342, Train Acc: 0.6189, Val Acc: 0.5859, Test Acc: 0.5235\n",
                        "Seed: 456, Epoch: 470, Loss: 1.3244, Train Acc: 0.6207, Val Acc: 0.5869, Test Acc: 0.5238\n",
                        "Seed: 456, Epoch: 480, Loss: 1.3212, Train Acc: 0.6205, Val Acc: 0.5845, Test Acc: 0.5200\n",
                        "Seed: 456, Epoch: 490, Loss: 1.3362, Train Acc: 0.6155, Val Acc: 0.5775, Test Acc: 0.5106\n",
                        "Seed: 456, Epoch: 500, Loss: 1.3199, Train Acc: 0.6202, Val Acc: 0.5824, Test Acc: 0.5154\n",
                        "Seed: 42, Best Val Acc: 0.5944, Corresponding Test Acc: 0.5371, Time: 73.73s, Memory: 3.92MB, GPU Memory: 8132.38MB\n",
                        "Seed: 123, Best Val Acc: 0.5948, Corresponding Test Acc: 0.5387, Time: 73.76s, Memory: 1.50MB, GPU Memory: 8062.15MB\n",
                        "Seed: 456, Best Val Acc: 0.5920, Corresponding Test Acc: 0.5324, Time: 73.46s, Memory: 1.50MB, GPU Memory: 8062.15MB\n",
                        "\n",
                        "Average Best Validation Accuracy: 0.5937\n",
                        "Average Corresponding Test Accuracy: 0.5361\n",
                        "Average Time: 73.65s\n",
                        "Average Memory Usage: 2.31MB\n",
                        "Average GPU Memory Usage: 8085.56MB\n"
                    ]
                }
            ],
            "source": "from torch_geometric.datasets import GitHub\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nimport time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, TopKPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = dataset_sparse\ngraph = dataset[0]\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.5, 0.5]\nclass HierarchicalGCN_NOPool(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_NOPool, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.sum_res = sum_res\n        self.act = act\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = self.down_convs[0](x, edge_index)\n        x = F.relu(x) \n        xs = [x]\n        edge_indices = [edge_index]\n        for i in range(1, self.depth + 1):\n            x = self.down_convs[i](x, edge_index)\n            x = F.relu(x)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            up = res\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n            x = F.relu(x)\n        x = self.up_convs[-1](x, edge_index)\n        return x.log_softmax(dim=-1)\ndef train(model, data, train_idx, optimizer):\n    model.train()\n    optimizer.zero_grad()\n    out = model(data.x, data.edge_index)[train_idx]\n    loss = F.nll_loss(out, data.y.squeeze(1)[train_idx])\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n@torch.no_grad()\ndef test(model, data, split_idx, evaluator):\n    model.eval()\n    out = model(data.x, data.edge_index)\n    y_pred = out.argmax(dim=-1, keepdim=True)\n    train_acc = evaluator.eval({\n        'y_true': data.y[split_idx['train']],\n        'y_pred': y_pred[split_idx['train']],\n    })['acc']\n    valid_acc = evaluator.eval({\n        'y_true': data.y[split_idx['valid']],\n        'y_pred': y_pred[split_idx['valid']],\n    })['acc']\n    test_acc = evaluator.eval({\n        'y_true': data.y[split_idx['test']],\n        'y_pred': y_pred[split_idx['test']],\n    })['acc']\n    return train_acc, valid_acc, test_acc\nseeds = [42, 123, 456]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    test_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    model = HierarchicalGCN_NOPool(\n        in_channels=graph.num_features,\n        hidden_channels=256,\n        out_channels=dataset.num_classes,\n        depth=2,\n        act=F.relu,\n        sum_res=False\n    ).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n    split_idx = dataset.get_idx_split()\n    train_idx = split_idx['train'].to(device)\n    for epoch in range(1, 501):\n        loss = train(model, graph, split_idx['train'], optimizer)\n        train_acc, valid_acc, test_acc = test(model, graph, split_idx, evaluator)\n        val_accuracies.append(valid_acc)\n        test_accuracies.append(test_acc)\n        if epoch % 10 == 0:\n            print(f'Seed: {seed:03d}, Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n                  f'Train Acc: {train_acc:.4f}, Val Acc: {valid_acc:.4f}, Test Acc: {test_acc:.4f}')\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    elapsed_time = end_time - start_time\n    memory_usage = current / 10**6  \n    peak_memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.max_memory_allocated(device) / 1024**2  \n        torch.cuda.reset_max_memory_allocated(device)\n    else:\n        gpu_memory_usage = 0\n    val_accuracies_list.append(val_accuracies)\n    times.append(elapsed_time)\n    memories.append(memory_usage)\n    gpu_memories.append(gpu_memory_usage)\n    best_val_acc = max(val_accuracies)\n    best_val_index = val_accuracies.index(best_val_acc)\n    corresponding_test_acc = test_accuracies[best_val_index]\n    results.append({\n        'seed': seed,\n        'best_val_acc': best_val_acc,\n        'corresponding_test_acc': corresponding_test_acc,\n        'elapsed_time': elapsed_time,\n        'memory_usage': memory_usage,\n        'gpu_memory_usage': gpu_memory_usage\n    })\nfor result in results:\n    print(f\"Seed: {result['seed']}, Best Val Acc: {result['best_val_acc']:.4f}, \"\n          f\"Corresponding Test Acc: {result['corresponding_test_acc']:.4f}, \"\n          f\"Time: {result['elapsed_time']:.2f}s, Memory: {result['memory_usage']:.2f}MB, \"\n          f\"GPU Memory: {result['gpu_memory_usage']:.2f}MB\")\navg_val_acc = np.mean([result['best_val_acc'] for result in results])\navg_test_acc = np.mean([result['corresponding_test_acc'] for result in results])\navg_time = np.mean(times)\navg_memory = np.mean(memories)\navg_gpu_memory = np.mean(gpu_memories)\nprint(f\"\\nAverage Best Validation Accuracy: {avg_val_acc:.4f}\")\nprint(f\"Average Corresponding Test Accuracy: {avg_test_acc:.4f}\")\nprint(f\"Average Time: {avg_time:.2f}s\")\nprint(f\"Average Memory Usage: {avg_memory:.2f}MB\")\nprint(f\"Average GPU Memory Usage: {avg_gpu_memory:.2f}MB\")"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "CG-ODE",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}