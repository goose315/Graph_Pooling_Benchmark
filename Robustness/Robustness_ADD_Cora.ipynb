{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using GPU(s): 1\n",
                        "True\n",
                        "Available GPUs: 1\n",
                        "Original number of edges: 10556\n",
                        "New number of edges: 21092\n"
                    ]
                }
            ],
            "source": "import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\nimport random\nimport pandas as pd\nimport torch\nvisible_devices = os.environ[\"CUDA_VISIBLE_DEVICES\"]\nprint(f\"Using GPU(s): {visible_devices}\")\nprint(torch.cuda.is_available())\nnum_gpus = torch.cuda.device_count()\nprint(f'Available GPUs: {num_gpus}')\nimport torch_geometric.transforms as T\nfrom typing import Optional\nimport torch\nfrom torch import Tensor\nfrom torch_geometric.data import Data\nfrom torch_geometric.data.datapipes import functional_transform\nfrom torch_geometric.transforms import BaseTransform\nfrom torch_geometric.utils import to_undirected, add_self_loops\nimport torch_geometric.transforms as T\nfrom torch_geometric.datasets import Planetoid\nfrom torch_geometric.datasets import WebKB\nfrom torch_geometric.datasets import Actor\nfrom torch_geometric.datasets import CitationFull\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndataset_sparse = Planetoid(root=\"/data/ /Pooling\", name='Cora')\ndataset_sparse = dataset_sparse[0]\nnum_nodes = dataset_sparse.num_nodes\nedge_index = dataset_sparse.edge_index\nnum_edges = edge_index.size(1)\nnum_new_edges = int(0.5 * num_edges)\nnew_edges = set()\nwhile len(new_edges) < num_new_edges:\n    i = torch.randint(0, num_nodes, (1,))\n    j = torch.randint(0, num_nodes, (1,))\n    if i != j:  \n        edge = (i.item(), j.item())\n        reverse_edge = (j.item(), i.item())\n        if edge not in new_edges and reverse_edge not in new_edges:\n            new_edges.add(edge)\nnew_edges = torch.tensor(list(new_edges)).t().contiguous()\nnew_edge_index = torch.cat([edge_index, new_edges], dim=1)\nnew_edge_index = to_undirected(new_edge_index)\ndataset_sparse.edge_index = new_edge_index\nprint(f\"Original number of edges: {num_edges}\")\nprint(f\"New number of edges: {dataset_sparse.edge_index.size(1)}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### TopKPooling with HierarchicalGCN (2019)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Seed 42, Fold 1 Val Acc: 0.762\n",
                        "Seed 42, Fold 2 Val Acc: 0.731\n",
                        "Seed 42, Fold 3 Val Acc: 0.731\n",
                        "Seed 42, Fold 4 Val Acc: 0.723\n",
                        "Seed 42, Fold 5 Val Acc: 0.763\n",
                        "Seed 42 Results: Mean Val Acc: 0.742, Time: 26.687 seconds, Memory: 0.359 MB, GPU Memory: 94.372 MB\n",
                        "Seed 123, Fold 1 Val Acc: 0.766\n",
                        "Seed 123, Fold 2 Val Acc: 0.745\n",
                        "Seed 123, Fold 3 Val Acc: 0.721\n",
                        "Seed 123, Fold 4 Val Acc: 0.738\n",
                        "Seed 123, Fold 5 Val Acc: 0.726\n",
                        "Seed 123 Results: Mean Val Acc: 0.739, Time: 25.960 seconds, Memory: 0.333 MB, GPU Memory: 94.372 MB\n",
                        "Seed 456, Fold 1 Val Acc: 0.732\n",
                        "Seed 456, Fold 2 Val Acc: 0.736\n",
                        "Seed 456, Fold 3 Val Acc: 0.751\n",
                        "Seed 456, Fold 4 Val Acc: 0.734\n",
                        "Seed 456, Fold 5 Val Acc: 0.726\n",
                        "Seed 456 Results: Mean Val Acc: 0.736, Time: 26.387 seconds, Memory: 0.330 MB, GPU Memory: 94.372 MB\n",
                        "{'seed': 42, 'mean_val_acc': 0.7418768032412302, 'time': 26.68696689605713, 'memory': 0.358538, 'gpu_memory': 94.37184}\n",
                        "{'seed': 123, 'mean_val_acc': 0.7392855924862392, 'time': 25.959501028060913, 'memory': 0.333399, 'gpu_memory': 94.37184}\n",
                        "{'seed': 456, 'mean_val_acc': 0.735963195121785, 'time': 26.386794328689575, 'memory': 0.330142, 'gpu_memory': 94.37184}\n",
                        "Total Mean Val Acc: 73.90$\\pm$0.24\n"
                    ]
                }
            ],
            "source": "import time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, TopKPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = Planetoid(root=\"/data/ /Pooling\", name='Cora')\ngraph = dataset_sparse\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.7, 0.7]  \nclass HierarchicalGCN_TOPK(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, pool_ratios, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_TOPK, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.pool_ratios = pool_ratios\n        self.act = act\n        self.sum_res = sum_res\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.pools = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.pools.append(TopKPooling(channels, ratio=pool_ratios[i]))\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        x = self.act(x)\n        xs = [x]\n        edge_indices = [edge_index]\n        perms = []\n        for i in range(1, self.depth + 1):\n            x, edge_index, _, batch, perm, _ = self.pools[i - 1](x, edge_index, batch=batch)\n            x = self.down_convs[i](x, edge_index)\n            x = self.act(x)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n            perms.append(perm)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            perm = perms[j]\n            up = torch.zeros_like(res)\n            up[perm] = x\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n            x = self.act(x)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_TOPK(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values) * 100\nstandard_deviation = np.std(mean_val_acc_values) * 100\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}$\\\\pm${standard_deviation:.2f}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### SAGPooling with HierarchicalGCN (2019)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Seed 42, Fold 1 Val Acc: 0.744\n",
                        "Seed 42, Fold 2 Val Acc: 0.749\n",
                        "Seed 42, Fold 3 Val Acc: 0.734\n",
                        "Seed 42, Fold 4 Val Acc: 0.734\n",
                        "Seed 42, Fold 5 Val Acc: 0.760\n",
                        "Seed 42 Results: Mean Val Acc: 0.744, Time: 29.773 seconds, Memory: 0.960 MB, GPU Memory: 96.469 MB\n",
                        "Seed 123, Fold 1 Val Acc: 0.753\n",
                        "Seed 123, Fold 2 Val Acc: 0.753\n",
                        "Seed 123, Fold 3 Val Acc: 0.727\n",
                        "Seed 123, Fold 4 Val Acc: 0.758\n",
                        "Seed 123, Fold 5 Val Acc: 0.738\n",
                        "Seed 123 Results: Mean Val Acc: 0.746, Time: 29.040 seconds, Memory: 0.404 MB, GPU Memory: 96.469 MB\n",
                        "Seed 456, Fold 1 Val Acc: 0.731\n",
                        "Seed 456, Fold 2 Val Acc: 0.745\n",
                        "Seed 456, Fold 3 Val Acc: 0.751\n",
                        "Seed 456, Fold 4 Val Acc: 0.730\n",
                        "Seed 456, Fold 5 Val Acc: 0.756\n",
                        "Seed 456 Results: Mean Val Acc: 0.743, Time: 28.802 seconds, Memory: 0.404 MB, GPU Memory: 96.469 MB\n",
                        "{'seed': 42, 'mean_val_acc': 0.7440935536896959, 'time': 29.772623777389526, 'memory': 0.960185, 'gpu_memory': 96.468992}\n",
                        "{'seed': 123, 'mean_val_acc': 0.7455702505269045, 'time': 29.039822816848755, 'memory': 0.403968, 'gpu_memory': 96.468992}\n",
                        "{'seed': 456, 'mean_val_acc': 0.7426148106213041, 'time': 28.802465200424194, 'memory': 0.40428, 'gpu_memory': 96.468992}\n",
                        "Total Mean Val Acc: 74.41$\\pm$0.12\n"
                    ]
                }
            ],
            "source": "import time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, SAGPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = Planetoid(root=\"/data/ /Pooling\", name='Cora')\ngraph = dataset_sparse\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.7, 0.7]  \nclass HierarchicalGCN_SAG(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, pool_ratios, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_SAG, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.pool_ratios = pool_ratios\n        self.act = act\n        self.sum_res = sum_res\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.pools = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.pools.append(SAGPooling(channels, ratio=pool_ratios[i]))\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        x = self.act(x)\n        xs = [x]\n        edge_indices = [edge_index]\n        perms = []\n        for i in range(1, self.depth + 1):\n            x, edge_index, _, batch, perm, _ = self.pools[i - 1](x, edge_index, None, batch)\n            x = self.down_convs[i](x, edge_index)\n            x = self.act(x)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n            perms.append(perm)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            perm = perms[j]\n            up = torch.zeros_like(res)\n            up[perm] = x\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n            x = self.act(x)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_SAG(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values) * 100\nstandard_deviation = np.std(mean_val_acc_values) * 100\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}$\\\\pm${standard_deviation:.2f}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ASAPooling with HierarchicalGCN (2020)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/boot/anaconda3/envs/ 1/lib/python3.10/site-packages/torch_geometric/utils/sparse.py:268: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
                        "  adj = torch.sparse_csr_tensor(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Seed 42, Fold 1 Val Acc: 0.762\n"
                    ]
                },
                {
                    "ename": "RuntimeError",
                    "evalue": "CUDA error: insufficient resources when calling `cusparseSpGEMM_compute( handle, opA, opB, &alpha_, descA.descriptor(), descB.descriptor(), &beta_, descC.descriptor(), compute_type, CUSPARSE_SPGEMM_DEFAULT, spgemm_desc.descriptor(), &buffer_size2, buffer2.get())`",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[12], line 179\u001b[0m\n\u001b[1;32m    175\u001b[0m test_mask[test_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    177\u001b[0m val_mask \u001b[38;5;241m=\u001b[39m test_mask  \u001b[38;5;66;03m# In cross-validation, we use test_mask as val_mask\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m model, best_val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_node_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m val_accuracies\u001b[38;5;241m.\u001b[39mappend(best_val_acc)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSeed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_val_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
                        "Cell \u001b[0;32mIn[12], line 118\u001b[0m, in \u001b[0;36mtrain_node_classifier\u001b[0;34m(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs, patience, min_delta)\u001b[0m\n\u001b[1;32m    115\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    116\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 118\u001b[0m val_acc \u001b[38;5;241m=\u001b[39m \u001b[43meval_node_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Early stopping logic\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_acc \u001b[38;5;241m>\u001b[39m best_val_acc \u001b[38;5;241m+\u001b[39m min_delta:\n",
                        "Cell \u001b[0;32mIn[12], line 135\u001b[0m, in \u001b[0;36meval_node_classifier\u001b[0;34m(model, graph, mask)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval_node_classifier\u001b[39m(model, graph, mask):\n\u001b[1;32m    134\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 135\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    136\u001b[0m     correct \u001b[38;5;241m=\u001b[39m (pred[mask] \u001b[38;5;241m==\u001b[39m graph\u001b[38;5;241m.\u001b[39my[mask])\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    137\u001b[0m     acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(correct) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mint\u001b[39m(mask\u001b[38;5;241m.\u001b[39msum())\n",
                        "File \u001b[0;32m~/anaconda3/envs/ 1/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/anaconda3/envs/ 1/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "Cell \u001b[0;32mIn[12], line 79\u001b[0m, in \u001b[0;36mHierarchicalGCN_ASA.forward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     76\u001b[0m perms \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 79\u001b[0m     x, edge_index, _, batch, perm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpools\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_convs[i](x, edge_index)\n\u001b[1;32m     81\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n",
                        "File \u001b[0;32m~/anaconda3/envs/ 1/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/anaconda3/envs/ 1/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/anaconda3/envs/ 1/lib/python3.10/site-packages/torch_geometric/nn/pool/asap.py:150\u001b[0m, in \u001b[0;36mASAPooling.forward\u001b[0;34m(self, x, edge_index, edge_weight, batch)\u001b[0m\n\u001b[1;32m    148\u001b[0m S \u001b[38;5;241m=\u001b[39m to_torch_coo_tensor(edge_index, score, size\u001b[38;5;241m=\u001b[39m(N, N))\n\u001b[1;32m    149\u001b[0m S \u001b[38;5;241m=\u001b[39m S\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;241m1\u001b[39m, perm)\u001b[38;5;241m.\u001b[39mto_sparse_csr()\n\u001b[0;32m--> 150\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sparse_csr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     edge_index, _ \u001b[38;5;241m=\u001b[39m to_edge_index(A)\n",
                        "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: insufficient resources when calling `cusparseSpGEMM_compute( handle, opA, opB, &alpha_, descA.descriptor(), descB.descriptor(), &beta_, descC.descriptor(), compute_type, CUSPARSE_SPGEMM_DEFAULT, spgemm_desc.descriptor(), &buffer_size2, buffer2.get())`"
                    ]
                }
            ],
            "source": "import time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, ASAPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = Planetoid(root=\"/data/ /Pooling\", name='Cora')\ngraph = dataset_sparse\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.7, 0.7]  \nclass HierarchicalGCN_ASA(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, pool_ratios, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_ASA, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.pool_ratios = pool_ratios\n        self.act = act\n        self.sum_res = sum_res\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.pools = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.pools.append(ASAPooling(channels, ratio=pool_ratios[i]))\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        x = self.act(x)\n        xs = [x]\n        edge_indices = [edge_index]\n        perms = []\n        for i in range(1, self.depth + 1):\n            x, edge_index, _, batch, perm = self.pools[i - 1](x, edge_index, batch=batch)\n            x = self.down_convs[i](x, edge_index)\n            x = self.act(x)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n            perms.append(perm)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            perm = perms[j]\n            up = torch.zeros_like(res)\n            up[perm] = x\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n            x = self.act(x)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_ASA(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values) * 100\nstandard_deviation = np.std(mean_val_acc_values) * 100\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}$\\\\pm${standard_deviation:.2f}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### PANPooling with HierarchicalGCN (2020)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "from torch_geometric.utils.num_nodes import maybe_num_nodes\nfrom torch_sparse import spspmm\nfrom torch_sparse import coalesce\nfrom torch_sparse import eye\nfrom torch.nn import Parameter\nfrom torch_scatter import scatter_add\nfrom torch_scatter import scatter_max\nclass PANPooling(torch.nn.Module):\n    r\"\"\" General Graph pooling layer based on PAN, which can work with all layers.\n    \"\"\"\n    def __init__(self, in_channels, ratio=0.5, pan_pool_weight=None, min_score=None, multiplier=1,\n                 nonlinearity=torch.tanh, filter_size=3, panpool_filter_weight=None):\n        super(PANPooling, self).__init__()\n        self.in_channels = in_channels\n        self.ratio = ratio\n        self.min_score = min_score\n        self.multiplier = multiplier\n        self.nonlinearity = nonlinearity\n        self.filter_size = filter_size\n        if panpool_filter_weight is None:\n            self.panpool_filter_weight = torch.nn.Parameter(0.5 * torch.ones(filter_size), requires_grad=True)\n        self.transform = Parameter(torch.ones(in_channels), requires_grad=True)\n        if pan_pool_weight is None:\n            self.pan_pool_weight = torch.nn.Parameter(0.5 * torch.ones(2), requires_grad=True)\n        else:\n            self.pan_pool_weight = pan_pool_weight\n    def forward(self, x, edge_index, M=None, batch=None, num_nodes=None):\n        \"\"\"\"\"\"\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        num_nodes = maybe_num_nodes(edge_index, num_nodes)\n        edge_index, edge_weight = self.panentropy_sparse(edge_index, num_nodes)\n        num_nodes = x.size(0)\n        degree = torch.zeros(num_nodes, device=edge_index.device)\n        degree = scatter_add(edge_weight, edge_index[0], out=degree)\n        xtransform = torch.matmul(x, self.transform)\n        x_transform_norm = xtransform \n        degree_norm = degree \n        score = self.pan_pool_weight[0] * x_transform_norm + self.pan_pool_weight[1] * degree_norm\n        if self.min_score is None:\n            score = self.nonlinearity(score)\n        else:\n            score = softmax(score, batch)\n        perm = self.topk(score, self.ratio, batch, self.min_score)\n        x = x[perm] * score[perm].view(-1, 1)\n        x = self.multiplier * x if self.multiplier != 1 else x\n        batch = batch[perm]\n        edge_index, edge_weight = self.filter_adj(edge_index, edge_weight, perm, num_nodes=score.size(0))\n        return x, edge_index, edge_weight, batch, perm, score[perm]\n    def topk(self, x, ratio, batch, min_score=None, tol=1e-7):\n        if min_score is not None:\n            scores_max = scatter_max(x, batch)[0][batch] - tol\n            scores_min = scores_max.clamp(max=min_score)\n            perm = torch.nonzero(x > scores_min).view(-1)\n        else:\n            num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)\n            batch_size, max_num_nodes = num_nodes.size(0), num_nodes.max().item()\n            cum_num_nodes = torch.cat(\n                [num_nodes.new_zeros(1),\n                 num_nodes.cumsum(dim=0)[:-1]], dim=0)\n            index = torch.arange(batch.size(0), dtype=torch.long, device=x.device)\n            index = (index - cum_num_nodes[batch]) + (batch * max_num_nodes)\n            dense_x = x.new_full((batch_size * max_num_nodes, ), -2)\n            dense_x[index] = x\n            dense_x = dense_x.view(batch_size, max_num_nodes)\n            _, perm = dense_x.sort(dim=-1, descending=True)\n            perm = perm + cum_num_nodes.view(-1, 1)\n            perm = perm.view(-1)\n            k = (ratio * num_nodes.to(torch.float)).ceil().to(torch.long)\n            mask = [\n                torch.arange(k[i], dtype=torch.long, device=x.device) +\n                i * max_num_nodes for i in range(batch_size)\n            ]\n            mask = torch.cat(mask, dim=0)\n            perm = perm[mask]\n        return perm\n    def filter_adj(self, edge_index, edge_weight, perm, num_nodes=None):\n        num_nodes = maybe_num_nodes(edge_index, num_nodes)\n        mask = perm.new_full((num_nodes, ), -1)\n        i = torch.arange(perm.size(0), dtype=torch.long, device=perm.device)\n        mask[perm] = i\n        row, col = edge_index\n        row, col = mask[row], mask[col]\n        mask = (row >= 0) & (col >= 0)\n        row, col = row[mask], col[mask]\n        if edge_weight is not None:\n            edge_weight = edge_weight[mask]\n        return torch.stack([row, col], dim=0), edge_weight\n    def panentropy_sparse(self, edge_index, num_nodes):\n        edge_value = torch.ones(edge_index.size(1), device=edge_index.device)\n        edge_index, edge_value = coalesce(edge_index, edge_value, num_nodes, num_nodes)\n        pan_index, pan_value = eye(num_nodes, device=edge_index.device)\n        indextmp = pan_index.clone().to(edge_index.device)\n        valuetmp = pan_value.clone().to(edge_index.device)\n        pan_value = self.panpool_filter_weight[0] * pan_value\n        for i in range(self.filter_size - 1):\n            indextmp, valuetmp = spspmm(indextmp, valuetmp, edge_index, edge_value, num_nodes, num_nodes, num_nodes)\n            valuetmp = valuetmp * self.panpool_filter_weight[i+1]\n            indextmp, valuetmp = coalesce(indextmp, valuetmp, num_nodes, num_nodes)\n            pan_index = torch.cat((pan_index, indextmp), 1)\n            pan_value = torch.cat((pan_value, valuetmp))\n        return coalesce(pan_index, pan_value, num_nodes, num_nodes, op='add')"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Seed 42, Fold 1 Val Acc: 0.769\n",
                        "Seed 42, Fold 2 Val Acc: 0.751\n",
                        "Seed 42, Fold 3 Val Acc: 0.755\n",
                        "Seed 42, Fold 4 Val Acc: 0.738\n",
                        "Seed 42, Fold 5 Val Acc: 0.780\n",
                        "Seed 42 Results: Mean Val Acc: 0.758, Time: 63.517 seconds, Memory: 10.927 MB, GPU Memory: 55807.312 MB\n",
                        "Seed 123, Fold 1 Val Acc: 0.782\n",
                        "Seed 123, Fold 2 Val Acc: 0.762\n",
                        "Seed 123, Fold 3 Val Acc: 0.740\n",
                        "Seed 123, Fold 4 Val Acc: 0.760\n",
                        "Seed 123, Fold 5 Val Acc: 0.749\n",
                        "Seed 123 Results: Mean Val Acc: 0.758, Time: 63.952 seconds, Memory: 0.309 MB, GPU Memory: 55807.312 MB\n",
                        "Seed 456, Fold 1 Val Acc: 0.753\n",
                        "Seed 456, Fold 2 Val Acc: 0.760\n",
                        "Seed 456, Fold 3 Val Acc: 0.766\n",
                        "Seed 456, Fold 4 Val Acc: 0.747\n",
                        "Seed 456, Fold 5 Val Acc: 0.752\n",
                        "Seed 456 Results: Mean Val Acc: 0.756, Time: 63.655 seconds, Memory: 0.309 MB, GPU Memory: 55807.312 MB\n",
                        "{'seed': 42, 'mean_val_acc': 0.7584935646029289, 'time': 63.51655697822571, 'memory': 10.926841, 'gpu_memory': 55807.311872}\n",
                        "{'seed': 123, 'mean_val_acc': 0.7584901542176234, 'time': 63.95180559158325, 'memory': 0.309082, 'gpu_memory': 55807.311872}\n",
                        "{'seed': 456, 'mean_val_acc': 0.755534714312023, 'time': 63.65460133552551, 'memory': 0.309416, 'gpu_memory': 55807.311872}\n",
                        "Total Mean Val Acc: 75.75$\\pm$0.14\n"
                    ]
                }
            ],
            "source": "import time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, ASAPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = Planetoid(root=\"/data/ /Pooling\", name='Cora')\ngraph = dataset_sparse\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.7, 0.7]  \nclass HierarchicalGCN_PAN(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, pool_ratios, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_PAN, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.pool_ratios = pool_ratios\n        self.act = act\n        self.sum_res = sum_res\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.pools = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.pools.append(PANPooling(channels, ratio=pool_ratios[i]))\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        x = self.act(x)\n        xs = [x]\n        edge_indices = [edge_index]\n        perms = []\n        for i in range(1, self.depth + 1):\n            x, edge_index, _, batch, perm, score_perm = self.pools[i - 1](x, edge_index, batch=batch, M=None)\n            x = self.down_convs[i](x, edge_index)\n            x = self.act(x)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n            perms.append(perm)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            perm = perms[j]\n            up = torch.zeros_like(res)\n            up[perm] = x\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n            x = self.act(x)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_PAN(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values) * 100\nstandard_deviation = np.std(mean_val_acc_values) * 100\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}$\\\\pm${standard_deviation:.2f}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### CoPooling with HierarchicalGCN (2023)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn import Parameter\nfrom torch_geometric.nn.conv import MessagePassing\nfrom torch_geometric.nn.conv.gcn_conv import gcn_norm\nfrom torch_geometric.utils import add_remaining_self_loops, to_dense_adj, add_self_loops\nfrom typing import Callable, Optional, Union\nfrom torch_sparse import coalesce, transpose\nfrom torch_scatter import scatter\ndef cumsum(x: Tensor, dim: int = 0) -> Tensor:\n    r\"\"\"Returns the cumulative sum of elements of :obj:`x`.\n    In contrast to :meth:`torch.cumsum`, prepends the output with zero.\n    Args:\n        x (torch.Tensor): The input tensor.\n        dim (int, optional): The dimension to do the operation over.\n            (default: :obj:`0`)\n    Example:\n        >>> x = torch.tensor([2, 4, 1])\n        >>> cumsum(x)\n        tensor([0, 2, 6, 7])\n    \"\"\"\n    size = x.size()[:dim] + (x.size(dim) + 1, ) + x.size()[dim + 1:]\n    out = x.new_empty(size)\n    out.narrow(dim, 0, 1).zero_()\n    torch.cumsum(x, dim=dim, out=out.narrow(dim, 1, x.size(dim)))\n    return out\ndef maybe_num_nodes(edge_index, num_nodes=None):\n    if num_nodes is not None:\n        return num_nodes\n    elif isinstance(edge_index, Tensor):\n        return int(edge_index.max()) + 1 if edge_index.numel() > 0 else 0\n    else:\n        return max(edge_index.size(0), edge_index.size(1))\ndef maybe_num_nodes(edge_index, num_nodes=None):\n    if num_nodes is not None:\n        return num_nodes\n    elif isinstance(edge_index, Tensor):\n        return int(edge_index.max()) + 1 if edge_index.numel() > 0 else 0\n    else:\n        return max(edge_index.size(0), edge_index.size(1))\ndef filter_adj(edge_index, edge_attr, perm, num_nodes=None):\n    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n    mask = perm.new_full((num_nodes, ), -1)\n    i = torch.arange(perm.size(0), dtype=torch.long, device=perm.device)\n    mask[perm] = i\n    row, col = edge_index\n    row, col = mask[row], mask[col]\n    mask = (row >= 0) & (col >= 0)\n    row, col = row[mask], col[mask]\n    if edge_attr is not None:\n        edge_attr = edge_attr[mask]\n    return torch.stack([row, col], dim=0), edge_attr\ndef topk(\n    x: Tensor,\n    ratio: Optional[Union[float, int]],\n    batch: Tensor,\n    min_score: Optional[float] = None,\n    tol: float = 1e-7,\n) -> Tensor:\n    if min_score is not None:\n        scores_max = scatter(x, batch, reduce='max')[batch] - tol\n        scores_min = scores_max.clamp(max=min_score)\n        perm = (x > scores_min).nonzero().view(-1)\n        return perm\n    if ratio is not None:\n        num_nodes = scatter(batch.new_ones(x.size(0)), batch, reduce='sum')\n        if ratio >= 1:\n            k = num_nodes.new_full((num_nodes.size(0), ), int(ratio))\n        else:\n            k = (float(ratio) * num_nodes.to(x.dtype)).ceil().to(torch.long)\n        x, x_perm = torch.sort(x.view(-1), descending=True)\n        batch = batch[x_perm]\n        batch, batch_perm = torch.sort(batch, descending=False, stable=True)\n        arange = torch.arange(x.size(0), dtype=torch.long, device=x.device)\n        ptr = cumsum(num_nodes)\n        batched_arange = arange - ptr[batch]\n        mask = batched_arange < k[batch]\n        return x_perm[batch_perm[mask]]\n    raise ValueError(\"At least one of the 'ratio' and 'min_score' parameters \"\n                     \"must be specified\")\nclass GPR_prop(MessagePassing):\n    '''\n    propagation class for GPR_GNN\n    '''\n    def __init__(self, K, alpha, Init, Gamma=None, bias=True, **kwargs):\n        super(GPR_prop, self).__init__(aggr='add', **kwargs)\n        self.K = K\n        self.Init = Init\n        self.alpha = alpha\n        assert Init in ['SGC', 'PPR', 'NPPR', 'Random', 'WS']\n        if Init == 'SGC':\n            TEMP = 0.0*np.ones(K+1)\n            TEMP[alpha] = 1.0\n        elif Init == 'PPR':\n            TEMP = alpha*(1-alpha)**np.arange(K+1)\n            TEMP[-1] = (1-alpha)**K\n        elif Init == 'NPPR':\n            TEMP = (alpha)**np.arange(K+1)\n            TEMP = TEMP/np.sum(np.abs(TEMP))\n        elif Init == 'Random':\n            bound = np.sqrt(3/(K+1))\n            TEMP = np.random.uniform(-bound, bound, K+1)\n            TEMP = TEMP/np.sum(np.abs(TEMP))\n        elif Init == 'WS':\n            TEMP = Gamma\n        self.temp = Parameter(torch.tensor(TEMP))\n    def reset_parameters(self):\n        torch.nn.init.zeros_(self.temp)\n        for k in range(self.K+1):\n            self.temp.data[k] = self.alpha*(1-self.alpha)**k\n        self.temp.data[-1] = (1-self.alpha)**self.K\n    def forward(self, x, edge_index, edge_weight=None):\n        edge_index, norm = gcn_norm(\n            edge_index, edge_weight, num_nodes=x.size(0), dtype=x.dtype)\n        hidden = x*(self.temp[0])\n        for k in range(self.K):\n            x = self.propagate(edge_index, x=x, norm=norm)\n            gamma = self.temp[k+1]\n            hidden = hidden + gamma*x\n        return hidden\n    def message(self, x_j, norm):\n        return norm.view(-1, 1) * x_j\n    def __repr__(self):\n        return '{}(K={}, temp={})'.format(self.__class__.__name__, self.K,\n                                           self.temp)\nclass NodeInformationScore(MessagePassing):\n    def __init__(self, improved=False, cached=False, **kwargs):\n        super(NodeInformationScore, self).__init__(aggr='add', **kwargs)\n        self.improved = improved\n        self.cached = cached\n        self.cached_result = None\n        self.cached_num_edges = None\n    @staticmethod\n    def norm(edge_index, num_nodes, edge_weight, dtype=None):\n        if edge_weight is None:\n            edge_weight = torch.ones((edge_index.size(1),), dtype=dtype, device=edge_index.device)\n        edge_index, edge_weight = add_remaining_self_loops(edge_index, edge_weight, 0, num_nodes) \n        edge_index = edge_index.type(torch.long)\n        row, col = edge_index\n        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n        deg_inv_sqrt = deg.pow(-0.5)\n        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n        expand_deg = torch.zeros((edge_weight.size(0),), dtype=dtype, device=edge_index.device)\n        expand_deg[-num_nodes:] = torch.ones((num_nodes,), dtype=dtype, device=edge_index.device)\n        return edge_index, expand_deg - deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n    def forward(self, x, edge_index, edge_weight):\n        if self.cached and self.cached_result is not None:\n            if edge_index.size(1) != self.cached_num_edges:\n                raise RuntimeError(\n                    'Cached {} number of edges, but found {}'.format(self.cached_num_edges, edge_index.size(1)))\n        if not self.cached or self.cached_result is None:\n            self.cached_num_edges = edge_index.size(1)\n            edge_index, norm = self.norm(edge_index, x.size(0), edge_weight, x.dtype)\n            self.cached_result = edge_index, norm\n        edge_index, norm = self.cached_result\n        return self.propagate(edge_index, x=x, norm=norm)\n    def message(self, x_j, norm):\n        return norm.view(-1, 1) * x_j\n    def update(self, aggr_out):\n        return aggr_out\nclass graph_attention(torch.nn.Module):\n    src_nodes_dim = 0  \n    trg_nodes_dim = 1  \n    nodes_dim = 0      \n    head_dim = 1       \n    def __init__(self, num_in_features, num_out_features, num_of_heads, dropout_prob=0.6, log_attention_weights=False):\n        super().__init__()\n        self.num_of_heads = num_of_heads\n        self.num_out_features = num_out_features\n        self.linear_proj = nn.Linear(num_in_features, num_of_heads * num_out_features, bias=False)\n        self.scoring_fn_target = nn.Parameter(torch.Tensor(1, num_of_heads, num_out_features))\n        self.scoring_fn_source = nn.Parameter(torch.Tensor(1, num_of_heads, num_out_features))\n        self.init_params()\n    def init_params(self):\n        \"\"\"\n        The reason we're using Glorot (aka Xavier uniform) initialization is because it's a default TF initialization:\n            https://stackoverflow.com/questions/37350131/what-is-the-default-variable-initializer-in-tensorflow\n        The original repo was developed in TensorFlow (TF) and they used the default initialization.\n        Feel free to experiment - there may be better initializations depending on your problem.\n        \"\"\"\n        nn.init.xavier_uniform_(self.linear_proj.weight)\n        nn.init.xavier_uniform_(self.scoring_fn_target)\n        nn.init.xavier_uniform_(self.scoring_fn_source)\n    def forward(self, x, edge_index):\n        in_nodes_features = x  \n        num_of_nodes = in_nodes_features.shape[self.nodes_dim]\n        nodes_features_proj = self.linear_proj(in_nodes_features).view(-1, self.num_of_heads, self.num_out_features)\n        scores_source = (nodes_features_proj * self.scoring_fn_source).sum(dim=-1)\n        scores_target = (nodes_features_proj * self.scoring_fn_target).sum(dim=-1)\n        scores_source_lifted, scores_target_lifted, nodes_features_proj_lifted = self.lift(scores_source, scores_target, nodes_features_proj, edge_index)\n        scores_per_edge = scores_source_lifted + scores_target_lifted\n        return torch.sigmoid(scores_per_edge)\n    def lift(self, scores_source, scores_target, nodes_features_matrix_proj, edge_index):\n        \"\"\"\n        Lifts i.e. duplicates certain vectors depending on the edge index.\n        One of the tensor dims goes from N -> E (that's where the \"lift\" comes from).\n        \"\"\"\n        src_nodes_index = edge_index[self.src_nodes_dim]\n        trg_nodes_index = edge_index[self.trg_nodes_dim]\n        scores_source = scores_source.index_select(self.nodes_dim, src_nodes_index)\n        scores_target = scores_target.index_select(self.nodes_dim, trg_nodes_index)\n        nodes_features_matrix_proj_lifted = nodes_features_matrix_proj.index_select(self.nodes_dim, src_nodes_index)\n        return scores_source, scores_target, nodes_features_matrix_proj_lifted\nclass CoPooling(torch.nn.Module):\n    def __init__(self, ratio=0.5, K=0.05, edge_ratio=0.6, nhid=64, alpha=0.1, Init='Random', Gamma=None):\n        super(CoPooling, self).__init__()\n        self.ratio = ratio\n        self.calc_information_score = NodeInformationScore()\n        self.edge_ratio = edge_ratio\n        self.prop1 = GPR_prop(K, alpha, Init, Gamma)\n        score_dim = 32\n        self.G_att = graph_attention(num_in_features=nhid, num_out_features=score_dim, num_of_heads=1)\n        self.weight = Parameter(torch.Tensor(2*nhid, nhid))\n        nn.init.xavier_uniform_(self.weight.data)\n        self.bias = Parameter(torch.Tensor(nhid))\n        nn.init.zeros_(self.bias.data)\n        self.reset_parameters()\n    def reset_parameters(self):\n        nn.init.xavier_uniform_(self.weight.data)\n        nn.init.zeros_(self.bias.data)\n        self.prop1.reset_parameters()\n        self.G_att.init_params()\n    def forward(self, x, edge_index, edge_attr, batch=None, nodes_index=None, node_attr=None):\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        ori_batch = batch.clone()\n        device = x.device\n        num_nodes = x.shape[0]\n        x_cut = self.prop1(x, edge_index) \n        attention = self.G_att(x_cut, edge_index) \n        attention = attention.sum(dim=1) \n        edge_index, attention = add_self_loops(edge_index, attention, 1.0, num_nodes) \n        edge_index_t, attention_t = transpose(edge_index, attention, num_nodes, num_nodes)\n        edge_tmp = torch.cat((edge_index, edge_index_t), 1)\n        att_tmp = torch.cat((attention, attention_t),0)\n        edge_index, attention = coalesce(edge_tmp, att_tmp, num_nodes, num_nodes, 'mean')\n        attention_np = attention.cpu().data.numpy()\n        cut_val = np.percentile(attention_np, int(100*(1-self.edge_ratio))) \n        attention = attention * (attention >= cut_val) \n        kep_idx = attention > 0.0\n        cut_edge_index, cut_edge_attr = edge_index[:, kep_idx], attention[kep_idx]\n        x_information_score = self.calc_information_score(x, cut_edge_index, cut_edge_attr)\n        score = torch.sum(torch.abs(x_information_score), dim=1)\n        perm = topk(score, self.ratio, batch)\n        x_topk = x[perm]\n        batch = batch[perm]\n        if nodes_index is not None:\n            nodes_index = nodes_index[perm]\n        if node_attr is not None:\n            node_attr = node_attr[perm]\n        if cut_edge_index is not None or cut_edge_index.nelement() != 0:\n            induced_edge_index, induced_edge_attr = filter_adj(cut_edge_index, cut_edge_attr, perm, num_nodes=num_nodes)\n        else:\n            print('All edges are cut!')\n            induced_edge_index, induced_edge_attr = cut_edge_index, cut_edge_attr\n        attention_dense = (to_dense_adj(cut_edge_index, edge_attr=cut_edge_attr, max_num_nodes=num_nodes)).squeeze()\n        x = F.relu(torch.matmul(torch.cat((x_topk, torch.matmul(attention_dense[perm],x)), 1), self.weight) + self.bias)\n        return x, induced_edge_index, perm, induced_edge_attr, batch, nodes_index, node_attr, attention_dense"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Seed 42, Fold 1 Val Acc: 0.679\n",
                        "Seed 42, Fold 2 Val Acc: 0.688\n",
                        "Seed 42, Fold 3 Val Acc: 0.686\n",
                        "Seed 42, Fold 4 Val Acc: 0.697\n",
                        "Seed 42, Fold 5 Val Acc: 0.704\n",
                        "Seed 42 Results: Mean Val Acc: 0.691, Time: 60.191 seconds, Memory: 0.534 MB, GPU Memory: 55813.603 MB\n",
                        "Seed 123, Fold 1 Val Acc: 0.690\n",
                        "Seed 123, Fold 2 Val Acc: 0.708\n",
                        "Seed 123, Fold 3 Val Acc: 0.672\n",
                        "Seed 123, Fold 4 Val Acc: 0.725\n",
                        "Seed 123, Fold 5 Val Acc: 0.662\n",
                        "Seed 123 Results: Mean Val Acc: 0.691, Time: 59.388 seconds, Memory: 0.450 MB, GPU Memory: 55813.603 MB\n",
                        "Seed 456, Fold 1 Val Acc: 0.723\n",
                        "Seed 456, Fold 2 Val Acc: 0.720\n",
                        "Seed 456, Fold 3 Val Acc: 0.729\n",
                        "Seed 456, Fold 4 Val Acc: 0.640\n",
                        "Seed 456, Fold 5 Val Acc: 0.706\n",
                        "Seed 456 Results: Mean Val Acc: 0.703, Time: 60.791 seconds, Memory: 0.451 MB, GPU Memory: 55813.603 MB\n",
                        "{'seed': 42, 'mean_val_acc': 0.690922918471329, 'time': 60.19131898880005, 'memory': 0.53436, 'gpu_memory': 55813.603328}\n",
                        "{'seed': 123, 'mean_val_acc': 0.6912864655448773, 'time': 59.3875253200531, 'memory': 0.449903, 'gpu_memory': 55813.603328}\n",
                        "{'seed': 456, 'mean_val_acc': 0.7034485816207516, 'time': 60.791237592697144, 'memory': 0.450847, 'gpu_memory': 55813.603328}\n",
                        "Total Mean Val Acc: 69.52$\\pm$0.58\n"
                    ]
                }
            ],
            "source": "import time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, ASAPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = Planetoid(root=\"/data/ /Pooling\", name='Cora')\ngraph = dataset_sparse\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.7, 0.7]  \nclass HierarchicalGCN_CO(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, pool_ratios, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_CO, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.pool_ratios = pool_ratios\n        self.act = act\n        self.sum_res = sum_res\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.pools = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.pools.append(CoPooling(ratio=pool_ratios[i], K=1, edge_ratio=0.6, nhid=64, alpha=0.1, Init='Random', Gamma=1.0))\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        x = self.act(x)\n        xs = [x]\n        edge_indices = [edge_index]\n        perms = []\n        for i in range(1, self.depth + 1):\n            x, edge_index, perm, _, batch, _, _, _ = self.pools[i - 1](x, edge_index, edge_attr=None, batch=batch)\n            x = self.down_convs[i](x, edge_index)\n            x = self.act(x)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n            perms.append(perm)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            perm = perms[j]\n            up = torch.zeros_like(res)\n            up[perm] = x\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n            x = self.act(x)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_CO(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values) * 100\nstandard_deviation = np.std(mean_val_acc_values) * 100\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}$\\\\pm${standard_deviation:.2f}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### CGIPooling with HierarchicalGCN (2021)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": "from torch_scatter import scatter_add, scatter\nfrom torch_geometric.nn.inits import uniform\nfrom torch_geometric.nn.resolver import activation_resolver\nfrom torch_geometric.nn import GCNConv, GATConv, LEConv, GCNConv, GraphConv\nfrom torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\nfrom dataclasses import dataclass\nfrom typing import Optional\nimport torch\nfrom torch import Tensor\n@dataclass(init=False)\nclass SelectOutput:\n    r\"\"\"The output of the :class:`Select` method, which holds an assignment\n    from selected nodes to their respective cluster(s).\n    Args:\n        node_index (torch.Tensor): The indices of the selected nodes.\n        num_nodes (int): The number of nodes.\n        cluster_index (torch.Tensor): The indices of the clusters each node in\n            :obj:`node_index` is assigned to.\n        num_clusters (int): The number of clusters.\n        weight (torch.Tensor, optional): A weight vector, denoting the strength\n            of the assignment of a node to its cluster. (default: :obj:`None`)\n    \"\"\"\n    node_index: Tensor\n    num_nodes: int\n    cluster_index: Tensor\n    num_clusters: int\n    weight: Optional[Tensor] = None\n    def __init__(\n        self,\n        node_index: Tensor,\n        num_nodes: int,\n        cluster_index: Tensor,\n        num_clusters: int,\n        weight: Optional[Tensor] = None,\n    ):\n        if node_index.dim() != 1:\n            raise ValueError(f\"Expected 'node_index' to be one-dimensional \"\n                             f\"(got {node_index.dim()} dimensions)\")\n        if cluster_index.dim() != 1:\n            raise ValueError(f\"Expected 'cluster_index' to be one-dimensional \"\n                             f\"(got {cluster_index.dim()} dimensions)\")\n        if node_index.numel() != cluster_index.numel():\n            raise ValueError(f\"Expected 'node_index' and 'cluster_index' to \"\n                             f\"hold the same number of values (got \"\n                             f\"{node_index.numel()} and \"\n                             f\"{cluster_index.numel()} values)\")\n        if weight is not None and weight.dim() != 1:\n            raise ValueError(f\"Expected 'weight' vector to be one-dimensional \"\n                             f\"(got {weight.dim()} dimensions)\")\n        if weight is not None and weight.numel() != node_index.numel():\n            raise ValueError(f\"Expected 'weight' to hold {node_index.numel()} \"\n                             f\"values (got {weight.numel()} values)\")\n        self.node_index = node_index\n        self.num_nodes = num_nodes\n        self.cluster_index = cluster_index\n        self.num_clusters = num_clusters\n        self.weight = weight\nclass Select(torch.nn.Module):\n    r\"\"\"An abstract base class for implementing custom node selections as\n    described in the `\"Understanding Pooling in Graph Neural Networks\"\n    <https://arxiv.org/abs/1905.05178>`_ paper, which maps the nodes of an\n    input graph to supernodes in the coarsened graph.\n    Specifically, :class:`Select` returns a :class:`SelectOutput` output, which\n    holds a (sparse) mapping :math:`\\mathbf{C} \\in {[0, 1]}^{N \\times C}` that\n    assigns selected nodes to one or more of :math:`C` super nodes.\n    \"\"\"\n    def reset_parameters(self):\n        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n        pass\n    def forward(self, *args, **kwargs) -> SelectOutput:\n        raise NotImplementedError\n    def __repr__(self) -> str:\n        return f'{self.__class__.__name__}()'\ndef cumsum(x: Tensor, dim: int = 0) -> Tensor:\n    r\"\"\"Returns the cumulative sum of elements of :obj:`x`.\n    In contrast to :meth:`torch.cumsum`, prepends the output with zero.\n    Args:\n        x (torch.Tensor): The input tensor.\n        dim (int, optional): The dimension to do the operation over.\n            (default: :obj:`0`)\n    Example:\n        >>> x = torch.tensor([2, 4, 1])\n        >>> cumsum(x)\n        tensor([0, 2, 6, 7])\n    \"\"\"\n    size = x.size()[:dim] + (x.size(dim) + 1, ) + x.size()[dim + 1:]\n    out = x.new_empty(size)\n    out.narrow(dim, 0, 1).zero_()\n    torch.cumsum(x, dim=dim, out=out.narrow(dim, 1, x.size(dim)))\n    return out\ndef maybe_num_nodes(edge_index, num_nodes=None):\n    if num_nodes is not None:\n        return num_nodes\n    elif isinstance(edge_index, Tensor):\n        return int(edge_index.max()) + 1 if edge_index.numel() > 0 else 0\n    else:\n        return max(edge_index.size(0), edge_index.size(1))\ndef maybe_num_nodes(edge_index, num_nodes=None):\n    if num_nodes is not None:\n        return num_nodes\n    elif isinstance(edge_index, Tensor):\n        return int(edge_index.max()) + 1 if edge_index.numel() > 0 else 0\n    else:\n        return max(edge_index.size(0), edge_index.size(1))\ndef filter_adj(edge_index, edge_attr, perm, num_nodes=None):\n    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n    mask = perm.new_full((num_nodes, ), -1)\n    i = torch.arange(perm.size(0), dtype=torch.long, device=perm.device)\n    mask[perm] = i\n    row, col = edge_index\n    row, col = mask[row], mask[col]\n    mask = (row >= 0) & (col >= 0)\n    row, col = row[mask], col[mask]\n    if edge_attr is not None:\n        edge_attr = edge_attr[mask]\n    return torch.stack([row, col], dim=0), edge_attr\ndef topk(\n    x: Tensor,\n    ratio: Optional[Union[float, int]],\n    batch: Tensor,\n    min_score: Optional[float] = None,\n    tol: float = 1e-7,\n) -> Tensor:\n    if min_score is not None:\n        scores_max = scatter(x, batch, reduce='max')[batch] - tol\n        scores_min = scores_max.clamp(max=min_score)\n        perm = (x > scores_min).nonzero().view(-1)\n        return perm\n    if ratio is not None:\n        num_nodes = scatter(batch.new_ones(x.size(0)), batch, reduce='sum')\n        if ratio >= 1:\n            k = num_nodes.new_full((num_nodes.size(0), ), int(ratio))\n        else:\n            k = (float(ratio) * num_nodes.to(x.dtype)).ceil().to(torch.long)\n        x, x_perm = torch.sort(x.view(-1), descending=True)\n        batch = batch[x_perm]\n        batch, batch_perm = torch.sort(batch, descending=False, stable=True)\n        arange = torch.arange(x.size(0), dtype=torch.long, device=x.device)\n        ptr = cumsum(num_nodes)\n        batched_arange = arange - ptr[batch]\n        mask = batched_arange < k[batch]\n        return x_perm[batch_perm[mask]]\n    raise ValueError(\"At least one of the 'ratio' and 'min_score' parameters \"\n                     \"must be specified\")\nclass Discriminator(torch.nn.Module):\n    def __init__(self, in_channels):\n        super(Discriminator, self).__init__()\n        self.fc1 = nn.Linear(in_channels * 2, in_channels)\n        self.fc2 = nn.Linear(in_channels, 1)\n    def forward(self, x):\n        x = F.leaky_relu(self.fc1(x), 0.2)\n        x = F.sigmoid(self.fc2(x))\n        return x\nclass CGIPool(torch.nn.Module):\n    def __init__(self, in_channels, ratio=0.5, non_lin=torch.tanh):\n        super(CGIPool, self).__init__()\n        self.in_channels = in_channels\n        self.ratio = ratio\n        self.non_lin = non_lin\n        self.hidden_dim = in_channels\n        self.transform = GraphConv(in_channels, self.hidden_dim)\n        self.pp_conv = GraphConv(self.hidden_dim, self.hidden_dim)\n        self.np_conv = GraphConv(self.hidden_dim, self.hidden_dim)\n        self.positive_pooling = GraphConv(self.hidden_dim, 1)\n        self.negative_pooling = GraphConv(self.hidden_dim, 1)\n        self.discriminator = Discriminator(self.hidden_dim)\n        self.loss_fn = torch.nn.BCELoss()\n    def forward(self, x, edge_index, edge_attr=None, batch=None):\n        device = x.device  \n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        x_transform = F.leaky_relu(self.transform(x, edge_index), 0.2)\n        x_tp = F.leaky_relu(self.pp_conv(x, edge_index), 0.2)\n        x_tn = F.leaky_relu(self.np_conv(x, edge_index), 0.2)\n        s_pp = self.positive_pooling(x_tp, edge_index).squeeze()\n        s_np = self.negative_pooling(x_tn, edge_index).squeeze()\n        perm_positive = topk(s_pp, 1, batch)\n        perm_negative = topk(s_np, 1, batch)\n        x_pp = x_transform[perm_positive] * self.non_lin(s_pp[perm_positive]).view(-1, 1)\n        x_np = x_transform[perm_negative] * self.non_lin(s_np[perm_negative]).view(-1, 1)\n        x_pp_readout = gap(x_pp, batch[perm_positive])\n        x_np_readout = gap(x_np, batch[perm_negative])\n        x_readout = gap(x_transform, batch)\n        positive_pair = torch.cat([x_pp_readout, x_readout], dim=1)\n        negative_pair = torch.cat([x_np_readout, x_readout], dim=1)\n        real = torch.ones(positive_pair.shape[0], device=device)  \n        fake = torch.zeros(negative_pair.shape[0], device=device)  \n        score = (s_pp - s_np)\n        perm = topk(score, self.ratio, batch)\n        x = x_transform[perm] * self.non_lin(score[perm]).view(-1, 1)\n        batch = batch[perm]\n        filter_edge_index, filter_edge_attr = filter_adj(edge_index, edge_attr, perm, num_nodes=score.size(0))\n        return x, filter_edge_index, filter_edge_attr, batch, perm"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Seed 42, Fold 1 Val Acc: 0.716\n",
                        "Seed 42, Fold 2 Val Acc: 0.688\n",
                        "Seed 42, Fold 3 Val Acc: 0.712\n",
                        "Seed 42, Fold 4 Val Acc: 0.699\n",
                        "Seed 42, Fold 5 Val Acc: 0.701\n",
                        "Seed 42 Results: Mean Val Acc: 0.703, Time: 51.433 seconds, Memory: 0.746 MB, GPU Memory: 55815.700 MB\n",
                        "Seed 123, Fold 1 Val Acc: 0.731\n",
                        "Seed 123, Fold 2 Val Acc: 0.696\n",
                        "Seed 123, Fold 3 Val Acc: 0.686\n",
                        "Seed 123, Fold 4 Val Acc: 0.684\n",
                        "Seed 123, Fold 5 Val Acc: 0.704\n",
                        "Seed 123 Results: Mean Val Acc: 0.700, Time: 50.921 seconds, Memory: 0.717 MB, GPU Memory: 55815.700 MB\n",
                        "Seed 456, Fold 1 Val Acc: 0.696\n",
                        "Seed 456, Fold 2 Val Acc: 0.734\n",
                        "Seed 456, Fold 3 Val Acc: 0.697\n",
                        "Seed 456, Fold 4 Val Acc: 0.695\n",
                        "Seed 456, Fold 5 Val Acc: 0.664\n",
                        "Seed 456 Results: Mean Val Acc: 0.697, Time: 49.904 seconds, Memory: 0.714 MB, GPU Memory: 55815.700 MB\n",
                        "{'seed': 42, 'mean_val_acc': 0.7030993581654854, 'time': 51.43271255493164, 'memory': 0.745922, 'gpu_memory': 55815.70048}\n",
                        "{'seed': 123, 'mean_val_acc': 0.7001432361828239, 'time': 50.92082858085632, 'memory': 0.717016, 'gpu_memory': 55815.70048}\n",
                        "{'seed': 456, 'mean_val_acc': 0.6971802934295516, 'time': 49.90385818481445, 'memory': 0.714103, 'gpu_memory': 55815.70048}\n",
                        "Total Mean Val Acc: 70.01$\\pm$0.24\n"
                    ]
                }
            ],
            "source": "import time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, TopKPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = Planetoid(root=\"/data/ /Pooling\", name='Cora')\ngraph = dataset_sparse\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.7, 0.7]  \nclass HierarchicalGCN_CGI(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, pool_ratios, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_CGI, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.pool_ratios = pool_ratios\n        self.act = act\n        self.sum_res = sum_res\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.pools = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.pools.append(CGIPool(channels, ratio=pool_ratios[i]))\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        x = self.act(x)\n        xs = [x]\n        edge_indices = [edge_index]\n        perms = []\n        for i in range(1, self.depth + 1):\n            x, edge_index, _, batch, perm = self.pools[i - 1](x, edge_index, None, batch)\n            x = self.down_convs[i](x, edge_index)\n            x = self.act(x)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n            perms.append(perm)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            perm = perms[j]\n            up = torch.zeros_like(res)\n            up[perm] = x\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n            x = self.act(x)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_CGI(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values) * 100\nstandard_deviation = np.std(mean_val_acc_values) * 100\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}$\\\\pm${standard_deviation:.2f}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### KMISPooling with HierarchicalGCN (2023)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": "from typing import Callable, Optional, Tuple, Union\nfrom torch_geometric.typing import Adj, OptTensor, PairTensor, Tensor\nScorer = Callable[[Tensor, Adj, OptTensor, OptTensor], Tensor]\nfrom torch_sparse import SparseTensor, remove_diag\nfrom torch_geometric.nn.aggr import Aggregation\nfrom torch_geometric.nn.dense import Linear\nfrom torch.nn import Module\nfrom torch_scatter import scatter_max, scatter_min\ndef maximal_independent_set(edge_index: Adj, k: int = 1,\n                            perm: OptTensor = None) -> Tensor:\n    r\"\"\"Returns a Maximal :math:`k`-Independent Set of a graph, i.e., a set of\n    nodes (as a :class:`ByteTensor`) such that none of them are :math:`k`-hop\n    neighbors, and any node in the graph has a :math:`k`-hop neighbor in the\n    returned set.\n    The algorithm greedily selects the nodes in their canonical order. If a\n    permutation :obj:`perm` is provided, the nodes are extracted following\n    that permutation instead.\n    This method follows `Blelloch's Alogirithm\n    <https://arxiv.org/abs/1202.3205>`_ for :math:`k = 1`, and its\n    generalization by `Bacciu et al. <https://arxiv.org/abs/2208.03523>`_ for\n    higher values of :math:`k`.\n    Args:\n        edge_index (Tensor or SparseTensor): The graph connectivity.\n        k (int): The :math:`k` value (defaults to 1).\n        perm (LongTensor, optional): Permutation vector. Must be of size\n            :obj:`(n,)` (defaults to :obj:`None`).\n    :rtype: :class:`ByteTensor`\n    \"\"\"\n    if isinstance(edge_index, SparseTensor):\n        row, col, _ = edge_index.coo()\n        device = edge_index.device()\n        n = edge_index.size(0)\n    else:\n        row, col = edge_index[0], edge_index[1]\n        device = row.device\n        n = edge_index.max().item() + 1\n    if perm is None:\n        rank = torch.arange(n, dtype=torch.long, device=device)\n    else:\n        rank = torch.zeros_like(perm)\n        rank[perm] = torch.arange(n, dtype=torch.long, device=device)\n    mis = torch.zeros(n, dtype=torch.bool, device=device)\n    mask = mis.clone()\n    min_rank = rank.clone()\n    while not mask.all():\n        for _ in range(k):\n            min_neigh = torch.full_like(min_rank, fill_value=n)\n            scatter_min(min_rank[row], col, out=min_neigh)\n            torch.minimum(min_neigh, min_rank, out=min_rank)  \n        mis = mis | torch.eq(rank, min_rank)\n        mask = mis.clone().byte()\n        for _ in range(k):\n            max_neigh = torch.full_like(mask, fill_value=0)\n            scatter_max(mask[row], col, out=max_neigh)\n            torch.maximum(max_neigh, mask, out=mask)  \n        mask = mask.to(dtype=torch.bool)\n        min_rank = rank.clone()\n        min_rank[mask] = n\n    return mis\ndef maximal_independent_set_cluster(edge_index: Adj, k: int = 1,\n                                    perm: OptTensor = None) -> PairTensor:\n    r\"\"\"Computes the Maximal :math:`k`-Independent Set (:math:`k`-MIS)\n    clustering of a graph, as defined in `\"Generalizing Downsampling from\n    Regular Data to Graphs\" <https://arxiv.org/abs/2208.03523>`_.\n    The algorithm greedily selects the nodes in their canonical order. If a\n    permutation :obj:`perm` is provided, the nodes are extracted following\n    that permutation instead.\n    This method returns both the :math:`k`-MIS and the clustering, where the\n    :math:`c`-th cluster refers to the :math:`c`-th element of the\n    :math:`k`-MIS.\n    Args:\n        edge_index (Tensor or SparseTensor): The graph connectivity.\n        k (int): The :math:`k` value (defaults to 1).\n        perm (LongTensor, optional): Permutation vector. Must be of size\n            :obj:`(n,)` (defaults to :obj:`None`).\n    :rtype: (:class:`ByteTensor`, :class:`LongTensor`)\n    \"\"\"\n    mis = maximal_independent_set(edge_index=edge_index, k=k, perm=perm)\n    n, device = mis.size(0), mis.device\n    if isinstance(edge_index, SparseTensor):\n        row, col, _ = edge_index.coo()\n    else:\n        row, col = edge_index[0], edge_index[1]\n    if perm is None:\n        rank = torch.arange(n, dtype=torch.long, device=device)\n    else:\n        rank = torch.zeros_like(perm)\n        rank[perm] = torch.arange(n, dtype=torch.long, device=device)\n    min_rank = torch.full((n, ), fill_value=n, dtype=torch.long, device=device)\n    rank_mis = rank[mis]\n    min_rank[mis] = rank_mis\n    for _ in range(k):\n        min_neigh = torch.full_like(min_rank, fill_value=n)\n        scatter_min(min_rank[row], col, out=min_neigh)\n        torch.minimum(min_neigh, min_rank, out=min_rank)\n    _, clusters = torch.unique(min_rank, return_inverse=True)\n    perm = torch.argsort(rank_mis)\n    return mis, perm[clusters]\nclass KMISPooling(Module):\n    _heuristics = {None, 'greedy', 'w-greedy'}\n    _passthroughs = {None, 'before', 'after'}\n    _scorers = {\n        'linear',\n        'random',\n        'constant',\n        'canonical',\n        'first',\n        'last',\n    }\n    def __init__(self, in_channels: Optional[int] = None, k: int = 1,\n                 scorer: Union[Scorer, str] = 'linear',\n                 score_heuristic: Optional[str] = 'greedy',\n                 score_passthrough: Optional[str] = 'before',\n                 aggr_x: Optional[Union[str, Aggregation]] = None,\n                 aggr_edge: str = 'sum',\n                 aggr_score: Callable[[Tensor, Tensor], Tensor] = torch.mul,\n                 remove_self_loops: bool = True) -> None:\n        super(KMISPooling, self).__init__()\n        assert score_heuristic in self._heuristics, \\\n            \"Unrecognized `score_heuristic` value.\"\n        assert score_passthrough in self._passthroughs, \\\n            \"Unrecognized `score_passthrough` value.\"\n        if not callable(scorer):\n            assert scorer in self._scorers, \\\n                \"Unrecognized `scorer` value.\"\n        self.k = k\n        self.scorer = scorer\n        self.score_heuristic = score_heuristic\n        self.score_passthrough = score_passthrough\n        self.aggr_x = aggr_x\n        self.aggr_edge = aggr_edge\n        self.aggr_score = aggr_score\n        self.remove_self_loops = remove_self_loops\n        if scorer == 'linear':\n            assert self.score_passthrough is not None, \\\n                \"`'score_passthrough'` must not be `None`\" \\\n                \" when using `'linear'` scorer\"\n            self.lin = Linear(in_features=in_channels, out_features=1)\n    def _apply_heuristic(self, x: Tensor, adj: SparseTensor) -> Tensor:\n        if self.score_heuristic is None:\n            return x\n        row, col, _ = adj.coo()\n        x = x.view(-1)\n        if self.score_heuristic == 'greedy':\n            k_sums = torch.ones_like(x)\n        else:\n            k_sums = x.clone()\n        for _ in range(self.k):\n            scatter_add(k_sums[row], col, out=k_sums)\n        return x / k_sums\n    def _scorer(self, x: Tensor, edge_index: Adj, edge_attr: OptTensor = None,\n                batch: OptTensor = None) -> Tensor:\n        if self.scorer == 'linear':\n            return self.lin(x).sigmoid()\n        if self.scorer == 'random':\n            return torch.rand((x.size(0), 1), device=x.device)\n        if self.scorer == 'constant':\n            return torch.ones((x.size(0), 1), device=x.device)\n        if self.scorer == 'canonical':\n            return -torch.arange(x.size(0), device=x.device).view(-1, 1)\n        if self.scorer == 'first':\n            return x[..., [0]]\n        if self.scorer == 'last':\n            return x[..., [-1]]\n        return self.scorer(x, edge_index, edge_attr, batch)\n    def forward(self, x: Tensor, edge_index: Adj,\n                edge_attr: OptTensor = None,\n                batch: OptTensor = None) \\\n            -> Tuple[Tensor, Adj, OptTensor, OptTensor, Tensor, Tensor]:\n        \"\"\"\"\"\"\n        edge_index = edge_index.long()\n        adj, n = edge_index, x.size(0)\n        if not isinstance(edge_index, SparseTensor):\n            adj = SparseTensor.from_edge_index(edge_index, edge_attr, (n, n))\n        score = self._scorer(x, edge_index, edge_attr, batch)\n        updated_score = self._apply_heuristic(score, adj)\n        perm = torch.argsort(updated_score.view(-1), 0, descending=True)\n        mis, cluster = maximal_independent_set_cluster(adj, self.k, perm)\n        row, col, val = adj.coo()\n        c = mis.sum()\n        if val is None:\n            val = torch.ones_like(row, dtype=torch.float)\n        adj = SparseTensor(row=cluster[row], col=cluster[col], value=val,\n                           is_sorted=False,\n                           sparse_sizes=(c, c)).coalesce(self.aggr_edge)\n        if self.remove_self_loops:\n            adj = remove_diag(adj)\n        if self.score_passthrough == 'before':\n            x = self.aggr_score(x, score)\n        if self.aggr_x is None:\n            x = x[mis]\n        elif isinstance(self.aggr_x, str):\n            x = scatter(x, cluster, dim=0, dim_size=mis.sum(),\n                        reduce=self.aggr_x)\n        else:\n            x = self.aggr_x(x, cluster, dim_size=c)\n        if self.score_passthrough == 'after':\n            x = self.aggr_score(x, score[mis])\n        if isinstance(edge_index, SparseTensor):\n            edge_index, edge_attr = adj, None\n        else:\n            row, col, edge_attr = adj.coo()\n            edge_index = torch.stack([row, col])\n        if batch is not None:\n            batch = batch[mis]\n        perm = perm[mis]\n        return x, edge_index, edge_attr, batch, mis, cluster, perm\n    def __repr__(self):\n        if self.scorer == 'linear':\n            channels = f\"in_channels={self.lin.in_channels}, \"\n        else:\n            channels = \"\"\n        return f'{self.__class__.__name__}({channels}k={self.k})'"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Seed 42, Fold 1 Val Acc: 0.768\n",
                        "Seed 42, Fold 2 Val Acc: 0.751\n",
                        "Seed 42, Fold 3 Val Acc: 0.734\n",
                        "Seed 42, Fold 4 Val Acc: 0.741\n",
                        "Seed 42, Fold 5 Val Acc: 0.786\n",
                        "Seed 42 Results: Mean Val Acc: 0.756, Time: 39.296 seconds, Memory: 0.349 MB, GPU Memory: 55815.700 MB\n",
                        "Seed 123, Fold 1 Val Acc: 0.777\n",
                        "Seed 123, Fold 2 Val Acc: 0.766\n",
                        "Seed 123, Fold 3 Val Acc: 0.738\n",
                        "Seed 123, Fold 4 Val Acc: 0.758\n",
                        "Seed 123, Fold 5 Val Acc: 0.745\n",
                        "Seed 123 Results: Mean Val Acc: 0.757, Time: 38.617 seconds, Memory: 0.314 MB, GPU Memory: 55815.700 MB\n",
                        "Seed 456, Fold 1 Val Acc: 0.753\n",
                        "Seed 456, Fold 2 Val Acc: 0.762\n",
                        "Seed 456, Fold 3 Val Acc: 0.762\n",
                        "Seed 456, Fold 4 Val Acc: 0.756\n",
                        "Seed 456, Fold 5 Val Acc: 0.750\n",
                        "Seed 456 Results: Mean Val Acc: 0.757, Time: 36.226 seconds, Memory: 0.343 MB, GPU Memory: 55815.700 MB\n",
                        "{'seed': 42, 'mean_val_acc': 0.7559139491579758, 'time': 39.296337366104126, 'memory': 0.349017, 'gpu_memory': 55815.70048}\n",
                        "{'seed': 123, 'mean_val_acc': 0.7566430895362558, 'time': 38.616806507110596, 'memory': 0.314254, 'gpu_memory': 55815.70048}\n",
                        "{'seed': 456, 'mean_val_acc': 0.7566444536903779, 'time': 36.22608017921448, 'memory': 0.343103, 'gpu_memory': 55815.70048}\n",
                        "Total Mean Val Acc: 75.64$\\pm$0.03\n"
                    ]
                }
            ],
            "source": "import time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, TopKPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = Planetoid(root=\"/data/ /Pooling\", name='Cora')\ngraph = dataset_sparse\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.7, 0.7]  \nclass HierarchicalGCN_KMIS(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, pool_ratios, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_KMIS, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.pool_ratios = pool_ratios\n        self.act = act\n        self.sum_res = sum_res\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.pools = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.pools.append(KMISPooling(64, k=1, aggr_x='sum'))\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        x = self.act(x)\n        xs = [x]\n        edge_indices = [edge_index]\n        perms = []\n        for i in range(1, self.depth + 1):\n            x, edge_index, _, batch, _, cluster, perm = self.pools[i - 1](x, edge_index, batch=batch)\n            x = self.down_convs[i](x, edge_index)\n            x = self.act(x)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n            perms.append(perm)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            perm = perms[j]\n            up = torch.zeros_like(res)\n            up[perm] = x\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n            x = self.act(x)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_KMIS(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values) * 100\nstandard_deviation = np.std(mean_val_acc_values) * 100\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}$\\\\pm${standard_deviation:.2f}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### GSAPooling with HierarchicalGCN (2021)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": "import math\nfrom typing import Union, Optional, Callable\nfrom torch_scatter import scatter_add, scatter_max\nfrom torch_geometric.utils import softmax\nfrom torch_geometric.nn import GCNConv, GCNConv, GATConv, ChebConv, GraphConv\ndef uniform(size, tensor):\n    if tensor is not None:\n        bound = 1.0 / math.sqrt(size)\n        tensor.data.uniform_(-bound, bound)\ndef maybe_num_nodes(edge_index, num_nodes=None):\n    if num_nodes is not None:\n        return num_nodes\n    elif isinstance(edge_index, Tensor):\n        return int(edge_index.max()) + 1 if edge_index.numel() > 0 else 0\n    else:\n        return max(edge_index.size(0), edge_index.size(1))\ndef topk(x, ratio, batch, min_score=None, tol=1e-7):\n    if min_score is not None:\n        scores_max = scatter_max(x, batch)[0][batch] - tol\n        scores_min = scores_max.clamp(max=min_score)\n        perm = (x > scores_min).nonzero(as_tuple=False).view(-1)\n    else:\n        num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)\n        batch_size, max_num_nodes = num_nodes.size(0), num_nodes.max().item()\n        cum_num_nodes = torch.cat(\n            [num_nodes.new_zeros(1),\n             num_nodes.cumsum(dim=0)[:-1]], dim=0)\n        index = torch.arange(batch.size(0), dtype=torch.long, device=x.device)\n        index = (index - cum_num_nodes[batch]) + (batch * max_num_nodes)\n        dense_x = x.new_full((batch_size * max_num_nodes, ),\n                             torch.finfo(x.dtype).min)\n        dense_x[index] = x\n        dense_x = dense_x.view(batch_size, max_num_nodes)\n        _, perm = dense_x.sort(dim=-1, descending=True)\n        perm = perm + cum_num_nodes.view(-1, 1)\n        perm = perm.view(-1)\n        if isinstance(ratio, int):\n            k = num_nodes.new_full((num_nodes.size(0), ), ratio)\n            k = torch.min(k, num_nodes)\n        else:\n            k = (ratio * num_nodes.to(torch.float)).ceil().to(torch.long)\n        mask = [\n            torch.arange(k[i], dtype=torch.long, device=x.device) +\n            i * max_num_nodes for i in range(batch_size)\n        ]\n        mask = torch.cat(mask, dim=0)\n        perm = perm[mask]\n    return perm\ndef filter_adj(edge_index, edge_attr, perm, num_nodes=None):\n    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n    mask = perm.new_full((num_nodes, ), -1)\n    i = torch.arange(perm.size(0), dtype=torch.long, device=perm.device)\n    mask[perm] = i\n    row, col = edge_index\n    row, col = mask[row], mask[col]\n    mask = (row >= 0) & (col >= 0)\n    row, col = row[mask], col[mask]\n    if edge_attr is not None:\n        edge_attr = edge_attr[mask]\n    return torch.stack([row, col], dim=0), edge_attr\nclass GSAPool(torch.nn.Module):\n    def __init__(self, in_channels, pooling_ratio=0.5, alpha=0.6,\n                        min_score=None, multiplier=1,\n                        non_linearity=torch.tanh,\n                        cus_drop_ratio =0):\n        super(GSAPool,self).__init__()\n        self.in_channels = in_channels\n        self.ratio = pooling_ratio\n        self.alpha = alpha\n        self.sbtl_layer = GCNConv(in_channels,1)\n        self.fbtl_layer = nn.Linear(in_channels, 1)\n        self.fusion = GCNConv(in_channels,in_channels)\n        self.min_score = min_score\n        self.multiplier = multiplier\n        self.fusion_flag = 0\n        self.non_linearity = non_linearity\n        self.dropout = torch.nn.Dropout(cus_drop_ratio)\n    def conv_selection(self, conv, in_channels, conv_type=0):\n        if(conv_type == 0):\n            out_channels = 1\n        elif(conv_type == 1):\n            out_channels = in_channels\n        if(conv == \"GCNConv\"):\n            return GCNConv(in_channels,out_channels)\n        elif(conv == \"ChebConv\"):\n            return ChebConv(in_channels,out_channels,1)\n        elif(conv == \"GCNConv\"):\n            return GCNConv(in_channels,out_channels)\n        elif(conv == \"GATConv\"):\n            return GATConv(in_channels,out_channels, heads=1, concat=True)\n        elif(conv == \"GraphConv\"):\n            return GraphConv(in_channels,out_channels)\n        else:\n            raise ValueError\n    def forward(self, x, edge_index, edge_attr=None, batch=None):\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        x = x.unsqueeze(-1) if x.dim() == 1 else x\n        score_s = self.sbtl_layer(x,edge_index).squeeze()\n        score_f = self.fbtl_layer(x).squeeze()\n        score = score_s*self.alpha + score_f*(1-self.alpha)\n        score = score.unsqueeze(-1) if score.dim()==0 else score\n        if self.min_score is None:\n            score = self.non_linearity(score)\n        else:\n            score = softmax(score, batch)\n        sc = self.dropout(score)\n        perm = topk(sc, self.ratio, batch)\n        if(self.fusion_flag == 1):\n            x = self.fusion(x, edge_index)\n        x_ae = x[perm]\n        x = x[perm] * score[perm].view(-1, 1)\n        x = self.multiplier * x if self.multiplier != 1 else x\n        batch = batch[perm]\n        edge_index, edge_attr = filter_adj(\n            edge_index, edge_attr, perm, num_nodes=score.size(0))\n        return x, edge_index, edge_attr, batch, perm, x_ae"
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Seed 42, Fold 1 Val Acc: 0.749\n",
                        "Seed 42, Fold 2 Val Acc: 0.734\n",
                        "Seed 42, Fold 3 Val Acc: 0.749\n",
                        "Seed 42, Fold 4 Val Acc: 0.726\n",
                        "Seed 42, Fold 5 Val Acc: 0.762\n",
                        "Seed 42 Results: Mean Val Acc: 0.744, Time: 28.365 seconds, Memory: 0.482 MB, GPU Memory: 55815.700 MB\n",
                        "Seed 123, Fold 1 Val Acc: 0.769\n",
                        "Seed 123, Fold 2 Val Acc: 0.753\n",
                        "Seed 123, Fold 3 Val Acc: 0.729\n",
                        "Seed 123, Fold 4 Val Acc: 0.734\n",
                        "Seed 123, Fold 5 Val Acc: 0.734\n",
                        "Seed 123 Results: Mean Val Acc: 0.744, Time: 27.543 seconds, Memory: 0.452 MB, GPU Memory: 55815.700 MB\n",
                        "Seed 456, Fold 1 Val Acc: 0.745\n",
                        "Seed 456, Fold 2 Val Acc: 0.742\n",
                        "Seed 456, Fold 3 Val Acc: 0.758\n",
                        "Seed 456, Fold 4 Val Acc: 0.732\n",
                        "Seed 456, Fold 5 Val Acc: 0.726\n",
                        "Seed 456 Results: Mean Val Acc: 0.741, Time: 28.906 seconds, Memory: 0.455 MB, GPU Memory: 55815.700 MB\n",
                        "{'seed': 42, 'mean_val_acc': 0.7440915074585126, 'time': 28.364673852920532, 'memory': 0.481577, 'gpu_memory': 55815.70048}\n",
                        "{'seed': 123, 'mean_val_acc': 0.7437150009208041, 'time': 27.542988061904907, 'memory': 0.451648, 'gpu_memory': 55815.70048}\n",
                        "{'seed': 456, 'mean_val_acc': 0.7407595610152036, 'time': 28.90633797645569, 'memory': 0.454866, 'gpu_memory': 55815.70048}\n",
                        "Total Mean Val Acc: 74.29$\\pm$0.15\n"
                    ]
                }
            ],
            "source": "import time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, TopKPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = Planetoid(root=\"/data/ /Pooling\", name='Cora')\ngraph = dataset_sparse\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.7, 0.7]  \nclass HierarchicalGCN_GSA(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, pool_ratios, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_GSA, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.pool_ratios = pool_ratios\n        self.act = act\n        self.sum_res = sum_res\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.pools = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.pools.append(GSAPool(64, pooling_ratio=pool_ratios[i], alpha = 0.6, cus_drop_ratio = 0))\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        x = self.act(x)\n        xs = [x]\n        edge_indices = [edge_index]\n        perms = []\n        for i in range(1, self.depth + 1):\n            x, edge_index, edge_attr, batch, perm, _ = self.pools[i - 1](x, edge_index, None, batch)\n            x = self.down_convs[i](x, edge_index)\n            x = self.act(x)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n            perms.append(perm)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            perm = perms[j]\n            up = torch.zeros_like(res)\n            up[perm] = x\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n            x = self.act(x)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_GSA(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values) * 100\nstandard_deviation = np.std(mean_val_acc_values) * 100\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}$\\\\pm${standard_deviation:.2f}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### HGPSLPooling with HierarchicalGCN (2019)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor([0.5344, 0.0000, 0.0000, 0.4656, 0.0613, 0.0000, 0.0000, 0.0000, 0.5640,\n",
                        "        0.3748])\n"
                    ]
                }
            ],
            "source": "import torch\nimport torch.nn as nn\nfrom torch.autograd import Function\nfrom torch_scatter import scatter_add, scatter_max\nfrom torch_geometric.utils import softmax, dense_to_sparse, add_remaining_self_loops\ndef topk(x, ratio, batch, min_score=None, tol=1e-7):\n    if min_score is not None:\n        scores_max = scatter_max(x, batch)[0][batch] - tol\n        scores_min = scores_max.clamp(max=min_score)\n        perm = torch.nonzero(x > scores_min).view(-1)\n    else:\n        num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)\n        batch_size, max_num_nodes = num_nodes.size(0), num_nodes.max().item()\n        cum_num_nodes = torch.cat(\n            [num_nodes.new_zeros(1),\n            num_nodes.cumsum(dim=0)[:-1]], dim=0)\n        index = torch.arange(batch.size(0), dtype=torch.long, device=x.device)\n        index = (index - cum_num_nodes[batch]) + (batch * max_num_nodes)\n        dense_x = x.new_full((batch_size * max_num_nodes, ), -2)\n        dense_x[index] = x\n        dense_x = dense_x.view(batch_size, max_num_nodes)\n        _, perm = dense_x.sort(dim=-1, descending=True)\n        perm = perm + cum_num_nodes.view(-1, 1)\n        perm = perm.view(-1)\n        k = (ratio * num_nodes.to(torch.float)).ceil().to(torch.long)\n        mask = [\n            torch.arange(k[i], dtype=torch.long, device=x.device) +\n            i * max_num_nodes for i in range(batch_size)\n        ]\n        mask = torch.cat(mask, dim=0)\n        perm = perm[mask]\n    return perm\ndef filter_adj(edge_index, edge_weight, perm, num_nodes=None):\n        num_nodes = maybe_num_nodes(edge_index, num_nodes)\n        mask = perm.new_full((num_nodes, ), -1)\n        i = torch.arange(perm.size(0), dtype=torch.long, device=perm.device)\n        mask[perm] = i\n        row, col = edge_index\n        row, col = mask[row], mask[col]\n        mask = (row >= 0) & (col >= 0)\n        row, col = row[mask], col[mask]\n        if edge_weight is not None:\n            edge_weight = edge_weight[mask]\n        return torch.stack([row, col], dim=0), edge_weight\ndef scatter_sort(x, batch, fill_value=-1e16):\n    num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)\n    batch_size, max_num_nodes = num_nodes.size(0), num_nodes.max().item()\n    cum_num_nodes = torch.cat([num_nodes.new_zeros(1), num_nodes.cumsum(dim=0)[:-1]], dim=0)\n    index = torch.arange(batch.size(0), dtype=torch.long, device=x.device)\n    index = (index - cum_num_nodes[batch]) + (batch * max_num_nodes)\n    dense_x = x.new_full((batch_size * max_num_nodes,), fill_value)\n    dense_x[index] = x\n    dense_x = dense_x.view(batch_size, max_num_nodes)\n    sorted_x, _ = dense_x.sort(dim=-1, descending=True)\n    cumsum_sorted_x = sorted_x.cumsum(dim=-1)\n    cumsum_sorted_x = cumsum_sorted_x.view(-1)\n    sorted_x = sorted_x.view(-1)\n    filled_index = sorted_x != fill_value\n    sorted_x = sorted_x[filled_index]\n    cumsum_sorted_x = cumsum_sorted_x[filled_index]\n    return sorted_x, cumsum_sorted_x\ndef _make_ix_like(batch):\n    num_nodes = scatter_add(batch.new_ones(batch.size(0)), batch, dim=0)\n    idx = [torch.arange(1, i + 1, dtype=torch.long, device=batch.device) for i in num_nodes]\n    idx = torch.cat(idx, dim=0)\n    return idx\ndef _threshold_and_support(x, batch):\n    \"\"\"Sparsemax building block: compute the threshold\n    Args:\n        x: input tensor to apply the sparsemax\n        batch: group indicators\n    Returns:\n        the threshold value\n    \"\"\"\n    num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)\n    cum_num_nodes = torch.cat([num_nodes.new_zeros(1), num_nodes.cumsum(dim=0)[:-1]], dim=0)\n    sorted_input, input_cumsum = scatter_sort(x, batch)\n    input_cumsum = input_cumsum - 1.0\n    rhos = _make_ix_like(batch).to(x.dtype)\n    support = rhos * sorted_input > input_cumsum\n    support_size = scatter_add(support.to(batch.dtype), batch)\n    idx = support_size + cum_num_nodes - 1\n    mask = idx < 0\n    idx[mask] = 0\n    tau = input_cumsum.gather(0, idx)\n    tau /= support_size.to(x.dtype)\n    return tau, support_size\nclass SparsemaxFunction(Function):\n    @staticmethod\n    def forward(ctx, x, batch):\n        \"\"\"sparsemax: normalizing sparse transform\n        Parameters:\n            ctx: context object\n            x (Tensor): shape (N, )\n            batch: group indicator\n        Returns:\n            output (Tensor): same shape as input\n        \"\"\"\n        max_val, _ = scatter_max(x, batch)\n        x -= max_val[batch]\n        tau, supp_size = _threshold_and_support(x, batch)\n        output = torch.clamp(x - tau[batch], min=0)\n        ctx.save_for_backward(supp_size, output, batch)\n        return output\n    @staticmethod\n    def backward(ctx, grad_output):\n        supp_size, output, batch = ctx.saved_tensors\n        grad_input = grad_output.clone()\n        grad_input[output == 0] = 0\n        v_hat = scatter_add(grad_input, batch) / supp_size.to(output.dtype)\n        grad_input = torch.where(output != 0, grad_input - v_hat[batch], grad_input)\n        return grad_input, None\nsparsemax = SparsemaxFunction.apply\nclass Sparsemax(nn.Module):\n    def __init__(self):\n        super(Sparsemax, self).__init__()\n    def forward(self, x, batch):\n        return sparsemax(x, batch)\nif __name__ == '__main__':\n    sparse_attention = Sparsemax()\n    input_x = torch.tensor([1.7301, 0.6792, -1.0565, 1.6614, -0.3196, -0.7790, -0.3877, -0.4943, 0.1831, -0.0061])\n    input_batch = torch.cat([torch.zeros(4, dtype=torch.long), torch.ones(6, dtype=torch.long)], dim=0)\n    res = sparse_attention(input_x, input_batch)\n    print(res)\nclass TwoHopNeighborhood(object):\n    def __call__(self, data):\n        edge_index, edge_attr = data.edge_index, data.edge_attr\n        n = data.num_nodes\n        fill = 1e16\n        value = edge_index.new_full((edge_index.size(1),), fill, dtype=torch.float)\n        index, value = spspmm(edge_index, value, edge_index, value, n, n, n, True)\n        edge_index = torch.cat([edge_index, index], dim=1)\n        if edge_attr is None:\n            data.edge_index, _ = coalesce(edge_index, None, n, n)\n        else:\n            value = value.view(-1, *[1 for _ in range(edge_attr.dim() - 1)])\n            value = value.expand(-1, *list(edge_attr.size())[1:])\n            edge_attr = torch.cat([edge_attr, value], dim=0)\n            data.edge_index, edge_attr = coalesce(edge_index, edge_attr, n, n, op='min', fill_value=fill)\n            edge_attr[edge_attr >= fill] = 0\n            data.edge_attr = edge_attr\n        return data\n    def __repr__(self):\n        return '{}()'.format(self.__class__.__name__)\nclass GCN(MessagePassing):\n    def __init__(self, in_channels, out_channels, cached=False, bias=True, **kwargs):\n        super(GCN, self).__init__(aggr='add', **kwargs)\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.cached = cached\n        self.cached_result = None\n        self.cached_num_edges = None\n        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n        nn.init.xavier_uniform_(self.weight.data)\n        if bias:\n            self.bias = Parameter(torch.Tensor(out_channels))\n            nn.init.zeros_(self.bias.data)\n        else:\n            self.register_parameter('bias', None)\n        self.reset_parameters()\n    def reset_parameters(self):\n        self.cached_result = None\n        self.cached_num_edges = None\n    @staticmethod\n    def norm(edge_index, num_nodes, edge_weight, dtype=None):\n        if edge_weight is None:\n            edge_weight = torch.ones((edge_index.size(1),), dtype=dtype, device=edge_index.device)\n        row, col = edge_index\n        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n        deg_inv_sqrt = deg.pow(-0.5)\n        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n        return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n    def forward(self, x, edge_index, edge_weight=None):\n        x = torch.matmul(x, self.weight)\n        if self.cached and self.cached_result is not None:\n            if edge_index.size(1) != self.cached_num_edges:\n                raise RuntimeError(\n                    'Cached {} number of edges, but found {}'.format(self.cached_num_edges, edge_index.size(1)))\n        if not self.cached or self.cached_result is None:\n            self.cached_num_edges = edge_index.size(1)\n            edge_index, norm = self.norm(edge_index, x.size(0), edge_weight, x.dtype)\n            self.cached_result = edge_index, norm\n        edge_index, norm = self.cached_result\n        return self.propagate(edge_index, x=x, norm=norm)\n    def message(self, x_j, norm):\n        return norm.view(-1, 1) * x_j\n    def update(self, aggr_out):\n        if self.bias is not None:\n            aggr_out = aggr_out + self.bias\n        return aggr_out\n    def __repr__(self):\n        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels, self.out_channels)\nclass NodeInformationScore(MessagePassing):\n    def __init__(self, improved=False, cached=False, **kwargs):\n        super(NodeInformationScore, self).__init__(aggr='add', **kwargs)\n        self.improved = improved\n        self.cached = cached\n        self.cached_result = None\n        self.cached_num_edges = None\n    @staticmethod\n    def norm(edge_index, num_nodes, edge_weight, dtype=None):\n        if edge_weight is None:\n            edge_weight = torch.ones((edge_index.size(1),), dtype=dtype, device=edge_index.device)\n        row, col = edge_index\n        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n        deg_inv_sqrt = deg.pow(-0.5)\n        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n        edge_index, edge_weight = add_remaining_self_loops(edge_index, edge_weight, 0, num_nodes)\n        row, col = edge_index\n        expand_deg = torch.zeros((edge_weight.size(0),), dtype=dtype, device=edge_index.device)\n        expand_deg[-num_nodes:] = torch.ones((num_nodes,), dtype=dtype, device=edge_index.device)\n        return edge_index, expand_deg - deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n    def forward(self, x, edge_index, edge_weight):\n        if self.cached and self.cached_result is not None:\n            if edge_index.size(1) != self.cached_num_edges:\n                raise RuntimeError(\n                    'Cached {} number of edges, but found {}'.format(self.cached_num_edges, edge_index.size(1)))\n        if not self.cached or self.cached_result is None:\n            self.cached_num_edges = edge_index.size(1)\n            edge_index, norm = self.norm(edge_index, x.size(0), edge_weight, x.dtype)\n            self.cached_result = edge_index, norm\n        edge_index, norm = self.cached_result\n        return self.propagate(edge_index, x=x, norm=norm)\n    def message(self, x_j, norm):\n        return norm.view(-1, 1) * x_j\n    def update(self, aggr_out):\n        return aggr_out\nclass HGPSLPool(torch.nn.Module):\n    def __init__(self, in_channels, ratio=0.5, sample=False, sparse=False, sl=True, lamb=1.0, negative_slop=0.2):\n        super(HGPSLPool, self).__init__()\n        self.in_channels = in_channels\n        self.ratio = ratio\n        self.sample = sample\n        self.sparse = sparse\n        self.sl = sl\n        self.negative_slop = negative_slop\n        self.lamb = lamb\n        self.att = Parameter(torch.Tensor(1, self.in_channels * 2))\n        nn.init.xavier_uniform_(self.att.data)\n        self.sparse_attention = Sparsemax()\n        self.neighbor_augment = TwoHopNeighborhood()\n        self.calc_information_score = NodeInformationScore()\n    def forward(self, x, edge_index, edge_attr, batch):\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        x_information_score = self.calc_information_score(x, edge_index, edge_attr)\n        score = torch.sum(torch.abs(x_information_score), dim=1)\n        original_x = x\n        perm = topk(score, self.ratio, batch)\n        x = x[perm]\n        batch = batch[perm]\n        induced_edge_index, induced_edge_attr = filter_adj(edge_index, edge_attr, perm, num_nodes=score.size(0))\n        if self.sl is False:\n            return x, induced_edge_index, induced_edge_attr, batch\n        if self.sample:\n            k_hop = 3\n            if edge_attr is None:\n                edge_attr = torch.ones((edge_index.size(1),), dtype=torch.float, device=edge_index.device)\n            hop_data = Data(x=original_x, edge_index=edge_index, edge_attr=edge_attr)\n            for _ in range(k_hop - 1):\n                hop_data = self.neighbor_augment(hop_data)\n            hop_edge_index = hop_data.edge_index\n            hop_edge_attr = hop_data.edge_attr\n            new_edge_index, new_edge_attr = filter_adj(hop_edge_index, hop_edge_attr, perm, num_nodes=score.size(0))\n            new_edge_index, new_edge_attr = add_remaining_self_loops(new_edge_index, new_edge_attr, 0, x.size(0))\n            row, col = new_edge_index\n            weights = (torch.cat([x[row], x[col]], dim=1) * self.att).sum(dim=-1)\n            weights = F.leaky_relu(weights, self.negative_slop) + new_edge_attr * self.lamb\n            adj = torch.zeros((x.size(0), x.size(0)), dtype=torch.float, device=x.device)\n            adj[row, col] = weights\n            new_edge_index, weights = dense_to_sparse(adj)\n            row, col = new_edge_index\n            if self.sparse:\n                new_edge_attr = self.sparse_attention(weights, row)\n            else:\n                new_edge_attr = softmax(weights, row, x.size(0))\n            adj[row, col] = new_edge_attr\n            new_edge_index, new_edge_attr = dense_to_sparse(adj)\n            del adj\n            torch.cuda.empty_cache()\n        else:\n            if edge_attr is None:\n                induced_edge_attr = torch.ones((induced_edge_index.size(1),), dtype=x.dtype,\n                                               device=induced_edge_index.device)\n            num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)\n            shift_cum_num_nodes = torch.cat([num_nodes.new_zeros(1), num_nodes.cumsum(dim=0)[:-1]], dim=0)\n            cum_num_nodes = num_nodes.cumsum(dim=0)\n            adj = torch.zeros((x.size(0), x.size(0)), dtype=torch.float, device=x.device)\n            for idx_i, idx_j in zip(shift_cum_num_nodes, cum_num_nodes):\n                adj[idx_i:idx_j, idx_i:idx_j] = 1.0\n            new_edge_index, _ = dense_to_sparse(adj)\n            row, col = new_edge_index\n            weights = (torch.cat([x[row], x[col]], dim=1) * self.att).sum(dim=-1)\n            weights = F.leaky_relu(weights, self.negative_slop)\n            adj[row, col] = weights\n            induced_row, induced_col = induced_edge_index\n            adj[induced_row, induced_col] += induced_edge_attr * self.lamb\n            weights = adj[row, col]\n            if self.sparse:\n                new_edge_attr = self.sparse_attention(weights, row)\n            else:\n                new_edge_attr = softmax(weights, row, num_nodes=x.size(0))\n            adj[row, col] = new_edge_attr\n            new_edge_index, new_edge_attr = dense_to_sparse(adj)\n            del adj\n            torch.cuda.empty_cache()\n        return x, new_edge_index, new_edge_attr, batch, perm"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Seed 42, Fold 1 Val Acc: 0.762\n",
                        "Seed 42, Fold 2 Val Acc: 0.744\n",
                        "Seed 42, Fold 3 Val Acc: 0.755\n",
                        "Seed 42, Fold 4 Val Acc: 0.747\n",
                        "Seed 42, Fold 5 Val Acc: 0.780\n",
                        "Seed 42 Results: Mean Val Acc: 0.757, Time: 113.429 seconds, Memory: 0.397 MB, GPU Memory: 29787.947 MB\n",
                        "Seed 123, Fold 1 Val Acc: 0.780\n",
                        "Seed 123, Fold 2 Val Acc: 0.760\n",
                        "Seed 123, Fold 3 Val Acc: 0.738\n",
                        "Seed 123, Fold 4 Val Acc: 0.762\n",
                        "Seed 123, Fold 5 Val Acc: 0.739\n",
                        "Seed 123 Results: Mean Val Acc: 0.756, Time: 109.022 seconds, Memory: 0.360 MB, GPU Memory: 29787.947 MB\n",
                        "Seed 456, Fold 1 Val Acc: 0.747\n",
                        "Seed 456, Fold 2 Val Acc: 0.758\n",
                        "Seed 456, Fold 3 Val Acc: 0.768\n",
                        "Seed 456, Fold 4 Val Acc: 0.750\n",
                        "Seed 456, Fold 5 Val Acc: 0.747\n",
                        "Seed 456 Results: Mean Val Acc: 0.754, Time: 109.003 seconds, Memory: 0.359 MB, GPU Memory: 29787.947 MB\n",
                        "{'seed': 42, 'mean_val_acc': 0.7573899639181235, 'time': 113.42894172668457, 'memory': 0.397067, 'gpu_memory': 29787.947008}\n",
                        "{'seed': 123, 'mean_val_acc': 0.755904400079121, 'time': 109.02213883399963, 'memory': 0.360016, 'gpu_memory': 29787.947008}\n",
                        "{'seed': 456, 'mean_val_acc': 0.7540580174748144, 'time': 109.00256752967834, 'memory': 0.358974, 'gpu_memory': 29787.947008}\n",
                        "Total Mean Val Acc: 75.58$\\pm$0.14\n"
                    ]
                }
            ],
            "source": "import time\nimport tracemalloc\nimport torch\nfrom torch_geometric.datasets import Planetoid\nimport torch_geometric.transforms as T\nfrom torch_geometric.nn import GCNConv\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv, TopKPooling\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.datasets import TUDataset\nfrom torch_geometric.transforms import ToUndirected\nfrom torch.nn import Linear\nimport torch.optim as optim\nfrom torch_geometric.nn import global_mean_pool\nfrom torch_geometric.utils import to_dense_batch\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport random\nfrom typing import Callable, Optional, Union\ndataset = Planetoid(root=\"/data/ /Pooling\", name='Cora')\ngraph = dataset_sparse\nnum_classes = dataset.num_classes\nin_channels = dataset.num_features\nhidden_channels = 64\nout_channels = num_classes\ndepth = 2\npool_ratios = [0.7, 0.7]  \nclass HierarchicalGCN_HGPSL(torch.nn.Module):\n    def __init__(self, in_channels, hidden_channels, out_channels, depth, pool_ratios, act=F.relu, sum_res=False):\n        super(HierarchicalGCN_HGPSL, self).__init__()\n        assert depth >= 1\n        self.in_channels = in_channels\n        self.hidden_channels = hidden_channels\n        self.out_channels = out_channels\n        self.depth = depth\n        self.pool_ratios = pool_ratios\n        self.act = act\n        self.sum_res = sum_res\n        channels = self.hidden_channels\n        self.down_convs = torch.nn.ModuleList()\n        self.pools = torch.nn.ModuleList()\n        self.down_convs.append(GCNConv(self.in_channels, channels))\n        for i in range(self.depth):\n            self.pools.append(HGPSLPool(hidden_channels, ratio=pool_ratios[i], sample=False, sparse=False, sl=True, lamb=1.0, negative_slop=0.2))\n            self.down_convs.append(GCNConv(channels, channels))\n        in_channels = channels if sum_res else 2 * channels\n        self.up_convs = torch.nn.ModuleList()\n        for i in range(self.depth):\n            self.up_convs.append(GCNConv(in_channels, channels))\n        self.up_convs.append(GCNConv(channels, self.out_channels))\n    def forward(self, x, edge_index, batch=None):\n        x, edge_index = x.to(device), edge_index.to(device)\n        edge_attr = None\n        if batch is None:\n            batch = edge_index.new_zeros(x.size(0))\n        if batch is not None:\n            batch = batch.to(device)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.down_convs[0](x, edge_index)\n        x = self.act(x)\n        xs = [x]\n        edge_indices = [edge_index]\n        perms = []\n        for i in range(1, self.depth + 1):\n            x, edge_index, _, batch, perm = self.pools[i - 1](x, edge_index, edge_attr, batch)\n            x = self.down_convs[i](x, edge_index)\n            x = self.act(x)\n            if i < self.depth:\n                xs.append(x)\n                edge_indices.append(edge_index)\n            perms.append(perm)\n        for i in range(self.depth):\n            j = self.depth - 1 - i\n            res = xs[j]\n            edge_index = edge_indices[j]\n            perm = perms[j]\n            up = torch.zeros_like(res)\n            up[perm] = x\n            x = res + up if self.sum_res else torch.cat((res, up), dim=-1)\n            x = self.up_convs[i](x, edge_index)\n            x = self.act(x)\n        x = self.up_convs[-1](x, edge_index)\n        return x\ndef train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask, n_epochs=200, patience=150, min_delta=0.0001):\n    best_val_acc = 0\n    patience_counter = 0\n    model.to(device)\n    graph = graph.to(device)  \n    for epoch in range(1, n_epochs + 1):\n        model.train()\n        optimizer.zero_grad()\n        out = model(graph.x, graph.edge_index)\n        loss = criterion(out[train_mask], graph.y[train_mask])\n        loss.backward()\n        optimizer.step()\n        val_acc = eval_node_classifier(model, graph, val_mask)\n        if val_acc > best_val_acc + min_delta:\n            best_val_acc = val_acc\n            patience_counter = 0  \n        else:\n            patience_counter += 1  \n        if patience_counter >= patience:\n            break\n    return model, best_val_acc\ndef eval_node_classifier(model, graph, mask):\n    model.eval()\n    pred = model(graph.x, graph.edge_index).argmax(dim=1)\n    correct = (pred[mask] == graph.y[mask]).sum()\n    acc = int(correct) / int(mask.sum())\n    return acc\nkf = KFold(n_splits=5, shuffle=True)\nseeds = [42, 123, 456]\nresults = []\nval_accuracies_list = []\ntimes = []\nmemories = []\ngpu_memories = []\nfor seed in seeds:\n    graph = graph.to(device)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n    val_accuracies = []\n    start_time = time.time()\n    tracemalloc.start()\n    for fold, (train_index, test_index) in enumerate(kf.split(graph.x)):\n        model = HierarchicalGCN_HGPSL(in_channels, hidden_channels, out_channels, depth, pool_ratios).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n        criterion = nn.CrossEntropyLoss()\n        train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool)\n        train_mask[train_index] = True\n        test_mask[test_index] = True\n        val_mask = test_mask  \n        model, best_val_acc = train_node_classifier(model, graph, optimizer, criterion, train_mask, val_mask)\n        val_accuracies.append(best_val_acc)\n        print(f'Seed {seed}, Fold {fold + 1} Val Acc: {best_val_acc:.3f}')\n    mean_val_acc = np.mean(val_accuracies)\n    end_time = time.time()\n    current, peak = tracemalloc.get_traced_memory()\n    tracemalloc.stop()\n    memory_usage = peak / 10**6  \n    if torch.cuda.is_available():\n        gpu_memory_usage = torch.cuda.memory_reserved(device) / 10**6  \n    else:\n        gpu_memory_usage = 0\n    elapsed_time = end_time - start_time\n    results.append({\n        'seed': seed,\n        'mean_val_acc': mean_val_acc,\n        'time': elapsed_time,\n        'memory': memory_usage,\n        'gpu_memory': gpu_memory_usage\n    })\n    print(f'Seed {seed} Results: Mean Val Acc: {mean_val_acc:.3f}, Time: {elapsed_time:.3f} seconds, Memory: {memory_usage:.3f} MB, GPU Memory: {gpu_memory_usage:.3f} MB')\nfor result in results:\n    print(result)\nmean_val_acc_values = [result['mean_val_acc'] for result in results]\ntotal_mean_val_acc = np.mean(mean_val_acc_values) * 100\nstandard_deviation = np.std(mean_val_acc_values) * 100\nprint(f\"Total Mean Val Acc: {total_mean_val_acc:.2f}$\\\\pm${standard_deviation:.2f}\")"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}